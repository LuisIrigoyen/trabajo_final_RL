{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuisIrigoyen/trabajo_final_RL/blob/Carlos_Kong/Proyecto_pra%CC%81ctico_grupo_24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUehXgCyIRdq"
      },
      "source": [
        "# Actividad - Proyecto práctico\n",
        "\n",
        "\n",
        "> La actividad se desarrollará en grupos pre-definidos de 2-3 alumnos. Se debe indicar los nombres en orden alfabético (de apellidos). Recordad que esta actividad se corresponde con un 30% de la nota final de la asignatura. Se debe entregar entregar el trabajo en la presente notebook.\n",
        "*   Alumno 1:\n",
        "*   Alumno 2:\n",
        "*   Alumno 3:\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwpYlnjWJhS9"
      },
      "source": [
        "---\n",
        "## **PARTE 1** - Instalación y requisitos previos\n",
        "\n",
        "> Las prácticas han sido preparadas para poder realizarse en el entorno de trabajo de Google Colab. Sin embargo, esta plataforma presenta ciertas incompatibilidades a la hora de visualizar la renderización en gym. Por ello, para obtener estas visualizaciones, se deberá trasladar el entorno de trabajo a local. Por ello, el presente dosier presenta instrucciones para poder trabajar en ambos entornos. Siga los siguientes pasos para un correcto funcionamiento:\n",
        "1.   **LOCAL:** Preparar el enviroment, siguiendo las intrucciones detalladas en la sección *1.1.Preparar enviroment*.\n",
        "2.  **AMBOS:** Modificar las variables \"mount\" y \"drive_mount\" a la carpeta de trabajo en drive en el caso de estar en Colab, y ejecturar la celda *1.2.Localizar entorno de trabajo*.\n",
        "3. **COLAB:** se deberá ejecutar las celdas correspondientes al montaje de la carpeta de trabajo en Drive. Esta corresponde a la sección *1.3.Montar carpeta de datos local*.\n",
        "4.  **AMBOS:** Instalar las librerías necesarias, siguiendo la sección *1.4.Instalar librerías necesarias*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU2BPrK2JkP0"
      },
      "source": [
        "---\n",
        "### 1.1. Preparar enviroment (solo local)\n",
        "\n",
        "\n",
        "\n",
        "> Para preparar el entorno de trabajo en local, se han seguido los siguientes pasos:\n",
        "1. En Windows, puede ser necesario instalar las C++ Build Tools. Para ello, siga los siguientes pasos: https://towardsdatascience.com/how-to-install-openai-gym-in-a-windows-environment-338969e24d30.\n",
        "2. Instalar Anaconda\n",
        "3. Siguiendo el código que se presenta comentado en la próxima celda: Crear un enviroment, cambiar la ruta de trabajo, e instalar librerías básicas.\n",
        "\n",
        "\n",
        "```\n",
        "conda create --name miar_rl python=3.8\n",
        "conda activate miar_rl\n",
        "cd \"PATH_TO_FOLDER\"\n",
        "conda install git\n",
        "pip install jupyter\n",
        "```\n",
        "\n",
        "\n",
        "4. Abrir la notebook con *jupyter-notebook*.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "jupyter-notebook\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-kixNPiJqTc"
      },
      "source": [
        "---\n",
        "### 1.2. Localizar entorno de trabajo: Google colab o local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_YDFwZ-JscI"
      },
      "outputs": [],
      "source": [
        "# ATENCIÓN!! Modificar ruta relativa a la práctica si es distinta (drive_root)\n",
        "mount='/content/gdrive'\n",
        "drive_root = mount + \"/MyDrive/dqn_spaceinvaders_checkpoints\"\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  IN_COLAB=True\n",
        "except:\n",
        "  IN_COLAB=False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dp_a1iBJ0tf"
      },
      "source": [
        "---\n",
        "### 1.3. Montar carpeta de datos local (solo Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6n7MIefJ21i",
        "outputId": "09d49ced-2a7f-4b43-b3fb-f51b332f466e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We're running Colab\n",
            "Colab: mounting Google drive on  /content/gdrive\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "\n",
            "Colab: making sure  /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints  exists.\n",
            "\n",
            "Colab: Changing directory to  /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints\n",
            "/content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints\n",
            "Archivos en el directorio: \n",
            "['video', 'logs', 'checkpoint', 'dqn_SpaceInvaders-v0_weights.h5f.data-00000-of-00001', 'dqn_SpaceInvaders-v0_weights.h5f.index', '400k.zip', 'sequential_memory_2.pkl.zip', 'weightsv2.2', 'weightsv2.3', 'sequential_memory_2.3.pkl.zip', 'legacy', 'weightsv4', 'puntuacion 18.3 weigths 5', 'weights_5', 'sequential_memory_5.pkl', 'weights_6', 'wrapper', 'sequential_memory_6.pkl.zip', 'sequential_memory.pkl.zip', 'cut', 'sequential_memory_cut.pkl', 'cutv2', 'sequential_memory_cutv2.pkl']\n"
          ]
        }
      ],
      "source": [
        "# Switch to the directory on the Google Drive that you want to use\n",
        "import os\n",
        "if IN_COLAB:\n",
        "  print(\"We're running Colab\")\n",
        "\n",
        "  if IN_COLAB:\n",
        "    # Mount the Google Drive at mount\n",
        "    print(\"Colab: mounting Google drive on \", mount)\n",
        "\n",
        "    drive.mount(mount)\n",
        "\n",
        "    # Create drive_root if it doesn't exist\n",
        "    create_drive_root = True\n",
        "    if create_drive_root:\n",
        "      print(\"\\nColab: making sure \", drive_root, \" exists.\")\n",
        "      os.makedirs(drive_root, exist_ok=True)\n",
        "\n",
        "    # Change to the directory\n",
        "    print(\"\\nColab: Changing directory to \", drive_root)\n",
        "    %cd $drive_root\n",
        "# Verify we're in the correct working directory\n",
        "%pwd\n",
        "print(\"Archivos en el directorio: \")\n",
        "print(os.listdir())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1ZSL5bpJ560"
      },
      "source": [
        "---\n",
        "### 1.4. Instalar librerías necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UbVRjvHCJ8UF",
        "outputId": "a5cfce69-f39d-4f56-e357-ae42b1efaa62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gym==0.17.3\n",
            "  Downloading gym-0.17.3.tar.gz (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from gym==0.17.3) (1.15.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.11/dist-packages (from gym==0.17.3) (2.0.2)\n",
            "Collecting pyglet<=1.5.0,>=1.4.0 (from gym==0.17.3)\n",
            "  Downloading pyglet-1.5.0-py2.py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting cloudpickle<1.7.0,>=1.2.0 (from gym==0.17.3)\n",
            "  Downloading cloudpickle-1.6.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.17.3) (1.0.0)\n",
            "Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
            "Downloading pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.17.3-py3-none-any.whl size=1654617 sha256=a7fc139c037fde3cc6ede75d069b1374e0c7f50d5fa21f52a97c4a1c3942e3f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/8b/b7/570cb90b10f17e85ccb291ba1f04af41ec697745104a2263eb\n",
            "Successfully built gym\n",
            "Installing collected packages: pyglet, cloudpickle, gym\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 3.1.1\n",
            "    Uninstalling cloudpickle-3.1.1:\n",
            "      Successfully uninstalled cloudpickle-3.1.1\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 2.8.0 requires cloudpickle>=2.0.0, but you have cloudpickle 1.6.0 which is incompatible.\n",
            "distributed 2024.12.1 requires cloudpickle>=3.0.0, but you have cloudpickle 1.6.0 which is incompatible.\n",
            "dask 2024.12.1 requires cloudpickle>=3.0.0, but you have cloudpickle 1.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cloudpickle-1.6.0 gym-0.17.3 pyglet-1.5.0\n",
            "Collecting git+https://github.com/Kojoley/atari-py.git\n",
            "  Cloning https://github.com/Kojoley/atari-py.git to /tmp/pip-req-build-i_uuw2ov\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Kojoley/atari-py.git /tmp/pip-req-build-i_uuw2ov\n",
            "  Resolved https://github.com/Kojoley/atari-py.git to commit 86a1e05c0a95e9e6233c3a413521fdb34ca8a089\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from atari-py==1.2.2) (2.0.2)\n",
            "Building wheels for collected packages: atari-py\n",
            "  Building wheel for atari-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for atari-py: filename=atari_py-1.2.2-cp311-cp311-linux_x86_64.whl size=4738555 sha256=7b8dd34c518bd06b27aef50d644169b92cc91f1b8534427503fd233979f1ba55\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t4xr4t3p/wheels/1a/58/b3/3baab9d1509939ecce2dfd9ca349c222b7ee6590f4bd6097a1\n",
            "Successfully built atari-py\n",
            "Installing collected packages: atari-py\n",
            "Successfully installed atari-py-1.2.2\n",
            "Collecting keras-rl2==1.0.5\n",
            "  Downloading keras_rl2-1.0.5-py3-none-any.whl.metadata (304 bytes)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (from keras-rl2==1.0.5) (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (1.73.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow->keras-rl2==1.0.5) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->keras-rl2==1.0.5) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->keras-rl2==1.0.5) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->keras-rl2==1.0.5) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->keras-rl2==1.0.5) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->keras-rl2==1.0.5) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->keras-rl2==1.0.5) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->keras-rl2==1.0.5) (2025.6.15)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->keras-rl2==1.0.5) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->keras-rl2==1.0.5) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->keras-rl2==1.0.5) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow->keras-rl2==1.0.5) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->keras-rl2==1.0.5) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->keras-rl2==1.0.5) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->keras-rl2==1.0.5) (0.1.2)\n",
            "Downloading keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras-rl2\n",
            "Successfully installed keras-rl2-1.0.5\n",
            "Collecting tensorflow==2.12\n",
            "  Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (25.2.10)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.73.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (3.14.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (0.5.2)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (18.1.1)\n",
            "Collecting numpy<1.24,>=1.22 (from tensorflow==2.12)\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (24.2)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.12)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.17.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (4.14.0)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.12)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12) (0.45.1)\n",
            "Requirement already satisfied: jaxlib<=0.5.2,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.5.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.4.1)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.6.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib<=0.6.2,>=0.6.2 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.6.2-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting ml_dtypes>=0.5.0 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.6.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib<=0.6.1,>=0.6.1 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.6.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.6.0,>=0.6.0 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.6.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.5.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.3,>=0.5.3 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.5.3-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.5.1-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.0,>=0.5.0 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.5.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (978 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.38-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.38,>=0.4.38 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.38-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "INFO: pip is still looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.37-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.37,>=0.4.36 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.36-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.36-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.35,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.35-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.34,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.33-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.33,>=0.4.33 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.33-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.31-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.31,>=0.4.30 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.31-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.30-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.30,>=0.4.27 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12) (1.15.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.38.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.3.1)\n",
            "Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (586.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.0/586.0 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading jax-0.4.30-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl (79.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, protobuf, numpy, keras, gast, jaxlib, google-auth-oauthlib, tensorboard, jax, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.5.1\n",
            "    Uninstalling jaxlib-0.5.1:\n",
            "      Successfully uninstalled jaxlib-0.5.1\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.2\n",
            "    Uninstalling google-auth-oauthlib-1.2.2:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.5.2\n",
            "    Uninstalling jax-0.5.2:\n",
            "      Successfully uninstalled jax-0.5.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n",
            "bigframes 2.8.0 requires cloudpickle>=2.0.0, but you have cloudpickle 1.6.0 which is incompatible.\n",
            "bigframes 2.8.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.3.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "orbax-checkpoint 0.11.16 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "flax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "db-dtypes 1.4.3 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.5.0 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 jax-0.4.30 jaxlib-0.4.30 keras-2.12.0 numpy-1.23.5 protobuf-4.25.8 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              },
              "id": "74c24e1fbdd7452e86241b2bad4c7432"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "  %pip install gym==0.17.3\n",
        "  %pip install git+https://github.com/Kojoley/atari-py.git\n",
        "  %pip install keras-rl2==1.0.5\n",
        "  %pip install tensorflow==2.12  #2.8\n",
        "else:\n",
        "  %pip install gym==0.17.3\n",
        "  %pip install git+https://github.com/Kojoley/atari-py.git\n",
        "  %pip install pyglet==1.5.0\n",
        "  %pip install h5py==3.1.0\n",
        "  %pip install Pillow==9.5.0\n",
        "  %pip install keras-rl2==1.0.5\n",
        "  %pip install Keras==2.2.4\n",
        "  %pip install tensorflow==2.5.3\n",
        "  %pip install torch==2.0.1\n",
        "  %pip install agents==1.4.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hzP_5ZuGb2X"
      },
      "source": [
        "---\n",
        "## **PARTE 2**. Enunciado\n",
        "\n",
        "Consideraciones a tener en cuenta:\n",
        "\n",
        "- El entorno sobre el que trabajaremos será _SpaceInvaders-v0_ y el algoritmo que usaremos será _DQN_.\n",
        "\n",
        "- Para nuestro ejercicio, el requisito mínimo será alcanzado cuando el agente consiga una **media de recompensa por encima de 20 puntos en modo test**. Por ello, esta media de la recompensa se calculará a partir del código de test en la última celda del notebook.\n",
        "\n",
        "Este proyecto práctico consta de tres partes:\n",
        "\n",
        "1.   Implementar la red neuronal que se usará en la solución\n",
        "2.   Implementar las distintas piezas de la solución DQN\n",
        "3.   Justificar la respuesta en relación a los resultados obtenidos\n",
        "\n",
        "**Rúbrica**: Se valorará la originalidad en la solución aportada, así como la capacidad de discutir los resultados de forma detallada. El requisito mínimo servirá para aprobar la actividad, bajo premisa de que la discusión del resultado sera apropiada.\n",
        "\n",
        "IMPORTANTE:\n",
        "\n",
        "* Si no se consigue una puntuación óptima, responder sobre la mejor puntuación obtenida.\n",
        "* Para entrenamientos largos, recordad que podéis usar checkpoints de vuestros modelos para retomar los entrenamientos. En este caso, recordad cambiar los parámetros adecuadamente (sobre todo los relacionados con el proceso de exploración).\n",
        "* Se deberá entregar unicamente el notebook y los pesos del mejor modelo en un fichero .zip, de forma organizada.\n",
        "* Cada alumno deberá de subir la solución de forma individual."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_b3mzw8IzJP"
      },
      "source": [
        "---\n",
        "## **PARTE 3**. Desarrollo y preguntas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duPmUNOVGb2a"
      },
      "source": [
        "#### Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3eRhgI-Gb2a"
      },
      "outputs": [],
      "source": [
        "from __future__ import division\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import gym\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten, Convolution2D, Permute\n",
        "# from keras.optimizers import Adam  # from tensorflow.keras.optimizers import Adam\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.policy import LinearAnnealedPolicy, BoltzmannQPolicy, EpsGreedyQPolicy\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.core import Processor\n",
        "from rl.callbacks import FileLogger, ModelIntervalCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4jgQjzoGb2a"
      },
      "source": [
        "#### Configuración base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwOE6I_KGb2a"
      },
      "outputs": [],
      "source": [
        "INPUT_SHAPE = (84, 84)\n",
        "WINDOW_LENGTH = 4\n",
        "\n",
        "env_name = 'SpaceInvaders-v0'\n",
        "env = gym.make(env_name)\n",
        "\n",
        "np.random.seed(123)\n",
        "env.seed(123)\n",
        "nb_actions = env.action_space.n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AtariProcessor(Processor):\n",
        "    def process_observation(self, observation):\n",
        "        assert observation.ndim == 3  # (height, width, channel)\n",
        "        img = Image.fromarray(observation)\n",
        "        img = img.resize(INPUT_SHAPE).convert('L')\n",
        "        processed_observation = np.array(img)\n",
        "        assert processed_observation.shape == INPUT_SHAPE\n",
        "        return processed_observation.astype('uint8')\n",
        "\n",
        "    def process_state_batch(self, batch):\n",
        "        processed_batch = batch.astype('float32') / 255.\n",
        "        return processed_batch\n",
        "\n",
        "    def process_reward(self, reward):\n",
        "        return np.clip(reward, -1., 1.)"
      ],
      "metadata": {
        "id": "uRl-zPaXr4iQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayFHvtRSPH7F"
      },
      "outputs": [],
      "source": [
        "processor = AtariProcessor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yitXTADGb2b"
      },
      "source": [
        "## 1. Implementación de la red neuronal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QmA5qbKpKpW"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Permute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4GKrfWSGb2b",
        "outputId": "c34d35b7-2323-4105-df0d-2ed963e7aad6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " permute (Permute)           (None, 84, 84, 4)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 20, 20, 32)        8224      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 9, 9, 64)          32832     \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 7, 7, 64)          36928     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3136)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1606144   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 3078      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,687,206\n",
            "Trainable params: 1,687,206\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Red neuronal\n",
        "model = Sequential()\n",
        "model.add(Permute((2, 3, 1), input_shape=(WINDOW_LENGTH, 84, 84)))\n",
        "model.add(Conv2D(32, (8, 8), strides=(4, 4), activation='relu'))\n",
        "model.add(Conv2D(64, (4, 4), strides=(2, 2), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), strides=(1, 1), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(nb_actions, activation='linear'))\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definimos una red neuronal también para la arquitectura Dueling DQN:"
      ],
      "metadata": {
        "id": "J616bDZ8Wt-u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhwO3z2oPVq3"
      },
      "outputs": [],
      "source": [
        "def build_model(height, width, channels, actions):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Capa 1: Conv2D con BatchNorm y ReLU\n",
        "    model.add(Convolution2D(32, (8, 8), strides=(4, 4), padding='same', input_shape=(4,84,84,1)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    # Capa 2: Conv2D con BatchNorm y ReLU\n",
        "    model.add(Convolution2D(64, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    # Capa 3: Conv2D con BatchNorm y ReLU\n",
        "    model.add(Convolution2D(64, (3, 3), strides=(1, 1), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    # Aplanar + Capas Dense\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Capa Fully Connected con Dropout\n",
        "    model.add(Dense(512))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    # model.add(Dropout(0.3))  # Opcional para evitar overfitting\n",
        "\n",
        "    # Capa de salida\n",
        "    model.add(Dense(actions, activation='linear'))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "K93-fNbEXJku"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eBwiHKuZ6J_",
        "outputId": "02d7fc3e-eb0b-4ffb-b592-fb2994514c1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\curso\\anaconda3\\envs\\miar_rl\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\normalization.py:534: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 4, 21, 21, 32)     2080      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 4, 21, 21, 32)     128       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 4, 21, 21, 32)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 4, 11, 11, 64)     32832     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 4, 11, 11, 64)     256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 4, 11, 11, 64)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 4, 11, 11, 64)     36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 4, 11, 11, 64)     256       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 4, 11, 11, 64)     0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30976)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               15860224  \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 3078      \n",
            "=================================================================\n",
            "Total params: 15,937,830\n",
            "Trainable params: 15,936,486\n",
            "Non-trainable params: 1,344\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = build_model(84, 84, 1, nb_actions)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para realizar la implementación se creó una red neuronal convolucional para tareas de visión por computadora. La arquitectura se eligió considerando buenas prácticas validadas en literatura como el paper original de DeepMind (Mnih et al., 2015), adaptándola con batch normalization y capacidad para extenderse hacia variantes como Double DQN o Dueling DQN.\n",
        "\n",
        "Así mismo, a continuación justificamos la estructura:\n",
        "- Entrada de 4 frames apilados: Lo que permite capturar la dinámica temporal del entorno.\n",
        "- 3 Capas convolucionales profundas: Que nos permite extraer patrones visuales progresivamente desde bordes simples hasta características más complejas.\n",
        "- Batch Normalization: Que sirve para mejorar la estabilidad y acelera la convergencia, siendo especialmente útil cuando se entrenan en sesiones de tiempo limitado (como en el caso de este modelo, que fue ejecutado empleando Colab).\n",
        "- Capa densa de 512 neuronas: Que actuó como codificador del estado de la toma de decisiones.\n",
        "- Capa de salida lineal: Que produjo los valores Q para cada acción posible, sin necesidad de usar el softmax.\n",
        "\n",
        "**Antecedentes técnicos y de uso**:\n",
        "Debido a que en mi caso no contaba con recursos de cómputo locales con GPU integrado, opté por desarrollar y entrenar el modelo usando Google Colab, aprovechando:\n",
        "1.   Acceso gratuito a GPU.\n",
        "1.   Facilidad de colaboración en línea con el equipo de trabajo.\n",
        "1.   Soporte integrado para librerias requeridas.\n",
        "1.   Cabe resaltar, que por la disponibilidad de Colab, se almacenaron los pesos paulatinamente en una ruta de Drive para no perder el entrenamiento."
      ],
      "metadata": {
        "id": "8bpkfX1JZd-n"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB9-_5HPGb2b"
      },
      "source": [
        "## 2. Implementación de la solución DQN"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w8JZdL6tXGp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Código Eduardo (Después cambiamos el nombre de esta sección)"
      ],
      "metadata": {
        "id": "kHZLDmwlq3ud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero hacemos una modificación del preprocesador, ya que en las observaciones (imágenes del juego) se incluye una barra superior que muestra el puntaje actual. Sin embargo, esta región de la imagen no forma parte del estado del juego que el agente necesita para tomar decisiones óptimas, ya que el puntaje refleja el rendimiento pasado, no información sobre la situación actual en el entorno (como la posición de enemigos o del jugador). Además, incluir el puntaje en las observaciones puede inducir sesgos. Originalmente las observaciones se ven de la siguiente manera:"
      ],
      "metadata": {
        "id": "BuZ3-c0LlDZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processor = AtariProcessor()"
      ],
      "metadata": {
        "id": "Ao4K3o1vrXB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "amf0W7J0O1Ea",
        "outputId": "98e94451-7067-400e-f6e5-09becf7ec205"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "frame = env.reset()\n",
        "processed_frame = processor.process_observation(frame)\n",
        "\n",
        "plt.imshow(processed_frame, cmap='gray')\n",
        "plt.title(\"Processed Frame\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por lo que procedemos a quitar esta región de la imagen agregando al preprocesador la línea: `cropped_observation = observation[34:194, :, :]`"
      ],
      "metadata": {
        "id": "gynlkWTxoFcV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PofZgFA1OoJS"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "class AtariProcessor(Processor):\n",
        "    def process_observation(self, observation):\n",
        "        assert observation.ndim == 3  # (height, width, channel)\n",
        "\n",
        "        # 1. Recortar imagen (eliminar HUD, solo zona de juego)\n",
        "        # Gym Atari frames suelen ser 210x160x3, recortamos y=34:194\n",
        "        cropped_observation = observation[34:194, :, :]\n",
        "\n",
        "        # 2. Convertir a PIL, escala de grises, redimensionar\n",
        "        img = Image.fromarray(cropped_observation)\n",
        "        img = img.resize(INPUT_SHAPE).convert('L')  # INPUT_SHAPE usualmente (84, 84)\n",
        "\n",
        "        processed_observation = np.array(img)\n",
        "        assert processed_observation.shape == INPUT_SHAPE\n",
        "        return processed_observation.astype('uint8')\n",
        "\n",
        "    def process_state_batch(self, batch):\n",
        "        processed_batch = batch.astype('float32') / 255.\n",
        "        return processed_batch\n",
        "\n",
        "    def process_reward(self, reward):\n",
        "        return np.clip(reward, -1., 1.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "zOvkptkyP1t6",
        "outputId": "aa52da7d-2a4a-4010-ed02-68663d952096"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "frame = env.reset()\n",
        "processed_frame = processor.process_observation(frame)\n",
        "\n",
        "plt.imshow(processed_frame, cmap='gray')\n",
        "plt.title(\"Processed Frame\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMxBpewG7GsH"
      },
      "source": [
        "Usamos un wrapper que termina el episodio al perder una vida, así reducimos la duración media de cada episodio, lo cual permite realizar más iteraciones de entrenamiento en menos tiempo real, donde el agente puede sobrevivir por largo tiempo en las vidas siguientes, incluso sin mejorar significativamente su política."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXGZHQ4_8nVe"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "\n",
        "class LifeTerminatingWrapper(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        self.lives = 0\n",
        "        self.was_real_done = True\n",
        "        self.steps_since_enemy_kill = 0  # Nuevo contador\n",
        "        self.consecutive_shots = 0\n",
        "\n",
        "    def step(self, action):\n",
        "        obs, reward, done, info = self.env.step(action)\n",
        "\n",
        "        # --- Terminar episodio si pierde una vida ---\n",
        "        lives = info.get('ale.lives', 0)\n",
        "        if self.lives > lives > 0:\n",
        "            done = True\n",
        "        self.lives = lives\n",
        "\n",
        "        return obs, reward, done, info\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        if self.was_real_done:\n",
        "            obs = self.env.reset(**kwargs)\n",
        "        else:\n",
        "            obs, _, _, _ = self.env.step(0)\n",
        "        self.lives = self.env.unwrapped.ale.lives()\n",
        "        self.last_direction = None\n",
        "        self.direction_streak = 0\n",
        "        return obs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtOZyg8Wo2KR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from gym.wrappers import Monitor\n",
        "\n",
        "checkpoint_dir = drive_root\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYEJLlV0sQeK"
      },
      "outputs": [],
      "source": [
        "from rl.callbacks import Callback\n",
        "\n",
        "class SaveCheckpointCallback(Callback):\n",
        "    def __init__(self, interval, path_template, reward_log_path):\n",
        "        self.interval = interval\n",
        "        self.path_template = path_template\n",
        "        self.reward_log_path = reward_log_path\n",
        "        self.episode_rewards = []\n",
        "\n",
        "        # Crear carpeta para rewards si es necesario\n",
        "        if self.reward_log_path:\n",
        "            reward_dir = os.path.dirname(self.reward_log_path)\n",
        "            if reward_dir and not os.path.exists(reward_dir):\n",
        "                os.makedirs(reward_dir)\n",
        "                print(f\"📂 Carpeta creada: {reward_dir}\")\n",
        "\n",
        "    def on_step_end(self, step, logs={}):\n",
        "        if step % self.interval == 0:\n",
        "            filename = self.path_template.format(step=step)\n",
        "            print(f\"\\n💾 Guardando pesos en: {filename}\")\n",
        "            self.model.save_weights(filename, overwrite=True)\n",
        "\n",
        "\n",
        "    def on_episode_end(self, episode, logs={}):\n",
        "        reward = logs.get('episode_reward', 0)\n",
        "        self.episode_rewards.append(reward)\n",
        "        if self.reward_log_path:\n",
        "            np.save(self.reward_log_path, np.array(self.episode_rewards))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-QmXS59pdPS"
      },
      "outputs": [],
      "source": [
        "memory = SequentialMemory(limit=330000, window_length=WINDOW_LENGTH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlCT0pUP6OXa"
      },
      "outputs": [],
      "source": [
        "env = gym.make(env_name)\n",
        "env = LifeTerminatingWrapper(env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnGIkWsfUSHx"
      },
      "source": [
        "#### Entrenamiento parte 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRFy2z18UbZ2"
      },
      "outputs": [],
      "source": [
        "# Exploracion 1 a 0.1, # steps -> 400k\n",
        "nb_steps = 400000\n",
        "nb_steps_annealing = 300000\n",
        "nb_steps_warmup=40000\n",
        "\n",
        "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(),\n",
        "                              attr='eps',\n",
        "                              value_max=1, #0.22 # 0.24 # 0.35\n",
        "                              value_min=0.1, # 0.08\n",
        "                              value_test=0.0,\n",
        "                              nb_steps=nb_steps_annealing)\n",
        "\n",
        "\n",
        "dqn = DQNAgent(model=model,\n",
        "               nb_actions=nb_actions,\n",
        "               policy=policy,\n",
        "               memory=memory,\n",
        "               processor=processor,\n",
        "               nb_steps_warmup=nb_steps_warmup, #30000\n",
        "               enable_double_dqn=True,\n",
        "               gamma=0.99, # 0.99\n",
        "               target_model_update=8500,\n",
        "               train_interval=4,\n",
        "               delta_clip=1.0) # si el loss no baja, probar bajarlo a 0.5\n",
        "\n",
        "dqn.compile(Adam(learning_rate=0.0001), metrics=['mae']) # antes 0.00025"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EE3lRQ1YdeTu",
        "outputId": "f45691bd-1d7b-4168-adfd-9c4f4d741f4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for 400000 steps ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "    501/400000: episode: 1, duration: 3.645s, episode steps: 501, steps per second: 137, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "    717/400000: episode: 2, duration: 1.424s, episode steps: 216, steps per second: 152, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "    939/400000: episode: 3, duration: 1.454s, episode steps: 222, steps per second: 153, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.320 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   1128/400000: episode: 4, duration: 1.264s, episode steps: 189, steps per second: 149, episode reward:  2.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   1338/400000: episode: 5, duration: 1.767s, episode steps: 210, steps per second: 119, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   1628/400000: episode: 6, duration: 2.778s, episode steps: 290, steps per second: 104, episode reward:  6.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   1999/400000: episode: 7, duration: 2.312s, episode steps: 371, steps per second: 160, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   2245/400000: episode: 8, duration: 1.604s, episode steps: 246, steps per second: 153, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.358 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   2451/400000: episode: 9, duration: 1.332s, episode steps: 206, steps per second: 155, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   2965/400000: episode: 10, duration: 3.217s, episode steps: 514, steps per second: 160, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   3177/400000: episode: 11, duration: 1.411s, episode steps: 212, steps per second: 150, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.387 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   3392/400000: episode: 12, duration: 2.117s, episode steps: 215, steps per second: 102, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   3517/400000: episode: 13, duration: 1.282s, episode steps: 125, steps per second:  97, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.576 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   3724/400000: episode: 14, duration: 1.450s, episode steps: 207, steps per second: 143, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   3930/400000: episode: 15, duration: 1.362s, episode steps: 206, steps per second: 151, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   4147/400000: episode: 16, duration: 1.411s, episode steps: 217, steps per second: 154, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   4354/400000: episode: 17, duration: 1.330s, episode steps: 207, steps per second: 156, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   4822/400000: episode: 18, duration: 2.933s, episode steps: 468, steps per second: 160, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.618 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   5061/400000: episode: 19, duration: 1.509s, episode steps: 239, steps per second: 158, episode reward:  4.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   5340/400000: episode: 20, duration: 2.684s, episode steps: 279, steps per second: 104, episode reward:  4.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   5547/400000: episode: 21, duration: 1.727s, episode steps: 207, steps per second: 120, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   5924/400000: episode: 22, duration: 2.417s, episode steps: 377, steps per second: 156, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   6208/400000: episode: 23, duration: 1.845s, episode steps: 284, steps per second: 154, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   6461/400000: episode: 24, duration: 1.690s, episode steps: 253, steps per second: 150, episode reward:  2.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   6662/400000: episode: 25, duration: 1.328s, episode steps: 201, steps per second: 151, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.622 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   6865/400000: episode: 26, duration: 1.348s, episode steps: 203, steps per second: 151, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.389 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   6983/400000: episode: 27, duration: 0.911s, episode steps: 118, steps per second: 130, episode reward:  2.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.720 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   7260/400000: episode: 28, duration: 2.683s, episode steps: 277, steps per second: 103, episode reward:  5.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   7471/400000: episode: 29, duration: 1.640s, episode steps: 211, steps per second: 129, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   7731/400000: episode: 30, duration: 1.641s, episode steps: 260, steps per second: 158, episode reward:  3.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.700 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   7977/400000: episode: 31, duration: 1.650s, episode steps: 246, steps per second: 149, episode reward:  2.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   8248/400000: episode: 32, duration: 1.753s, episode steps: 271, steps per second: 155, episode reward:  2.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.631 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   8554/400000: episode: 33, duration: 1.972s, episode steps: 306, steps per second: 155, episode reward:  4.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   8831/400000: episode: 34, duration: 1.784s, episode steps: 277, steps per second: 155, episode reward:  2.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   9055/400000: episode: 35, duration: 2.018s, episode steps: 224, steps per second: 111, episode reward:  1.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   9255/400000: episode: 36, duration: 1.997s, episode steps: 200, steps per second: 100, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   9480/400000: episode: 37, duration: 1.448s, episode steps: 225, steps per second: 155, episode reward:  3.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   9714/400000: episode: 38, duration: 1.555s, episode steps: 234, steps per second: 151, episode reward:  3.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   9925/400000: episode: 39, duration: 1.388s, episode steps: 211, steps per second: 152, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  10481/400000: episode: 40, duration: 3.586s, episode steps: 556, steps per second: 155, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  10716/400000: episode: 41, duration: 1.522s, episode steps: 235, steps per second: 154, episode reward:  3.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.749 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  10983/400000: episode: 42, duration: 2.442s, episode steps: 267, steps per second: 109, episode reward:  3.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  11170/400000: episode: 43, duration: 1.830s, episode steps: 187, steps per second: 102, episode reward:  2.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  11426/400000: episode: 44, duration: 1.658s, episode steps: 256, steps per second: 154, episode reward:  4.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.629 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  11714/400000: episode: 45, duration: 1.797s, episode steps: 288, steps per second: 160, episode reward:  3.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  11922/400000: episode: 46, duration: 1.325s, episode steps: 208, steps per second: 157, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  12158/400000: episode: 47, duration: 1.512s, episode steps: 236, steps per second: 156, episode reward:  4.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  12349/400000: episode: 48, duration: 1.272s, episode steps: 191, steps per second: 150, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.670 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  12724/400000: episode: 49, duration: 2.331s, episode steps: 375, steps per second: 161, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.699 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  13007/400000: episode: 50, duration: 2.763s, episode steps: 283, steps per second: 102, episode reward:  3.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  13669/400000: episode: 51, duration: 4.406s, episode steps: 662, steps per second: 150, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.625 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  13870/400000: episode: 52, duration: 1.359s, episode steps: 201, steps per second: 148, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.905 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  14099/400000: episode: 53, duration: 1.519s, episode steps: 229, steps per second: 151, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  14566/400000: episode: 54, duration: 2.989s, episode steps: 467, steps per second: 156, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.690 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  14827/400000: episode: 55, duration: 2.226s, episode steps: 261, steps per second: 117, episode reward:  3.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.732 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  15085/400000: episode: 56, duration: 2.361s, episode steps: 258, steps per second: 109, episode reward:  3.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  15357/400000: episode: 57, duration: 1.789s, episode steps: 272, steps per second: 152, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.651 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  15558/400000: episode: 58, duration: 1.315s, episode steps: 201, steps per second: 153, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.682 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  15913/400000: episode: 59, duration: 2.263s, episode steps: 355, steps per second: 157, episode reward:  8.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  16115/400000: episode: 60, duration: 1.331s, episode steps: 202, steps per second: 152, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.579 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  16431/400000: episode: 61, duration: 2.065s, episode steps: 316, steps per second: 153, episode reward:  6.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  16696/400000: episode: 62, duration: 2.187s, episode steps: 265, steps per second: 121, episode reward:  5.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  17094/400000: episode: 63, duration: 3.393s, episode steps: 398, steps per second: 117, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.741 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  17347/400000: episode: 64, duration: 1.673s, episode steps: 253, steps per second: 151, episode reward:  7.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.751 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  17852/400000: episode: 65, duration: 3.290s, episode steps: 505, steps per second: 153, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.731 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  18516/400000: episode: 66, duration: 4.314s, episode steps: 664, steps per second: 154, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  18845/400000: episode: 67, duration: 3.186s, episode steps: 329, steps per second: 103, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  19091/400000: episode: 68, duration: 1.668s, episode steps: 246, steps per second: 147, episode reward:  5.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.663 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  19654/400000: episode: 69, duration: 3.551s, episode steps: 563, steps per second: 159, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  19930/400000: episode: 70, duration: 1.812s, episode steps: 276, steps per second: 152, episode reward:  5.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  20119/400000: episode: 71, duration: 1.291s, episode steps: 189, steps per second: 146, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.783 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  20350/400000: episode: 72, duration: 1.515s, episode steps: 231, steps per second: 153, episode reward:  3.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.680 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  20626/400000: episode: 73, duration: 2.652s, episode steps: 276, steps per second: 104, episode reward:  5.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.685 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  20819/400000: episode: 74, duration: 1.719s, episode steps: 193, steps per second: 112, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.653 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  21080/400000: episode: 75, duration: 1.714s, episode steps: 261, steps per second: 152, episode reward:  4.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.667 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  21275/400000: episode: 76, duration: 1.310s, episode steps: 195, steps per second: 149, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.574 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  21533/400000: episode: 77, duration: 1.681s, episode steps: 258, steps per second: 153, episode reward:  7.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  22242/400000: episode: 78, duration: 4.398s, episode steps: 709, steps per second: 161, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.650 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  22511/400000: episode: 79, duration: 2.404s, episode steps: 269, steps per second: 112, episode reward:  5.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.628 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  22774/400000: episode: 80, duration: 2.322s, episode steps: 263, steps per second: 113, episode reward:  5.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.814 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  23582/400000: episode: 81, duration: 4.914s, episode steps: 808, steps per second: 164, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.657 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  23803/400000: episode: 82, duration: 1.431s, episode steps: 221, steps per second: 154, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  24057/400000: episode: 83, duration: 1.647s, episode steps: 254, steps per second: 154, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.669 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  24264/400000: episode: 84, duration: 1.356s, episode steps: 207, steps per second: 153, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.739 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  24541/400000: episode: 85, duration: 2.741s, episode steps: 277, steps per second: 101, episode reward:  2.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.939 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  24752/400000: episode: 86, duration: 1.748s, episode steps: 211, steps per second: 121, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  24970/400000: episode: 87, duration: 1.422s, episode steps: 218, steps per second: 153, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.821 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  25261/400000: episode: 88, duration: 1.888s, episode steps: 291, steps per second: 154, episode reward:  5.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  25583/400000: episode: 89, duration: 2.088s, episode steps: 322, steps per second: 154, episode reward:  5.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  25829/400000: episode: 90, duration: 1.591s, episode steps: 246, steps per second: 155, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  26067/400000: episode: 91, duration: 1.593s, episode steps: 238, steps per second: 149, episode reward:  4.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  26309/400000: episode: 92, duration: 2.200s, episode steps: 242, steps per second: 110, episode reward:  5.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.719 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  26511/400000: episode: 93, duration: 2.074s, episode steps: 202, steps per second:  97, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.832 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  26717/400000: episode: 94, duration: 1.407s, episode steps: 206, steps per second: 146, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.767 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  26947/400000: episode: 95, duration: 1.591s, episode steps: 230, steps per second: 145, episode reward:  1.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.652 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  27362/400000: episode: 96, duration: 2.587s, episode steps: 415, steps per second: 160, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.718 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  27583/400000: episode: 97, duration: 1.411s, episode steps: 221, steps per second: 157, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  27860/400000: episode: 98, duration: 1.778s, episode steps: 277, steps per second: 156, episode reward:  5.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.791 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  28085/400000: episode: 99, duration: 1.578s, episode steps: 225, steps per second: 143, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  28304/400000: episode: 100, duration: 2.166s, episode steps: 219, steps per second: 101, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.763 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  28589/400000: episode: 101, duration: 2.236s, episode steps: 285, steps per second: 127, episode reward:  6.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.765 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  28806/400000: episode: 102, duration: 1.413s, episode steps: 217, steps per second: 154, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.783 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  29054/400000: episode: 103, duration: 1.608s, episode steps: 248, steps per second: 154, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.754 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  29280/400000: episode: 104, duration: 1.529s, episode steps: 226, steps per second: 148, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.823 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  29606/400000: episode: 105, duration: 2.098s, episode steps: 326, steps per second: 155, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.702 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  29892/400000: episode: 106, duration: 1.850s, episode steps: 286, steps per second: 155, episode reward:  3.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.822 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  30227/400000: episode: 107, duration: 3.025s, episode steps: 335, steps per second: 111, episode reward:  7.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  30461/400000: episode: 108, duration: 1.869s, episode steps: 234, steps per second: 125, episode reward:  4.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.987 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  30718/400000: episode: 109, duration: 1.653s, episode steps: 257, steps per second: 156, episode reward:  6.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.673 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  31148/400000: episode: 110, duration: 2.700s, episode steps: 430, steps per second: 159, episode reward: 10.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.688 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  31386/400000: episode: 111, duration: 1.573s, episode steps: 238, steps per second: 151, episode reward:  3.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  31770/400000: episode: 112, duration: 2.403s, episode steps: 384, steps per second: 160, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  32513/400000: episode: 113, duration: 5.962s, episode steps: 743, steps per second: 125, episode reward: 15.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.697 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  32733/400000: episode: 114, duration: 1.465s, episode steps: 220, steps per second: 150, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.641 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  32942/400000: episode: 115, duration: 1.389s, episode steps: 209, steps per second: 150, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.823 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  33185/400000: episode: 116, duration: 1.601s, episode steps: 243, steps per second: 152, episode reward:  4.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.687 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  33477/400000: episode: 117, duration: 1.852s, episode steps: 292, steps per second: 158, episode reward:  2.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.771 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  33667/400000: episode: 118, duration: 1.240s, episode steps: 190, steps per second: 153, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.663 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  33948/400000: episode: 119, duration: 2.227s, episode steps: 281, steps per second: 126, episode reward:  4.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.772 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  34161/400000: episode: 120, duration: 2.141s, episode steps: 213, steps per second:  99, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.671 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  34395/400000: episode: 121, duration: 1.636s, episode steps: 234, steps per second: 143, episode reward:  3.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  34659/400000: episode: 122, duration: 1.696s, episode steps: 264, steps per second: 156, episode reward:  5.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.652 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  34910/400000: episode: 123, duration: 1.582s, episode steps: 251, steps per second: 159, episode reward:  5.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.749 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  35150/400000: episode: 124, duration: 1.544s, episode steps: 240, steps per second: 155, episode reward:  5.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.812 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  35344/400000: episode: 125, duration: 1.303s, episode steps: 194, steps per second: 149, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.763 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  35749/400000: episode: 126, duration: 2.532s, episode steps: 405, steps per second: 160, episode reward:  9.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.647 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  35974/400000: episode: 127, duration: 2.227s, episode steps: 225, steps per second: 101, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.738 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  36687/400000: episode: 128, duration: 4.984s, episode steps: 713, steps per second: 143, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.773 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  37286/400000: episode: 129, duration: 3.803s, episode steps: 599, steps per second: 158, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.765 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  37553/400000: episode: 130, duration: 1.759s, episode steps: 267, steps per second: 152, episode reward:  2.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.730 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  37780/400000: episode: 131, duration: 1.805s, episode steps: 227, steps per second: 126, episode reward:  3.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.617 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  38076/400000: episode: 132, duration: 2.833s, episode steps: 296, steps per second: 104, episode reward:  5.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.963 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  38292/400000: episode: 133, duration: 1.412s, episode steps: 216, steps per second: 153, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.894 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  38655/400000: episode: 134, duration: 2.307s, episode steps: 363, steps per second: 157, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.860 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  38896/400000: episode: 135, duration: 1.596s, episode steps: 241, steps per second: 151, episode reward:  4.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 3.021 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  39188/400000: episode: 136, duration: 1.861s, episode steps: 292, steps per second: 157, episode reward:  6.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.774 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  39858/400000: episode: 137, duration: 4.922s, episode steps: 670, steps per second: 136, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.852 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  40185/400000: episode: 138, duration: 14.709s, episode steps: 327, steps per second:  22, episode reward:  6.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.746 [0.000, 5.000],  loss: 0.005168, mae: 0.034906, mean_q: 0.060796, mean_eps: 0.879718\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  40344/400000: episode: 139, duration: 9.459s, episode steps: 159, steps per second:  17, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.447 [0.000, 5.000],  loss: 0.008573, mae: 0.018618, mean_q: 0.015574, mean_eps: 0.879208\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  40589/400000: episode: 140, duration: 16.391s, episode steps: 245, steps per second:  15, episode reward:  9.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 2.792 [0.000, 5.000],  loss: 0.009388, mae: 0.037327, mean_q: 0.052743, mean_eps: 0.878602\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  40821/400000: episode: 141, duration: 15.609s, episode steps: 232, steps per second:  15, episode reward:  5.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.655 [0.000, 5.000],  loss: 0.007931, mae: 0.014728, mean_q: 0.022529, mean_eps: 0.877882\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  41233/400000: episode: 142, duration: 25.883s, episode steps: 412, steps per second:  16, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.007494, mae: 0.029310, mean_q: 0.039038, mean_eps: 0.876916\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  41452/400000: episode: 143, duration: 14.290s, episode steps: 219, steps per second:  15, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.006558, mae: 0.023306, mean_q: 0.029221, mean_eps: 0.875974\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  41675/400000: episode: 144, duration: 14.821s, episode steps: 223, steps per second:  15, episode reward:  6.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.006511, mae: 0.017208, mean_q: 0.005971, mean_eps: 0.875314\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  41866/400000: episode: 145, duration: 11.478s, episode steps: 191, steps per second:  17, episode reward:  3.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.009110, mae: 0.030251, mean_q: 0.044281, mean_eps: 0.874690\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  42304/400000: episode: 146, duration: 28.314s, episode steps: 438, steps per second:  15, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.358 [0.000, 5.000],  loss: 0.008477, mae: 0.026115, mean_q: 0.037863, mean_eps: 0.873748\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  42544/400000: episode: 147, duration: 16.687s, episode steps: 240, steps per second:  14, episode reward:  4.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: 0.008627, mae: 0.033542, mean_q: 0.042300, mean_eps: 0.872734\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  42721/400000: episode: 148, duration: 10.268s, episode steps: 177, steps per second:  17, episode reward:  3.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.305 [0.000, 5.000],  loss: 0.006260, mae: 0.029327, mean_q: 0.038579, mean_eps: 0.872104\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  42939/400000: episode: 149, duration: 13.961s, episode steps: 218, steps per second:  16, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: 0.007390, mae: 0.033428, mean_q: 0.042761, mean_eps: 0.871510\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  43068/400000: episode: 150, duration: 9.172s, episode steps: 129, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.721 [0.000, 5.000],  loss: 0.009086, mae: 0.042575, mean_q: 0.054895, mean_eps: 0.870994\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  43305/400000: episode: 151, duration: 15.259s, episode steps: 237, steps per second:  16, episode reward:  5.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.641 [0.000, 5.000],  loss: 0.008954, mae: 0.037102, mean_q: 0.047628, mean_eps: 0.870442\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  43538/400000: episode: 152, duration: 14.917s, episode steps: 233, steps per second:  16, episode reward:  5.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.005878, mae: 0.033172, mean_q: 0.046488, mean_eps: 0.869734\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  43662/400000: episode: 153, duration: 8.662s, episode steps: 124, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.226 [0.000, 5.000],  loss: 0.007466, mae: 0.036775, mean_q: 0.047839, mean_eps: 0.869200\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  43875/400000: episode: 154, duration: 13.757s, episode steps: 213, steps per second:  15, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.009529, mae: 0.037874, mean_q: 0.050485, mean_eps: 0.868696\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  44086/400000: episode: 155, duration: 13.638s, episode steps: 211, steps per second:  15, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.007239, mae: 0.034102, mean_q: 0.043012, mean_eps: 0.868060\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  44286/400000: episode: 156, duration: 13.057s, episode steps: 200, steps per second:  15, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.007357, mae: 0.035715, mean_q: 0.047318, mean_eps: 0.867442\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  44500/400000: episode: 157, duration: 13.875s, episode steps: 214, steps per second:  15, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.304 [0.000, 5.000],  loss: 0.010327, mae: 0.043094, mean_q: 0.051762, mean_eps: 0.866824\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  44743/400000: episode: 158, duration: 15.344s, episode steps: 243, steps per second:  16, episode reward:  6.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.708 [0.000, 5.000],  loss: 0.006021, mae: 0.030344, mean_q: 0.040504, mean_eps: 0.866140\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  45052/400000: episode: 159, duration: 19.119s, episode steps: 309, steps per second:  16, episode reward:  7.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.686 [0.000, 5.000],  loss: 0.006977, mae: 0.029039, mean_q: 0.039845, mean_eps: 0.865312\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  45302/400000: episode: 160, duration: 15.882s, episode steps: 250, steps per second:  16, episode reward:  4.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.292 [0.000, 5.000],  loss: 0.009596, mae: 0.038370, mean_q: 0.050987, mean_eps: 0.864472\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  45745/400000: episode: 161, duration: 28.033s, episode steps: 443, steps per second:  16, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.007627, mae: 0.035245, mean_q: 0.047360, mean_eps: 0.863428\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  46014/400000: episode: 162, duration: 18.442s, episode steps: 269, steps per second:  15, episode reward:  5.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.006249, mae: 0.030423, mean_q: 0.039082, mean_eps: 0.862360\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  46281/400000: episode: 163, duration: 16.856s, episode steps: 267, steps per second:  16, episode reward:  5.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.009038, mae: 0.036229, mean_q: 0.043729, mean_eps: 0.861556\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  46661/400000: episode: 164, duration: 24.820s, episode steps: 380, steps per second:  15, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.716 [0.000, 5.000],  loss: 0.006482, mae: 0.030663, mean_q: 0.038393, mean_eps: 0.860584\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  46817/400000: episode: 165, duration: 8.909s, episode steps: 156, steps per second:  18, episode reward:  1.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: 0.007449, mae: 0.034806, mean_q: 0.043410, mean_eps: 0.859780\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  46945/400000: episode: 166, duration: 9.132s, episode steps: 128, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.500 [0.000, 5.000],  loss: 0.007598, mae: 0.034331, mean_q: 0.042835, mean_eps: 0.859354\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  47239/400000: episode: 167, duration: 18.076s, episode steps: 294, steps per second:  16, episode reward:  5.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.006091, mae: 0.032724, mean_q: 0.046099, mean_eps: 0.858724\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  47476/400000: episode: 168, duration: 15.711s, episode steps: 237, steps per second:  15, episode reward:  2.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.249 [0.000, 5.000],  loss: 0.006461, mae: 0.031929, mean_q: 0.047163, mean_eps: 0.857932\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  47600/400000: episode: 169, duration: 8.518s, episode steps: 124, steps per second:  15, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.524 [0.000, 5.000],  loss: 0.010097, mae: 0.036261, mean_q: 0.048497, mean_eps: 0.857392\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  47803/400000: episode: 170, duration: 13.163s, episode steps: 203, steps per second:  15, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.007527, mae: 0.034338, mean_q: 0.043723, mean_eps: 0.856900\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  48188/400000: episode: 171, duration: 25.153s, episode steps: 385, steps per second:  15, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.309 [0.000, 5.000],  loss: 0.007150, mae: 0.033521, mean_q: 0.043261, mean_eps: 0.856018\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  48793/400000: episode: 172, duration: 39.058s, episode steps: 605, steps per second:  15, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.754 [0.000, 5.000],  loss: 0.009256, mae: 0.036558, mean_q: 0.049621, mean_eps: 0.854530\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  49311/400000: episode: 173, duration: 32.640s, episode steps: 518, steps per second:  16, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.741 [0.000, 5.000],  loss: 0.008360, mae: 0.034579, mean_q: 0.048011, mean_eps: 0.852844\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  49613/400000: episode: 174, duration: 18.682s, episode steps: 302, steps per second:  16, episode reward:  9.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.006795, mae: 0.033027, mean_q: 0.044468, mean_eps: 0.851614\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  49870/400000: episode: 175, duration: 17.561s, episode steps: 257, steps per second:  15, episode reward:  7.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.696 [0.000, 5.000],  loss: 0.007364, mae: 0.035390, mean_q: 0.047938, mean_eps: 0.850774\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  50083/400000: episode: 176, duration: 13.340s, episode steps: 213, steps per second:  16, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.008929, mae: 0.037573, mean_q: 0.050254, mean_eps: 0.850072\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  50201/400000: episode: 177, duration: 7.272s, episode steps: 118, steps per second:  16, episode reward:  1.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.008205, mae: 0.036744, mean_q: 0.050157, mean_eps: 0.849574\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  50425/400000: episode: 178, duration: 14.377s, episode steps: 224, steps per second:  16, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.009981, mae: 0.036558, mean_q: 0.048558, mean_eps: 0.849058\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  50660/400000: episode: 179, duration: 15.080s, episode steps: 235, steps per second:  16, episode reward:  1.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.277 [0.000, 5.000],  loss: 0.006829, mae: 0.036862, mean_q: 0.048592, mean_eps: 0.848374\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  50908/400000: episode: 180, duration: 15.995s, episode steps: 248, steps per second:  16, episode reward:  2.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.006135, mae: 0.030230, mean_q: 0.042236, mean_eps: 0.847654\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  51460/400000: episode: 181, duration: 36.316s, episode steps: 552, steps per second:  15, episode reward: 13.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: 0.006767, mae: 0.044610, mean_q: 0.060090, mean_eps: 0.846454\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  51687/400000: episode: 182, duration: 14.689s, episode steps: 227, steps per second:  15, episode reward:  5.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.008346, mae: 0.047887, mean_q: 0.061777, mean_eps: 0.845284\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  51952/400000: episode: 183, duration: 16.825s, episode steps: 265, steps per second:  16, episode reward:  5.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: 0.006062, mae: 0.048034, mean_q: 0.064496, mean_eps: 0.844546\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  52231/400000: episode: 184, duration: 19.126s, episode steps: 279, steps per second:  15, episode reward:  2.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.009790, mae: 0.050954, mean_q: 0.065283, mean_eps: 0.843730\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  52478/400000: episode: 185, duration: 15.738s, episode steps: 247, steps per second:  16, episode reward:  1.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.704 [0.000, 5.000],  loss: 0.007473, mae: 0.049321, mean_q: 0.063780, mean_eps: 0.842938\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  52668/400000: episode: 186, duration: 12.699s, episode steps: 190, steps per second:  15, episode reward:  4.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.316 [0.000, 5.000],  loss: 0.007817, mae: 0.050537, mean_q: 0.065230, mean_eps: 0.842284\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  52931/400000: episode: 187, duration: 16.720s, episode steps: 263, steps per second:  16, episode reward:  5.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.006827, mae: 0.046101, mean_q: 0.060159, mean_eps: 0.841606\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  53141/400000: episode: 188, duration: 13.770s, episode steps: 210, steps per second:  15, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.762 [0.000, 5.000],  loss: 0.007752, mae: 0.050999, mean_q: 0.065641, mean_eps: 0.840892\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  53380/400000: episode: 189, duration: 15.357s, episode steps: 239, steps per second:  16, episode reward:  4.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.005732, mae: 0.044836, mean_q: 0.057692, mean_eps: 0.840220\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  53514/400000: episode: 190, duration: 9.533s, episode steps: 134, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.672 [0.000, 5.000],  loss: 0.006297, mae: 0.045285, mean_q: 0.059801, mean_eps: 0.839662\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  53660/400000: episode: 191, duration: 8.528s, episode steps: 146, steps per second:  17, episode reward:  1.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.010045, mae: 0.057968, mean_q: 0.076880, mean_eps: 0.839242\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  53916/400000: episode: 192, duration: 17.499s, episode steps: 256, steps per second:  15, episode reward:  4.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.009270, mae: 0.054911, mean_q: 0.071641, mean_eps: 0.838642\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  54296/400000: episode: 193, duration: 23.506s, episode steps: 380, steps per second:  16, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.009174, mae: 0.049155, mean_q: 0.063773, mean_eps: 0.837688\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  54480/400000: episode: 194, duration: 12.372s, episode steps: 184, steps per second:  15, episode reward:  3.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.006716, mae: 0.046002, mean_q: 0.060682, mean_eps: 0.836842\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  54674/400000: episode: 195, duration: 12.787s, episode steps: 194, steps per second:  15, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.629 [0.000, 5.000],  loss: 0.007517, mae: 0.046926, mean_q: 0.062013, mean_eps: 0.836272\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  54930/400000: episode: 196, duration: 16.258s, episode steps: 256, steps per second:  16, episode reward:  5.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.672 [0.000, 5.000],  loss: 0.007386, mae: 0.049374, mean_q: 0.064867, mean_eps: 0.835594\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  55411/400000: episode: 197, duration: 31.522s, episode steps: 481, steps per second:  15, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.006530, mae: 0.047669, mean_q: 0.063020, mean_eps: 0.834490\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  55843/400000: episode: 198, duration: 27.489s, episode steps: 432, steps per second:  16, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.618 [0.000, 5.000],  loss: 0.006598, mae: 0.044033, mean_q: 0.060407, mean_eps: 0.833122\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  55983/400000: episode: 199, duration: 8.789s, episode steps: 140, steps per second:  16, episode reward:  1.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.004914, mae: 0.046615, mean_q: 0.062209, mean_eps: 0.832264\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  56198/400000: episode: 200, duration: 13.856s, episode steps: 215, steps per second:  16, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.008755, mae: 0.047215, mean_q: 0.059248, mean_eps: 0.831730\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  56713/400000: episode: 201, duration: 33.218s, episode steps: 515, steps per second:  16, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: 0.007807, mae: 0.050754, mean_q: 0.066135, mean_eps: 0.830632\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  56928/400000: episode: 202, duration: 14.016s, episode steps: 215, steps per second:  15, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.772 [0.000, 5.000],  loss: 0.007500, mae: 0.048473, mean_q: 0.063177, mean_eps: 0.829540\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  57184/400000: episode: 203, duration: 16.824s, episode steps: 256, steps per second:  15, episode reward:  7.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.006266, mae: 0.048223, mean_q: 0.063988, mean_eps: 0.828838\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  57432/400000: episode: 204, duration: 16.838s, episode steps: 248, steps per second:  15, episode reward:  4.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.907 [0.000, 5.000],  loss: 0.010027, mae: 0.053525, mean_q: 0.069875, mean_eps: 0.828082\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  57652/400000: episode: 205, duration: 15.198s, episode steps: 220, steps per second:  14, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.007798, mae: 0.048696, mean_q: 0.064123, mean_eps: 0.827380\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  57940/400000: episode: 206, duration: 18.034s, episode steps: 288, steps per second:  16, episode reward:  3.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.006900, mae: 0.046002, mean_q: 0.062529, mean_eps: 0.826618\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  58146/400000: episode: 207, duration: 13.410s, episode steps: 206, steps per second:  15, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.008791, mae: 0.050890, mean_q: 0.067266, mean_eps: 0.825874\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  58369/400000: episode: 208, duration: 14.347s, episode steps: 223, steps per second:  16, episode reward:  5.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.865 [0.000, 5.000],  loss: 0.005973, mae: 0.043658, mean_q: 0.064188, mean_eps: 0.825226\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  58576/400000: episode: 209, duration: 13.546s, episode steps: 207, steps per second:  15, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.010398, mae: 0.050629, mean_q: 0.065070, mean_eps: 0.824584\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  58763/400000: episode: 210, duration: 12.306s, episode steps: 187, steps per second:  15, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.006476, mae: 0.050439, mean_q: 0.064397, mean_eps: 0.823996\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  59022/400000: episode: 211, duration: 16.884s, episode steps: 259, steps per second:  15, episode reward:  2.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.232 [0.000, 5.000],  loss: 0.006155, mae: 0.044102, mean_q: 0.056268, mean_eps: 0.823324\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  59245/400000: episode: 212, duration: 15.163s, episode steps: 223, steps per second:  15, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: 0.007525, mae: 0.048601, mean_q: 0.061491, mean_eps: 0.822598\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  59364/400000: episode: 213, duration: 7.363s, episode steps: 119, steps per second:  16, episode reward:  1.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.294 [0.000, 5.000],  loss: 0.006681, mae: 0.052961, mean_q: 0.072840, mean_eps: 0.822088\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  59603/400000: episode: 214, duration: 15.187s, episode steps: 239, steps per second:  16, episode reward:  7.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.008104, mae: 0.052522, mean_q: 0.069228, mean_eps: 0.821554\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  59809/400000: episode: 215, duration: 13.342s, episode steps: 206, steps per second:  15, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.006805, mae: 0.069877, mean_q: 0.092847, mean_eps: 0.820882\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  59990/400000: episode: 216, duration: 12.090s, episode steps: 181, steps per second:  15, episode reward:  1.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.702 [0.000, 5.000],  loss: 0.004162, mae: 0.064099, mean_q: 0.085230, mean_eps: 0.820300\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  60198/400000: episode: 217, duration: 13.679s, episode steps: 208, steps per second:  15, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.168 [0.000, 5.000],  loss: 0.009362, mae: 0.074676, mean_q: 0.098203, mean_eps: 0.819718\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  60460/400000: episode: 218, duration: 16.804s, episode steps: 262, steps per second:  16, episode reward:  3.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.687 [0.000, 5.000],  loss: 0.006429, mae: 0.066055, mean_q: 0.087813, mean_eps: 0.819016\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  60668/400000: episode: 219, duration: 13.863s, episode steps: 208, steps per second:  15, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.007086, mae: 0.066602, mean_q: 0.087245, mean_eps: 0.818314\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  60874/400000: episode: 220, duration: 13.593s, episode steps: 206, steps per second:  15, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.641 [0.000, 5.000],  loss: 0.005446, mae: 0.064409, mean_q: 0.084439, mean_eps: 0.817690\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  61057/400000: episode: 221, duration: 12.295s, episode steps: 183, steps per second:  15, episode reward:  5.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.639 [0.000, 5.000],  loss: 0.007654, mae: 0.068226, mean_q: 0.089852, mean_eps: 0.817102\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  61357/400000: episode: 222, duration: 19.050s, episode steps: 300, steps per second:  16, episode reward:  6.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: 0.006940, mae: 0.064730, mean_q: 0.085175, mean_eps: 0.816376\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  61708/400000: episode: 223, duration: 23.058s, episode steps: 351, steps per second:  15, episode reward:  8.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.009022, mae: 0.072241, mean_q: 0.096671, mean_eps: 0.815404\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  62002/400000: episode: 224, duration: 18.784s, episode steps: 294, steps per second:  16, episode reward:  6.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.010134, mae: 0.073342, mean_q: 0.094860, mean_eps: 0.814438\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  62304/400000: episode: 225, duration: 20.133s, episode steps: 302, steps per second:  15, episode reward:  5.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.685 [0.000, 5.000],  loss: 0.008213, mae: 0.065064, mean_q: 0.089321, mean_eps: 0.813544\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  62450/400000: episode: 226, duration: 9.738s, episode steps: 146, steps per second:  15, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.945 [0.000, 5.000],  loss: 0.008126, mae: 0.070121, mean_q: 0.092844, mean_eps: 0.812872\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  62680/400000: episode: 227, duration: 15.187s, episode steps: 230, steps per second:  15, episode reward:  3.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.665 [0.000, 5.000],  loss: 0.006801, mae: 0.067605, mean_q: 0.090233, mean_eps: 0.812308\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  62882/400000: episode: 228, duration: 13.132s, episode steps: 202, steps per second:  15, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.007139, mae: 0.066993, mean_q: 0.087436, mean_eps: 0.811660\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  63258/400000: episode: 229, duration: 23.001s, episode steps: 376, steps per second:  16, episode reward: 11.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.008154, mae: 0.069693, mean_q: 0.092621, mean_eps: 0.810790\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  63519/400000: episode: 230, duration: 17.534s, episode steps: 261, steps per second:  15, episode reward:  5.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.006364, mae: 0.065146, mean_q: 0.086377, mean_eps: 0.809836\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  63764/400000: episode: 231, duration: 16.402s, episode steps: 245, steps per second:  15, episode reward:  4.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: 0.008869, mae: 0.067601, mean_q: 0.089420, mean_eps: 0.809080\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  63905/400000: episode: 232, duration: 8.227s, episode steps: 141, steps per second:  17, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.709 [0.000, 5.000],  loss: 0.004994, mae: 0.063428, mean_q: 0.086363, mean_eps: 0.808498\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  64183/400000: episode: 233, duration: 19.096s, episode steps: 278, steps per second:  15, episode reward:  8.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.007308, mae: 0.064997, mean_q: 0.086244, mean_eps: 0.807868\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  64393/400000: episode: 234, duration: 13.883s, episode steps: 210, steps per second:  15, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.007121, mae: 0.066841, mean_q: 0.087957, mean_eps: 0.807136\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  64546/400000: episode: 235, duration: 8.779s, episode steps: 153, steps per second:  17, episode reward:  1.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.078 [0.000, 5.000],  loss: 0.007524, mae: 0.072722, mean_q: 0.094193, mean_eps: 0.806590\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  64693/400000: episode: 236, duration: 10.249s, episode steps: 147, steps per second:  14, episode reward:  2.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.293 [0.000, 5.000],  loss: 0.010313, mae: 0.074084, mean_q: 0.096183, mean_eps: 0.806140\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  64983/400000: episode: 237, duration: 18.290s, episode steps: 290, steps per second:  16, episode reward:  8.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.314 [0.000, 5.000],  loss: 0.007064, mae: 0.065736, mean_q: 0.086130, mean_eps: 0.805486\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  65197/400000: episode: 238, duration: 14.161s, episode steps: 214, steps per second:  15, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.009370, mae: 0.068632, mean_q: 0.088168, mean_eps: 0.804730\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  65782/400000: episode: 239, duration: 38.132s, episode steps: 585, steps per second:  15, episode reward: 14.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.008009, mae: 0.066431, mean_q: 0.090590, mean_eps: 0.803530\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  66255/400000: episode: 240, duration: 30.139s, episode steps: 473, steps per second:  16, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.668 [0.000, 5.000],  loss: 0.007727, mae: 0.068384, mean_q: 0.089561, mean_eps: 0.801946\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  66653/400000: episode: 241, duration: 26.068s, episode steps: 398, steps per second:  15, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: 0.007300, mae: 0.066939, mean_q: 0.087131, mean_eps: 0.800638\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  66866/400000: episode: 242, duration: 13.866s, episode steps: 213, steps per second:  15, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.007747, mae: 0.069611, mean_q: 0.090627, mean_eps: 0.799720\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  67078/400000: episode: 243, duration: 13.817s, episode steps: 212, steps per second:  15, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.005792, mae: 0.063743, mean_q: 0.084725, mean_eps: 0.799084\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  67285/400000: episode: 244, duration: 13.688s, episode steps: 207, steps per second:  15, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.329 [0.000, 5.000],  loss: 0.006819, mae: 0.064325, mean_q: 0.085235, mean_eps: 0.798454\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  67570/400000: episode: 245, duration: 19.443s, episode steps: 285, steps per second:  15, episode reward:  6.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.008916, mae: 0.069097, mean_q: 0.089786, mean_eps: 0.797716\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  68008/400000: episode: 246, duration: 28.672s, episode steps: 438, steps per second:  15, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.008715, mae: 0.069383, mean_q: 0.089834, mean_eps: 0.796636\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  68421/400000: episode: 247, duration: 26.639s, episode steps: 413, steps per second:  16, episode reward:  9.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.879 [0.000, 5.000],  loss: 0.006615, mae: 0.078836, mean_q: 0.103534, mean_eps: 0.795358\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  68715/400000: episode: 248, duration: 18.473s, episode steps: 294, steps per second:  16, episode reward:  6.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.006510, mae: 0.076782, mean_q: 0.100116, mean_eps: 0.794296\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  68926/400000: episode: 249, duration: 13.660s, episode steps: 211, steps per second:  15, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.194 [0.000, 5.000],  loss: 0.007177, mae: 0.078284, mean_q: 0.105545, mean_eps: 0.793540\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  69209/400000: episode: 250, duration: 17.822s, episode steps: 283, steps per second:  16, episode reward:  6.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.004481, mae: 0.070133, mean_q: 0.091429, mean_eps: 0.792796\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  69517/400000: episode: 251, duration: 21.232s, episode steps: 308, steps per second:  15, episode reward:  7.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.808 [0.000, 5.000],  loss: 0.007696, mae: 0.082245, mean_q: 0.107144, mean_eps: 0.791908\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  69790/400000: episode: 252, duration: 17.393s, episode steps: 273, steps per second:  16, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.615 [0.000, 5.000],  loss: 0.006984, mae: 0.075436, mean_q: 0.101925, mean_eps: 0.791038\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  70649/400000: episode: 253, duration: 55.208s, episode steps: 859, steps per second:  16, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.007029, mae: 0.076042, mean_q: 0.099283, mean_eps: 0.789340\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  70924/400000: episode: 254, duration: 17.449s, episode steps: 275, steps per second:  16, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.920 [0.000, 5.000],  loss: 0.007915, mae: 0.078556, mean_q: 0.101401, mean_eps: 0.787642\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  71134/400000: episode: 255, duration: 13.974s, episode steps: 210, steps per second:  15, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.006757, mae: 0.075470, mean_q: 0.096876, mean_eps: 0.786916\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  71340/400000: episode: 256, duration: 13.762s, episode steps: 206, steps per second:  15, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.008900, mae: 0.083339, mean_q: 0.103763, mean_eps: 0.786292\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  71545/400000: episode: 257, duration: 13.847s, episode steps: 205, steps per second:  15, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.007694, mae: 0.079486, mean_q: 0.104119, mean_eps: 0.785674\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  71795/400000: episode: 258, duration: 15.907s, episode steps: 250, steps per second:  16, episode reward:  4.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.096 [0.000, 5.000],  loss: 0.006478, mae: 0.068039, mean_q: 0.097399, mean_eps: 0.784990\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  72069/400000: episode: 259, duration: 19.081s, episode steps: 274, steps per second:  14, episode reward:  1.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.033 [0.000, 5.000],  loss: 0.006771, mae: 0.073387, mean_q: 0.099646, mean_eps: 0.784204\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  72342/400000: episode: 260, duration: 17.172s, episode steps: 273, steps per second:  16, episode reward:  3.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.110 [0.000, 5.000],  loss: 0.008935, mae: 0.073204, mean_q: 0.093049, mean_eps: 0.783382\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  72684/400000: episode: 261, duration: 22.991s, episode steps: 342, steps per second:  15, episode reward:  7.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.009471, mae: 0.077965, mean_q: 0.103279, mean_eps: 0.782464\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  72885/400000: episode: 262, duration: 13.187s, episode steps: 201, steps per second:  15, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 3.010 [0.000, 5.000],  loss: 0.007957, mae: 0.081347, mean_q: 0.108998, mean_eps: 0.781648\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  73092/400000: episode: 263, duration: 13.694s, episode steps: 207, steps per second:  15, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.870 [0.000, 5.000],  loss: 0.006857, mae: 0.072245, mean_q: 0.098042, mean_eps: 0.781036\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  73323/400000: episode: 264, duration: 15.335s, episode steps: 231, steps per second:  15, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.007936, mae: 0.079931, mean_q: 0.108046, mean_eps: 0.780382\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  74045/400000: episode: 265, duration: 46.273s, episode steps: 722, steps per second:  16, episode reward: 17.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.007674, mae: 0.077205, mean_q: 0.102771, mean_eps: 0.778948\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  74264/400000: episode: 266, duration: 14.312s, episode steps: 219, steps per second:  15, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.006787, mae: 0.076234, mean_q: 0.101498, mean_eps: 0.777538\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  74535/400000: episode: 267, duration: 17.245s, episode steps: 271, steps per second:  16, episode reward:  2.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.008420, mae: 0.078595, mean_q: 0.101464, mean_eps: 0.776806\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  74775/400000: episode: 268, duration: 15.917s, episode steps: 240, steps per second:  15, episode reward:  5.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.621 [0.000, 5.000],  loss: 0.006459, mae: 0.072445, mean_q: 0.095698, mean_eps: 0.776038\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  75285/400000: episode: 269, duration: 33.915s, episode steps: 510, steps per second:  15, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.622 [0.000, 5.000],  loss: 0.008104, mae: 0.075756, mean_q: 0.100090, mean_eps: 0.774910\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  75410/400000: episode: 270, duration: 7.824s, episode steps: 125, steps per second:  16, episode reward:  1.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.007014, mae: 0.075224, mean_q: 0.098986, mean_eps: 0.773956\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  75617/400000: episode: 271, duration: 13.571s, episode steps: 207, steps per second:  15, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.251 [0.000, 5.000],  loss: 0.006996, mae: 0.075590, mean_q: 0.101044, mean_eps: 0.773458\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  75815/400000: episode: 272, duration: 12.857s, episode steps: 198, steps per second:  15, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.909 [0.000, 5.000],  loss: 0.010147, mae: 0.082512, mean_q: 0.107656, mean_eps: 0.772852\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  76101/400000: episode: 273, duration: 19.911s, episode steps: 286, steps per second:  14, episode reward:  8.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.006145, mae: 0.074431, mean_q: 0.101577, mean_eps: 0.772126\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  76364/400000: episode: 274, duration: 16.834s, episode steps: 263, steps per second:  16, episode reward:  5.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.852 [0.000, 5.000],  loss: 0.008542, mae: 0.083682, mean_q: 0.109941, mean_eps: 0.771304\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  76708/400000: episode: 275, duration: 23.723s, episode steps: 344, steps per second:  15, episode reward:  5.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.241 [0.000, 5.000],  loss: 0.008782, mae: 0.092360, mean_q: 0.120200, mean_eps: 0.770398\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  77008/400000: episode: 276, duration: 19.411s, episode steps: 300, steps per second:  15, episode reward:  5.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.810 [0.000, 5.000],  loss: 0.007666, mae: 0.099632, mean_q: 0.131504, mean_eps: 0.769432\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  77211/400000: episode: 277, duration: 13.675s, episode steps: 203, steps per second:  15, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.704 [0.000, 5.000],  loss: 0.007603, mae: 0.097893, mean_q: 0.130342, mean_eps: 0.768676\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  77487/400000: episode: 278, duration: 17.553s, episode steps: 276, steps per second:  16, episode reward:  5.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.341 [0.000, 5.000],  loss: 0.006618, mae: 0.099725, mean_q: 0.130743, mean_eps: 0.767956\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  77647/400000: episode: 279, duration: 10.930s, episode steps: 160, steps per second:  15, episode reward:  1.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.806 [0.000, 5.000],  loss: 0.008842, mae: 0.103747, mean_q: 0.136642, mean_eps: 0.767302\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  78110/400000: episode: 280, duration: 29.873s, episode steps: 463, steps per second:  15, episode reward: 13.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.007907, mae: 0.100081, mean_q: 0.130877, mean_eps: 0.766366\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  78381/400000: episode: 281, duration: 18.939s, episode steps: 271, steps per second:  14, episode reward:  3.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.351 [0.000, 5.000],  loss: 0.007064, mae: 0.098472, mean_q: 0.129533, mean_eps: 0.765262\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  78582/400000: episode: 282, duration: 13.105s, episode steps: 201, steps per second:  15, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.781 [0.000, 5.000],  loss: 0.010017, mae: 0.104016, mean_q: 0.134141, mean_eps: 0.764554\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  78784/400000: episode: 283, duration: 12.970s, episode steps: 202, steps per second:  16, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.277 [0.000, 5.000],  loss: 0.006423, mae: 0.098054, mean_q: 0.128240, mean_eps: 0.763954\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  79010/400000: episode: 284, duration: 15.268s, episode steps: 226, steps per second:  15, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.006416, mae: 0.092978, mean_q: 0.123566, mean_eps: 0.763312\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  79878/400000: episode: 285, duration: 56.226s, episode steps: 868, steps per second:  15, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.005809, mae: 0.093902, mean_q: 0.123985, mean_eps: 0.761668\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  80132/400000: episode: 286, duration: 16.409s, episode steps: 254, steps per second:  15, episode reward:  3.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.006578, mae: 0.096028, mean_q: 0.126232, mean_eps: 0.759988\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  80759/400000: episode: 287, duration: 41.073s, episode steps: 627, steps per second:  15, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.616 [0.000, 5.000],  loss: 0.007582, mae: 0.094178, mean_q: 0.124720, mean_eps: 0.758668\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  81023/400000: episode: 288, duration: 16.970s, episode steps: 264, steps per second:  16, episode reward:  7.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.625 [0.000, 5.000],  loss: 0.007498, mae: 0.099336, mean_q: 0.128159, mean_eps: 0.757330\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  81816/400000: episode: 289, duration: 51.953s, episode steps: 793, steps per second:  15, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.006928, mae: 0.096199, mean_q: 0.125681, mean_eps: 0.755746\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  81993/400000: episode: 290, duration: 12.152s, episode steps: 177, steps per second:  15, episode reward:  2.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.678 [0.000, 5.000],  loss: 0.007194, mae: 0.096273, mean_q: 0.125853, mean_eps: 0.754288\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  82212/400000: episode: 291, duration: 14.661s, episode steps: 219, steps per second:  15, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.004703, mae: 0.091088, mean_q: 0.119348, mean_eps: 0.753694\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  82462/400000: episode: 292, duration: 16.245s, episode steps: 250, steps per second:  15, episode reward:  3.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: 0.005958, mae: 0.097749, mean_q: 0.124680, mean_eps: 0.752992\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  82716/400000: episode: 293, duration: 16.446s, episode steps: 254, steps per second:  15, episode reward:  4.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.732 [0.000, 5.000],  loss: 0.006534, mae: 0.094922, mean_q: 0.122604, mean_eps: 0.752236\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  83272/400000: episode: 294, duration: 37.509s, episode steps: 556, steps per second:  15, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.236 [0.000, 5.000],  loss: 0.007228, mae: 0.098755, mean_q: 0.127587, mean_eps: 0.751024\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  83437/400000: episode: 295, duration: 10.965s, episode steps: 165, steps per second:  15, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.642 [0.000, 5.000],  loss: 0.005558, mae: 0.093675, mean_q: 0.122858, mean_eps: 0.749938\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  83683/400000: episode: 296, duration: 16.117s, episode steps: 246, steps per second:  15, episode reward:  2.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.009136, mae: 0.101193, mean_q: 0.129796, mean_eps: 0.749320\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  83920/400000: episode: 297, duration: 15.574s, episode steps: 237, steps per second:  15, episode reward:  5.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.006714, mae: 0.096045, mean_q: 0.123195, mean_eps: 0.748600\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  84035/400000: episode: 298, duration: 6.745s, episode steps: 115, steps per second:  17, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.991 [0.000, 5.000],  loss: 0.008498, mae: 0.093257, mean_q: 0.119825, mean_eps: 0.748072\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  84743/400000: episode: 299, duration: 47.097s, episode steps: 708, steps per second:  15, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.007125, mae: 0.095843, mean_q: 0.124895, mean_eps: 0.746836\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  84866/400000: episode: 300, duration: 7.187s, episode steps: 123, steps per second:  17, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.821 [0.000, 5.000],  loss: 0.005630, mae: 0.095982, mean_q: 0.122581, mean_eps: 0.745588\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  85146/400000: episode: 301, duration: 19.611s, episode steps: 280, steps per second:  14, episode reward:  4.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.006083, mae: 0.100579, mean_q: 0.129798, mean_eps: 0.744982\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  85568/400000: episode: 302, duration: 27.608s, episode steps: 422, steps per second:  15, episode reward:  9.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.007393, mae: 0.106863, mean_q: 0.136153, mean_eps: 0.743932\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  85763/400000: episode: 303, duration: 12.746s, episode steps: 195, steps per second:  15, episode reward:  4.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.621 [0.000, 5.000],  loss: 0.006240, mae: 0.112717, mean_q: 0.145454, mean_eps: 0.743008\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  85981/400000: episode: 304, duration: 14.412s, episode steps: 218, steps per second:  15, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.367 [0.000, 5.000],  loss: 0.007862, mae: 0.105136, mean_q: 0.133728, mean_eps: 0.742384\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  86157/400000: episode: 305, duration: 10.432s, episode steps: 176, steps per second:  17, episode reward:  3.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.739 [0.000, 5.000],  loss: 0.006682, mae: 0.106037, mean_q: 0.136936, mean_eps: 0.741790\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  86377/400000: episode: 306, duration: 14.741s, episode steps: 220, steps per second:  15, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.891 [0.000, 5.000],  loss: 0.007785, mae: 0.109361, mean_q: 0.137956, mean_eps: 0.741196\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  86545/400000: episode: 307, duration: 10.689s, episode steps: 168, steps per second:  16, episode reward:  1.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.696 [0.000, 5.000],  loss: 0.007628, mae: 0.109457, mean_q: 0.140247, mean_eps: 0.740614\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  86811/400000: episode: 308, duration: 18.516s, episode steps: 266, steps per second:  14, episode reward:  7.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.008601, mae: 0.112447, mean_q: 0.143470, mean_eps: 0.739966\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  87027/400000: episode: 309, duration: 14.882s, episode steps: 216, steps per second:  15, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.829 [0.000, 5.000],  loss: 0.006525, mae: 0.105559, mean_q: 0.134778, mean_eps: 0.739246\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  87222/400000: episode: 310, duration: 13.604s, episode steps: 195, steps per second:  14, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.779 [0.000, 5.000],  loss: 0.009233, mae: 0.106575, mean_q: 0.134207, mean_eps: 0.738628\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  87420/400000: episode: 311, duration: 13.134s, episode steps: 198, steps per second:  15, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.753 [0.000, 5.000],  loss: 0.006047, mae: 0.102242, mean_q: 0.134170, mean_eps: 0.738040\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  87647/400000: episode: 312, duration: 15.312s, episode steps: 227, steps per second:  15, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.630 [0.000, 5.000],  loss: 0.005440, mae: 0.100728, mean_q: 0.130254, mean_eps: 0.737404\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  87912/400000: episode: 313, duration: 17.100s, episode steps: 265, steps per second:  15, episode reward:  3.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.007175, mae: 0.104469, mean_q: 0.133674, mean_eps: 0.736666\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  88366/400000: episode: 314, duration: 29.668s, episode steps: 454, steps per second:  15, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.007015, mae: 0.102832, mean_q: 0.133805, mean_eps: 0.735586\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  88671/400000: episode: 315, duration: 19.773s, episode steps: 305, steps per second:  15, episode reward:  7.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.007442, mae: 0.106024, mean_q: 0.138249, mean_eps: 0.734446\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  88880/400000: episode: 316, duration: 13.816s, episode steps: 209, steps per second:  15, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: 0.010242, mae: 0.114808, mean_q: 0.146631, mean_eps: 0.733678\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  89085/400000: episode: 317, duration: 13.373s, episode steps: 205, steps per second:  15, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.007344, mae: 0.107863, mean_q: 0.141167, mean_eps: 0.733054\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  89316/400000: episode: 318, duration: 16.305s, episode steps: 231, steps per second:  14, episode reward:  3.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.368 [0.000, 5.000],  loss: 0.005434, mae: 0.102056, mean_q: 0.136520, mean_eps: 0.732400\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  89677/400000: episode: 319, duration: 22.685s, episode steps: 361, steps per second:  16, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: 0.006549, mae: 0.100037, mean_q: 0.129668, mean_eps: 0.731512\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  90065/400000: episode: 320, duration: 25.658s, episode steps: 388, steps per second:  15, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: 0.007110, mae: 0.105127, mean_q: 0.135860, mean_eps: 0.730384\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  90252/400000: episode: 321, duration: 12.482s, episode steps: 187, steps per second:  15, episode reward:  3.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.273 [0.000, 5.000],  loss: 0.006793, mae: 0.106813, mean_q: 0.138268, mean_eps: 0.729526\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  90478/400000: episode: 322, duration: 14.741s, episode steps: 226, steps per second:  15, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.007571, mae: 0.103728, mean_q: 0.133542, mean_eps: 0.728908\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  90689/400000: episode: 323, duration: 13.936s, episode steps: 211, steps per second:  15, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.611 [0.000, 5.000],  loss: 0.009274, mae: 0.113774, mean_q: 0.145323, mean_eps: 0.728248\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  91377/400000: episode: 324, duration: 44.495s, episode steps: 688, steps per second:  15, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.006927, mae: 0.104122, mean_q: 0.138055, mean_eps: 0.726898\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  91668/400000: episode: 325, duration: 20.201s, episode steps: 291, steps per second:  14, episode reward:  4.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.914 [0.000, 5.000],  loss: 0.005575, mae: 0.100406, mean_q: 0.131859, mean_eps: 0.725434\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  91876/400000: episode: 326, duration: 14.005s, episode steps: 208, steps per second:  15, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.322 [0.000, 5.000],  loss: 0.005682, mae: 0.101411, mean_q: 0.131135, mean_eps: 0.724690\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  92062/400000: episode: 327, duration: 12.606s, episode steps: 186, steps per second:  15, episode reward:  2.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.844 [0.000, 5.000],  loss: 0.008818, mae: 0.107995, mean_q: 0.139649, mean_eps: 0.724096\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  92315/400000: episode: 328, duration: 16.282s, episode steps: 253, steps per second:  16, episode reward:  5.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.901 [0.000, 5.000],  loss: 0.008321, mae: 0.111730, mean_q: 0.144250, mean_eps: 0.723436\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  92650/400000: episode: 329, duration: 21.080s, episode steps: 335, steps per second:  16, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.005629, mae: 0.100772, mean_q: 0.130307, mean_eps: 0.722554\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  92945/400000: episode: 330, duration: 20.484s, episode steps: 295, steps per second:  14, episode reward:  7.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.006445, mae: 0.099440, mean_q: 0.127761, mean_eps: 0.721606\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  93061/400000: episode: 331, duration: 6.771s, episode steps: 116, steps per second:  17, episode reward:  1.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 3.069 [0.000, 5.000],  loss: 0.005886, mae: 0.103143, mean_q: 0.133158, mean_eps: 0.720988\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  93250/400000: episode: 332, duration: 12.454s, episode steps: 189, steps per second:  15, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.008250, mae: 0.110066, mean_q: 0.142016, mean_eps: 0.720532\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  93471/400000: episode: 333, duration: 14.229s, episode steps: 221, steps per second:  16, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.006819, mae: 0.108774, mean_q: 0.143355, mean_eps: 0.719920\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  93733/400000: episode: 334, duration: 18.009s, episode steps: 262, steps per second:  15, episode reward:  7.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.771 [0.000, 5.000],  loss: 0.007690, mae: 0.124940, mean_q: 0.160839, mean_eps: 0.719194\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  94289/400000: episode: 335, duration: 35.390s, episode steps: 556, steps per second:  16, episode reward: 15.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.333 [0.000, 5.000],  loss: 0.008257, mae: 0.128592, mean_q: 0.166473, mean_eps: 0.717964\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  94543/400000: episode: 336, duration: 16.167s, episode steps: 254, steps per second:  16, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.006662, mae: 0.124292, mean_q: 0.159827, mean_eps: 0.716752\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  94879/400000: episode: 337, duration: 22.603s, episode steps: 336, steps per second:  15, episode reward:  7.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.860 [0.000, 5.000],  loss: 0.007673, mae: 0.121592, mean_q: 0.156838, mean_eps: 0.715870\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  95135/400000: episode: 338, duration: 16.404s, episode steps: 256, steps per second:  16, episode reward:  2.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 1.879 [0.000, 5.000],  loss: 0.007137, mae: 0.122010, mean_q: 0.158125, mean_eps: 0.714982\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  95383/400000: episode: 339, duration: 16.049s, episode steps: 248, steps per second:  15, episode reward:  5.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.250 [0.000, 5.000],  loss: 0.009271, mae: 0.122721, mean_q: 0.156479, mean_eps: 0.714226\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  95573/400000: episode: 340, duration: 12.855s, episode steps: 190, steps per second:  15, episode reward:  2.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.005594, mae: 0.119811, mean_q: 0.154755, mean_eps: 0.713566\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  95787/400000: episode: 341, duration: 14.128s, episode steps: 214, steps per second:  15, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: 0.006953, mae: 0.122940, mean_q: 0.157715, mean_eps: 0.712960\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  95942/400000: episode: 342, duration: 10.764s, episode steps: 155, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.555 [0.000, 5.000],  loss: 0.006111, mae: 0.115829, mean_q: 0.147947, mean_eps: 0.712408\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  96223/400000: episode: 343, duration: 17.789s, episode steps: 281, steps per second:  16, episode reward:  4.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.655 [0.000, 5.000],  loss: 0.006773, mae: 0.124035, mean_q: 0.157801, mean_eps: 0.711754\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  96657/400000: episode: 344, duration: 28.372s, episode steps: 434, steps per second:  15, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.818 [0.000, 5.000],  loss: 0.006703, mae: 0.121919, mean_q: 0.156911, mean_eps: 0.710680\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  97070/400000: episode: 345, duration: 27.081s, episode steps: 413, steps per second:  15, episode reward:  9.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.007709, mae: 0.127700, mean_q: 0.162954, mean_eps: 0.709408\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  97353/400000: episode: 346, duration: 19.664s, episode steps: 283, steps per second:  14, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.717 [0.000, 5.000],  loss: 0.005718, mae: 0.117203, mean_q: 0.149994, mean_eps: 0.708364\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  97722/400000: episode: 347, duration: 23.096s, episode steps: 369, steps per second:  16, episode reward: 10.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.006027, mae: 0.122399, mean_q: 0.157342, mean_eps: 0.707386\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  98142/400000: episode: 348, duration: 27.408s, episode steps: 420, steps per second:  15, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.005982, mae: 0.119098, mean_q: 0.152828, mean_eps: 0.706204\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  98377/400000: episode: 349, duration: 16.417s, episode steps: 235, steps per second:  14, episode reward:  4.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: 0.005836, mae: 0.124886, mean_q: 0.162947, mean_eps: 0.705220\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  98617/400000: episode: 350, duration: 15.954s, episode steps: 240, steps per second:  15, episode reward:  6.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.900 [0.000, 5.000],  loss: 0.005131, mae: 0.120077, mean_q: 0.153736, mean_eps: 0.704506\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  98773/400000: episode: 351, duration: 9.077s, episode steps: 156, steps per second:  17, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.763 [0.000, 5.000],  loss: 0.007559, mae: 0.120052, mean_q: 0.153169, mean_eps: 0.703912\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  98990/400000: episode: 352, duration: 14.412s, episode steps: 217, steps per second:  15, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.945 [0.000, 5.000],  loss: 0.007196, mae: 0.116892, mean_q: 0.150184, mean_eps: 0.703354\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  99518/400000: episode: 353, duration: 35.090s, episode steps: 528, steps per second:  15, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.288 [0.000, 5.000],  loss: 0.006650, mae: 0.118375, mean_q: 0.151342, mean_eps: 0.702238\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  99746/400000: episode: 354, duration: 14.848s, episode steps: 228, steps per second:  15, episode reward:  1.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.007052, mae: 0.122386, mean_q: 0.159156, mean_eps: 0.701104\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 100254/400000: episode: 355, duration: 32.803s, episode steps: 508, steps per second:  15, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.868 [0.000, 5.000],  loss: 0.006140, mae: 0.116681, mean_q: 0.147654, mean_eps: 0.700000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 100476/400000: episode: 356, duration: 15.506s, episode steps: 222, steps per second:  14, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.221 [0.000, 5.000],  loss: 0.007999, mae: 0.127504, mean_q: 0.159652, mean_eps: 0.698908\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 100876/400000: episode: 357, duration: 25.503s, episode steps: 400, steps per second:  16, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.618 [0.000, 5.000],  loss: 0.006068, mae: 0.114986, mean_q: 0.146168, mean_eps: 0.697978\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 101076/400000: episode: 358, duration: 13.407s, episode steps: 200, steps per second:  15, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.150 [0.000, 5.000],  loss: 0.007141, mae: 0.119901, mean_q: 0.151437, mean_eps: 0.697078\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 101630/400000: episode: 359, duration: 36.935s, episode steps: 554, steps per second:  15, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.150 [0.000, 5.000],  loss: 0.007276, mae: 0.120759, mean_q: 0.154502, mean_eps: 0.695944\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 101882/400000: episode: 360, duration: 16.332s, episode steps: 252, steps per second:  15, episode reward:  4.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.006972, mae: 0.123204, mean_q: 0.156974, mean_eps: 0.694732\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 102212/400000: episode: 361, duration: 22.682s, episode steps: 330, steps per second:  15, episode reward:  1.000, mean reward:  0.003 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.006991, mae: 0.128580, mean_q: 0.164535, mean_eps: 0.693862\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 102471/400000: episode: 362, duration: 16.858s, episode steps: 259, steps per second:  15, episode reward:  4.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.996 [0.000, 5.000],  loss: 0.008528, mae: 0.142408, mean_q: 0.185076, mean_eps: 0.692980\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 102690/400000: episode: 363, duration: 14.456s, episode steps: 219, steps per second:  15, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.817 [0.000, 5.000],  loss: 0.008451, mae: 0.138734, mean_q: 0.179667, mean_eps: 0.692260\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 102920/400000: episode: 364, duration: 15.216s, episode steps: 230, steps per second:  15, episode reward:  4.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.006466, mae: 0.130951, mean_q: 0.168459, mean_eps: 0.691588\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 103134/400000: episode: 365, duration: 14.177s, episode steps: 214, steps per second:  15, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.008500, mae: 0.141915, mean_q: 0.181633, mean_eps: 0.690922\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 103354/400000: episode: 366, duration: 14.414s, episode steps: 220, steps per second:  15, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.173 [0.000, 5.000],  loss: 0.007053, mae: 0.137053, mean_q: 0.174483, mean_eps: 0.690268\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 103555/400000: episode: 367, duration: 13.172s, episode steps: 201, steps per second:  15, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.642 [0.000, 5.000],  loss: 0.008249, mae: 0.141712, mean_q: 0.182088, mean_eps: 0.689638\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 103915/400000: episode: 368, duration: 23.876s, episode steps: 360, steps per second:  15, episode reward: 10.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.686 [0.000, 5.000],  loss: 0.007671, mae: 0.138491, mean_q: 0.175132, mean_eps: 0.688798\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 104145/400000: episode: 369, duration: 15.246s, episode steps: 230, steps per second:  15, episode reward:  1.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.283 [0.000, 5.000],  loss: 0.006009, mae: 0.139738, mean_q: 0.177548, mean_eps: 0.687910\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 104336/400000: episode: 370, duration: 12.725s, episode steps: 191, steps per second:  15, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.366 [0.000, 5.000],  loss: 0.006480, mae: 0.130768, mean_q: 0.166837, mean_eps: 0.687280\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 104553/400000: episode: 371, duration: 14.256s, episode steps: 217, steps per second:  15, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.006118, mae: 0.134426, mean_q: 0.171756, mean_eps: 0.686668\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 104812/400000: episode: 372, duration: 16.725s, episode steps: 259, steps per second:  15, episode reward:  5.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.625 [0.000, 5.000],  loss: 0.007457, mae: 0.138850, mean_q: 0.174275, mean_eps: 0.685954\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 105077/400000: episode: 373, duration: 19.654s, episode steps: 265, steps per second:  13, episode reward:  6.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.177 [0.000, 5.000],  loss: 0.006361, mae: 0.134987, mean_q: 0.173003, mean_eps: 0.685168\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 105598/400000: episode: 374, duration: 34.515s, episode steps: 521, steps per second:  15, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.008188, mae: 0.141157, mean_q: 0.176499, mean_eps: 0.683986\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 105803/400000: episode: 375, duration: 13.755s, episode steps: 205, steps per second:  15, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.007970, mae: 0.139905, mean_q: 0.176400, mean_eps: 0.682900\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 106056/400000: episode: 376, duration: 16.609s, episode steps: 253, steps per second:  15, episode reward:  2.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.273 [0.000, 5.000],  loss: 0.007524, mae: 0.138612, mean_q: 0.177822, mean_eps: 0.682216\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 106313/400000: episode: 377, duration: 17.904s, episode steps: 257, steps per second:  14, episode reward:  6.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.813 [0.000, 5.000],  loss: 0.005662, mae: 0.133975, mean_q: 0.171404, mean_eps: 0.681448\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 106590/400000: episode: 378, duration: 18.416s, episode steps: 277, steps per second:  15, episode reward:  5.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.007859, mae: 0.135215, mean_q: 0.172622, mean_eps: 0.680644\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 106953/400000: episode: 379, duration: 24.230s, episode steps: 363, steps per second:  15, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.788 [0.000, 5.000],  loss: 0.006479, mae: 0.135543, mean_q: 0.175761, mean_eps: 0.679684\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 107104/400000: episode: 380, duration: 9.020s, episode steps: 151, steps per second:  17, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.642 [0.000, 5.000],  loss: 0.007038, mae: 0.132568, mean_q: 0.168896, mean_eps: 0.678916\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 107219/400000: episode: 381, duration: 8.527s, episode steps: 115, steps per second:  13, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 3.070 [0.000, 5.000],  loss: 0.006894, mae: 0.136919, mean_q: 0.174053, mean_eps: 0.678520\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 107486/400000: episode: 382, duration: 17.310s, episode steps: 267, steps per second:  15, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.678 [0.000, 5.000],  loss: 0.006656, mae: 0.136319, mean_q: 0.171784, mean_eps: 0.677944\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 107687/400000: episode: 383, duration: 13.541s, episode steps: 201, steps per second:  15, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.009134, mae: 0.134151, mean_q: 0.168131, mean_eps: 0.677242\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 107824/400000: episode: 384, duration: 9.960s, episode steps: 137, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.204 [0.000, 5.000],  loss: 0.007599, mae: 0.134254, mean_q: 0.169586, mean_eps: 0.676738\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 107952/400000: episode: 385, duration: 7.948s, episode steps: 128, steps per second:  16, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.797 [0.000, 5.000],  loss: 0.006714, mae: 0.148782, mean_q: 0.190614, mean_eps: 0.676342\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 108171/400000: episode: 386, duration: 15.092s, episode steps: 219, steps per second:  15, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.005421, mae: 0.128033, mean_q: 0.161499, mean_eps: 0.675820\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 108491/400000: episode: 387, duration: 21.271s, episode steps: 320, steps per second:  15, episode reward:  5.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.007389, mae: 0.139892, mean_q: 0.175812, mean_eps: 0.675010\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 108616/400000: episode: 388, duration: 9.233s, episode steps: 125, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.648 [0.000, 5.000],  loss: 0.009107, mae: 0.141157, mean_q: 0.180359, mean_eps: 0.674344\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 108867/400000: episode: 389, duration: 16.332s, episode steps: 251, steps per second:  15, episode reward:  4.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.006014, mae: 0.125125, mean_q: 0.161177, mean_eps: 0.673780\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 109086/400000: episode: 390, duration: 14.531s, episode steps: 219, steps per second:  15, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.007711, mae: 0.142160, mean_q: 0.179224, mean_eps: 0.673072\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 109556/400000: episode: 391, duration: 30.598s, episode steps: 470, steps per second:  15, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.005769, mae: 0.132743, mean_q: 0.169184, mean_eps: 0.672040\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 110052/400000: episode: 392, duration: 33.107s, episode steps: 496, steps per second:  15, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.006266, mae: 0.135573, mean_q: 0.172050, mean_eps: 0.670594\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 110241/400000: episode: 393, duration: 12.195s, episode steps: 189, steps per second:  15, episode reward:  3.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.725 [0.000, 5.000],  loss: 0.006673, mae: 0.138262, mean_q: 0.176016, mean_eps: 0.669562\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 110462/400000: episode: 394, duration: 14.790s, episode steps: 221, steps per second:  15, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.007981, mae: 0.140453, mean_q: 0.176979, mean_eps: 0.668944\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 110655/400000: episode: 395, duration: 12.349s, episode steps: 193, steps per second:  16, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.104 [0.000, 5.000],  loss: 0.005565, mae: 0.138614, mean_q: 0.175902, mean_eps: 0.668326\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 110902/400000: episode: 396, duration: 17.704s, episode steps: 247, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.032 [0.000, 5.000],  loss: 0.008728, mae: 0.150983, mean_q: 0.194594, mean_eps: 0.667666\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 111354/400000: episode: 397, duration: 29.574s, episode steps: 452, steps per second:  15, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.836 [0.000, 5.000],  loss: 0.007007, mae: 0.148323, mean_q: 0.188425, mean_eps: 0.666616\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 111625/400000: episode: 398, duration: 17.503s, episode steps: 271, steps per second:  15, episode reward:  2.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: 0.007208, mae: 0.147888, mean_q: 0.187749, mean_eps: 0.665530\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 112631/400000: episode: 399, duration: 66.377s, episode steps: 1006, steps per second:  15, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.798 [0.000, 5.000],  loss: 0.008402, mae: 0.148143, mean_q: 0.189360, mean_eps: 0.663616\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 112903/400000: episode: 400, duration: 17.617s, episode steps: 272, steps per second:  15, episode reward:  3.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.029 [0.000, 5.000],  loss: 0.006632, mae: 0.142926, mean_q: 0.184056, mean_eps: 0.661702\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 113022/400000: episode: 401, duration: 8.894s, episode steps: 119, steps per second:  13, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.353 [0.000, 5.000],  loss: 0.009786, mae: 0.154700, mean_q: 0.192911, mean_eps: 0.661114\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 113143/400000: episode: 402, duration: 7.025s, episode steps: 121, steps per second:  17, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.289 [0.000, 5.000],  loss: 0.006906, mae: 0.137984, mean_q: 0.173374, mean_eps: 0.660754\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 113262/400000: episode: 403, duration: 8.729s, episode steps: 119, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.647 [0.000, 5.000],  loss: 0.007566, mae: 0.141203, mean_q: 0.179677, mean_eps: 0.660394\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 113508/400000: episode: 404, duration: 16.082s, episode steps: 246, steps per second:  15, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.007539, mae: 0.147294, mean_q: 0.188014, mean_eps: 0.659848\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 114019/400000: episode: 405, duration: 33.351s, episode steps: 511, steps per second:  15, episode reward: 13.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.006971, mae: 0.146257, mean_q: 0.184781, mean_eps: 0.658714\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 114263/400000: episode: 406, duration: 16.742s, episode steps: 244, steps per second:  15, episode reward:  8.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: 0.007142, mae: 0.150010, mean_q: 0.190469, mean_eps: 0.657580\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 114476/400000: episode: 407, duration: 14.170s, episode steps: 213, steps per second:  15, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.366 [0.000, 5.000],  loss: 0.006825, mae: 0.147623, mean_q: 0.188059, mean_eps: 0.656896\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 114690/400000: episode: 408, duration: 14.174s, episode steps: 214, steps per second:  15, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.911 [0.000, 5.000],  loss: 0.007314, mae: 0.145583, mean_q: 0.183644, mean_eps: 0.656254\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 114974/400000: episode: 409, duration: 18.463s, episode steps: 284, steps per second:  15, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 3.261 [0.000, 5.000],  loss: 0.007032, mae: 0.145736, mean_q: 0.185729, mean_eps: 0.655504\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 115203/400000: episode: 410, duration: 15.128s, episode steps: 229, steps per second:  15, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 1.991 [0.000, 5.000],  loss: 0.007165, mae: 0.146280, mean_q: 0.183844, mean_eps: 0.654736\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 115438/400000: episode: 411, duration: 15.436s, episode steps: 235, steps per second:  15, episode reward:  3.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.008395, mae: 0.151492, mean_q: 0.190801, mean_eps: 0.654040\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 116046/400000: episode: 412, duration: 40.539s, episode steps: 608, steps per second:  15, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.148 [0.000, 5.000],  loss: 0.007448, mae: 0.148911, mean_q: 0.187581, mean_eps: 0.652774\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 116318/400000: episode: 413, duration: 18.673s, episode steps: 272, steps per second:  15, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.239 [0.000, 5.000],  loss: 0.006624, mae: 0.145333, mean_q: 0.185562, mean_eps: 0.651454\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 116452/400000: episode: 414, duration: 8.614s, episode steps: 134, steps per second:  16, episode reward:  1.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.634 [0.000, 5.000],  loss: 0.006613, mae: 0.151159, mean_q: 0.190246, mean_eps: 0.650848\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 116571/400000: episode: 415, duration: 8.740s, episode steps: 119, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.882 [0.000, 5.000],  loss: 0.006340, mae: 0.142718, mean_q: 0.182647, mean_eps: 0.650470\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 116858/400000: episode: 416, duration: 18.471s, episode steps: 287, steps per second:  16, episode reward:  9.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.006464, mae: 0.144778, mean_q: 0.182689, mean_eps: 0.649858\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 117101/400000: episode: 417, duration: 15.885s, episode steps: 243, steps per second:  15, episode reward:  5.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.239 [0.000, 5.000],  loss: 0.006562, mae: 0.136863, mean_q: 0.171845, mean_eps: 0.649060\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 117300/400000: episode: 418, duration: 13.346s, episode steps: 199, steps per second:  15, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.809 [0.000, 5.000],  loss: 0.007307, mae: 0.142141, mean_q: 0.178410, mean_eps: 0.648400\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 117657/400000: episode: 419, duration: 24.249s, episode steps: 357, steps per second:  15, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.005940, mae: 0.145331, mean_q: 0.183735, mean_eps: 0.647566\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 118021/400000: episode: 420, duration: 24.408s, episode steps: 364, steps per second:  15, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.007707, mae: 0.149172, mean_q: 0.187434, mean_eps: 0.646480\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 118488/400000: episode: 421, duration: 30.680s, episode steps: 467, steps per second:  15, episode reward: 12.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.268 [0.000, 5.000],  loss: 0.007833, mae: 0.147228, mean_q: 0.184971, mean_eps: 0.645238\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 118689/400000: episode: 422, duration: 13.663s, episode steps: 201, steps per second:  15, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.244 [0.000, 5.000],  loss: 0.005719, mae: 0.147951, mean_q: 0.189535, mean_eps: 0.644236\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 118849/400000: episode: 423, duration: 11.143s, episode steps: 160, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.200 [0.000, 5.000],  loss: 0.008971, mae: 0.151810, mean_q: 0.189473, mean_eps: 0.643690\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 119052/400000: episode: 424, duration: 13.623s, episode steps: 203, steps per second:  15, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.008259, mae: 0.154238, mean_q: 0.194038, mean_eps: 0.643150\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 119345/400000: episode: 425, duration: 19.120s, episode steps: 293, steps per second:  15, episode reward:  6.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.007371, mae: 0.185875, mean_q: 0.233410, mean_eps: 0.642406\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 119635/400000: episode: 426, duration: 19.038s, episode steps: 290, steps per second:  15, episode reward:  5.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.008362, mae: 0.183220, mean_q: 0.231118, mean_eps: 0.641530\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 119887/400000: episode: 427, duration: 17.256s, episode steps: 252, steps per second:  15, episode reward:  5.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: 0.005900, mae: 0.176364, mean_q: 0.223861, mean_eps: 0.640720\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 120094/400000: episode: 428, duration: 13.897s, episode steps: 207, steps per second:  15, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.280 [0.000, 5.000],  loss: 0.006457, mae: 0.178309, mean_q: 0.224032, mean_eps: 0.640030\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 120303/400000: episode: 429, duration: 13.848s, episode steps: 209, steps per second:  15, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 3.182 [0.000, 5.000],  loss: 0.008320, mae: 0.178345, mean_q: 0.223866, mean_eps: 0.639406\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 120670/400000: episode: 430, duration: 23.226s, episode steps: 367, steps per second:  16, episode reward:  9.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.763 [0.000, 5.000],  loss: 0.006824, mae: 0.177778, mean_q: 0.223766, mean_eps: 0.638542\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 121289/400000: episode: 431, duration: 40.480s, episode steps: 619, steps per second:  15, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.599 [0.000, 5.000],  loss: 0.007252, mae: 0.179122, mean_q: 0.226753, mean_eps: 0.637060\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 121454/400000: episode: 432, duration: 11.246s, episode steps: 165, steps per second:  15, episode reward:  1.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 1.952 [0.000, 5.000],  loss: 0.008197, mae: 0.174908, mean_q: 0.218905, mean_eps: 0.635884\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 121742/400000: episode: 433, duration: 19.619s, episode steps: 288, steps per second:  15, episode reward:  6.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.006153, mae: 0.188231, mean_q: 0.236779, mean_eps: 0.635206\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 121972/400000: episode: 434, duration: 15.777s, episode steps: 230, steps per second:  15, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.274 [0.000, 5.000],  loss: 0.006511, mae: 0.177405, mean_q: 0.223975, mean_eps: 0.634432\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 122193/400000: episode: 435, duration: 14.827s, episode steps: 221, steps per second:  15, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.878 [0.000, 5.000],  loss: 0.006709, mae: 0.178183, mean_q: 0.223918, mean_eps: 0.633754\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 122424/400000: episode: 436, duration: 15.202s, episode steps: 231, steps per second:  15, episode reward:  7.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.007171, mae: 0.176984, mean_q: 0.224305, mean_eps: 0.633076\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 122758/400000: episode: 437, duration: 21.488s, episode steps: 334, steps per second:  16, episode reward:  8.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.057 [0.000, 5.000],  loss: 0.006944, mae: 0.177849, mean_q: 0.225315, mean_eps: 0.632230\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 122886/400000: episode: 438, duration: 8.753s, episode steps: 128, steps per second:  15, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.688 [0.000, 5.000],  loss: 0.006831, mae: 0.183401, mean_q: 0.232901, mean_eps: 0.631534\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 123413/400000: episode: 439, duration: 35.616s, episode steps: 527, steps per second:  15, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.008276, mae: 0.176151, mean_q: 0.222184, mean_eps: 0.630550\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 123606/400000: episode: 440, duration: 12.373s, episode steps: 193, steps per second:  16, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.337 [0.000, 5.000],  loss: 0.008109, mae: 0.186002, mean_q: 0.236680, mean_eps: 0.629470\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 123786/400000: episode: 441, duration: 10.934s, episode steps: 180, steps per second:  16, episode reward:  2.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.867 [0.000, 5.000],  loss: 0.007216, mae: 0.173440, mean_q: 0.223937, mean_eps: 0.628912\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 124189/400000: episode: 442, duration: 26.773s, episode steps: 403, steps per second:  15, episode reward: 13.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.233 [0.000, 5.000],  loss: 0.007792, mae: 0.176097, mean_q: 0.224892, mean_eps: 0.628036\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 124745/400000: episode: 443, duration: 37.221s, episode steps: 556, steps per second:  15, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.006846, mae: 0.179839, mean_q: 0.227602, mean_eps: 0.626596\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 125129/400000: episode: 444, duration: 25.842s, episode steps: 384, steps per second:  15, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.008429, mae: 0.186199, mean_q: 0.233780, mean_eps: 0.625186\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 125250/400000: episode: 445, duration: 7.058s, episode steps: 121, steps per second:  17, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.455 [0.000, 5.000],  loss: 0.009974, mae: 0.187186, mean_q: 0.234118, mean_eps: 0.624430\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 125782/400000: episode: 446, duration: 36.190s, episode steps: 532, steps per second:  15, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.006625, mae: 0.176774, mean_q: 0.221779, mean_eps: 0.623452\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 125983/400000: episode: 447, duration: 13.474s, episode steps: 201, steps per second:  15, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.007814, mae: 0.185591, mean_q: 0.232787, mean_eps: 0.622354\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 126306/400000: episode: 448, duration: 21.142s, episode steps: 323, steps per second:  15, episode reward:  7.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.972 [0.000, 5.000],  loss: 0.006749, mae: 0.181282, mean_q: 0.229207, mean_eps: 0.621568\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 126521/400000: episode: 449, duration: 14.576s, episode steps: 215, steps per second:  15, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.837 [0.000, 5.000],  loss: 0.006301, mae: 0.176935, mean_q: 0.223394, mean_eps: 0.620758\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 126785/400000: episode: 450, duration: 17.744s, episode steps: 264, steps per second:  15, episode reward:  2.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.280 [0.000, 5.000],  loss: 0.006361, mae: 0.178313, mean_q: 0.222738, mean_eps: 0.620038\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 127059/400000: episode: 451, duration: 17.621s, episode steps: 274, steps per second:  16, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.883 [0.000, 5.000],  loss: 0.007012, mae: 0.181481, mean_q: 0.228434, mean_eps: 0.619234\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 127259/400000: episode: 452, duration: 13.503s, episode steps: 200, steps per second:  15, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 1.760 [0.000, 5.000],  loss: 0.005157, mae: 0.179360, mean_q: 0.228265, mean_eps: 0.618526\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 127480/400000: episode: 453, duration: 14.896s, episode steps: 221, steps per second:  15, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.344 [0.000, 5.000],  loss: 0.006890, mae: 0.175138, mean_q: 0.219106, mean_eps: 0.617896\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 127694/400000: episode: 454, duration: 14.512s, episode steps: 214, steps per second:  15, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.004078, mae: 0.188233, mean_q: 0.239025, mean_eps: 0.617242\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 127910/400000: episode: 455, duration: 14.364s, episode steps: 216, steps per second:  15, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.815 [0.000, 5.000],  loss: 0.006637, mae: 0.197586, mean_q: 0.247382, mean_eps: 0.616594\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 128433/400000: episode: 456, duration: 35.088s, episode steps: 523, steps per second:  15, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.007220, mae: 0.201259, mean_q: 0.253503, mean_eps: 0.615484\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 128558/400000: episode: 457, duration: 7.293s, episode steps: 125, steps per second:  17, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.520 [0.000, 5.000],  loss: 0.008664, mae: 0.196813, mean_q: 0.246772, mean_eps: 0.614512\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 128750/400000: episode: 458, duration: 12.815s, episode steps: 192, steps per second:  15, episode reward:  3.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.693 [0.000, 5.000],  loss: 0.006449, mae: 0.193855, mean_q: 0.244651, mean_eps: 0.614038\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 129134/400000: episode: 459, duration: 25.414s, episode steps: 384, steps per second:  15, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.328 [0.000, 5.000],  loss: 0.007241, mae: 0.193963, mean_q: 0.245377, mean_eps: 0.613174\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 129791/400000: episode: 460, duration: 42.858s, episode steps: 657, steps per second:  15, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.007095, mae: 0.199075, mean_q: 0.250602, mean_eps: 0.611614\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 130029/400000: episode: 461, duration: 15.548s, episode steps: 238, steps per second:  15, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.668 [0.000, 5.000],  loss: 0.006323, mae: 0.196404, mean_q: 0.246541, mean_eps: 0.610270\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 130151/400000: episode: 462, duration: 8.651s, episode steps: 122, steps per second:  14, episode reward:  2.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.664 [0.000, 5.000],  loss: 0.010680, mae: 0.200512, mean_q: 0.253039, mean_eps: 0.609730\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 130430/400000: episode: 463, duration: 17.865s, episode steps: 279, steps per second:  16, episode reward:  3.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.240 [0.000, 5.000],  loss: 0.007062, mae: 0.200836, mean_q: 0.254839, mean_eps: 0.609130\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 130640/400000: episode: 464, duration: 14.071s, episode steps: 210, steps per second:  15, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.008866, mae: 0.197109, mean_q: 0.250218, mean_eps: 0.608398\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 130868/400000: episode: 465, duration: 15.244s, episode steps: 228, steps per second:  15, episode reward:  3.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.987 [0.000, 5.000],  loss: 0.006587, mae: 0.188670, mean_q: 0.240797, mean_eps: 0.607744\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 131056/400000: episode: 466, duration: 12.840s, episode steps: 188, steps per second:  15, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.005 [0.000, 5.000],  loss: 0.006429, mae: 0.196663, mean_q: 0.246507, mean_eps: 0.607120\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 131216/400000: episode: 467, duration: 11.276s, episode steps: 160, steps per second:  14, episode reward:  2.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.100 [0.000, 5.000],  loss: 0.005170, mae: 0.192759, mean_q: 0.241051, mean_eps: 0.606598\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 131487/400000: episode: 468, duration: 17.523s, episode steps: 271, steps per second:  15, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.103 [0.000, 5.000],  loss: 0.006468, mae: 0.195366, mean_q: 0.244587, mean_eps: 0.605950\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 131691/400000: episode: 469, duration: 13.521s, episode steps: 204, steps per second:  15, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.010232, mae: 0.210219, mean_q: 0.265879, mean_eps: 0.605236\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 131967/400000: episode: 470, duration: 19.270s, episode steps: 276, steps per second:  14, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.006680, mae: 0.196831, mean_q: 0.249168, mean_eps: 0.604516\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 132097/400000: episode: 471, duration: 7.763s, episode steps: 130, steps per second:  17, episode reward:  1.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.869 [0.000, 5.000],  loss: 0.007311, mae: 0.197515, mean_q: 0.248317, mean_eps: 0.603904\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 132355/400000: episode: 472, duration: 18.222s, episode steps: 258, steps per second:  14, episode reward:  6.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: 0.007566, mae: 0.197853, mean_q: 0.250604, mean_eps: 0.603322\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 132580/400000: episode: 473, duration: 14.989s, episode steps: 225, steps per second:  15, episode reward:  3.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.862 [0.000, 5.000],  loss: 0.008161, mae: 0.195915, mean_q: 0.246495, mean_eps: 0.602602\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 132998/400000: episode: 474, duration: 27.803s, episode steps: 418, steps per second:  15, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.077 [0.000, 5.000],  loss: 0.007543, mae: 0.193711, mean_q: 0.242397, mean_eps: 0.601636\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 133242/400000: episode: 475, duration: 15.987s, episode steps: 244, steps per second:  15, episode reward:  5.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.007851, mae: 0.201073, mean_q: 0.253306, mean_eps: 0.600640\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 133446/400000: episode: 476, duration: 13.592s, episode steps: 204, steps per second:  15, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.108 [0.000, 5.000],  loss: 0.006463, mae: 0.191185, mean_q: 0.240443, mean_eps: 0.599968\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 133598/400000: episode: 477, duration: 10.646s, episode steps: 152, steps per second:  14, episode reward:  1.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.257 [0.000, 5.000],  loss: 0.008343, mae: 0.205613, mean_q: 0.258531, mean_eps: 0.599434\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 133810/400000: episode: 478, duration: 14.281s, episode steps: 212, steps per second:  15, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: 0.006816, mae: 0.192487, mean_q: 0.239695, mean_eps: 0.598888\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 134078/400000: episode: 479, duration: 17.440s, episode steps: 268, steps per second:  15, episode reward:  3.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.142 [0.000, 5.000],  loss: 0.007978, mae: 0.205051, mean_q: 0.255119, mean_eps: 0.598168\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 134519/400000: episode: 480, duration: 29.075s, episode steps: 441, steps per second:  15, episode reward: 13.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.789 [0.000, 5.000],  loss: 0.008259, mae: 0.199888, mean_q: 0.249319, mean_eps: 0.597106\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 134803/400000: episode: 481, duration: 18.464s, episode steps: 284, steps per second:  15, episode reward:  5.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.006077, mae: 0.191197, mean_q: 0.240264, mean_eps: 0.596020\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 134919/400000: episode: 482, duration: 8.584s, episode steps: 116, steps per second:  14, episode reward:  1.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.086 [0.000, 5.000],  loss: 0.008796, mae: 0.199633, mean_q: 0.248423, mean_eps: 0.595420\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 135045/400000: episode: 483, duration: 9.204s, episode steps: 126, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.738 [0.000, 5.000],  loss: 0.007083, mae: 0.192681, mean_q: 0.241856, mean_eps: 0.595054\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 135164/400000: episode: 484, duration: 7.321s, episode steps: 119, steps per second:  16, episode reward:  1.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.647 [0.000, 5.000],  loss: 0.011130, mae: 0.199054, mean_q: 0.247256, mean_eps: 0.594688\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 135280/400000: episode: 485, duration: 8.881s, episode steps: 116, steps per second:  13, episode reward:  1.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.681 [0.000, 5.000],  loss: 0.006413, mae: 0.193316, mean_q: 0.243338, mean_eps: 0.594340\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 135503/400000: episode: 486, duration: 14.861s, episode steps: 223, steps per second:  15, episode reward:  5.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.848 [0.000, 5.000],  loss: 0.010204, mae: 0.209067, mean_q: 0.259633, mean_eps: 0.593830\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 135786/400000: episode: 487, duration: 18.408s, episode steps: 283, steps per second:  15, episode reward:  6.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.774 [0.000, 5.000],  loss: 0.008320, mae: 0.197781, mean_q: 0.247845, mean_eps: 0.593068\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 135980/400000: episode: 488, duration: 13.181s, episode steps: 194, steps per second:  15, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 3.088 [0.000, 5.000],  loss: 0.005334, mae: 0.189537, mean_q: 0.236270, mean_eps: 0.592354\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 136540/400000: episode: 489, duration: 38.218s, episode steps: 560, steps per second:  15, episode reward: 13.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.304 [0.000, 5.000],  loss: 0.008329, mae: 0.223929, mean_q: 0.280179, mean_eps: 0.591226\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 136852/400000: episode: 490, duration: 20.777s, episode steps: 312, steps per second:  15, episode reward:  3.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.008562, mae: 0.233598, mean_q: 0.291678, mean_eps: 0.589918\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 137057/400000: episode: 491, duration: 13.679s, episode steps: 205, steps per second:  15, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.868 [0.000, 5.000],  loss: 0.009614, mae: 0.231848, mean_q: 0.289801, mean_eps: 0.589138\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 137289/400000: episode: 492, duration: 16.141s, episode steps: 232, steps per second:  14, episode reward:  4.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.007544, mae: 0.222492, mean_q: 0.277739, mean_eps: 0.588478\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 137404/400000: episode: 493, duration: 6.990s, episode steps: 115, steps per second:  16, episode reward:  1.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.843 [0.000, 5.000],  loss: 0.006588, mae: 0.225046, mean_q: 0.283712, mean_eps: 0.587962\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 137625/400000: episode: 494, duration: 14.814s, episode steps: 221, steps per second:  15, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.006336, mae: 0.223743, mean_q: 0.282962, mean_eps: 0.587458\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 138216/400000: episode: 495, duration: 39.186s, episode steps: 591, steps per second:  15, episode reward: 15.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.006713, mae: 0.230320, mean_q: 0.288803, mean_eps: 0.586240\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 138485/400000: episode: 496, duration: 17.570s, episode steps: 269, steps per second:  15, episode reward:  7.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.677 [0.000, 5.000],  loss: 0.006316, mae: 0.222824, mean_q: 0.278418, mean_eps: 0.584950\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 138748/400000: episode: 497, duration: 18.881s, episode steps: 263, steps per second:  14, episode reward:  5.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.006698, mae: 0.223311, mean_q: 0.278752, mean_eps: 0.584152\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 139433/400000: episode: 498, duration: 44.990s, episode steps: 685, steps per second:  15, episode reward: 19.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.784 [0.000, 5.000],  loss: 0.006960, mae: 0.223052, mean_q: 0.279368, mean_eps: 0.582730\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 139548/400000: episode: 499, duration: 7.170s, episode steps: 115, steps per second:  16, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 3.443 [0.000, 5.000],  loss: 0.008765, mae: 0.219718, mean_q: 0.276466, mean_eps: 0.581530\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 139744/400000: episode: 500, duration: 13.219s, episode steps: 196, steps per second:  15, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.240 [0.000, 5.000],  loss: 0.007224, mae: 0.226106, mean_q: 0.281905, mean_eps: 0.581068\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 140161/400000: episode: 501, duration: 28.146s, episode steps: 417, steps per second:  15, episode reward:  9.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.628 [0.000, 5.000],  loss: 0.007321, mae: 0.226580, mean_q: 0.282198, mean_eps: 0.580144\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 140396/400000: episode: 502, duration: 16.831s, episode steps: 235, steps per second:  14, episode reward:  1.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.230 [0.000, 5.000],  loss: 0.009139, mae: 0.232327, mean_q: 0.289480, mean_eps: 0.579166\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 140610/400000: episode: 503, duration: 14.402s, episode steps: 214, steps per second:  15, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.271 [0.000, 5.000],  loss: 0.007424, mae: 0.224627, mean_q: 0.278883, mean_eps: 0.578494\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 141032/400000: episode: 504, duration: 27.977s, episode steps: 422, steps per second:  15, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.853 [0.000, 5.000],  loss: 0.007491, mae: 0.227043, mean_q: 0.282704, mean_eps: 0.577540\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 141498/400000: episode: 505, duration: 30.748s, episode steps: 466, steps per second:  15, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.955 [0.000, 5.000],  loss: 0.008032, mae: 0.228493, mean_q: 0.285331, mean_eps: 0.576208\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 141691/400000: episode: 506, duration: 13.105s, episode steps: 193, steps per second:  15, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.130 [0.000, 5.000],  loss: 0.008394, mae: 0.232397, mean_q: 0.288203, mean_eps: 0.575218\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 142102/400000: episode: 507, duration: 27.509s, episode steps: 411, steps per second:  15, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.776 [0.000, 5.000],  loss: 0.007004, mae: 0.217606, mean_q: 0.272251, mean_eps: 0.574312\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 142497/400000: episode: 508, duration: 26.544s, episode steps: 395, steps per second:  15, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.699 [0.000, 5.000],  loss: 0.007782, mae: 0.227745, mean_q: 0.283298, mean_eps: 0.573100\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 142745/400000: episode: 509, duration: 16.292s, episode steps: 248, steps per second:  15, episode reward:  3.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: 0.009178, mae: 0.220919, mean_q: 0.275853, mean_eps: 0.572134\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 142988/400000: episode: 510, duration: 16.135s, episode steps: 243, steps per second:  15, episode reward:  5.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.691 [0.000, 5.000],  loss: 0.008112, mae: 0.227101, mean_q: 0.282000, mean_eps: 0.571402\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 143188/400000: episode: 511, duration: 13.678s, episode steps: 200, steps per second:  15, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.775 [0.000, 5.000],  loss: 0.009436, mae: 0.237924, mean_q: 0.294967, mean_eps: 0.570742\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 143354/400000: episode: 512, duration: 11.737s, episode steps: 166, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.229 [0.000, 5.000],  loss: 0.007294, mae: 0.231232, mean_q: 0.287291, mean_eps: 0.570190\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 143751/400000: episode: 513, duration: 26.333s, episode steps: 397, steps per second:  15, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.007975, mae: 0.226655, mean_q: 0.281964, mean_eps: 0.569344\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 143953/400000: episode: 514, duration: 13.586s, episode steps: 202, steps per second:  15, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.337 [0.000, 5.000],  loss: 0.006941, mae: 0.219319, mean_q: 0.274456, mean_eps: 0.568444\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 144157/400000: episode: 515, duration: 13.580s, episode steps: 204, steps per second:  15, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.779 [0.000, 5.000],  loss: 0.008519, mae: 0.223796, mean_q: 0.278750, mean_eps: 0.567832\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 144417/400000: episode: 516, duration: 16.780s, episode steps: 260, steps per second:  15, episode reward:  6.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 3.008 [0.000, 5.000],  loss: 0.007699, mae: 0.226410, mean_q: 0.284865, mean_eps: 0.567136\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 144838/400000: episode: 517, duration: 27.734s, episode steps: 421, steps per second:  15, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.748 [0.000, 5.000],  loss: 0.008180, mae: 0.243456, mean_q: 0.304547, mean_eps: 0.566116\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 145059/400000: episode: 518, duration: 14.702s, episode steps: 221, steps per second:  15, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.919 [0.000, 5.000],  loss: 0.008072, mae: 0.247471, mean_q: 0.309620, mean_eps: 0.565156\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 145304/400000: episode: 519, duration: 16.189s, episode steps: 245, steps per second:  15, episode reward:  3.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.290 [0.000, 5.000],  loss: 0.007553, mae: 0.246914, mean_q: 0.308966, mean_eps: 0.564460\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 145513/400000: episode: 520, duration: 14.122s, episode steps: 209, steps per second:  15, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.115 [0.000, 5.000],  loss: 0.008131, mae: 0.246835, mean_q: 0.308291, mean_eps: 0.563776\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 145730/400000: episode: 521, duration: 14.471s, episode steps: 217, steps per second:  15, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.008924, mae: 0.252635, mean_q: 0.315322, mean_eps: 0.563134\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 146239/400000: episode: 522, duration: 34.747s, episode steps: 509, steps per second:  15, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.008252, mae: 0.242397, mean_q: 0.302619, mean_eps: 0.562048\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 146366/400000: episode: 523, duration: 8.552s, episode steps: 127, steps per second:  15, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.961 [0.000, 5.000],  loss: 0.007606, mae: 0.233173, mean_q: 0.291583, mean_eps: 0.561094\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 146569/400000: episode: 524, duration: 13.663s, episode steps: 203, steps per second:  15, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.990 [0.000, 5.000],  loss: 0.006708, mae: 0.245251, mean_q: 0.306715, mean_eps: 0.560596\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 146788/400000: episode: 525, duration: 15.217s, episode steps: 219, steps per second:  14, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.007156, mae: 0.227745, mean_q: 0.285603, mean_eps: 0.559966\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 147034/400000: episode: 526, duration: 16.374s, episode steps: 246, steps per second:  15, episode reward:  5.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.772 [0.000, 5.000],  loss: 0.006654, mae: 0.245625, mean_q: 0.305893, mean_eps: 0.559270\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 147151/400000: episode: 527, duration: 6.889s, episode steps: 117, steps per second:  17, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.530 [0.000, 5.000],  loss: 0.005543, mae: 0.231883, mean_q: 0.288093, mean_eps: 0.558724\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 147346/400000: episode: 528, duration: 13.131s, episode steps: 195, steps per second:  15, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.236 [0.000, 5.000],  loss: 0.009581, mae: 0.251572, mean_q: 0.311851, mean_eps: 0.558256\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 147561/400000: episode: 529, duration: 14.332s, episode steps: 215, steps per second:  15, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.163 [0.000, 5.000],  loss: 0.007764, mae: 0.238695, mean_q: 0.297608, mean_eps: 0.557638\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 147778/400000: episode: 530, duration: 14.347s, episode steps: 217, steps per second:  15, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 1.963 [0.000, 5.000],  loss: 0.006693, mae: 0.226906, mean_q: 0.283433, mean_eps: 0.556990\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 148003/400000: episode: 531, duration: 15.320s, episode steps: 225, steps per second:  15, episode reward:  3.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.008568, mae: 0.240830, mean_q: 0.301139, mean_eps: 0.556330\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 148259/400000: episode: 532, duration: 17.719s, episode steps: 256, steps per second:  14, episode reward:  5.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.133 [0.000, 5.000],  loss: 0.006198, mae: 0.238507, mean_q: 0.298593, mean_eps: 0.555610\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 148817/400000: episode: 533, duration: 35.632s, episode steps: 558, steps per second:  16, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.008732, mae: 0.239014, mean_q: 0.298444, mean_eps: 0.554386\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 149004/400000: episode: 534, duration: 12.685s, episode steps: 187, steps per second:  15, episode reward:  6.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.007464, mae: 0.246993, mean_q: 0.308215, mean_eps: 0.553270\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 149384/400000: episode: 535, duration: 25.996s, episode steps: 380, steps per second:  15, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.687 [0.000, 5.000],  loss: 0.008337, mae: 0.245301, mean_q: 0.307544, mean_eps: 0.552424\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 149557/400000: episode: 536, duration: 12.107s, episode steps: 173, steps per second:  14, episode reward:  3.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.879 [0.000, 5.000],  loss: 0.009615, mae: 0.246353, mean_q: 0.306637, mean_eps: 0.551590\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 149954/400000: episode: 537, duration: 26.669s, episode steps: 397, steps per second:  15, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.929 [0.000, 5.000],  loss: 0.008541, mae: 0.245788, mean_q: 0.306691, mean_eps: 0.550732\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 150246/400000: episode: 538, duration: 18.849s, episode steps: 292, steps per second:  15, episode reward:  6.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.661 [0.000, 5.000],  loss: 0.008430, mae: 0.241811, mean_q: 0.300668, mean_eps: 0.549700\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 150527/400000: episode: 539, duration: 19.781s, episode steps: 281, steps per second:  14, episode reward:  8.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.107 [0.000, 5.000],  loss: 0.009200, mae: 0.235038, mean_q: 0.292453, mean_eps: 0.548842\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 150823/400000: episode: 540, duration: 19.018s, episode steps: 296, steps per second:  16, episode reward:  4.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.794 [0.000, 5.000],  loss: 0.007177, mae: 0.236496, mean_q: 0.298456, mean_eps: 0.547978\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 150938/400000: episode: 541, duration: 8.530s, episode steps: 115, steps per second:  13, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.983 [0.000, 5.000],  loss: 0.006789, mae: 0.235817, mean_q: 0.297525, mean_eps: 0.547360\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 151420/400000: episode: 542, duration: 31.826s, episode steps: 482, steps per second:  15, episode reward: 13.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.834 [0.000, 5.000],  loss: 0.007374, mae: 0.244529, mean_q: 0.305260, mean_eps: 0.546466\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 151653/400000: episode: 543, duration: 15.514s, episode steps: 233, steps per second:  15, episode reward:  4.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.206 [0.000, 5.000],  loss: 0.007399, mae: 0.248151, mean_q: 0.309591, mean_eps: 0.545392\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 151772/400000: episode: 544, duration: 8.738s, episode steps: 119, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.866 [0.000, 5.000],  loss: 0.008490, mae: 0.238973, mean_q: 0.297169, mean_eps: 0.544864\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 151985/400000: episode: 545, duration: 14.254s, episode steps: 213, steps per second:  15, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.817 [0.000, 5.000],  loss: 0.008315, mae: 0.239418, mean_q: 0.298218, mean_eps: 0.544366\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 152211/400000: episode: 546, duration: 14.690s, episode steps: 226, steps per second:  15, episode reward:  3.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.708 [0.000, 5.000],  loss: 0.007909, mae: 0.245392, mean_q: 0.304733, mean_eps: 0.543706\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 152526/400000: episode: 547, duration: 20.510s, episode steps: 315, steps per second:  15, episode reward:  5.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.007864, mae: 0.236454, mean_q: 0.295661, mean_eps: 0.542896\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 152745/400000: episode: 548, duration: 15.012s, episode steps: 219, steps per second:  15, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.863 [0.000, 5.000],  loss: 0.008517, mae: 0.241567, mean_q: 0.302782, mean_eps: 0.542092\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 153023/400000: episode: 549, duration: 18.724s, episode steps: 278, steps per second:  15, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.007652, mae: 0.238759, mean_q: 0.300032, mean_eps: 0.541348\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 153199/400000: episode: 550, duration: 11.979s, episode steps: 176, steps per second:  15, episode reward:  3.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.631 [0.000, 5.000],  loss: 0.007978, mae: 0.265188, mean_q: 0.330495, mean_eps: 0.540670\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 153498/400000: episode: 551, duration: 19.217s, episode steps: 299, steps per second:  16, episode reward:  6.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.020 [0.000, 5.000],  loss: 0.008183, mae: 0.253429, mean_q: 0.315764, mean_eps: 0.539956\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 153765/400000: episode: 552, duration: 17.483s, episode steps: 267, steps per second:  15, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 3.052 [0.000, 5.000],  loss: 0.009031, mae: 0.266786, mean_q: 0.334359, mean_eps: 0.539104\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 153982/400000: episode: 553, duration: 14.659s, episode steps: 217, steps per second:  15, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.078 [0.000, 5.000],  loss: 0.006677, mae: 0.253828, mean_q: 0.315523, mean_eps: 0.538378\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 154201/400000: episode: 554, duration: 15.216s, episode steps: 219, steps per second:  14, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.689 [0.000, 5.000],  loss: 0.009848, mae: 0.261029, mean_q: 0.323460, mean_eps: 0.537724\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 154465/400000: episode: 555, duration: 17.742s, episode steps: 264, steps per second:  15, episode reward:  7.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 1.905 [0.000, 5.000],  loss: 0.007794, mae: 0.250490, mean_q: 0.312533, mean_eps: 0.536998\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 154658/400000: episode: 556, duration: 13.385s, episode steps: 193, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.824 [0.000, 5.000],  loss: 0.006644, mae: 0.249963, mean_q: 0.311888, mean_eps: 0.536314\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 154956/400000: episode: 557, duration: 19.458s, episode steps: 298, steps per second:  15, episode reward:  4.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.336 [0.000, 5.000],  loss: 0.009590, mae: 0.258786, mean_q: 0.321203, mean_eps: 0.535582\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 155217/400000: episode: 558, duration: 18.280s, episode steps: 261, steps per second:  14, episode reward:  6.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.234 [0.000, 5.000],  loss: 0.008501, mae: 0.264164, mean_q: 0.329592, mean_eps: 0.534742\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 155413/400000: episode: 559, duration: 12.792s, episode steps: 196, steps per second:  15, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.006964, mae: 0.250667, mean_q: 0.313758, mean_eps: 0.534052\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 155685/400000: episode: 560, duration: 18.782s, episode steps: 272, steps per second:  14, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.147 [0.000, 5.000],  loss: 0.006901, mae: 0.248140, mean_q: 0.309788, mean_eps: 0.533350\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 155944/400000: episode: 561, duration: 17.074s, episode steps: 259, steps per second:  15, episode reward:  3.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.290 [0.000, 5.000],  loss: 0.007098, mae: 0.259804, mean_q: 0.322411, mean_eps: 0.532558\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 156177/400000: episode: 562, duration: 15.628s, episode steps: 233, steps per second:  15, episode reward:  3.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.107 [0.000, 5.000],  loss: 0.009726, mae: 0.260690, mean_q: 0.322294, mean_eps: 0.531820\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 156394/400000: episode: 563, duration: 14.681s, episode steps: 217, steps per second:  15, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.226 [0.000, 5.000],  loss: 0.010509, mae: 0.264797, mean_q: 0.330830, mean_eps: 0.531142\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 156671/400000: episode: 564, duration: 19.728s, episode steps: 277, steps per second:  14, episode reward:  5.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.697 [0.000, 5.000],  loss: 0.007994, mae: 0.250454, mean_q: 0.314695, mean_eps: 0.530404\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 156900/400000: episode: 565, duration: 15.538s, episode steps: 229, steps per second:  15, episode reward:  3.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.978 [0.000, 5.000],  loss: 0.007552, mae: 0.245848, mean_q: 0.306393, mean_eps: 0.529648\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 157075/400000: episode: 566, duration: 12.141s, episode steps: 175, steps per second:  14, episode reward:  3.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.869 [0.000, 5.000],  loss: 0.006822, mae: 0.260633, mean_q: 0.325296, mean_eps: 0.529042\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 157285/400000: episode: 567, duration: 14.300s, episode steps: 210, steps per second:  15, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.929 [0.000, 5.000],  loss: 0.007643, mae: 0.253787, mean_q: 0.315126, mean_eps: 0.528460\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 157791/400000: episode: 568, duration: 33.102s, episode steps: 506, steps per second:  15, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: 0.009118, mae: 0.256957, mean_q: 0.320558, mean_eps: 0.527386\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 158008/400000: episode: 569, duration: 14.646s, episode steps: 217, steps per second:  15, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.008817, mae: 0.256957, mean_q: 0.322512, mean_eps: 0.526306\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 158315/400000: episode: 570, duration: 21.423s, episode steps: 307, steps per second:  14, episode reward:  5.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.283 [0.000, 5.000],  loss: 0.007526, mae: 0.253607, mean_q: 0.316225, mean_eps: 0.525520\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 158612/400000: episode: 571, duration: 19.396s, episode steps: 297, steps per second:  15, episode reward:  5.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.098 [0.000, 5.000],  loss: 0.008039, mae: 0.254092, mean_q: 0.316448, mean_eps: 0.524614\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 159197/400000: episode: 572, duration: 39.444s, episode steps: 585, steps per second:  15, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.289 [0.000, 5.000],  loss: 0.008152, mae: 0.252391, mean_q: 0.314664, mean_eps: 0.523288\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 159407/400000: episode: 573, duration: 13.986s, episode steps: 210, steps per second:  15, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 3.014 [0.000, 5.000],  loss: 0.008094, mae: 0.253862, mean_q: 0.316838, mean_eps: 0.522094\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 159775/400000: episode: 574, duration: 25.025s, episode steps: 368, steps per second:  15, episode reward:  8.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.698 [0.000, 5.000],  loss: 0.009248, mae: 0.261225, mean_q: 0.323635, mean_eps: 0.521230\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 160002/400000: episode: 575, duration: 15.033s, episode steps: 227, steps per second:  15, episode reward:  5.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.718 [0.000, 5.000],  loss: 0.009668, mae: 0.257966, mean_q: 0.327298, mean_eps: 0.520336\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 160129/400000: episode: 576, duration: 8.286s, episode steps: 127, steps per second:  15, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.354 [0.000, 5.000],  loss: 0.009317, mae: 0.263099, mean_q: 0.330542, mean_eps: 0.519802\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 160402/400000: episode: 577, duration: 18.744s, episode steps: 273, steps per second:  15, episode reward:  7.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.007223, mae: 0.259189, mean_q: 0.328030, mean_eps: 0.519202\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 160624/400000: episode: 578, duration: 14.790s, episode steps: 222, steps per second:  15, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.757 [0.000, 5.000],  loss: 0.008313, mae: 0.251450, mean_q: 0.313061, mean_eps: 0.518464\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 160741/400000: episode: 579, duration: 7.664s, episode steps: 117, steps per second:  15, episode reward:  1.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 3.034 [0.000, 5.000],  loss: 0.006997, mae: 0.252457, mean_q: 0.316312, mean_eps: 0.517954\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 160993/400000: episode: 580, duration: 17.697s, episode steps: 252, steps per second:  14, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 3.052 [0.000, 5.000],  loss: 0.008257, mae: 0.249409, mean_q: 0.312250, mean_eps: 0.517396\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 161236/400000: episode: 581, duration: 16.068s, episode steps: 243, steps per second:  15, episode reward:  4.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.951 [0.000, 5.000],  loss: 0.008598, mae: 0.250366, mean_q: 0.312664, mean_eps: 0.516658\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 161379/400000: episode: 582, duration: 10.467s, episode steps: 143, steps per second:  14, episode reward:  1.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.734 [0.000, 5.000],  loss: 0.007053, mae: 0.255701, mean_q: 0.318915, mean_eps: 0.516082\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 161491/400000: episode: 583, duration: 6.792s, episode steps: 112, steps per second:  16, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.857 [0.000, 5.000],  loss: 0.006686, mae: 0.242720, mean_q: 0.303323, mean_eps: 0.515698\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 161715/400000: episode: 584, duration: 15.286s, episode steps: 224, steps per second:  15, episode reward:  5.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.008963, mae: 0.294167, mean_q: 0.368045, mean_eps: 0.515194\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 161963/400000: episode: 585, duration: 17.519s, episode steps: 248, steps per second:  14, episode reward:  4.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.677 [0.000, 5.000],  loss: 0.010118, mae: 0.306106, mean_q: 0.383103, mean_eps: 0.514486\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 162321/400000: episode: 586, duration: 23.760s, episode steps: 358, steps per second:  15, episode reward:  6.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.358 [0.000, 5.000],  loss: 0.009477, mae: 0.291480, mean_q: 0.366451, mean_eps: 0.513574\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 162591/400000: episode: 587, duration: 18.851s, episode steps: 270, steps per second:  14, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.007713, mae: 0.293052, mean_q: 0.367539, mean_eps: 0.512632\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 162811/400000: episode: 588, duration: 15.025s, episode steps: 220, steps per second:  15, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.336 [0.000, 5.000],  loss: 0.008866, mae: 0.302861, mean_q: 0.379874, mean_eps: 0.511900\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 162962/400000: episode: 589, duration: 9.038s, episode steps: 151, steps per second:  17, episode reward:  2.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.901 [0.000, 5.000],  loss: 0.011277, mae: 0.315718, mean_q: 0.394727, mean_eps: 0.511342\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 163170/400000: episode: 590, duration: 14.311s, episode steps: 208, steps per second:  15, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 1.538 [0.000, 5.000],  loss: 0.008475, mae: 0.300364, mean_q: 0.378483, mean_eps: 0.510802\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 163411/400000: episode: 591, duration: 17.731s, episode steps: 241, steps per second:  14, episode reward:  6.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.195 [0.000, 5.000],  loss: 0.009317, mae: 0.305527, mean_q: 0.384062, mean_eps: 0.510130\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 163612/400000: episode: 592, duration: 14.014s, episode steps: 201, steps per second:  14, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: 0.007730, mae: 0.290214, mean_q: 0.361931, mean_eps: 0.509470\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 163860/400000: episode: 593, duration: 16.917s, episode steps: 248, steps per second:  15, episode reward:  5.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.254 [0.000, 5.000],  loss: 0.006563, mae: 0.294708, mean_q: 0.368352, mean_eps: 0.508798\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 163977/400000: episode: 594, duration: 7.984s, episode steps: 117, steps per second:  15, episode reward:  1.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.111 [0.000, 5.000],  loss: 0.006712, mae: 0.287706, mean_q: 0.358735, mean_eps: 0.508246\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 164132/400000: episode: 595, duration: 10.618s, episode steps: 155, steps per second:  15, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.110 [0.000, 5.000],  loss: 0.009288, mae: 0.316426, mean_q: 0.393653, mean_eps: 0.507838\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 164392/400000: episode: 596, duration: 19.049s, episode steps: 260, steps per second:  14, episode reward:  7.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.969 [0.000, 5.000],  loss: 0.007295, mae: 0.292757, mean_q: 0.365583, mean_eps: 0.507220\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 164968/400000: episode: 597, duration: 38.153s, episode steps: 576, steps per second:  15, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.727 [0.000, 5.000],  loss: 0.008201, mae: 0.295547, mean_q: 0.369602, mean_eps: 0.505966\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 165494/400000: episode: 598, duration: 36.054s, episode steps: 526, steps per second:  15, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.008691, mae: 0.297030, mean_q: 0.371115, mean_eps: 0.504310\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 165721/400000: episode: 599, duration: 15.299s, episode steps: 227, steps per second:  15, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.211 [0.000, 5.000],  loss: 0.007674, mae: 0.304581, mean_q: 0.380811, mean_eps: 0.503176\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 165993/400000: episode: 600, duration: 18.127s, episode steps: 272, steps per second:  15, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.805 [0.000, 5.000],  loss: 0.009268, mae: 0.297833, mean_q: 0.372586, mean_eps: 0.502426\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 166314/400000: episode: 601, duration: 22.227s, episode steps: 321, steps per second:  14, episode reward:  5.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.193 [0.000, 5.000],  loss: 0.007237, mae: 0.299955, mean_q: 0.376980, mean_eps: 0.501538\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 166546/400000: episode: 602, duration: 15.432s, episode steps: 232, steps per second:  15, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.007422, mae: 0.299815, mean_q: 0.375289, mean_eps: 0.500710\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 166789/400000: episode: 603, duration: 16.500s, episode steps: 243, steps per second:  15, episode reward:  3.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 3.025 [0.000, 5.000],  loss: 0.007758, mae: 0.299881, mean_q: 0.374584, mean_eps: 0.499996\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 167057/400000: episode: 604, duration: 19.221s, episode steps: 268, steps per second:  14, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.914 [0.000, 5.000],  loss: 0.008269, mae: 0.296694, mean_q: 0.371808, mean_eps: 0.499228\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 167186/400000: episode: 605, duration: 7.650s, episode steps: 129, steps per second:  17, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 3.287 [0.000, 5.000],  loss: 0.010086, mae: 0.292510, mean_q: 0.363351, mean_eps: 0.498634\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 167318/400000: episode: 606, duration: 9.515s, episode steps: 132, steps per second:  14, episode reward:  1.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 3.152 [0.000, 5.000],  loss: 0.007205, mae: 0.301360, mean_q: 0.374492, mean_eps: 0.498244\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 167431/400000: episode: 607, duration: 7.510s, episode steps: 113, steps per second:  15, episode reward:  1.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 1.912 [0.000, 5.000],  loss: 0.008487, mae: 0.295884, mean_q: 0.367546, mean_eps: 0.497878\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 167578/400000: episode: 608, duration: 9.662s, episode steps: 147, steps per second:  15, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.020 [0.000, 5.000],  loss: 0.009190, mae: 0.301002, mean_q: 0.375236, mean_eps: 0.497488\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 167800/400000: episode: 609, duration: 14.859s, episode steps: 222, steps per second:  15, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.270 [0.000, 5.000],  loss: 0.008843, mae: 0.295388, mean_q: 0.365278, mean_eps: 0.496936\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 167958/400000: episode: 610, duration: 11.232s, episode steps: 158, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.259 [0.000, 5.000],  loss: 0.008343, mae: 0.299419, mean_q: 0.372243, mean_eps: 0.496366\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 168248/400000: episode: 611, duration: 19.802s, episode steps: 290, steps per second:  15, episode reward:  6.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.883 [0.000, 5.000],  loss: 0.008418, mae: 0.293489, mean_q: 0.365003, mean_eps: 0.495694\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 168456/400000: episode: 612, duration: 14.454s, episode steps: 208, steps per second:  14, episode reward:  6.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.260 [0.000, 5.000],  loss: 0.009218, mae: 0.301923, mean_q: 0.375404, mean_eps: 0.494950\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 168667/400000: episode: 613, duration: 14.834s, episode steps: 211, steps per second:  14, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.682 [0.000, 5.000],  loss: 0.007466, mae: 0.291908, mean_q: 0.363473, mean_eps: 0.494320\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 168816/400000: episode: 614, duration: 9.277s, episode steps: 149, steps per second:  16, episode reward:  1.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.832 [0.000, 5.000],  loss: 0.009465, mae: 0.302214, mean_q: 0.373531, mean_eps: 0.493780\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 168934/400000: episode: 615, duration: 8.964s, episode steps: 118, steps per second:  13, episode reward:  1.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 3.161 [0.000, 5.000],  loss: 0.009752, mae: 0.304575, mean_q: 0.377287, mean_eps: 0.493378\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 169057/400000: episode: 616, duration: 8.689s, episode steps: 123, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.398 [0.000, 5.000],  loss: 0.008475, mae: 0.293847, mean_q: 0.364064, mean_eps: 0.493012\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 169379/400000: episode: 617, duration: 21.257s, episode steps: 322, steps per second:  15, episode reward:  6.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.009444, mae: 0.302650, mean_q: 0.375081, mean_eps: 0.492346\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 169495/400000: episode: 618, duration: 8.577s, episode steps: 116, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.819 [0.000, 5.000],  loss: 0.007720, mae: 0.289387, mean_q: 0.360511, mean_eps: 0.491692\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 169710/400000: episode: 619, duration: 14.588s, episode steps: 215, steps per second:  15, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.809 [0.000, 5.000],  loss: 0.007039, mae: 0.291252, mean_q: 0.363154, mean_eps: 0.491194\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 169932/400000: episode: 620, duration: 15.111s, episode steps: 222, steps per second:  15, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 3.153 [0.000, 5.000],  loss: 0.007412, mae: 0.298199, mean_q: 0.370705, mean_eps: 0.490540\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 170047/400000: episode: 621, duration: 7.339s, episode steps: 115, steps per second:  16, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.713 [0.000, 5.000],  loss: 0.008934, mae: 0.322717, mean_q: 0.397054, mean_eps: 0.490036\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 170763/400000: episode: 622, duration: 49.323s, episode steps: 716, steps per second:  15, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: 0.009220, mae: 0.339079, mean_q: 0.419510, mean_eps: 0.488788\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 171047/400000: episode: 623, duration: 18.894s, episode steps: 284, steps per second:  15, episode reward:  4.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.008935, mae: 0.324913, mean_q: 0.400659, mean_eps: 0.487288\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 171416/400000: episode: 624, duration: 25.854s, episode steps: 369, steps per second:  14, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.640 [0.000, 5.000],  loss: 0.008699, mae: 0.333974, mean_q: 0.414638, mean_eps: 0.486310\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 171628/400000: episode: 625, duration: 14.674s, episode steps: 212, steps per second:  14, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.010689, mae: 0.321995, mean_q: 0.398344, mean_eps: 0.485440\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 171870/400000: episode: 626, duration: 16.831s, episode steps: 242, steps per second:  14, episode reward:  4.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.215 [0.000, 5.000],  loss: 0.008928, mae: 0.351193, mean_q: 0.438168, mean_eps: 0.484756\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 172013/400000: episode: 627, duration: 9.911s, episode steps: 143, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.783 [0.000, 5.000],  loss: 0.008105, mae: 0.342875, mean_q: 0.427560, mean_eps: 0.484174\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 172128/400000: episode: 628, duration: 8.769s, episode steps: 115, steps per second:  13, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.400 [0.000, 5.000],  loss: 0.008812, mae: 0.324316, mean_q: 0.404267, mean_eps: 0.483790\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 172345/400000: episode: 629, duration: 14.886s, episode steps: 217, steps per second:  15, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 3.120 [0.000, 5.000],  loss: 0.009057, mae: 0.332149, mean_q: 0.413250, mean_eps: 0.483292\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 172828/400000: episode: 630, duration: 32.304s, episode steps: 483, steps per second:  15, episode reward: 10.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.009387, mae: 0.328958, mean_q: 0.409421, mean_eps: 0.482242\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 173035/400000: episode: 631, duration: 14.183s, episode steps: 207, steps per second:  15, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.008735, mae: 0.335598, mean_q: 0.416988, mean_eps: 0.481210\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 173410/400000: episode: 632, duration: 25.804s, episode steps: 375, steps per second:  15, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.765 [0.000, 5.000],  loss: 0.009069, mae: 0.329063, mean_q: 0.407583, mean_eps: 0.480334\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 173682/400000: episode: 633, duration: 18.690s, episode steps: 272, steps per second:  15, episode reward:  4.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.754 [0.000, 5.000],  loss: 0.009770, mae: 0.334498, mean_q: 0.414718, mean_eps: 0.479362\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 173906/400000: episode: 634, duration: 16.538s, episode steps: 224, steps per second:  14, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.170 [0.000, 5.000],  loss: 0.009278, mae: 0.321939, mean_q: 0.399831, mean_eps: 0.478618\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 174039/400000: episode: 635, duration: 8.300s, episode steps: 133, steps per second:  16, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.256 [0.000, 5.000],  loss: 0.008413, mae: 0.350022, mean_q: 0.434510, mean_eps: 0.478084\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 174196/400000: episode: 636, duration: 11.458s, episode steps: 157, steps per second:  14, episode reward:  3.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.204 [0.000, 5.000],  loss: 0.008572, mae: 0.338965, mean_q: 0.419589, mean_eps: 0.477652\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 174466/400000: episode: 637, duration: 18.116s, episode steps: 270, steps per second:  15, episode reward:  4.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.009838, mae: 0.336224, mean_q: 0.413693, mean_eps: 0.477010\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 174690/400000: episode: 638, duration: 16.310s, episode steps: 224, steps per second:  14, episode reward:  1.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.008569, mae: 0.335400, mean_q: 0.415929, mean_eps: 0.476266\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 175101/400000: episode: 639, duration: 28.549s, episode steps: 411, steps per second:  14, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.009323, mae: 0.333709, mean_q: 0.412238, mean_eps: 0.475312\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 175336/400000: episode: 640, duration: 16.244s, episode steps: 235, steps per second:  14, episode reward:  5.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 3.000 [0.000, 5.000],  loss: 0.008591, mae: 0.341957, mean_q: 0.421222, mean_eps: 0.474346\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 175844/400000: episode: 641, duration: 33.992s, episode steps: 508, steps per second:  15, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.163 [0.000, 5.000],  loss: 0.008617, mae: 0.339901, mean_q: 0.419266, mean_eps: 0.473236\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 176043/400000: episode: 642, duration: 13.608s, episode steps: 199, steps per second:  15, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.009076, mae: 0.345878, mean_q: 0.426748, mean_eps: 0.472174\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 176266/400000: episode: 643, duration: 15.155s, episode steps: 223, steps per second:  15, episode reward:  3.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.013 [0.000, 5.000],  loss: 0.008952, mae: 0.322598, mean_q: 0.400867, mean_eps: 0.471538\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 176400/400000: episode: 644, duration: 9.860s, episode steps: 134, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.552 [0.000, 5.000],  loss: 0.008966, mae: 0.335053, mean_q: 0.414619, mean_eps: 0.471004\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 176876/400000: episode: 645, duration: 32.084s, episode steps: 476, steps per second:  15, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.863 [0.000, 5.000],  loss: 0.008525, mae: 0.323775, mean_q: 0.400721, mean_eps: 0.470092\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 177117/400000: episode: 646, duration: 17.843s, episode steps: 241, steps per second:  14, episode reward:  7.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.373 [0.000, 5.000],  loss: 0.008281, mae: 0.332022, mean_q: 0.410937, mean_eps: 0.469012\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 177298/400000: episode: 647, duration: 11.433s, episode steps: 181, steps per second:  16, episode reward:  3.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 3.011 [0.000, 5.000],  loss: 0.008594, mae: 0.327404, mean_q: 0.407910, mean_eps: 0.468376\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 177460/400000: episode: 648, duration: 11.038s, episode steps: 162, steps per second:  15, episode reward:  1.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.007651, mae: 0.321404, mean_q: 0.398035, mean_eps: 0.467866\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 177595/400000: episode: 649, duration: 9.889s, episode steps: 135, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.259 [0.000, 5.000],  loss: 0.009411, mae: 0.323465, mean_q: 0.401142, mean_eps: 0.467422\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 177729/400000: episode: 650, duration: 9.924s, episode steps: 134, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.500 [0.000, 5.000],  loss: 0.006688, mae: 0.329429, mean_q: 0.411431, mean_eps: 0.467014\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 177875/400000: episode: 651, duration: 8.634s, episode steps: 146, steps per second:  17, episode reward:  1.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.068 [0.000, 5.000],  loss: 0.006141, mae: 0.330963, mean_q: 0.413212, mean_eps: 0.466594\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 178159/400000: episode: 652, duration: 20.271s, episode steps: 284, steps per second:  14, episode reward:  6.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.008215, mae: 0.326296, mean_q: 0.405619, mean_eps: 0.465952\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 178288/400000: episode: 653, duration: 8.026s, episode steps: 129, steps per second:  16, episode reward:  1.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.124 [0.000, 5.000],  loss: 0.008890, mae: 0.329877, mean_q: 0.408608, mean_eps: 0.465334\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 178493/400000: episode: 654, duration: 14.511s, episode steps: 205, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.737 [0.000, 5.000],  loss: 0.008119, mae: 0.344058, mean_q: 0.426705, mean_eps: 0.464830\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 178690/400000: episode: 655, duration: 13.284s, episode steps: 197, steps per second:  15, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.244 [0.000, 5.000],  loss: 0.010206, mae: 0.363254, mean_q: 0.449070, mean_eps: 0.464224\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 178956/400000: episode: 656, duration: 19.664s, episode steps: 266, steps per second:  14, episode reward:  3.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 1.951 [0.000, 5.000],  loss: 0.009013, mae: 0.371193, mean_q: 0.458763, mean_eps: 0.463534\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 179160/400000: episode: 657, duration: 14.197s, episode steps: 204, steps per second:  14, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.745 [0.000, 5.000],  loss: 0.009723, mae: 0.374531, mean_q: 0.463308, mean_eps: 0.462832\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 179360/400000: episode: 658, duration: 14.104s, episode steps: 200, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.009067, mae: 0.369966, mean_q: 0.457788, mean_eps: 0.462226\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 179584/400000: episode: 659, duration: 15.785s, episode steps: 224, steps per second:  14, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 3.196 [0.000, 5.000],  loss: 0.010703, mae: 0.373892, mean_q: 0.462866, mean_eps: 0.461590\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 179707/400000: episode: 660, duration: 9.076s, episode steps: 123, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.333 [0.000, 5.000],  loss: 0.013031, mae: 0.390085, mean_q: 0.484432, mean_eps: 0.461068\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 179819/400000: episode: 661, duration: 7.103s, episode steps: 112, steps per second:  16, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.036 [0.000, 5.000],  loss: 0.009715, mae: 0.378369, mean_q: 0.470418, mean_eps: 0.460714\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 179978/400000: episode: 662, duration: 11.470s, episode steps: 159, steps per second:  14, episode reward:  2.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.214 [0.000, 5.000],  loss: 0.008980, mae: 0.371225, mean_q: 0.459694, mean_eps: 0.460306\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 180123/400000: episode: 663, duration: 10.769s, episode steps: 145, steps per second:  13, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.441 [0.000, 5.000],  loss: 0.010401, mae: 0.370261, mean_q: 0.458439, mean_eps: 0.459850\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 180313/400000: episode: 664, duration: 13.319s, episode steps: 190, steps per second:  14, episode reward:  4.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.258 [0.000, 5.000],  loss: 0.010815, mae: 0.354021, mean_q: 0.436947, mean_eps: 0.459346\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 180452/400000: episode: 665, duration: 8.575s, episode steps: 139, steps per second:  16, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.986 [0.000, 5.000],  loss: 0.008708, mae: 0.366789, mean_q: 0.456872, mean_eps: 0.458854\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 180665/400000: episode: 666, duration: 14.711s, episode steps: 213, steps per second:  14, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.011679, mae: 0.371937, mean_q: 0.459681, mean_eps: 0.458326\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 180797/400000: episode: 667, duration: 9.778s, episode steps: 132, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.076 [0.000, 5.000],  loss: 0.007666, mae: 0.360521, mean_q: 0.445944, mean_eps: 0.457804\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 181039/400000: episode: 668, duration: 16.153s, episode steps: 242, steps per second:  15, episode reward:  3.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.136 [0.000, 5.000],  loss: 0.009267, mae: 0.370825, mean_q: 0.457873, mean_eps: 0.457246\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 181249/400000: episode: 669, duration: 14.424s, episode steps: 210, steps per second:  15, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.267 [0.000, 5.000],  loss: 0.006796, mae: 0.362459, mean_q: 0.448766, mean_eps: 0.456568\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 181455/400000: episode: 670, duration: 14.011s, episode steps: 206, steps per second:  15, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 3.257 [0.000, 5.000],  loss: 0.006793, mae: 0.363902, mean_q: 0.449435, mean_eps: 0.455944\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 181688/400000: episode: 671, duration: 16.276s, episode steps: 233, steps per second:  14, episode reward:  4.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.682 [0.000, 5.000],  loss: 0.008143, mae: 0.364249, mean_q: 0.450567, mean_eps: 0.455290\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 181926/400000: episode: 672, duration: 17.369s, episode steps: 238, steps per second:  14, episode reward:  4.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.962 [0.000, 5.000],  loss: 0.009404, mae: 0.364925, mean_q: 0.452307, mean_eps: 0.454582\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 182054/400000: episode: 673, duration: 7.839s, episode steps: 128, steps per second:  16, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.773 [0.000, 5.000],  loss: 0.006952, mae: 0.347636, mean_q: 0.430021, mean_eps: 0.454030\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 182194/400000: episode: 674, duration: 10.367s, episode steps: 140, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.679 [0.000, 5.000],  loss: 0.011139, mae: 0.370738, mean_q: 0.456429, mean_eps: 0.453628\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 182492/400000: episode: 675, duration: 21.054s, episode steps: 298, steps per second:  14, episode reward:  5.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.007828, mae: 0.364186, mean_q: 0.454249, mean_eps: 0.452974\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 182876/400000: episode: 676, duration: 25.993s, episode steps: 384, steps per second:  15, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.893 [0.000, 5.000],  loss: 0.008425, mae: 0.370729, mean_q: 0.458028, mean_eps: 0.451954\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 183127/400000: episode: 677, duration: 18.415s, episode steps: 251, steps per second:  14, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.629 [0.000, 5.000],  loss: 0.010328, mae: 0.360043, mean_q: 0.445227, mean_eps: 0.451000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 183512/400000: episode: 678, duration: 26.539s, episode steps: 385, steps per second:  15, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.009881, mae: 0.358529, mean_q: 0.443069, mean_eps: 0.450046\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 184349/400000: episode: 679, duration: 57.624s, episode steps: 837, steps per second:  15, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.231 [0.000, 5.000],  loss: 0.008524, mae: 0.362462, mean_q: 0.447252, mean_eps: 0.448210\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 184496/400000: episode: 680, duration: 9.769s, episode steps: 147, steps per second:  15, episode reward:  1.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 1.755 [0.000, 5.000],  loss: 0.008749, mae: 0.365626, mean_q: 0.449930, mean_eps: 0.446734\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 184914/400000: episode: 681, duration: 29.499s, episode steps: 418, steps per second:  14, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.191 [0.000, 5.000],  loss: 0.008653, mae: 0.359238, mean_q: 0.444564, mean_eps: 0.445888\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 185262/400000: episode: 682, duration: 23.139s, episode steps: 348, steps per second:  15, episode reward:  9.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.615 [0.000, 5.000],  loss: 0.008646, mae: 0.365028, mean_q: 0.450440, mean_eps: 0.444736\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 185471/400000: episode: 683, duration: 14.419s, episode steps: 209, steps per second:  14, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.220 [0.000, 5.000],  loss: 0.010521, mae: 0.369310, mean_q: 0.457889, mean_eps: 0.443902\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 185704/400000: episode: 684, duration: 17.463s, episode steps: 233, steps per second:  13, episode reward:  8.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 3.116 [0.000, 5.000],  loss: 0.011393, mae: 0.371654, mean_q: 0.461410, mean_eps: 0.443242\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 185843/400000: episode: 685, duration: 8.825s, episode steps: 139, steps per second:  16, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.691 [0.000, 5.000],  loss: 0.007132, mae: 0.376066, mean_q: 0.467026, mean_eps: 0.442684\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 186068/400000: episode: 686, duration: 15.493s, episode steps: 225, steps per second:  15, episode reward:  6.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 3.280 [0.000, 5.000],  loss: 0.007836, mae: 0.351571, mean_q: 0.434660, mean_eps: 0.442138\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 186346/400000: episode: 687, duration: 20.339s, episode steps: 278, steps per second:  14, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.009366, mae: 0.369275, mean_q: 0.456585, mean_eps: 0.441382\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 186548/400000: episode: 688, duration: 14.170s, episode steps: 202, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.327 [0.000, 5.000],  loss: 0.010405, mae: 0.356940, mean_q: 0.439220, mean_eps: 0.440662\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 186869/400000: episode: 689, duration: 21.419s, episode steps: 321, steps per second:  15, episode reward:  5.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.639 [0.000, 5.000],  loss: 0.007543, mae: 0.367096, mean_q: 0.453862, mean_eps: 0.439876\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 187144/400000: episode: 690, duration: 19.735s, episode steps: 275, steps per second:  14, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.829 [0.000, 5.000],  loss: 0.010057, mae: 0.394771, mean_q: 0.488465, mean_eps: 0.438982\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 187699/400000: episode: 691, duration: 37.785s, episode steps: 555, steps per second:  15, episode reward: 15.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.110 [0.000, 5.000],  loss: 0.009947, mae: 0.420262, mean_q: 0.520741, mean_eps: 0.437740\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 188333/400000: episode: 692, duration: 43.781s, episode steps: 634, steps per second:  14, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.009542, mae: 0.405704, mean_q: 0.500134, mean_eps: 0.435952\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 188571/400000: episode: 693, duration: 16.065s, episode steps: 238, steps per second:  15, episode reward:  5.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.021 [0.000, 5.000],  loss: 0.009992, mae: 0.409785, mean_q: 0.506777, mean_eps: 0.434644\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 188814/400000: episode: 694, duration: 16.504s, episode steps: 243, steps per second:  15, episode reward:  4.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.218 [0.000, 5.000],  loss: 0.008415, mae: 0.407024, mean_q: 0.504281, mean_eps: 0.433924\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 188962/400000: episode: 695, duration: 10.728s, episode steps: 148, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.797 [0.000, 5.000],  loss: 0.014691, mae: 0.434953, mean_q: 0.536879, mean_eps: 0.433336\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 189176/400000: episode: 696, duration: 14.779s, episode steps: 214, steps per second:  14, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.921 [0.000, 5.000],  loss: 0.011314, mae: 0.401615, mean_q: 0.496470, mean_eps: 0.432796\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 189380/400000: episode: 697, duration: 14.529s, episode steps: 204, steps per second:  14, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.025 [0.000, 5.000],  loss: 0.009583, mae: 0.408202, mean_q: 0.503625, mean_eps: 0.432172\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 189607/400000: episode: 698, duration: 15.664s, episode steps: 227, steps per second:  14, episode reward:  3.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.921 [0.000, 5.000],  loss: 0.009298, mae: 0.394966, mean_q: 0.489595, mean_eps: 0.431524\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 189863/400000: episode: 699, duration: 17.185s, episode steps: 256, steps per second:  15, episode reward:  6.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.010105, mae: 0.400758, mean_q: 0.495178, mean_eps: 0.430798\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 190016/400000: episode: 700, duration: 11.170s, episode steps: 153, steps per second:  14, episode reward:  1.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.294 [0.000, 5.000],  loss: 0.011559, mae: 0.418188, mean_q: 0.515654, mean_eps: 0.430186\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 190178/400000: episode: 701, duration: 11.750s, episode steps: 162, steps per second:  14, episode reward:  1.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.346 [0.000, 5.000],  loss: 0.010773, mae: 0.413452, mean_q: 0.510884, mean_eps: 0.429712\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 190422/400000: episode: 702, duration: 16.409s, episode steps: 244, steps per second:  15, episode reward:  3.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.791 [0.000, 5.000],  loss: 0.009233, mae: 0.416337, mean_q: 0.514190, mean_eps: 0.429100\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 190685/400000: episode: 703, duration: 18.333s, episode steps: 263, steps per second:  14, episode reward: 10.000, mean reward:  0.038 [ 0.000,  1.000], mean action: 2.137 [0.000, 5.000],  loss: 0.012307, mae: 0.415333, mean_q: 0.511592, mean_eps: 0.428338\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 190931/400000: episode: 704, duration: 17.451s, episode steps: 246, steps per second:  14, episode reward:  5.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.980 [0.000, 5.000],  loss: 0.009185, mae: 0.406857, mean_q: 0.500420, mean_eps: 0.427576\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 191149/400000: episode: 705, duration: 15.046s, episode steps: 218, steps per second:  14, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.266 [0.000, 5.000],  loss: 0.010499, mae: 0.413071, mean_q: 0.509461, mean_eps: 0.426880\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 191354/400000: episode: 706, duration: 14.053s, episode steps: 205, steps per second:  15, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 3.205 [0.000, 5.000],  loss: 0.008586, mae: 0.406041, mean_q: 0.502311, mean_eps: 0.426244\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 191477/400000: episode: 707, duration: 8.057s, episode steps: 123, steps per second:  15, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 3.138 [0.000, 5.000],  loss: 0.009551, mae: 0.386866, mean_q: 0.477514, mean_eps: 0.425752\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 191676/400000: episode: 708, duration: 13.672s, episode steps: 199, steps per second:  15, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 3.171 [0.000, 5.000],  loss: 0.009586, mae: 0.416380, mean_q: 0.518955, mean_eps: 0.425272\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 191995/400000: episode: 709, duration: 22.214s, episode steps: 319, steps per second:  14, episode reward:  4.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.009475, mae: 0.407292, mean_q: 0.502916, mean_eps: 0.424498\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 192267/400000: episode: 710, duration: 18.199s, episode steps: 272, steps per second:  15, episode reward:  4.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: 0.009472, mae: 0.402338, mean_q: 0.494435, mean_eps: 0.423610\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 192805/400000: episode: 711, duration: 37.171s, episode steps: 538, steps per second:  14, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.340 [0.000, 5.000],  loss: 0.009461, mae: 0.407813, mean_q: 0.502416, mean_eps: 0.422392\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 192931/400000: episode: 712, duration: 9.169s, episode steps: 126, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.651 [0.000, 5.000],  loss: 0.011185, mae: 0.414490, mean_q: 0.511440, mean_eps: 0.421396\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 193108/400000: episode: 713, duration: 12.200s, episode steps: 177, steps per second:  15, episode reward:  2.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.008714, mae: 0.403677, mean_q: 0.498799, mean_eps: 0.420946\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 193459/400000: episode: 714, duration: 22.817s, episode steps: 351, steps per second:  15, episode reward:  8.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.376 [0.000, 5.000],  loss: 0.009103, mae: 0.408378, mean_q: 0.502139, mean_eps: 0.420154\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 193755/400000: episode: 715, duration: 20.934s, episode steps: 296, steps per second:  14, episode reward:  7.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.009993, mae: 0.414136, mean_q: 0.508796, mean_eps: 0.419182\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 193976/400000: episode: 716, duration: 15.177s, episode steps: 221, steps per second:  15, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.204 [0.000, 5.000],  loss: 0.009578, mae: 0.409599, mean_q: 0.503208, mean_eps: 0.418408\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 194212/400000: episode: 717, duration: 16.267s, episode steps: 236, steps per second:  15, episode reward:  3.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.072 [0.000, 5.000],  loss: 0.006546, mae: 0.400436, mean_q: 0.495446, mean_eps: 0.417724\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 194409/400000: episode: 718, duration: 13.995s, episode steps: 197, steps per second:  14, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 1.878 [0.000, 5.000],  loss: 0.008237, mae: 0.411632, mean_q: 0.506719, mean_eps: 0.417070\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 194826/400000: episode: 719, duration: 28.563s, episode steps: 417, steps per second:  15, episode reward:  9.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.683 [0.000, 5.000],  loss: 0.009892, mae: 0.409796, mean_q: 0.506472, mean_eps: 0.416146\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 194996/400000: episode: 720, duration: 12.312s, episode steps: 170, steps per second:  14, episode reward:  1.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.706 [0.000, 5.000],  loss: 0.007422, mae: 0.405654, mean_q: 0.502311, mean_eps: 0.415270\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 195140/400000: episode: 721, duration: 10.823s, episode steps: 144, steps per second:  13, episode reward:  2.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.715 [0.000, 5.000],  loss: 0.011330, mae: 0.418192, mean_q: 0.514377, mean_eps: 0.414802\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 195347/400000: episode: 722, duration: 14.413s, episode steps: 207, steps per second:  14, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.092 [0.000, 5.000],  loss: 0.008096, mae: 0.401695, mean_q: 0.493671, mean_eps: 0.414274\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 195623/400000: episode: 723, duration: 18.911s, episode steps: 276, steps per second:  15, episode reward:  5.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.009092, mae: 0.419100, mean_q: 0.514759, mean_eps: 0.413548\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 196632/400000: episode: 724, duration: 70.291s, episode steps: 1009, steps per second:  14, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.718 [0.000, 5.000],  loss: 0.010039, mae: 0.422681, mean_q: 0.522147, mean_eps: 0.411622\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 196826/400000: episode: 725, duration: 13.665s, episode steps: 194, steps per second:  14, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 1.619 [0.000, 5.000],  loss: 0.011127, mae: 0.425757, mean_q: 0.526310, mean_eps: 0.409816\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 197048/400000: episode: 726, duration: 15.409s, episode steps: 222, steps per second:  14, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.270 [0.000, 5.000],  loss: 0.009221, mae: 0.424539, mean_q: 0.525106, mean_eps: 0.409192\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 197280/400000: episode: 727, duration: 17.402s, episode steps: 232, steps per second:  13, episode reward:  5.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.685 [0.000, 5.000],  loss: 0.009516, mae: 0.428603, mean_q: 0.529506, mean_eps: 0.408514\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 197418/400000: episode: 728, duration: 8.645s, episode steps: 138, steps per second:  16, episode reward:  1.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.739 [0.000, 5.000],  loss: 0.009610, mae: 0.428959, mean_q: 0.531540, mean_eps: 0.407956\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 197668/400000: episode: 729, duration: 18.393s, episode steps: 250, steps per second:  14, episode reward:  4.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.304 [0.000, 5.000],  loss: 0.009833, mae: 0.428034, mean_q: 0.527507, mean_eps: 0.407374\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 197928/400000: episode: 730, duration: 17.708s, episode steps: 260, steps per second:  15, episode reward:  6.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: 0.010352, mae: 0.424833, mean_q: 0.523827, mean_eps: 0.406612\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 198087/400000: episode: 731, duration: 11.359s, episode steps: 159, steps per second:  14, episode reward:  1.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 1.491 [0.000, 5.000],  loss: 0.010887, mae: 0.445443, mean_q: 0.549306, mean_eps: 0.405982\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 198278/400000: episode: 732, duration: 13.134s, episode steps: 191, steps per second:  15, episode reward:  3.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.890 [0.000, 5.000],  loss: 0.010690, mae: 0.428521, mean_q: 0.529898, mean_eps: 0.405454\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 198487/400000: episode: 733, duration: 14.053s, episode steps: 209, steps per second:  15, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.976 [0.000, 5.000],  loss: 0.012293, mae: 0.423639, mean_q: 0.522406, mean_eps: 0.404854\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 198712/400000: episode: 734, duration: 15.480s, episode steps: 225, steps per second:  15, episode reward:  3.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.973 [0.000, 5.000],  loss: 0.010175, mae: 0.422487, mean_q: 0.523105, mean_eps: 0.404206\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 198914/400000: episode: 735, duration: 14.036s, episode steps: 202, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.980 [0.000, 5.000],  loss: 0.010480, mae: 0.426049, mean_q: 0.526834, mean_eps: 0.403564\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 199096/400000: episode: 736, duration: 12.702s, episode steps: 182, steps per second:  14, episode reward:  2.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.192 [0.000, 5.000],  loss: 0.009054, mae: 0.407238, mean_q: 0.502331, mean_eps: 0.402988\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 199351/400000: episode: 737, duration: 17.250s, episode steps: 255, steps per second:  15, episode reward:  4.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.251 [0.000, 5.000],  loss: 0.009662, mae: 0.431021, mean_q: 0.532886, mean_eps: 0.402334\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 199892/400000: episode: 738, duration: 37.910s, episode steps: 541, steps per second:  14, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.070 [0.000, 5.000],  loss: 0.007669, mae: 0.407793, mean_q: 0.505054, mean_eps: 0.401140\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 200192/400000: episode: 739, duration: 20.009s, episode steps: 300, steps per second:  15, episode reward:  7.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.008906, mae: 0.425079, mean_q: 0.524394, mean_eps: 0.399880\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 201209/400000: episode: 740, duration: 69.114s, episode steps: 1017, steps per second:  15, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.011044, mae: 0.431165, mean_q: 0.532208, mean_eps: 0.397900\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 201406/400000: episode: 741, duration: 13.665s, episode steps: 197, steps per second:  14, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.008254, mae: 0.415471, mean_q: 0.512764, mean_eps: 0.396076\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 201522/400000: episode: 742, duration: 8.823s, episode steps: 116, steps per second:  13, episode reward:  1.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.086 [0.000, 5.000],  loss: 0.007375, mae: 0.422414, mean_q: 0.522415, mean_eps: 0.395608\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 201747/400000: episode: 743, duration: 15.354s, episode steps: 225, steps per second:  15, episode reward:  3.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.280 [0.000, 5.000],  loss: 0.009265, mae: 0.426547, mean_q: 0.527495, mean_eps: 0.395098\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 201952/400000: episode: 744, duration: 14.266s, episode steps: 205, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.273 [0.000, 5.000],  loss: 0.009280, mae: 0.426683, mean_q: 0.526570, mean_eps: 0.394456\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 202093/400000: episode: 745, duration: 10.511s, episode steps: 141, steps per second:  13, episode reward:  1.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 3.000 [0.000, 5.000],  loss: 0.012754, mae: 0.440749, mean_q: 0.544277, mean_eps: 0.393934\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 202304/400000: episode: 746, duration: 14.708s, episode steps: 211, steps per second:  14, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.820 [0.000, 5.000],  loss: 0.008994, mae: 0.417228, mean_q: 0.516079, mean_eps: 0.393406\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 202532/400000: episode: 747, duration: 15.701s, episode steps: 228, steps per second:  15, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.022 [0.000, 5.000],  loss: 0.009138, mae: 0.412509, mean_q: 0.507403, mean_eps: 0.392752\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 202735/400000: episode: 748, duration: 14.170s, episode steps: 203, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.911 [0.000, 5.000],  loss: 0.010156, mae: 0.433085, mean_q: 0.533666, mean_eps: 0.392104\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 202978/400000: episode: 749, duration: 16.481s, episode steps: 243, steps per second:  15, episode reward:  4.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.630 [0.000, 5.000],  loss: 0.007535, mae: 0.418609, mean_q: 0.516524, mean_eps: 0.391432\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 203189/400000: episode: 750, duration: 14.744s, episode steps: 211, steps per second:  14, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.735 [0.000, 5.000],  loss: 0.007393, mae: 0.418780, mean_q: 0.516155, mean_eps: 0.390748\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 203544/400000: episode: 751, duration: 24.837s, episode steps: 355, steps per second:  14, episode reward:  8.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.034 [0.000, 5.000],  loss: 0.009864, mae: 0.435070, mean_q: 0.535680, mean_eps: 0.389902\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 203701/400000: episode: 752, duration: 11.467s, episode steps: 157, steps per second:  14, episode reward:  2.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.669 [0.000, 5.000],  loss: 0.008566, mae: 0.435691, mean_q: 0.538823, mean_eps: 0.389134\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 203901/400000: episode: 753, duration: 13.863s, episode steps: 200, steps per second:  14, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.235 [0.000, 5.000],  loss: 0.008411, mae: 0.402449, mean_q: 0.496226, mean_eps: 0.388594\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 204105/400000: episode: 754, duration: 14.081s, episode steps: 204, steps per second:  14, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.319 [0.000, 5.000],  loss: 0.009538, mae: 0.432307, mean_q: 0.532011, mean_eps: 0.387988\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 204473/400000: episode: 755, duration: 26.443s, episode steps: 368, steps per second:  14, episode reward: 11.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.258 [0.000, 5.000],  loss: 0.011329, mae: 0.447949, mean_q: 0.552126, mean_eps: 0.387130\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 204987/400000: episode: 756, duration: 34.728s, episode steps: 514, steps per second:  15, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 3.134 [0.000, 5.000],  loss: 0.008833, mae: 0.441800, mean_q: 0.546493, mean_eps: 0.385810\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 205255/400000: episode: 757, duration: 19.500s, episode steps: 268, steps per second:  14, episode reward: 10.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 2.201 [0.000, 5.000],  loss: 0.010340, mae: 0.444722, mean_q: 0.546921, mean_eps: 0.384640\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 205461/400000: episode: 758, duration: 14.377s, episode steps: 206, steps per second:  14, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.354 [0.000, 5.000],  loss: 0.010044, mae: 0.450942, mean_q: 0.554406, mean_eps: 0.383926\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 205580/400000: episode: 759, duration: 7.403s, episode steps: 119, steps per second:  16, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.504 [0.000, 5.000],  loss: 0.009870, mae: 0.453232, mean_q: 0.557055, mean_eps: 0.383440\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 205852/400000: episode: 760, duration: 20.248s, episode steps: 272, steps per second:  13, episode reward:  4.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.151 [0.000, 5.000],  loss: 0.009549, mae: 0.439677, mean_q: 0.542854, mean_eps: 0.382858\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 206070/400000: episode: 761, duration: 15.536s, episode steps: 218, steps per second:  14, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.271 [0.000, 5.000],  loss: 0.008223, mae: 0.438320, mean_q: 0.540795, mean_eps: 0.382120\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 206269/400000: episode: 762, duration: 14.064s, episode steps: 199, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.075 [0.000, 5.000],  loss: 0.010486, mae: 0.453332, mean_q: 0.559201, mean_eps: 0.381490\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 206721/400000: episode: 763, duration: 31.305s, episode steps: 452, steps per second:  14, episode reward: 12.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.644 [0.000, 5.000],  loss: 0.010850, mae: 0.439825, mean_q: 0.540969, mean_eps: 0.380512\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 207000/400000: episode: 764, duration: 21.148s, episode steps: 279, steps per second:  13, episode reward:  9.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.007704, mae: 0.439727, mean_q: 0.542797, mean_eps: 0.379420\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 207425/400000: episode: 765, duration: 29.879s, episode steps: 425, steps per second:  14, episode reward: 12.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.186 [0.000, 5.000],  loss: 0.009193, mae: 0.445613, mean_q: 0.549056, mean_eps: 0.378364\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 207635/400000: episode: 766, duration: 14.691s, episode steps: 210, steps per second:  14, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.007264, mae: 0.423538, mean_q: 0.522719, mean_eps: 0.377410\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 207891/400000: episode: 767, duration: 17.569s, episode steps: 256, steps per second:  15, episode reward:  5.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.652 [0.000, 5.000],  loss: 0.009548, mae: 0.426789, mean_q: 0.525345, mean_eps: 0.376714\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 208097/400000: episode: 768, duration: 14.773s, episode steps: 206, steps per second:  14, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.704 [0.000, 5.000],  loss: 0.007705, mae: 0.435283, mean_q: 0.535868, mean_eps: 0.376018\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 208284/400000: episode: 769, duration: 13.412s, episode steps: 187, steps per second:  14, episode reward:  3.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.936 [0.000, 5.000],  loss: 0.010004, mae: 0.456810, mean_q: 0.561977, mean_eps: 0.375430\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 208565/400000: episode: 770, duration: 21.079s, episode steps: 281, steps per second:  13, episode reward:  3.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.046 [0.000, 5.000],  loss: 0.010248, mae: 0.442547, mean_q: 0.547379, mean_eps: 0.374728\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 208770/400000: episode: 771, duration: 14.633s, episode steps: 205, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.907 [0.000, 5.000],  loss: 0.007692, mae: 0.442592, mean_q: 0.545443, mean_eps: 0.373996\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 209023/400000: episode: 772, duration: 17.291s, episode steps: 253, steps per second:  15, episode reward:  4.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 3.134 [0.000, 5.000],  loss: 0.010848, mae: 0.433861, mean_q: 0.532502, mean_eps: 0.373312\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 209230/400000: episode: 773, duration: 14.541s, episode steps: 207, steps per second:  14, episode reward:  6.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.011307, mae: 0.452830, mean_q: 0.555230, mean_eps: 0.372622\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 209500/400000: episode: 774, duration: 19.263s, episode steps: 270, steps per second:  14, episode reward:  2.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.170 [0.000, 5.000],  loss: 0.009743, mae: 0.446703, mean_q: 0.550384, mean_eps: 0.371908\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 209706/400000: episode: 775, duration: 14.921s, episode steps: 206, steps per second:  14, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.218 [0.000, 5.000],  loss: 0.010135, mae: 0.441063, mean_q: 0.543070, mean_eps: 0.371194\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 209911/400000: episode: 776, duration: 14.386s, episode steps: 205, steps per second:  14, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.146 [0.000, 5.000],  loss: 0.009100, mae: 0.439476, mean_q: 0.541492, mean_eps: 0.370576\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 210214/400000: episode: 777, duration: 20.337s, episode steps: 303, steps per second:  15, episode reward:  7.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.274 [0.000, 5.000],  loss: 0.009191, mae: 0.450222, mean_q: 0.555511, mean_eps: 0.369814\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 210420/400000: episode: 778, duration: 14.703s, episode steps: 206, steps per second:  14, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.655 [0.000, 5.000],  loss: 0.009499, mae: 0.435892, mean_q: 0.537287, mean_eps: 0.369052\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 210622/400000: episode: 779, duration: 14.435s, episode steps: 202, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.545 [0.000, 5.000],  loss: 0.008462, mae: 0.445761, mean_q: 0.549304, mean_eps: 0.368440\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 210943/400000: episode: 780, duration: 22.955s, episode steps: 321, steps per second:  14, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.685 [0.000, 5.000],  loss: 0.010089, mae: 0.446017, mean_q: 0.548679, mean_eps: 0.367654\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 211315/400000: episode: 781, duration: 26.098s, episode steps: 372, steps per second:  14, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.008588, mae: 0.433820, mean_q: 0.533664, mean_eps: 0.366616\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 211526/400000: episode: 782, duration: 14.847s, episode steps: 211, steps per second:  14, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 3.014 [0.000, 5.000],  loss: 0.010661, mae: 0.432829, mean_q: 0.535408, mean_eps: 0.365740\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 211732/400000: episode: 783, duration: 14.598s, episode steps: 206, steps per second:  14, episode reward:  6.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.883 [0.000, 5.000],  loss: 0.010189, mae: 0.434432, mean_q: 0.535173, mean_eps: 0.365116\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 211904/400000: episode: 784, duration: 12.426s, episode steps: 172, steps per second:  14, episode reward:  3.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.105 [0.000, 5.000],  loss: 0.011397, mae: 0.456562, mean_q: 0.561047, mean_eps: 0.364552\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 212148/400000: episode: 785, duration: 16.724s, episode steps: 244, steps per second:  15, episode reward:  9.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 2.324 [0.000, 5.000],  loss: 0.011102, mae: 0.438125, mean_q: 0.540693, mean_eps: 0.363928\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 212357/400000: episode: 786, duration: 14.760s, episode steps: 209, steps per second:  14, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.646 [0.000, 5.000],  loss: 0.008240, mae: 0.425560, mean_q: 0.526119, mean_eps: 0.363244\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 213254/400000: episode: 787, duration: 62.318s, episode steps: 897, steps per second:  14, episode reward: 21.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.009934, mae: 0.461019, mean_q: 0.569735, mean_eps: 0.361582\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 213475/400000: episode: 788, duration: 15.569s, episode steps: 221, steps per second:  14, episode reward:  6.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.701 [0.000, 5.000],  loss: 0.011553, mae: 0.466044, mean_q: 0.572864, mean_eps: 0.359908\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 213678/400000: episode: 789, duration: 14.300s, episode steps: 203, steps per second:  14, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.315 [0.000, 5.000],  loss: 0.006241, mae: 0.463443, mean_q: 0.571804, mean_eps: 0.359272\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 213827/400000: episode: 790, duration: 9.558s, episode steps: 149, steps per second:  16, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.886 [0.000, 5.000],  loss: 0.007950, mae: 0.448396, mean_q: 0.551571, mean_eps: 0.358744\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 213974/400000: episode: 791, duration: 10.381s, episode steps: 147, steps per second:  14, episode reward:  1.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.010168, mae: 0.448739, mean_q: 0.552400, mean_eps: 0.358300\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 214219/400000: episode: 792, duration: 17.117s, episode steps: 245, steps per second:  14, episode reward:  3.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.849 [0.000, 5.000],  loss: 0.008190, mae: 0.455254, mean_q: 0.563586, mean_eps: 0.357712\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 214461/400000: episode: 793, duration: 17.865s, episode steps: 242, steps per second:  14, episode reward:  6.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.010456, mae: 0.433349, mean_q: 0.535583, mean_eps: 0.356980\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 214706/400000: episode: 794, duration: 16.645s, episode steps: 245, steps per second:  15, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.286 [0.000, 5.000],  loss: 0.009207, mae: 0.466111, mean_q: 0.575948, mean_eps: 0.356248\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 214952/400000: episode: 795, duration: 16.977s, episode steps: 246, steps per second:  14, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.724 [0.000, 5.000],  loss: 0.010057, mae: 0.451302, mean_q: 0.555198, mean_eps: 0.355516\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 215175/400000: episode: 796, duration: 15.813s, episode steps: 223, steps per second:  14, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: 0.008512, mae: 0.454106, mean_q: 0.560032, mean_eps: 0.354814\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 215381/400000: episode: 797, duration: 14.609s, episode steps: 206, steps per second:  14, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.733 [0.000, 5.000],  loss: 0.008222, mae: 0.464602, mean_q: 0.573848, mean_eps: 0.354166\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 215642/400000: episode: 798, duration: 19.289s, episode steps: 261, steps per second:  14, episode reward:  5.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.010601, mae: 0.475308, mean_q: 0.584323, mean_eps: 0.353464\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 216205/400000: episode: 799, duration: 39.431s, episode steps: 563, steps per second:  14, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.008902, mae: 0.454013, mean_q: 0.559730, mean_eps: 0.352228\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 216646/400000: episode: 800, duration: 30.614s, episode steps: 441, steps per second:  14, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.694 [0.000, 5.000],  loss: 0.008589, mae: 0.450982, mean_q: 0.557313, mean_eps: 0.350722\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 217195/400000: episode: 801, duration: 38.896s, episode steps: 549, steps per second:  14, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.332 [0.000, 5.000],  loss: 0.010267, mae: 0.456866, mean_q: 0.562075, mean_eps: 0.349240\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 217401/400000: episode: 802, duration: 14.505s, episode steps: 206, steps per second:  14, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.009437, mae: 0.463825, mean_q: 0.572472, mean_eps: 0.348106\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 217672/400000: episode: 803, duration: 18.451s, episode steps: 271, steps per second:  15, episode reward: 10.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.009506, mae: 0.451191, mean_q: 0.557208, mean_eps: 0.347392\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 217881/400000: episode: 804, duration: 14.681s, episode steps: 209, steps per second:  14, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.354 [0.000, 5.000],  loss: 0.008540, mae: 0.472473, mean_q: 0.583109, mean_eps: 0.346672\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 218089/400000: episode: 805, duration: 14.388s, episode steps: 208, steps per second:  14, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.188 [0.000, 5.000],  loss: 0.009314, mae: 0.457774, mean_q: 0.563228, mean_eps: 0.346042\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 218311/400000: episode: 806, duration: 15.146s, episode steps: 222, steps per second:  15, episode reward:  7.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.721 [0.000, 5.000],  loss: 0.009180, mae: 0.457287, mean_q: 0.562926, mean_eps: 0.345400\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 218529/400000: episode: 807, duration: 15.617s, episode steps: 218, steps per second:  14, episode reward:  6.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.010878, mae: 0.459071, mean_q: 0.564300, mean_eps: 0.344740\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 218723/400000: episode: 808, duration: 13.475s, episode steps: 194, steps per second:  14, episode reward:  4.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.974 [0.000, 5.000],  loss: 0.009140, mae: 0.445493, mean_q: 0.551679, mean_eps: 0.344122\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 218922/400000: episode: 809, duration: 14.064s, episode steps: 199, steps per second:  14, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.261 [0.000, 5.000],  loss: 0.009539, mae: 0.446955, mean_q: 0.549903, mean_eps: 0.343534\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 219127/400000: episode: 810, duration: 15.216s, episode steps: 205, steps per second:  13, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.902 [0.000, 5.000],  loss: 0.012162, mae: 0.477859, mean_q: 0.588298, mean_eps: 0.342928\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 219344/400000: episode: 811, duration: 16.136s, episode steps: 217, steps per second:  13, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.009708, mae: 0.453241, mean_q: 0.559063, mean_eps: 0.342298\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 219584/400000: episode: 812, duration: 16.857s, episode steps: 240, steps per second:  14, episode reward:  4.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.992 [0.000, 5.000],  loss: 0.010307, mae: 0.464623, mean_q: 0.574244, mean_eps: 0.341614\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 219789/400000: episode: 813, duration: 15.088s, episode steps: 205, steps per second:  14, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.898 [0.000, 5.000],  loss: 0.008195, mae: 0.461199, mean_q: 0.569939, mean_eps: 0.340942\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 219990/400000: episode: 814, duration: 14.215s, episode steps: 201, steps per second:  14, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.010974, mae: 0.476430, mean_q: 0.584542, mean_eps: 0.340330\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 220367/400000: episode: 815, duration: 26.735s, episode steps: 377, steps per second:  14, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.009329, mae: 0.453687, mean_q: 0.557730, mean_eps: 0.339466\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 220577/400000: episode: 816, duration: 14.943s, episode steps: 210, steps per second:  14, episode reward:  6.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.007236, mae: 0.455502, mean_q: 0.560357, mean_eps: 0.338584\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 220820/400000: episode: 817, duration: 16.703s, episode steps: 243, steps per second:  15, episode reward:  9.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.010049, mae: 0.450630, mean_q: 0.553453, mean_eps: 0.337906\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 221602/400000: episode: 818, duration: 54.808s, episode steps: 782, steps per second:  14, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.009300, mae: 0.473198, mean_q: 0.583649, mean_eps: 0.336370\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 222018/400000: episode: 819, duration: 28.737s, episode steps: 416, steps per second:  14, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.791 [0.000, 5.000],  loss: 0.010994, mae: 0.480135, mean_q: 0.592286, mean_eps: 0.334570\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 222214/400000: episode: 820, duration: 13.926s, episode steps: 196, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.990 [0.000, 5.000],  loss: 0.007264, mae: 0.458240, mean_q: 0.565407, mean_eps: 0.333652\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 222823/400000: episode: 821, duration: 42.266s, episode steps: 609, steps per second:  14, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.187 [0.000, 5.000],  loss: 0.010146, mae: 0.476844, mean_q: 0.589605, mean_eps: 0.332446\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 223050/400000: episode: 822, duration: 17.103s, episode steps: 227, steps per second:  13, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.344 [0.000, 5.000],  loss: 0.011341, mae: 0.486817, mean_q: 0.601252, mean_eps: 0.331192\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 223165/400000: episode: 823, duration: 7.294s, episode steps: 115, steps per second:  16, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.730 [0.000, 5.000],  loss: 0.008476, mae: 0.474253, mean_q: 0.587888, mean_eps: 0.330676\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 223387/400000: episode: 824, duration: 15.260s, episode steps: 222, steps per second:  15, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.288 [0.000, 5.000],  loss: 0.010412, mae: 0.479231, mean_q: 0.593109, mean_eps: 0.330172\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 223754/400000: episode: 825, duration: 26.218s, episode steps: 367, steps per second:  14, episode reward:  8.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.009394, mae: 0.478607, mean_q: 0.589276, mean_eps: 0.329290\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 223964/400000: episode: 826, duration: 14.759s, episode steps: 210, steps per second:  14, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.200 [0.000, 5.000],  loss: 0.010185, mae: 0.466697, mean_q: 0.575687, mean_eps: 0.328426\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 224173/400000: episode: 827, duration: 14.780s, episode steps: 209, steps per second:  14, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.201 [0.000, 5.000],  loss: 0.011483, mae: 0.476323, mean_q: 0.585745, mean_eps: 0.327796\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 224615/400000: episode: 828, duration: 31.887s, episode steps: 442, steps per second:  14, episode reward: 11.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.190 [0.000, 5.000],  loss: 0.009629, mae: 0.469768, mean_q: 0.579043, mean_eps: 0.326818\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 224916/400000: episode: 829, duration: 20.954s, episode steps: 301, steps per second:  14, episode reward:  8.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.023 [0.000, 5.000],  loss: 0.009302, mae: 0.479832, mean_q: 0.591068, mean_eps: 0.325708\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 225147/400000: episode: 830, duration: 16.155s, episode steps: 231, steps per second:  14, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.052 [0.000, 5.000],  loss: 0.008716, mae: 0.465635, mean_q: 0.575451, mean_eps: 0.324910\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 225352/400000: episode: 831, duration: 14.480s, episode steps: 205, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.376 [0.000, 5.000],  loss: 0.007422, mae: 0.479559, mean_q: 0.591642, mean_eps: 0.324256\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 225602/400000: episode: 832, duration: 18.937s, episode steps: 250, steps per second:  13, episode reward:  7.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.668 [0.000, 5.000],  loss: 0.012022, mae: 0.491543, mean_q: 0.605632, mean_eps: 0.323572\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 225888/400000: episode: 833, duration: 19.552s, episode steps: 286, steps per second:  15, episode reward:  9.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 1.979 [0.000, 5.000],  loss: 0.010589, mae: 0.472314, mean_q: 0.583519, mean_eps: 0.322768\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 226109/400000: episode: 834, duration: 15.545s, episode steps: 221, steps per second:  14, episode reward:  6.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.008556, mae: 0.478208, mean_q: 0.590600, mean_eps: 0.322006\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 226311/400000: episode: 835, duration: 14.021s, episode steps: 202, steps per second:  14, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.009299, mae: 0.485241, mean_q: 0.602345, mean_eps: 0.321370\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 226787/400000: episode: 836, duration: 34.033s, episode steps: 476, steps per second:  14, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.933 [0.000, 5.000],  loss: 0.008356, mae: 0.471302, mean_q: 0.583892, mean_eps: 0.320356\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 227293/400000: episode: 837, duration: 34.356s, episode steps: 506, steps per second:  15, episode reward: 13.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.889 [0.000, 5.000],  loss: 0.009377, mae: 0.477021, mean_q: 0.589395, mean_eps: 0.318880\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 227710/400000: episode: 838, duration: 28.595s, episode steps: 417, steps per second:  15, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.010305, mae: 0.479677, mean_q: 0.591520, mean_eps: 0.317494\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 228295/400000: episode: 839, duration: 40.719s, episode steps: 585, steps per second:  14, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.176 [0.000, 5.000],  loss: 0.009770, mae: 0.475691, mean_q: 0.586038, mean_eps: 0.315994\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 228653/400000: episode: 840, duration: 25.431s, episode steps: 358, steps per second:  14, episode reward:  9.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.966 [0.000, 5.000],  loss: 0.009574, mae: 0.469344, mean_q: 0.577614, mean_eps: 0.314578\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 228890/400000: episode: 841, duration: 16.275s, episode steps: 237, steps per second:  15, episode reward:  7.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.009005, mae: 0.478605, mean_q: 0.590309, mean_eps: 0.313684\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 229151/400000: episode: 842, duration: 19.279s, episode steps: 261, steps per second:  14, episode reward:  6.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.992 [0.000, 5.000],  loss: 0.009511, mae: 0.475754, mean_q: 0.585587, mean_eps: 0.312940\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 229358/400000: episode: 843, duration: 14.613s, episode steps: 207, steps per second:  14, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.768 [0.000, 5.000],  loss: 0.010255, mae: 0.479278, mean_q: 0.588899, mean_eps: 0.312238\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 229576/400000: episode: 844, duration: 15.298s, episode steps: 218, steps per second:  14, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 3.060 [0.000, 5.000],  loss: 0.011080, mae: 0.499838, mean_q: 0.614634, mean_eps: 0.311602\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 229789/400000: episode: 845, duration: 15.092s, episode steps: 213, steps per second:  14, episode reward:  6.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 3.235 [0.000, 5.000],  loss: 0.010579, mae: 0.527036, mean_q: 0.648649, mean_eps: 0.310954\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 230150/400000: episode: 846, duration: 25.406s, episode steps: 361, steps per second:  14, episode reward:  9.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 3.252 [0.000, 5.000],  loss: 0.009466, mae: 0.510604, mean_q: 0.633761, mean_eps: 0.310090\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 230720/400000: episode: 847, duration: 40.830s, episode steps: 570, steps per second:  14, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.010635, mae: 0.524816, mean_q: 0.646914, mean_eps: 0.308698\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 230960/400000: episode: 848, duration: 16.955s, episode steps: 240, steps per second:  14, episode reward:  8.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.009577, mae: 0.513393, mean_q: 0.633800, mean_eps: 0.307486\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 231459/400000: episode: 849, duration: 35.772s, episode steps: 499, steps per second:  14, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: 0.009295, mae: 0.503319, mean_q: 0.619498, mean_eps: 0.306376\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 231699/400000: episode: 850, duration: 16.490s, episode steps: 240, steps per second:  15, episode reward:  5.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.642 [0.000, 5.000],  loss: 0.007664, mae: 0.490463, mean_q: 0.606989, mean_eps: 0.305266\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 232120/400000: episode: 851, duration: 29.344s, episode steps: 421, steps per second:  14, episode reward:  9.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.292 [0.000, 5.000],  loss: 0.010041, mae: 0.514371, mean_q: 0.633605, mean_eps: 0.304276\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 232360/400000: episode: 852, duration: 16.671s, episode steps: 240, steps per second:  14, episode reward:  8.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.008939, mae: 0.500020, mean_q: 0.615952, mean_eps: 0.303286\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 232774/400000: episode: 853, duration: 29.447s, episode steps: 414, steps per second:  14, episode reward:  9.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.010129, mae: 0.518327, mean_q: 0.639442, mean_eps: 0.302302\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 233036/400000: episode: 854, duration: 19.874s, episode steps: 262, steps per second:  13, episode reward:  7.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.683 [0.000, 5.000],  loss: 0.012327, mae: 0.516809, mean_q: 0.636564, mean_eps: 0.301288\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 233242/400000: episode: 855, duration: 14.810s, episode steps: 206, steps per second:  14, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.233 [0.000, 5.000],  loss: 0.009280, mae: 0.516103, mean_q: 0.636590, mean_eps: 0.300586\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 233835/400000: episode: 856, duration: 41.920s, episode steps: 593, steps per second:  14, episode reward: 13.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.228 [0.000, 5.000],  loss: 0.010571, mae: 0.512220, mean_q: 0.630346, mean_eps: 0.299386\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 234033/400000: episode: 857, duration: 14.236s, episode steps: 198, steps per second:  14, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.737 [0.000, 5.000],  loss: 0.009049, mae: 0.497762, mean_q: 0.615111, mean_eps: 0.298198\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 234412/400000: episode: 858, duration: 27.415s, episode steps: 379, steps per second:  14, episode reward: 10.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 1.982 [0.000, 5.000],  loss: 0.009757, mae: 0.507269, mean_q: 0.624144, mean_eps: 0.297334\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 234830/400000: episode: 859, duration: 29.550s, episode steps: 418, steps per second:  14, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.184 [0.000, 5.000],  loss: 0.008777, mae: 0.497602, mean_q: 0.611437, mean_eps: 0.296140\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 235030/400000: episode: 860, duration: 14.232s, episode steps: 200, steps per second:  14, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.240 [0.000, 5.000],  loss: 0.010151, mae: 0.520249, mean_q: 0.638898, mean_eps: 0.295210\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 235565/400000: episode: 861, duration: 38.259s, episode steps: 535, steps per second:  14, episode reward: 16.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.010441, mae: 0.514344, mean_q: 0.632307, mean_eps: 0.294106\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 235840/400000: episode: 862, duration: 18.813s, episode steps: 275, steps per second:  15, episode reward:  5.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.073 [0.000, 5.000],  loss: 0.010797, mae: 0.516794, mean_q: 0.636973, mean_eps: 0.292894\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 236091/400000: episode: 863, duration: 18.403s, episode steps: 251, steps per second:  14, episode reward:  5.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.363 [0.000, 5.000],  loss: 0.009182, mae: 0.495709, mean_q: 0.611888, mean_eps: 0.292108\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 236611/400000: episode: 864, duration: 36.945s, episode steps: 520, steps per second:  14, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.302 [0.000, 5.000],  loss: 0.009063, mae: 0.508732, mean_q: 0.628263, mean_eps: 0.290950\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 236821/400000: episode: 865, duration: 15.170s, episode steps: 210, steps per second:  14, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.033 [0.000, 5.000],  loss: 0.008277, mae: 0.508400, mean_q: 0.628938, mean_eps: 0.289852\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 237362/400000: episode: 866, duration: 39.436s, episode steps: 541, steps per second:  14, episode reward: 16.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.009541, mae: 0.518090, mean_q: 0.638255, mean_eps: 0.288724\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 237571/400000: episode: 867, duration: 14.825s, episode steps: 209, steps per second:  14, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.507 [0.000, 5.000],  loss: 0.009436, mae: 0.492524, mean_q: 0.605268, mean_eps: 0.287602\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 237799/400000: episode: 868, duration: 16.279s, episode steps: 228, steps per second:  14, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 1.794 [0.000, 5.000],  loss: 0.012629, mae: 0.513769, mean_q: 0.631736, mean_eps: 0.286948\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 238073/400000: episode: 869, duration: 20.599s, episode steps: 274, steps per second:  13, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.391 [0.000, 5.000],  loss: 0.010581, mae: 0.536147, mean_q: 0.661101, mean_eps: 0.286192\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 238363/400000: episode: 870, duration: 19.757s, episode steps: 290, steps per second:  15, episode reward:  6.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: 0.009139, mae: 0.554157, mean_q: 0.683180, mean_eps: 0.285346\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 238575/400000: episode: 871, duration: 15.023s, episode steps: 212, steps per second:  14, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.387 [0.000, 5.000],  loss: 0.007973, mae: 0.548525, mean_q: 0.678905, mean_eps: 0.284596\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 239153/400000: episode: 872, duration: 40.710s, episode steps: 578, steps per second:  14, episode reward: 13.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.263 [0.000, 5.000],  loss: 0.010189, mae: 0.558758, mean_q: 0.688729, mean_eps: 0.283408\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 239423/400000: episode: 873, duration: 20.004s, episode steps: 270, steps per second:  13, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.009717, mae: 0.553268, mean_q: 0.681616, mean_eps: 0.282136\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 239829/400000: episode: 874, duration: 28.649s, episode steps: 406, steps per second:  14, episode reward: 10.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.010822, mae: 0.558732, mean_q: 0.687862, mean_eps: 0.281122\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 240040/400000: episode: 875, duration: 14.826s, episode steps: 211, steps per second:  14, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.227 [0.000, 5.000],  loss: 0.009084, mae: 0.547609, mean_q: 0.673734, mean_eps: 0.280198\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 240281/400000: episode: 876, duration: 16.856s, episode steps: 241, steps per second:  14, episode reward:  5.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.162 [0.000, 5.000],  loss: 0.008970, mae: 0.563252, mean_q: 0.696522, mean_eps: 0.279520\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 240497/400000: episode: 877, duration: 15.145s, episode steps: 216, steps per second:  14, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.903 [0.000, 5.000],  loss: 0.008790, mae: 0.563931, mean_q: 0.695168, mean_eps: 0.278830\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 240721/400000: episode: 878, duration: 16.164s, episode steps: 224, steps per second:  14, episode reward:  5.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.290 [0.000, 5.000],  loss: 0.010283, mae: 0.562743, mean_q: 0.693469, mean_eps: 0.278170\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 240967/400000: episode: 879, duration: 17.811s, episode steps: 246, steps per second:  14, episode reward:  9.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 3.264 [0.000, 5.000],  loss: 0.011963, mae: 0.560964, mean_q: 0.691573, mean_eps: 0.277468\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 241191/400000: episode: 880, duration: 15.670s, episode steps: 224, steps per second:  14, episode reward:  6.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.746 [0.000, 5.000],  loss: 0.009375, mae: 0.571054, mean_q: 0.702865, mean_eps: 0.276766\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 241543/400000: episode: 881, duration: 25.208s, episode steps: 352, steps per second:  14, episode reward:  9.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.307 [0.000, 5.000],  loss: 0.010290, mae: 0.559505, mean_q: 0.688158, mean_eps: 0.275902\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 241801/400000: episode: 882, duration: 17.884s, episode steps: 258, steps per second:  14, episode reward:  7.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.760 [0.000, 5.000],  loss: 0.009782, mae: 0.569485, mean_q: 0.700191, mean_eps: 0.274984\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 242040/400000: episode: 883, duration: 16.730s, episode steps: 239, steps per second:  14, episode reward:  9.000, mean reward:  0.038 [ 0.000,  1.000], mean action: 1.891 [0.000, 5.000],  loss: 0.010206, mae: 0.549298, mean_q: 0.677217, mean_eps: 0.274240\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 242289/400000: episode: 884, duration: 18.450s, episode steps: 249, steps per second:  13, episode reward:  8.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.011181, mae: 0.560026, mean_q: 0.691515, mean_eps: 0.273508\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 242570/400000: episode: 885, duration: 19.299s, episode steps: 281, steps per second:  15, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.010427, mae: 0.566788, mean_q: 0.697374, mean_eps: 0.272710\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 243095/400000: episode: 886, duration: 37.249s, episode steps: 525, steps per second:  14, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.737 [0.000, 5.000],  loss: 0.010788, mae: 0.560394, mean_q: 0.689915, mean_eps: 0.271504\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 243374/400000: episode: 887, duration: 19.011s, episode steps: 279, steps per second:  15, episode reward:  5.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.853 [0.000, 5.000],  loss: 0.009225, mae: 0.546221, mean_q: 0.674721, mean_eps: 0.270298\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 243599/400000: episode: 888, duration: 15.677s, episode steps: 225, steps per second:  14, episode reward:  3.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.008866, mae: 0.531879, mean_q: 0.654804, mean_eps: 0.269542\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 243898/400000: episode: 889, duration: 21.940s, episode steps: 299, steps per second:  14, episode reward:  4.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.009370, mae: 0.541737, mean_q: 0.666416, mean_eps: 0.268756\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 244176/400000: episode: 890, duration: 19.129s, episode steps: 278, steps per second:  15, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.009162, mae: 0.553563, mean_q: 0.682145, mean_eps: 0.267892\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 244428/400000: episode: 891, duration: 18.829s, episode steps: 252, steps per second:  13, episode reward:  7.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.011424, mae: 0.557782, mean_q: 0.686664, mean_eps: 0.267100\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 244654/400000: episode: 892, duration: 16.253s, episode steps: 226, steps per second:  14, episode reward:  6.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.007719, mae: 0.541640, mean_q: 0.666582, mean_eps: 0.266380\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 244884/400000: episode: 893, duration: 16.121s, episode steps: 230, steps per second:  14, episode reward:  4.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.213 [0.000, 5.000],  loss: 0.012094, mae: 0.563016, mean_q: 0.691841, mean_eps: 0.265696\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 245750/400000: episode: 894, duration: 60.654s, episode steps: 866, steps per second:  14, episode reward: 21.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.009355, mae: 0.551596, mean_q: 0.678272, mean_eps: 0.264052\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 245960/400000: episode: 895, duration: 15.217s, episode steps: 210, steps per second:  14, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.971 [0.000, 5.000],  loss: 0.009679, mae: 0.562647, mean_q: 0.691052, mean_eps: 0.262438\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 246189/400000: episode: 896, duration: 17.358s, episode steps: 229, steps per second:  13, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.009897, mae: 0.549843, mean_q: 0.676690, mean_eps: 0.261778\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 246445/400000: episode: 897, duration: 17.559s, episode steps: 256, steps per second:  15, episode reward:  8.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.254 [0.000, 5.000],  loss: 0.008530, mae: 0.555292, mean_q: 0.683034, mean_eps: 0.261046\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 246637/400000: episode: 898, duration: 13.755s, episode steps: 192, steps per second:  14, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.011573, mae: 0.593681, mean_q: 0.731958, mean_eps: 0.260374\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 247082/400000: episode: 899, duration: 31.324s, episode steps: 445, steps per second:  14, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.008865, mae: 0.571338, mean_q: 0.703108, mean_eps: 0.259420\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 247320/400000: episode: 900, duration: 17.919s, episode steps: 238, steps per second:  13, episode reward:  6.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: 0.006902, mae: 0.559365, mean_q: 0.690358, mean_eps: 0.258400\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 247457/400000: episode: 901, duration: 9.651s, episode steps: 137, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.774 [0.000, 5.000],  loss: 0.011192, mae: 0.572716, mean_q: 0.703329, mean_eps: 0.257836\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 247662/400000: episode: 902, duration: 14.672s, episode steps: 205, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.932 [0.000, 5.000],  loss: 0.009418, mae: 0.578224, mean_q: 0.711399, mean_eps: 0.257320\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 247873/400000: episode: 903, duration: 15.238s, episode steps: 211, steps per second:  14, episode reward:  6.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 1.673 [0.000, 5.000],  loss: 0.008944, mae: 0.571633, mean_q: 0.703269, mean_eps: 0.256696\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 248493/400000: episode: 904, duration: 45.059s, episode steps: 620, steps per second:  14, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.929 [0.000, 5.000],  loss: 0.010908, mae: 0.594918, mean_q: 0.730603, mean_eps: 0.255448\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 248697/400000: episode: 905, duration: 14.613s, episode steps: 204, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.784 [0.000, 5.000],  loss: 0.010114, mae: 0.581157, mean_q: 0.714980, mean_eps: 0.254212\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 248952/400000: episode: 906, duration: 17.884s, episode steps: 255, steps per second:  14, episode reward:  8.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.009859, mae: 0.582732, mean_q: 0.719234, mean_eps: 0.253528\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 249192/400000: episode: 907, duration: 17.047s, episode steps: 240, steps per second:  14, episode reward:  6.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.009905, mae: 0.589388, mean_q: 0.723756, mean_eps: 0.252790\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 249410/400000: episode: 908, duration: 16.096s, episode steps: 218, steps per second:  14, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.890 [0.000, 5.000],  loss: 0.009605, mae: 0.567320, mean_q: 0.700795, mean_eps: 0.252100\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 249649/400000: episode: 909, duration: 18.094s, episode steps: 239, steps per second:  13, episode reward:  6.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.397 [0.000, 5.000],  loss: 0.009726, mae: 0.572579, mean_q: 0.704172, mean_eps: 0.251410\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 249877/400000: episode: 910, duration: 16.161s, episode steps: 228, steps per second:  14, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.009745, mae: 0.579759, mean_q: 0.713857, mean_eps: 0.250708\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 250075/400000: episode: 911, duration: 14.066s, episode steps: 198, steps per second:  14, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.747 [0.000, 5.000],  loss: 0.010387, mae: 0.570692, mean_q: 0.703325, mean_eps: 0.250072\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 250338/400000: episode: 912, duration: 18.386s, episode steps: 263, steps per second:  14, episode reward:  9.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 1.996 [0.000, 5.000],  loss: 0.012034, mae: 0.584923, mean_q: 0.717912, mean_eps: 0.249382\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 250581/400000: episode: 913, duration: 18.398s, episode steps: 243, steps per second:  13, episode reward:  5.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.897 [0.000, 5.000],  loss: 0.010688, mae: 0.577205, mean_q: 0.711061, mean_eps: 0.248620\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 250782/400000: episode: 914, duration: 14.443s, episode steps: 201, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.891 [0.000, 5.000],  loss: 0.010851, mae: 0.586195, mean_q: 0.723727, mean_eps: 0.247954\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 251177/400000: episode: 915, duration: 28.209s, episode steps: 395, steps per second:  14, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.208 [0.000, 5.000],  loss: 0.009725, mae: 0.582491, mean_q: 0.718113, mean_eps: 0.247060\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 251562/400000: episode: 916, duration: 27.644s, episode steps: 385, steps per second:  14, episode reward: 12.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.252 [0.000, 5.000],  loss: 0.009843, mae: 0.572021, mean_q: 0.703398, mean_eps: 0.245890\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 251762/400000: episode: 917, duration: 14.324s, episode steps: 200, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.010 [0.000, 5.000],  loss: 0.010098, mae: 0.579716, mean_q: 0.714279, mean_eps: 0.245014\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 252217/400000: episode: 918, duration: 31.972s, episode steps: 455, steps per second:  14, episode reward: 11.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.862 [0.000, 5.000],  loss: 0.011215, mae: 0.571616, mean_q: 0.704181, mean_eps: 0.244030\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 252623/400000: episode: 919, duration: 28.782s, episode steps: 406, steps per second:  14, episode reward:  9.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.904 [0.000, 5.000],  loss: 0.010138, mae: 0.565292, mean_q: 0.695575, mean_eps: 0.242740\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 252892/400000: episode: 920, duration: 20.381s, episode steps: 269, steps per second:  13, episode reward:  7.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 1.907 [0.000, 5.000],  loss: 0.010693, mae: 0.582368, mean_q: 0.713866, mean_eps: 0.241732\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 253099/400000: episode: 921, duration: 14.663s, episode steps: 207, steps per second:  14, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.008236, mae: 0.582280, mean_q: 0.716580, mean_eps: 0.241018\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 253397/400000: episode: 922, duration: 20.514s, episode steps: 298, steps per second:  15, episode reward:  5.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.008040, mae: 0.567956, mean_q: 0.697284, mean_eps: 0.240256\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 253604/400000: episode: 923, duration: 14.685s, episode steps: 207, steps per second:  14, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.010374, mae: 0.593226, mean_q: 0.728387, mean_eps: 0.239500\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 253849/400000: episode: 924, duration: 18.835s, episode steps: 245, steps per second:  13, episode reward:  7.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.011908, mae: 0.582471, mean_q: 0.714488, mean_eps: 0.238822\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 254111/400000: episode: 925, duration: 18.000s, episode steps: 262, steps per second:  15, episode reward:  6.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.008130, mae: 0.560469, mean_q: 0.688766, mean_eps: 0.238060\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 254321/400000: episode: 926, duration: 15.185s, episode steps: 210, steps per second:  14, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.012626, mae: 0.589811, mean_q: 0.724109, mean_eps: 0.237352\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 254532/400000: episode: 927, duration: 14.946s, episode steps: 211, steps per second:  14, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.008472, mae: 0.587994, mean_q: 0.723047, mean_eps: 0.236722\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 254849/400000: episode: 928, duration: 23.213s, episode steps: 317, steps per second:  14, episode reward:  4.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.271 [0.000, 5.000],  loss: 0.008969, mae: 0.574114, mean_q: 0.706342, mean_eps: 0.235930\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 255071/400000: episode: 929, duration: 15.490s, episode steps: 222, steps per second:  14, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.027 [0.000, 5.000],  loss: 0.009154, mae: 0.584486, mean_q: 0.719880, mean_eps: 0.235120\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 255367/400000: episode: 930, duration: 20.730s, episode steps: 296, steps per second:  14, episode reward:  3.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 1.591 [0.000, 5.000],  loss: 0.009837, mae: 0.581389, mean_q: 0.716197, mean_eps: 0.234346\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 255631/400000: episode: 931, duration: 19.304s, episode steps: 264, steps per second:  14, episode reward:  4.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.091 [0.000, 5.000],  loss: 0.011265, mae: 0.609464, mean_q: 0.750728, mean_eps: 0.233506\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 255831/400000: episode: 932, duration: 14.506s, episode steps: 200, steps per second:  14, episode reward:  6.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.009260, mae: 0.581684, mean_q: 0.716271, mean_eps: 0.232810\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 256212/400000: episode: 933, duration: 27.733s, episode steps: 381, steps per second:  14, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.979 [0.000, 5.000],  loss: 0.009813, mae: 0.587777, mean_q: 0.724797, mean_eps: 0.231940\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 256706/400000: episode: 934, duration: 35.598s, episode steps: 494, steps per second:  14, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.698 [0.000, 5.000],  loss: 0.011493, mae: 0.581622, mean_q: 0.717489, mean_eps: 0.230626\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 256927/400000: episode: 935, duration: 16.280s, episode steps: 221, steps per second:  14, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.010579, mae: 0.582609, mean_q: 0.718912, mean_eps: 0.229552\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 257129/400000: episode: 936, duration: 14.610s, episode steps: 202, steps per second:  14, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 3.074 [0.000, 5.000],  loss: 0.007529, mae: 0.579828, mean_q: 0.715530, mean_eps: 0.228916\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 257370/400000: episode: 937, duration: 17.617s, episode steps: 241, steps per second:  14, episode reward:  5.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.876 [0.000, 5.000],  loss: 0.009640, mae: 0.603200, mean_q: 0.744066, mean_eps: 0.228250\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 257578/400000: episode: 938, duration: 15.338s, episode steps: 208, steps per second:  14, episode reward:  6.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.009919, mae: 0.591442, mean_q: 0.729520, mean_eps: 0.227578\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 258007/400000: episode: 939, duration: 30.266s, episode steps: 429, steps per second:  14, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.233 [0.000, 5.000],  loss: 0.008415, mae: 0.587999, mean_q: 0.726771, mean_eps: 0.226624\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 258292/400000: episode: 940, duration: 21.279s, episode steps: 285, steps per second:  13, episode reward:  6.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.958 [0.000, 5.000],  loss: 0.009783, mae: 0.571410, mean_q: 0.703437, mean_eps: 0.225556\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 258538/400000: episode: 941, duration: 17.363s, episode steps: 246, steps per second:  14, episode reward:  7.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.183 [0.000, 5.000],  loss: 0.009891, mae: 0.596267, mean_q: 0.734652, mean_eps: 0.224758\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 259037/400000: episode: 942, duration: 36.155s, episode steps: 499, steps per second:  14, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: 0.009773, mae: 0.587913, mean_q: 0.722938, mean_eps: 0.223636\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 259300/400000: episode: 943, duration: 18.428s, episode steps: 263, steps per second:  14, episode reward:  6.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.327 [0.000, 5.000],  loss: 0.008213, mae: 0.591870, mean_q: 0.726713, mean_eps: 0.222496\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 259509/400000: episode: 944, duration: 15.093s, episode steps: 209, steps per second:  14, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.263 [0.000, 5.000],  loss: 0.009918, mae: 0.591619, mean_q: 0.726929, mean_eps: 0.221788\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 259720/400000: episode: 945, duration: 16.267s, episode steps: 211, steps per second:  13, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.853 [0.000, 5.000],  loss: 0.008625, mae: 0.586358, mean_q: 0.723828, mean_eps: 0.221158\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 260211/400000: episode: 946, duration: 36.224s, episode steps: 491, steps per second:  14, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.029 [0.000, 5.000],  loss: 0.009617, mae: 0.585684, mean_q: 0.721531, mean_eps: 0.220108\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 260413/400000: episode: 947, duration: 14.718s, episode steps: 202, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 3.054 [0.000, 5.000],  loss: 0.009888, mae: 0.584517, mean_q: 0.718409, mean_eps: 0.219064\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 260620/400000: episode: 948, duration: 14.749s, episode steps: 207, steps per second:  14, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.010633, mae: 0.602050, mean_q: 0.741235, mean_eps: 0.218452\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 261298/400000: episode: 949, duration: 49.131s, episode steps: 678, steps per second:  14, episode reward: 17.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.751 [0.000, 5.000],  loss: 0.008917, mae: 0.585541, mean_q: 0.722454, mean_eps: 0.217126\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 261507/400000: episode: 950, duration: 14.710s, episode steps: 209, steps per second:  14, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.009232, mae: 0.587654, mean_q: 0.725065, mean_eps: 0.215794\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 261704/400000: episode: 951, duration: 14.443s, episode steps: 197, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.487 [0.000, 5.000],  loss: 0.010079, mae: 0.581202, mean_q: 0.716373, mean_eps: 0.215188\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 261889/400000: episode: 952, duration: 13.506s, episode steps: 185, steps per second:  14, episode reward:  3.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.892 [0.000, 5.000],  loss: 0.009193, mae: 0.569361, mean_q: 0.702249, mean_eps: 0.214612\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 262154/400000: episode: 953, duration: 18.571s, episode steps: 265, steps per second:  14, episode reward:  5.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.653 [0.000, 5.000],  loss: 0.011289, mae: 0.600120, mean_q: 0.739347, mean_eps: 0.213934\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 262666/400000: episode: 954, duration: 37.099s, episode steps: 512, steps per second:  14, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.011198, mae: 0.594131, mean_q: 0.730550, mean_eps: 0.212770\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 262876/400000: episode: 955, duration: 15.016s, episode steps: 210, steps per second:  14, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 3.048 [0.000, 5.000],  loss: 0.011031, mae: 0.596988, mean_q: 0.733929, mean_eps: 0.211690\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 263117/400000: episode: 956, duration: 16.952s, episode steps: 241, steps per second:  14, episode reward:  8.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.809 [0.000, 5.000],  loss: 0.011076, mae: 0.592183, mean_q: 0.728499, mean_eps: 0.211012\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 263349/400000: episode: 957, duration: 16.150s, episode steps: 232, steps per second:  14, episode reward:  8.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.011183, mae: 0.614430, mean_q: 0.759344, mean_eps: 0.210298\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 263595/400000: episode: 958, duration: 18.759s, episode steps: 246, steps per second:  13, episode reward:  7.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 1.907 [0.000, 5.000],  loss: 0.009676, mae: 0.603631, mean_q: 0.743322, mean_eps: 0.209584\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 263791/400000: episode: 959, duration: 14.308s, episode steps: 196, steps per second:  14, episode reward:  5.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 1.694 [0.000, 5.000],  loss: 0.009293, mae: 0.589809, mean_q: 0.726225, mean_eps: 0.208924\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 264026/400000: episode: 960, duration: 16.585s, episode steps: 235, steps per second:  14, episode reward:  9.000, mean reward:  0.038 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: 0.010622, mae: 0.614723, mean_q: 0.756405, mean_eps: 0.208276\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 264228/400000: episode: 961, duration: 15.054s, episode steps: 202, steps per second:  13, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 3.233 [0.000, 5.000],  loss: 0.010010, mae: 0.606926, mean_q: 0.747918, mean_eps: 0.207622\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 264709/400000: episode: 962, duration: 34.116s, episode steps: 481, steps per second:  14, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.191 [0.000, 5.000],  loss: 0.009001, mae: 0.598643, mean_q: 0.735753, mean_eps: 0.206596\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 264955/400000: episode: 963, duration: 18.496s, episode steps: 246, steps per second:  13, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.789 [0.000, 5.000],  loss: 0.009151, mae: 0.614505, mean_q: 0.753367, mean_eps: 0.205504\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 265200/400000: episode: 964, duration: 17.366s, episode steps: 245, steps per second:  14, episode reward:  7.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.065 [0.000, 5.000],  loss: 0.011349, mae: 0.602054, mean_q: 0.740078, mean_eps: 0.204772\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 265709/400000: episode: 965, duration: 37.396s, episode steps: 509, steps per second:  14, episode reward: 19.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 2.890 [0.000, 5.000],  loss: 0.009501, mae: 0.601829, mean_q: 0.739741, mean_eps: 0.203638\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 265895/400000: episode: 966, duration: 13.435s, episode steps: 186, steps per second:  14, episode reward:  4.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.009820, mae: 0.620192, mean_q: 0.764208, mean_eps: 0.202594\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 266185/400000: episode: 967, duration: 20.220s, episode steps: 290, steps per second:  14, episode reward:  8.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.011125, mae: 0.616856, mean_q: 0.758707, mean_eps: 0.201880\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 266388/400000: episode: 968, duration: 14.638s, episode steps: 203, steps per second:  14, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.099 [0.000, 5.000],  loss: 0.010191, mae: 0.602832, mean_q: 0.742675, mean_eps: 0.201142\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 266704/400000: episode: 969, duration: 23.486s, episode steps: 316, steps per second:  13, episode reward:  9.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.009107, mae: 0.594792, mean_q: 0.733460, mean_eps: 0.200368\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 266935/400000: episode: 970, duration: 16.480s, episode steps: 231, steps per second:  14, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.861 [0.000, 5.000],  loss: 0.010168, mae: 0.598622, mean_q: 0.737566, mean_eps: 0.199546\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 267132/400000: episode: 971, duration: 14.434s, episode steps: 197, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.008876, mae: 0.593417, mean_q: 0.729539, mean_eps: 0.198904\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 267349/400000: episode: 972, duration: 15.572s, episode steps: 217, steps per second:  14, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.194 [0.000, 5.000],  loss: 0.011424, mae: 0.608569, mean_q: 0.750101, mean_eps: 0.198280\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 267560/400000: episode: 973, duration: 15.841s, episode steps: 211, steps per second:  13, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.825 [0.000, 5.000],  loss: 0.010086, mae: 0.588811, mean_q: 0.723474, mean_eps: 0.197638\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 267788/400000: episode: 974, duration: 17.052s, episode steps: 228, steps per second:  13, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.904 [0.000, 5.000],  loss: 0.010457, mae: 0.591899, mean_q: 0.727472, mean_eps: 0.196984\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 268071/400000: episode: 975, duration: 19.434s, episode steps: 283, steps per second:  15, episode reward:  8.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 3.081 [0.000, 5.000],  loss: 0.011484, mae: 0.609573, mean_q: 0.749824, mean_eps: 0.196216\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 268280/400000: episode: 976, duration: 15.155s, episode steps: 209, steps per second:  14, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.943 [0.000, 5.000],  loss: 0.011232, mae: 0.609560, mean_q: 0.751043, mean_eps: 0.195478\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 268485/400000: episode: 977, duration: 15.105s, episode steps: 205, steps per second:  14, episode reward:  6.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.117 [0.000, 5.000],  loss: 0.009449, mae: 0.592775, mean_q: 0.730437, mean_eps: 0.194854\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 268871/400000: episode: 978, duration: 27.886s, episode steps: 386, steps per second:  14, episode reward: 12.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.640 [0.000, 5.000],  loss: 0.009804, mae: 0.603640, mean_q: 0.742582, mean_eps: 0.193966\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 269122/400000: episode: 979, duration: 19.235s, episode steps: 251, steps per second:  13, episode reward:  9.000, mean reward:  0.036 [ 0.000,  1.000], mean action: 3.279 [0.000, 5.000],  loss: 0.009976, mae: 0.591822, mean_q: 0.727880, mean_eps: 0.193012\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 269371/400000: episode: 980, duration: 17.658s, episode steps: 249, steps per second:  14, episode reward:  7.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.149 [0.000, 5.000],  loss: 0.008246, mae: 0.595413, mean_q: 0.733044, mean_eps: 0.192262\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 269595/400000: episode: 981, duration: 16.110s, episode steps: 224, steps per second:  14, episode reward:  5.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.317 [0.000, 5.000],  loss: 0.009769, mae: 0.607401, mean_q: 0.746976, mean_eps: 0.191554\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 269804/400000: episode: 982, duration: 15.271s, episode steps: 209, steps per second:  14, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.876 [0.000, 5.000],  loss: 0.012088, mae: 0.600148, mean_q: 0.735689, mean_eps: 0.190906\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 270013/400000: episode: 983, duration: 16.425s, episode steps: 209, steps per second:  13, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.077 [0.000, 5.000],  loss: 0.011997, mae: 0.611226, mean_q: 0.750262, mean_eps: 0.190276\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 270209/400000: episode: 984, duration: 14.841s, episode steps: 196, steps per second:  13, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.009493, mae: 0.596001, mean_q: 0.731071, mean_eps: 0.189664\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 270444/400000: episode: 985, duration: 17.054s, episode steps: 235, steps per second:  14, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.008392, mae: 0.597486, mean_q: 0.734472, mean_eps: 0.189022\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 270690/400000: episode: 986, duration: 17.664s, episode steps: 246, steps per second:  14, episode reward:  7.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.902 [0.000, 5.000],  loss: 0.009620, mae: 0.589999, mean_q: 0.727226, mean_eps: 0.188302\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 270873/400000: episode: 987, duration: 13.468s, episode steps: 183, steps per second:  14, episode reward:  3.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.009167, mae: 0.606528, mean_q: 0.746893, mean_eps: 0.187654\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 271482/400000: episode: 988, duration: 43.426s, episode steps: 609, steps per second:  14, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.598 [0.000, 5.000],  loss: 0.009511, mae: 0.594313, mean_q: 0.729739, mean_eps: 0.186466\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 272098/400000: episode: 989, duration: 45.233s, episode steps: 616, steps per second:  14, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.005 [0.000, 5.000],  loss: 0.009763, mae: 0.601030, mean_q: 0.738969, mean_eps: 0.184630\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 272307/400000: episode: 990, duration: 15.414s, episode steps: 209, steps per second:  14, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.010381, mae: 0.627063, mean_q: 0.770831, mean_eps: 0.183394\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 272689/400000: episode: 991, duration: 27.412s, episode steps: 382, steps per second:  14, episode reward: 11.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 1.995 [0.000, 5.000],  loss: 0.010225, mae: 0.630664, mean_q: 0.775115, mean_eps: 0.182506\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 272954/400000: episode: 992, duration: 18.172s, episode steps: 265, steps per second:  15, episode reward:  9.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.766 [0.000, 5.000],  loss: 0.012110, mae: 0.623016, mean_q: 0.766400, mean_eps: 0.181534\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 273201/400000: episode: 993, duration: 17.168s, episode steps: 247, steps per second:  14, episode reward:  7.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 3.105 [0.000, 5.000],  loss: 0.012787, mae: 0.625815, mean_q: 0.769170, mean_eps: 0.180766\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 273486/400000: episode: 994, duration: 21.213s, episode steps: 285, steps per second:  13, episode reward:  9.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.361 [0.000, 5.000],  loss: 0.009392, mae: 0.632107, mean_q: 0.778479, mean_eps: 0.179968\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 273735/400000: episode: 995, duration: 17.429s, episode steps: 249, steps per second:  14, episode reward:  7.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 3.016 [0.000, 5.000],  loss: 0.009958, mae: 0.622471, mean_q: 0.765499, mean_eps: 0.179170\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 274082/400000: episode: 996, duration: 25.563s, episode steps: 347, steps per second:  14, episode reward: 10.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.010644, mae: 0.629683, mean_q: 0.773179, mean_eps: 0.178276\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 274452/400000: episode: 997, duration: 26.895s, episode steps: 370, steps per second:  14, episode reward: 11.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.000 [0.000, 5.000],  loss: 0.010236, mae: 0.623536, mean_q: 0.766772, mean_eps: 0.177202\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 274644/400000: episode: 998, duration: 14.547s, episode steps: 192, steps per second:  13, episode reward:  3.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.823 [0.000, 5.000],  loss: 0.011640, mae: 0.648576, mean_q: 0.796383, mean_eps: 0.176362\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 275068/400000: episode: 999, duration: 31.059s, episode steps: 424, steps per second:  14, episode reward: 10.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.172 [0.000, 5.000],  loss: 0.010737, mae: 0.625298, mean_q: 0.768737, mean_eps: 0.175438\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 275334/400000: episode: 1000, duration: 21.094s, episode steps: 266, steps per second:  13, episode reward:  6.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.793 [0.000, 5.000],  loss: 0.011384, mae: 0.630334, mean_q: 0.776882, mean_eps: 0.174400\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 275549/400000: episode: 1001, duration: 15.500s, episode steps: 215, steps per second:  14, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.010542, mae: 0.634415, mean_q: 0.781869, mean_eps: 0.173674\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 275756/400000: episode: 1002, duration: 14.904s, episode steps: 207, steps per second:  14, episode reward:  6.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.628 [0.000, 5.000],  loss: 0.008391, mae: 0.607480, mean_q: 0.749339, mean_eps: 0.173044\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 275952/400000: episode: 1003, duration: 14.324s, episode steps: 196, steps per second:  14, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.148 [0.000, 5.000],  loss: 0.011237, mae: 0.623128, mean_q: 0.765625, mean_eps: 0.172444\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 276160/400000: episode: 1004, duration: 15.187s, episode steps: 208, steps per second:  14, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.341 [0.000, 5.000],  loss: 0.009348, mae: 0.623323, mean_q: 0.766762, mean_eps: 0.171838\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 276373/400000: episode: 1005, duration: 15.489s, episode steps: 213, steps per second:  14, episode reward:  6.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.012218, mae: 0.641717, mean_q: 0.790173, mean_eps: 0.171202\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 276640/400000: episode: 1006, duration: 20.451s, episode steps: 267, steps per second:  13, episode reward:  9.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.009688, mae: 0.618220, mean_q: 0.761049, mean_eps: 0.170482\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 277243/400000: episode: 1007, duration: 43.513s, episode steps: 603, steps per second:  14, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.240 [0.000, 5.000],  loss: 0.009920, mae: 0.621903, mean_q: 0.766770, mean_eps: 0.169180\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 277748/400000: episode: 1008, duration: 36.174s, episode steps: 505, steps per second:  14, episode reward: 12.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.097 [0.000, 5.000],  loss: 0.009804, mae: 0.620932, mean_q: 0.763208, mean_eps: 0.167518\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 278049/400000: episode: 1009, duration: 21.930s, episode steps: 301, steps per second:  14, episode reward:  8.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.010602, mae: 0.626640, mean_q: 0.770225, mean_eps: 0.166306\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 278680/400000: episode: 1010, duration: 45.971s, episode steps: 631, steps per second:  14, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.284 [0.000, 5.000],  loss: 0.009678, mae: 0.626758, mean_q: 0.771103, mean_eps: 0.164908\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 279563/400000: episode: 1011, duration: 63.936s, episode steps: 883, steps per second:  14, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.010988, mae: 0.623856, mean_q: 0.766817, mean_eps: 0.162640\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 279790/400000: episode: 1012, duration: 16.344s, episode steps: 227, steps per second:  14, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 1.784 [0.000, 5.000],  loss: 0.009657, mae: 0.627790, mean_q: 0.773503, mean_eps: 0.160972\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 280056/400000: episode: 1013, duration: 20.660s, episode steps: 266, steps per second:  13, episode reward:  7.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.034 [0.000, 5.000],  loss: 0.008227, mae: 0.631343, mean_q: 0.778214, mean_eps: 0.160234\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 280264/400000: episode: 1014, duration: 15.758s, episode steps: 208, steps per second:  13, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.841 [0.000, 5.000],  loss: 0.009389, mae: 0.620092, mean_q: 0.764022, mean_eps: 0.159526\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 280551/400000: episode: 1015, duration: 20.517s, episode steps: 287, steps per second:  14, episode reward: 10.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 2.139 [0.000, 5.000],  loss: 0.009966, mae: 0.622146, mean_q: 0.767080, mean_eps: 0.158782\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 280798/400000: episode: 1016, duration: 19.576s, episode steps: 247, steps per second:  13, episode reward:  7.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.170 [0.000, 5.000],  loss: 0.012824, mae: 0.690677, mean_q: 0.851006, mean_eps: 0.157978\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 281074/400000: episode: 1017, duration: 19.756s, episode steps: 276, steps per second:  14, episode reward: 10.000, mean reward:  0.036 [ 0.000,  1.000], mean action: 3.040 [0.000, 5.000],  loss: 0.011998, mae: 0.656396, mean_q: 0.809864, mean_eps: 0.157192\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 281398/400000: episode: 1018, duration: 24.633s, episode steps: 324, steps per second:  13, episode reward: 10.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.775 [0.000, 5.000],  loss: 0.009751, mae: 0.661132, mean_q: 0.816327, mean_eps: 0.156292\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 281644/400000: episode: 1019, duration: 17.991s, episode steps: 246, steps per second:  14, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.012838, mae: 0.669269, mean_q: 0.822683, mean_eps: 0.155440\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 281897/400000: episode: 1020, duration: 20.163s, episode steps: 253, steps per second:  13, episode reward: 10.000, mean reward:  0.040 [ 0.000,  1.000], mean action: 2.162 [0.000, 5.000],  loss: 0.010801, mae: 0.656567, mean_q: 0.810161, mean_eps: 0.154690\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 282116/400000: episode: 1021, duration: 16.437s, episode steps: 219, steps per second:  13, episode reward:  6.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.123 [0.000, 5.000],  loss: 0.009284, mae: 0.673309, mean_q: 0.831043, mean_eps: 0.153982\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 282320/400000: episode: 1022, duration: 15.681s, episode steps: 204, steps per second:  13, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.858 [0.000, 5.000],  loss: 0.013007, mae: 0.682159, mean_q: 0.836914, mean_eps: 0.153352\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 282825/400000: episode: 1023, duration: 37.971s, episode steps: 505, steps per second:  13, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.010032, mae: 0.649830, mean_q: 0.800932, mean_eps: 0.152284\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 283110/400000: episode: 1024, duration: 20.099s, episode steps: 285, steps per second:  14, episode reward:  5.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.642 [0.000, 5.000],  loss: 0.009620, mae: 0.654376, mean_q: 0.805620, mean_eps: 0.151096\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 283501/400000: episode: 1025, duration: 29.142s, episode steps: 391, steps per second:  13, episode reward: 11.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.010107, mae: 0.651184, mean_q: 0.801123, mean_eps: 0.150082\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 283785/400000: episode: 1026, duration: 21.043s, episode steps: 284, steps per second:  13, episode reward:  8.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 1.588 [0.000, 5.000],  loss: 0.011148, mae: 0.655243, mean_q: 0.804595, mean_eps: 0.149068\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 284027/400000: episode: 1027, duration: 17.146s, episode steps: 242, steps per second:  14, episode reward:  8.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.198 [0.000, 5.000],  loss: 0.009638, mae: 0.654630, mean_q: 0.805663, mean_eps: 0.148282\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 284262/400000: episode: 1028, duration: 17.995s, episode steps: 235, steps per second:  13, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 3.294 [0.000, 5.000],  loss: 0.012038, mae: 0.658169, mean_q: 0.810750, mean_eps: 0.147568\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 284799/400000: episode: 1029, duration: 37.742s, episode steps: 537, steps per second:  14, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.762 [0.000, 5.000],  loss: 0.010413, mae: 0.653764, mean_q: 0.802902, mean_eps: 0.146410\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 285004/400000: episode: 1030, duration: 15.314s, episode steps: 205, steps per second:  13, episode reward:  6.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.127 [0.000, 5.000],  loss: 0.011185, mae: 0.667441, mean_q: 0.820902, mean_eps: 0.145300\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 285297/400000: episode: 1031, duration: 21.704s, episode steps: 293, steps per second:  13, episode reward:  8.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.123 [0.000, 5.000],  loss: 0.011212, mae: 0.654028, mean_q: 0.801527, mean_eps: 0.144550\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 285607/400000: episode: 1032, duration: 23.109s, episode steps: 310, steps per second:  13, episode reward:  9.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.671 [0.000, 5.000],  loss: 0.009901, mae: 0.653221, mean_q: 0.802437, mean_eps: 0.143644\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 286043/400000: episode: 1033, duration: 31.347s, episode steps: 436, steps per second:  14, episode reward: 12.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.906 [0.000, 5.000],  loss: 0.009480, mae: 0.648864, mean_q: 0.800203, mean_eps: 0.142528\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 286244/400000: episode: 1034, duration: 14.678s, episode steps: 201, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.279 [0.000, 5.000],  loss: 0.009361, mae: 0.642385, mean_q: 0.788969, mean_eps: 0.141574\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 286467/400000: episode: 1035, duration: 16.237s, episode steps: 223, steps per second:  14, episode reward:  5.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.444 [0.000, 5.000],  loss: 0.009788, mae: 0.667629, mean_q: 0.820158, mean_eps: 0.140938\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 286772/400000: episode: 1036, duration: 22.876s, episode steps: 305, steps per second:  13, episode reward:  7.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.377 [0.000, 5.000],  loss: 0.011682, mae: 0.668177, mean_q: 0.819983, mean_eps: 0.140146\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 287163/400000: episode: 1037, duration: 28.367s, episode steps: 391, steps per second:  14, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 3.064 [0.000, 5.000],  loss: 0.010901, mae: 0.659421, mean_q: 0.810183, mean_eps: 0.139102\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 287368/400000: episode: 1038, duration: 14.838s, episode steps: 205, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.971 [0.000, 5.000],  loss: 0.010678, mae: 0.640079, mean_q: 0.786117, mean_eps: 0.138208\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 287749/400000: episode: 1039, duration: 27.659s, episode steps: 381, steps per second:  14, episode reward: 11.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 1.840 [0.000, 5.000],  loss: 0.010331, mae: 0.664593, mean_q: 0.816789, mean_eps: 0.137326\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 288249/400000: episode: 1040, duration: 36.630s, episode steps: 500, steps per second:  14, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.380 [0.000, 5.000],  loss: 0.009516, mae: 0.648538, mean_q: 0.797083, mean_eps: 0.136000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 288651/400000: episode: 1041, duration: 29.034s, episode steps: 402, steps per second:  14, episode reward: 10.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.813 [0.000, 5.000],  loss: 0.010161, mae: 0.667937, mean_q: 0.823165, mean_eps: 0.134650\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 288862/400000: episode: 1042, duration: 15.258s, episode steps: 211, steps per second:  14, episode reward:  6.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.114 [0.000, 5.000],  loss: 0.009061, mae: 0.656731, mean_q: 0.808576, mean_eps: 0.133732\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 289151/400000: episode: 1043, duration: 21.028s, episode steps: 289, steps per second:  14, episode reward:  9.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.090 [0.000, 5.000],  loss: 0.010219, mae: 0.669727, mean_q: 0.822227, mean_eps: 0.132982\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 289359/400000: episode: 1044, duration: 15.827s, episode steps: 208, steps per second:  13, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.538 [0.000, 5.000],  loss: 0.011286, mae: 0.674418, mean_q: 0.829924, mean_eps: 0.132238\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 289756/400000: episode: 1045, duration: 28.895s, episode steps: 397, steps per second:  14, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.212 [0.000, 5.000],  loss: 0.010766, mae: 0.706734, mean_q: 0.868467, mean_eps: 0.131332\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 290156/400000: episode: 1046, duration: 29.277s, episode steps: 400, steps per second:  14, episode reward:  9.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.840 [0.000, 5.000],  loss: 0.010485, mae: 0.685235, mean_q: 0.841047, mean_eps: 0.130138\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 290555/400000: episode: 1047, duration: 29.175s, episode steps: 399, steps per second:  14, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: 0.010225, mae: 0.659499, mean_q: 0.809946, mean_eps: 0.128938\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 291077/400000: episode: 1048, duration: 38.388s, episode steps: 522, steps per second:  14, episode reward: 13.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.082 [0.000, 5.000],  loss: 0.012115, mae: 0.688991, mean_q: 0.846345, mean_eps: 0.127552\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 291279/400000: episode: 1049, duration: 14.671s, episode steps: 202, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.337 [0.000, 5.000],  loss: 0.010441, mae: 0.691407, mean_q: 0.851320, mean_eps: 0.126466\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 291519/400000: episode: 1050, duration: 16.993s, episode steps: 240, steps per second:  14, episode reward:  6.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.000 [0.000, 5.000],  loss: 0.011936, mae: 0.692176, mean_q: 0.850745, mean_eps: 0.125806\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 291943/400000: episode: 1051, duration: 30.510s, episode steps: 424, steps per second:  14, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.415 [0.000, 5.000],  loss: 0.010247, mae: 0.674535, mean_q: 0.828094, mean_eps: 0.124810\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 292187/400000: episode: 1052, duration: 18.958s, episode steps: 244, steps per second:  13, episode reward:  5.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.320 [0.000, 5.000],  loss: 0.010546, mae: 0.686615, mean_q: 0.843256, mean_eps: 0.123808\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 292445/400000: episode: 1053, duration: 18.397s, episode steps: 258, steps per second:  14, episode reward:  4.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.391 [0.000, 5.000],  loss: 0.013387, mae: 0.693884, mean_q: 0.850620, mean_eps: 0.123052\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 292846/400000: episode: 1054, duration: 28.715s, episode steps: 401, steps per second:  14, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.793 [0.000, 5.000],  loss: 0.010619, mae: 0.666321, mean_q: 0.817911, mean_eps: 0.122062\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 293283/400000: episode: 1055, duration: 31.687s, episode steps: 437, steps per second:  14, episode reward: 11.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.881 [0.000, 5.000],  loss: 0.009064, mae: 0.671624, mean_q: 0.824827, mean_eps: 0.120808\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 293875/400000: episode: 1056, duration: 43.579s, episode steps: 592, steps per second:  14, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.855 [0.000, 5.000],  loss: 0.009437, mae: 0.683071, mean_q: 0.841954, mean_eps: 0.119266\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 294180/400000: episode: 1057, duration: 21.086s, episode steps: 305, steps per second:  14, episode reward:  5.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.193 [0.000, 5.000],  loss: 0.011295, mae: 0.684429, mean_q: 0.840325, mean_eps: 0.117922\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 294451/400000: episode: 1058, duration: 20.426s, episode steps: 271, steps per second:  13, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.923 [0.000, 5.000],  loss: 0.008953, mae: 0.676668, mean_q: 0.831318, mean_eps: 0.117058\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 294705/400000: episode: 1059, duration: 17.953s, episode steps: 254, steps per second:  14, episode reward:  3.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 1.870 [0.000, 5.000],  loss: 0.012196, mae: 0.680390, mean_q: 0.834328, mean_eps: 0.116266\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 294935/400000: episode: 1060, duration: 16.264s, episode steps: 230, steps per second:  14, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.009 [0.000, 5.000],  loss: 0.008980, mae: 0.666961, mean_q: 0.819348, mean_eps: 0.115540\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 295213/400000: episode: 1061, duration: 21.253s, episode steps: 278, steps per second:  13, episode reward: 10.000, mean reward:  0.036 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.010080, mae: 0.673705, mean_q: 0.826405, mean_eps: 0.114778\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 295957/400000: episode: 1062, duration: 54.141s, episode steps: 744, steps per second:  14, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.988 [0.000, 5.000],  loss: 0.010683, mae: 0.672488, mean_q: 0.827037, mean_eps: 0.113242\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 296181/400000: episode: 1063, duration: 16.070s, episode steps: 224, steps per second:  14, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.250 [0.000, 5.000],  loss: 0.009304, mae: 0.666806, mean_q: 0.819433, mean_eps: 0.111790\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 296392/400000: episode: 1064, duration: 15.348s, episode steps: 211, steps per second:  14, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.227 [0.000, 5.000],  loss: 0.010912, mae: 0.653532, mean_q: 0.802110, mean_eps: 0.111142\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 296592/400000: episode: 1065, duration: 15.041s, episode steps: 200, steps per second:  13, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.750 [0.000, 5.000],  loss: 0.009034, mae: 0.677558, mean_q: 0.833214, mean_eps: 0.110530\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 296847/400000: episode: 1066, duration: 19.099s, episode steps: 255, steps per second:  13, episode reward:  7.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.009733, mae: 0.689810, mean_q: 0.847201, mean_eps: 0.109846\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 297123/400000: episode: 1067, duration: 20.543s, episode steps: 276, steps per second:  13, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.174 [0.000, 5.000],  loss: 0.011285, mae: 0.689304, mean_q: 0.845779, mean_eps: 0.109048\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 297320/400000: episode: 1068, duration: 14.555s, episode steps: 197, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 3.086 [0.000, 5.000],  loss: 0.010213, mae: 0.680750, mean_q: 0.836116, mean_eps: 0.108340\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 297724/400000: episode: 1069, duration: 29.578s, episode steps: 404, steps per second:  14, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.733 [0.000, 5.000],  loss: 0.010747, mae: 0.685260, mean_q: 0.842118, mean_eps: 0.107440\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 297946/400000: episode: 1070, duration: 16.073s, episode steps: 222, steps per second:  14, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.011141, mae: 0.688929, mean_q: 0.846522, mean_eps: 0.106498\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 298149/400000: episode: 1071, duration: 15.526s, episode steps: 203, steps per second:  13, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.936 [0.000, 5.000],  loss: 0.012351, mae: 0.715076, mean_q: 0.877253, mean_eps: 0.105856\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 298462/400000: episode: 1072, duration: 22.611s, episode steps: 313, steps per second:  14, episode reward:  7.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.220 [0.000, 5.000],  loss: 0.010653, mae: 0.702063, mean_q: 0.865535, mean_eps: 0.105082\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 298738/400000: episode: 1073, duration: 21.046s, episode steps: 276, steps per second:  13, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.935 [0.000, 5.000],  loss: 0.009918, mae: 0.709246, mean_q: 0.874123, mean_eps: 0.104200\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 299016/400000: episode: 1074, duration: 19.681s, episode steps: 278, steps per second:  14, episode reward:  4.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.809 [0.000, 5.000],  loss: 0.011167, mae: 0.723319, mean_q: 0.890292, mean_eps: 0.103372\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 299398/400000: episode: 1075, duration: 27.817s, episode steps: 382, steps per second:  14, episode reward: 10.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.003 [0.000, 5.000],  loss: 0.009856, mae: 0.688770, mean_q: 0.846232, mean_eps: 0.102382\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 299660/400000: episode: 1076, duration: 19.969s, episode steps: 262, steps per second:  13, episode reward:  5.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.725 [0.000, 5.000],  loss: 0.009978, mae: 0.706340, mean_q: 0.869144, mean_eps: 0.101416\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 300185/400000: episode: 1077, duration: 36.985s, episode steps: 525, steps per second:  14, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.009322, mae: 0.698915, mean_q: 0.858657, mean_eps: 0.100332\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 300774/400000: episode: 1078, duration: 43.208s, episode steps: 589, steps per second:  14, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.847 [0.000, 5.000],  loss: 0.011692, mae: 0.697788, mean_q: 0.857286, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 300974/400000: episode: 1079, duration: 15.009s, episode steps: 200, steps per second:  13, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.190 [0.000, 5.000],  loss: 0.010023, mae: 0.687569, mean_q: 0.845194, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 301206/400000: episode: 1080, duration: 16.849s, episode steps: 232, steps per second:  14, episode reward:  4.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 0.866 [0.000, 5.000],  loss: 0.011395, mae: 0.710471, mean_q: 0.873880, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 301574/400000: episode: 1081, duration: 26.684s, episode steps: 368, steps per second:  14, episode reward: 10.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 1.209 [0.000, 5.000],  loss: 0.009922, mae: 0.717916, mean_q: 0.881979, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 301787/400000: episode: 1082, duration: 15.317s, episode steps: 213, steps per second:  14, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.061 [0.000, 5.000],  loss: 0.011640, mae: 0.709770, mean_q: 0.870175, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 301987/400000: episode: 1083, duration: 14.789s, episode steps: 200, steps per second:  14, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.700 [0.000, 5.000],  loss: 0.011843, mae: 0.707074, mean_q: 0.868231, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 302208/400000: episode: 1084, duration: 16.002s, episode steps: 221, steps per second:  14, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.584 [0.000, 5.000],  loss: 0.009198, mae: 0.690563, mean_q: 0.847172, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 302402/400000: episode: 1085, duration: 14.237s, episode steps: 194, steps per second:  14, episode reward:  4.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.742 [0.000, 5.000],  loss: 0.008788, mae: 0.680139, mean_q: 0.835345, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 302642/400000: episode: 1086, duration: 17.614s, episode steps: 240, steps per second:  14, episode reward:  6.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.009229, mae: 0.705089, mean_q: 0.867657, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 303048/400000: episode: 1087, duration: 30.539s, episode steps: 406, steps per second:  13, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.333 [0.000, 5.000],  loss: 0.011751, mae: 0.700859, mean_q: 0.858992, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 303434/400000: episode: 1088, duration: 28.621s, episode steps: 386, steps per second:  13, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.010791, mae: 0.694937, mean_q: 0.853050, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 303663/400000: episode: 1089, duration: 16.414s, episode steps: 229, steps per second:  14, episode reward:  7.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.991 [0.000, 5.000],  loss: 0.010783, mae: 0.729645, mean_q: 0.896934, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 303908/400000: episode: 1090, duration: 17.737s, episode steps: 245, steps per second:  14, episode reward:  7.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.010288, mae: 0.710544, mean_q: 0.873044, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 304126/400000: episode: 1091, duration: 16.345s, episode steps: 218, steps per second:  13, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.835 [0.000, 5.000],  loss: 0.009549, mae: 0.713718, mean_q: 0.876242, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 304502/400000: episode: 1092, duration: 27.331s, episode steps: 376, steps per second:  14, episode reward:  9.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.952 [0.000, 5.000],  loss: 0.010958, mae: 0.711172, mean_q: 0.873197, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 304765/400000: episode: 1093, duration: 19.507s, episode steps: 263, steps per second:  13, episode reward:  6.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.905 [0.000, 5.000],  loss: 0.010239, mae: 0.700638, mean_q: 0.859673, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 305027/400000: episode: 1094, duration: 18.244s, episode steps: 262, steps per second:  14, episode reward:  7.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.683 [0.000, 5.000],  loss: 0.010866, mae: 0.710750, mean_q: 0.871602, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 305148/400000: episode: 1095, duration: 9.619s, episode steps: 121, steps per second:  13, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 3.008 [0.000, 5.000],  loss: 0.009407, mae: 0.700035, mean_q: 0.857353, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 305463/400000: episode: 1096, duration: 23.435s, episode steps: 315, steps per second:  13, episode reward:  6.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.943 [0.000, 5.000],  loss: 0.013422, mae: 0.700161, mean_q: 0.857384, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 305718/400000: episode: 1097, duration: 18.461s, episode steps: 255, steps per second:  14, episode reward:  7.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.011862, mae: 0.711065, mean_q: 0.871614, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 306213/400000: episode: 1098, duration: 37.532s, episode steps: 495, steps per second:  13, episode reward: 12.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.689 [0.000, 5.000],  loss: 0.011171, mae: 0.736485, mean_q: 0.902729, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 306456/400000: episode: 1099, duration: 17.548s, episode steps: 243, steps per second:  14, episode reward:  8.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.214 [0.000, 5.000],  loss: 0.011688, mae: 0.752095, mean_q: 0.922305, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 306670/400000: episode: 1100, duration: 15.765s, episode steps: 214, steps per second:  14, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.738 [0.000, 5.000],  loss: 0.010269, mae: 0.749085, mean_q: 0.919062, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 306881/400000: episode: 1101, duration: 16.007s, episode steps: 211, steps per second:  13, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.692 [0.000, 5.000],  loss: 0.011381, mae: 0.759966, mean_q: 0.931900, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 307174/400000: episode: 1102, duration: 22.289s, episode steps: 293, steps per second:  13, episode reward:  5.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 3.519 [0.000, 5.000],  loss: 0.011476, mae: 0.752431, mean_q: 0.924194, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 307762/400000: episode: 1103, duration: 42.778s, episode steps: 588, steps per second:  14, episode reward: 14.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 3.002 [0.000, 5.000],  loss: 0.011695, mae: 0.754197, mean_q: 0.925276, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 308023/400000: episode: 1104, duration: 18.891s, episode steps: 261, steps per second:  14, episode reward:  8.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.318 [0.000, 5.000],  loss: 0.011188, mae: 0.752238, mean_q: 0.922950, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 308264/400000: episode: 1105, duration: 18.543s, episode steps: 241, steps per second:  13, episode reward:  8.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.010013, mae: 0.745928, mean_q: 0.915401, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 308648/400000: episode: 1106, duration: 28.422s, episode steps: 384, steps per second:  14, episode reward: 11.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.012186, mae: 0.762327, mean_q: 0.938051, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 308918/400000: episode: 1107, duration: 19.433s, episode steps: 270, steps per second:  14, episode reward:  9.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.193 [0.000, 5.000],  loss: 0.013463, mae: 0.755869, mean_q: 0.927672, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 309188/400000: episode: 1108, duration: 20.798s, episode steps: 270, steps per second:  13, episode reward:  7.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.010001, mae: 0.748692, mean_q: 0.919065, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 309421/400000: episode: 1109, duration: 16.962s, episode steps: 233, steps per second:  14, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.021 [0.000, 5.000],  loss: 0.010033, mae: 0.734044, mean_q: 0.900281, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 309698/400000: episode: 1110, duration: 20.745s, episode steps: 277, steps per second:  13, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.303 [0.000, 5.000],  loss: 0.009919, mae: 0.741100, mean_q: 0.910184, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 309905/400000: episode: 1111, duration: 15.524s, episode steps: 207, steps per second:  13, episode reward:  6.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.232 [0.000, 5.000],  loss: 0.011914, mae: 0.737477, mean_q: 0.906758, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 310445/400000: episode: 1112, duration: 39.635s, episode steps: 540, steps per second:  14, episode reward: 15.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.194 [0.000, 5.000],  loss: 0.011546, mae: 0.746643, mean_q: 0.916145, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 310674/400000: episode: 1113, duration: 16.582s, episode steps: 229, steps per second:  14, episode reward:  7.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.869 [0.000, 5.000],  loss: 0.013139, mae: 0.755320, mean_q: 0.926580, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 311045/400000: episode: 1114, duration: 27.087s, episode steps: 371, steps per second:  14, episode reward: 11.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.181 [0.000, 5.000],  loss: 0.010980, mae: 0.758140, mean_q: 0.931156, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 311283/400000: episode: 1115, duration: 16.906s, episode steps: 238, steps per second:  14, episode reward:  6.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.584 [0.000, 5.000],  loss: 0.013957, mae: 0.754636, mean_q: 0.925423, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 311673/400000: episode: 1116, duration: 28.478s, episode steps: 390, steps per second:  14, episode reward: 10.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 1.559 [0.000, 5.000],  loss: 0.011287, mae: 0.765300, mean_q: 0.942053, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 311927/400000: episode: 1117, duration: 18.584s, episode steps: 254, steps per second:  14, episode reward:  8.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 3.185 [0.000, 5.000],  loss: 0.010186, mae: 0.754692, mean_q: 0.930339, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 312135/400000: episode: 1118, duration: 16.024s, episode steps: 208, steps per second:  13, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: 0.010921, mae: 0.762902, mean_q: 0.940401, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 312412/400000: episode: 1119, duration: 19.831s, episode steps: 277, steps per second:  14, episode reward:  9.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.769 [0.000, 5.000],  loss: 0.009960, mae: 0.754096, mean_q: 0.927018, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 312677/400000: episode: 1120, duration: 19.924s, episode steps: 265, steps per second:  13, episode reward:  9.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 1.981 [0.000, 5.000],  loss: 0.012473, mae: 0.768816, mean_q: 0.944113, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 313275/400000: episode: 1121, duration: 43.465s, episode steps: 598, steps per second:  14, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.234 [0.000, 5.000],  loss: 0.012195, mae: 0.752360, mean_q: 0.925026, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 313530/400000: episode: 1122, duration: 18.434s, episode steps: 255, steps per second:  14, episode reward:  9.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 2.792 [0.000, 5.000],  loss: 0.011441, mae: 0.754517, mean_q: 0.928180, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 313791/400000: episode: 1123, duration: 19.613s, episode steps: 261, steps per second:  13, episode reward:  7.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 3.383 [0.000, 5.000],  loss: 0.011884, mae: 0.733703, mean_q: 0.902432, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 314038/400000: episode: 1124, duration: 18.536s, episode steps: 247, steps per second:  13, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.757 [0.000, 5.000],  loss: 0.010169, mae: 0.735001, mean_q: 0.904965, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 314449/400000: episode: 1125, duration: 29.942s, episode steps: 411, steps per second:  14, episode reward:  9.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.946 [0.000, 5.000],  loss: 0.009628, mae: 0.753195, mean_q: 0.926335, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 314687/400000: episode: 1126, duration: 17.149s, episode steps: 238, steps per second:  14, episode reward:  7.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.319 [0.000, 5.000],  loss: 0.011119, mae: 0.768550, mean_q: 0.946614, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 314891/400000: episode: 1127, duration: 15.177s, episode steps: 204, steps per second:  13, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.686 [0.000, 5.000],  loss: 0.012358, mae: 0.789152, mean_q: 0.968412, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 315460/400000: episode: 1128, duration: 42.111s, episode steps: 569, steps per second:  14, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.276 [0.000, 5.000],  loss: 0.012117, mae: 0.791026, mean_q: 0.971902, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 315845/400000: episode: 1129, duration: 29.029s, episode steps: 385, steps per second:  13, episode reward: 10.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.049 [0.000, 5.000],  loss: 0.011572, mae: 0.765333, mean_q: 0.942233, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 316054/400000: episode: 1130, duration: 15.069s, episode steps: 209, steps per second:  14, episode reward:  6.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.134 [0.000, 5.000],  loss: 0.012055, mae: 0.777720, mean_q: 0.958712, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 316269/400000: episode: 1131, duration: 15.590s, episode steps: 215, steps per second:  14, episode reward:  6.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 1.879 [0.000, 5.000],  loss: 0.009525, mae: 0.744169, mean_q: 0.915321, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 316497/400000: episode: 1132, duration: 16.440s, episode steps: 228, steps per second:  14, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.010194, mae: 0.766455, mean_q: 0.943498, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 316938/400000: episode: 1133, duration: 32.243s, episode steps: 441, steps per second:  14, episode reward: 10.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.685 [0.000, 5.000],  loss: 0.010351, mae: 0.755469, mean_q: 0.930378, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 317537/400000: episode: 1134, duration: 44.249s, episode steps: 599, steps per second:  14, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.880 [0.000, 5.000],  loss: 0.011417, mae: 0.767706, mean_q: 0.942646, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 317740/400000: episode: 1135, duration: 14.734s, episode steps: 203, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.626 [0.000, 5.000],  loss: 0.013174, mae: 0.778375, mean_q: 0.958392, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 317985/400000: episode: 1136, duration: 17.775s, episode steps: 245, steps per second:  14, episode reward:  8.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 1.620 [0.000, 5.000],  loss: 0.011983, mae: 0.775063, mean_q: 0.953949, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 318264/400000: episode: 1137, duration: 21.300s, episode steps: 279, steps per second:  13, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.674 [0.000, 5.000],  loss: 0.012025, mae: 0.755449, mean_q: 0.927404, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 318643/400000: episode: 1138, duration: 28.754s, episode steps: 379, steps per second:  13, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.894 [0.000, 5.000],  loss: 0.010634, mae: 0.759951, mean_q: 0.934088, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 318894/400000: episode: 1139, duration: 17.874s, episode steps: 251, steps per second:  14, episode reward:  5.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.275 [0.000, 5.000],  loss: 0.010717, mae: 0.773895, mean_q: 0.953709, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 319148/400000: episode: 1140, duration: 18.132s, episode steps: 254, steps per second:  14, episode reward:  8.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 3.366 [0.000, 5.000],  loss: 0.009578, mae: 0.741041, mean_q: 0.913697, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 319516/400000: episode: 1141, duration: 27.176s, episode steps: 368, steps per second:  14, episode reward: 10.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.389 [0.000, 5.000],  loss: 0.011085, mae: 0.759383, mean_q: 0.933028, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 320040/400000: episode: 1142, duration: 39.097s, episode steps: 524, steps per second:  13, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.011825, mae: 0.757965, mean_q: 0.931000, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 320293/400000: episode: 1143, duration: 19.351s, episode steps: 253, steps per second:  13, episode reward: 10.000, mean reward:  0.040 [ 0.000,  1.000], mean action: 2.277 [0.000, 5.000],  loss: 0.008485, mae: 0.760194, mean_q: 0.935571, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 320601/400000: episode: 1144, duration: 21.785s, episode steps: 308, steps per second:  14, episode reward:  8.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.847 [0.000, 5.000],  loss: 0.010582, mae: 0.759076, mean_q: 0.932279, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 320874/400000: episode: 1145, duration: 20.697s, episode steps: 273, steps per second:  13, episode reward:  8.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: 0.012360, mae: 0.766393, mean_q: 0.940759, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 321145/400000: episode: 1146, duration: 19.360s, episode steps: 271, steps per second:  14, episode reward:  7.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.018 [0.000, 5.000],  loss: 0.010472, mae: 0.782566, mean_q: 0.963695, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 321745/400000: episode: 1147, duration: 43.689s, episode steps: 600, steps per second:  14, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.075 [0.000, 5.000],  loss: 0.010970, mae: 0.763620, mean_q: 0.937431, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 321951/400000: episode: 1148, duration: 15.420s, episode steps: 206, steps per second:  13, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.049 [0.000, 5.000],  loss: 0.013550, mae: 0.789517, mean_q: 0.969237, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 322203/400000: episode: 1149, duration: 19.531s, episode steps: 252, steps per second:  13, episode reward:  8.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.011410, mae: 0.757674, mean_q: 0.931037, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 322498/400000: episode: 1150, duration: 21.769s, episode steps: 295, steps per second:  14, episode reward: 10.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.963 [0.000, 5.000],  loss: 0.011138, mae: 0.754900, mean_q: 0.928658, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 322798/400000: episode: 1151, duration: 22.690s, episode steps: 300, steps per second:  13, episode reward:  8.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.010 [0.000, 5.000],  loss: 0.009473, mae: 0.766238, mean_q: 0.944473, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 323045/400000: episode: 1152, duration: 18.910s, episode steps: 247, steps per second:  13, episode reward:  9.000, mean reward:  0.036 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: 0.010358, mae: 0.762186, mean_q: 0.936617, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 323291/400000: episode: 1153, duration: 19.209s, episode steps: 246, steps per second:  13, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.756 [0.000, 5.000],  loss: 0.011312, mae: 0.816934, mean_q: 1.003537, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 323826/400000: episode: 1154, duration: 40.556s, episode steps: 535, steps per second:  13, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.936 [0.000, 5.000],  loss: 0.010837, mae: 0.801283, mean_q: 0.985293, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 324036/400000: episode: 1155, duration: 15.821s, episode steps: 210, steps per second:  13, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.667 [0.000, 5.000],  loss: 0.010407, mae: 0.814140, mean_q: 1.000542, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 324301/400000: episode: 1156, duration: 19.799s, episode steps: 265, steps per second:  13, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.792 [0.000, 5.000],  loss: 0.011501, mae: 0.810187, mean_q: 0.998549, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 324881/400000: episode: 1157, duration: 43.810s, episode steps: 580, steps per second:  13, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.012801, mae: 0.808926, mean_q: 0.994085, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 325281/400000: episode: 1158, duration: 29.276s, episode steps: 400, steps per second:  14, episode reward: 10.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.303 [0.000, 5.000],  loss: 0.012514, mae: 0.818192, mean_q: 1.006470, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 325577/400000: episode: 1159, duration: 21.137s, episode steps: 296, steps per second:  14, episode reward:  7.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.294 [0.000, 5.000],  loss: 0.012182, mae: 0.823570, mean_q: 1.013739, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 325841/400000: episode: 1160, duration: 20.647s, episode steps: 264, steps per second:  13, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.012137, mae: 0.798055, mean_q: 0.980662, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 326052/400000: episode: 1161, duration: 16.477s, episode steps: 211, steps per second:  13, episode reward:  6.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.275 [0.000, 5.000],  loss: 0.015083, mae: 0.836180, mean_q: 1.023679, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 326330/400000: episode: 1162, duration: 21.276s, episode steps: 278, steps per second:  13, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.928 [0.000, 5.000],  loss: 0.011065, mae: 0.804947, mean_q: 0.990132, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 326594/400000: episode: 1163, duration: 19.578s, episode steps: 264, steps per second:  13, episode reward:  9.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 1.879 [0.000, 5.000],  loss: 0.011553, mae: 0.807257, mean_q: 0.990119, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 327044/400000: episode: 1164, duration: 33.001s, episode steps: 450, steps per second:  14, episode reward: 11.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.320 [0.000, 5.000],  loss: 0.012464, mae: 0.825529, mean_q: 1.012893, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 327453/400000: episode: 1165, duration: 31.236s, episode steps: 409, steps per second:  13, episode reward: 10.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.692 [0.000, 5.000],  loss: 0.010798, mae: 0.810601, mean_q: 0.993737, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 327702/400000: episode: 1166, duration: 17.901s, episode steps: 249, steps per second:  14, episode reward:  7.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 1.478 [0.000, 5.000],  loss: 0.010182, mae: 0.815956, mean_q: 1.003490, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 327961/400000: episode: 1167, duration: 18.628s, episode steps: 259, steps per second:  14, episode reward:  9.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 2.293 [0.000, 5.000],  loss: 0.010294, mae: 0.809650, mean_q: 0.991917, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 328275/400000: episode: 1168, duration: 23.355s, episode steps: 314, steps per second:  13, episode reward:  8.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.064 [0.000, 5.000],  loss: 0.011016, mae: 0.816070, mean_q: 1.001059, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 328540/400000: episode: 1169, duration: 20.006s, episode steps: 265, steps per second:  13, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.013391, mae: 0.808160, mean_q: 0.992916, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 329024/400000: episode: 1170, duration: 35.120s, episode steps: 484, steps per second:  14, episode reward: 12.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.010867, mae: 0.797783, mean_q: 0.981073, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 329211/400000: episode: 1171, duration: 14.085s, episode steps: 187, steps per second:  13, episode reward:  2.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 1.802 [0.000, 5.000],  loss: 0.012170, mae: 0.794826, mean_q: 0.974794, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 329413/400000: episode: 1172, duration: 14.989s, episode steps: 202, steps per second:  13, episode reward:  6.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.356 [0.000, 5.000],  loss: 0.011594, mae: 0.818011, mean_q: 1.005816, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 329648/400000: episode: 1173, duration: 18.952s, episode steps: 235, steps per second:  12, episode reward:  7.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.336 [0.000, 5.000],  loss: 0.012898, mae: 0.801407, mean_q: 0.985202, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 329903/400000: episode: 1174, duration: 18.846s, episode steps: 255, steps per second:  14, episode reward:  9.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.011964, mae: 0.829541, mean_q: 1.017171, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 330172/400000: episode: 1175, duration: 20.713s, episode steps: 269, steps per second:  13, episode reward: 10.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 2.178 [0.000, 5.000],  loss: 0.011204, mae: 0.791815, mean_q: 0.972384, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 330527/400000: episode: 1176, duration: 26.541s, episode steps: 355, steps per second:  13, episode reward: 10.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.090 [0.000, 5.000],  loss: 0.012304, mae: 0.808537, mean_q: 0.991128, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 331074/400000: episode: 1177, duration: 40.533s, episode steps: 547, steps per second:  13, episode reward: 16.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 3.344 [0.000, 5.000],  loss: 0.011295, mae: 0.808425, mean_q: 0.992914, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 331331/400000: episode: 1178, duration: 19.814s, episode steps: 257, steps per second:  13, episode reward:  6.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.926 [0.000, 5.000],  loss: 0.011153, mae: 0.815546, mean_q: 1.002656, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 331744/400000: episode: 1179, duration: 30.186s, episode steps: 413, steps per second:  14, episode reward: 11.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 1.729 [0.000, 5.000],  loss: 0.012008, mae: 0.811268, mean_q: 0.995313, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 332246/400000: episode: 1180, duration: 37.675s, episode steps: 502, steps per second:  13, episode reward: 13.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.357 [0.000, 5.000],  loss: 0.011328, mae: 0.836134, mean_q: 1.026793, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 332756/400000: episode: 1181, duration: 37.335s, episode steps: 510, steps per second:  14, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.178 [0.000, 5.000],  loss: 0.011409, mae: 0.811788, mean_q: 0.997256, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 332971/400000: episode: 1182, duration: 16.688s, episode steps: 215, steps per second:  13, episode reward:  7.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.712 [0.000, 5.000],  loss: 0.011462, mae: 0.838666, mean_q: 1.027296, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 333334/400000: episode: 1183, duration: 27.048s, episode steps: 363, steps per second:  13, episode reward:  9.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.129 [0.000, 5.000],  loss: 0.010222, mae: 0.825529, mean_q: 1.011677, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 333933/400000: episode: 1184, duration: 44.017s, episode steps: 599, steps per second:  14, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.013547, mae: 0.836821, mean_q: 1.024737, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 334178/400000: episode: 1185, duration: 17.610s, episode steps: 245, steps per second:  14, episode reward:  7.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.011326, mae: 0.811552, mean_q: 0.996216, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 334693/400000: episode: 1186, duration: 38.036s, episode steps: 515, steps per second:  14, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.132 [0.000, 5.000],  loss: 0.011612, mae: 0.838539, mean_q: 1.030141, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 335107/400000: episode: 1187, duration: 29.850s, episode steps: 414, steps per second:  14, episode reward: 10.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.688 [0.000, 5.000],  loss: 0.011728, mae: 0.824776, mean_q: 1.014847, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 335524/400000: episode: 1188, duration: 31.210s, episode steps: 417, steps per second:  13, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.902 [0.000, 5.000],  loss: 0.011241, mae: 0.832998, mean_q: 1.025268, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 335729/400000: episode: 1189, duration: 16.266s, episode steps: 205, steps per second:  13, episode reward:  6.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 3.146 [0.000, 5.000],  loss: 0.012625, mae: 0.823988, mean_q: 1.014523, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 335976/400000: episode: 1190, duration: 17.748s, episode steps: 247, steps per second:  14, episode reward:  9.000, mean reward:  0.036 [ 0.000,  1.000], mean action: 2.304 [0.000, 5.000],  loss: 0.010569, mae: 0.821590, mean_q: 1.009829, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 336387/400000: episode: 1191, duration: 30.346s, episode steps: 411, steps per second:  14, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.679 [0.000, 5.000],  loss: 0.012799, mae: 0.830159, mean_q: 1.017460, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 336667/400000: episode: 1192, duration: 21.283s, episode steps: 280, steps per second:  13, episode reward:  8.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: 0.012300, mae: 0.828279, mean_q: 1.016062, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 336941/400000: episode: 1193, duration: 19.609s, episode steps: 274, steps per second:  14, episode reward:  8.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.701 [0.000, 5.000],  loss: 0.012335, mae: 0.822792, mean_q: 1.012169, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 337220/400000: episode: 1194, duration: 21.232s, episode steps: 279, steps per second:  13, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.724 [0.000, 5.000],  loss: 0.011161, mae: 0.804277, mean_q: 0.988886, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 337472/400000: episode: 1195, duration: 18.238s, episode steps: 252, steps per second:  14, episode reward:  8.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.013479, mae: 0.847416, mean_q: 1.040294, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 337747/400000: episode: 1196, duration: 20.240s, episode steps: 275, steps per second:  14, episode reward:  8.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 1.898 [0.000, 5.000],  loss: 0.010136, mae: 0.819060, mean_q: 1.006082, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 338092/400000: episode: 1197, duration: 25.143s, episode steps: 345, steps per second:  14, episode reward:  8.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.013386, mae: 0.851113, mean_q: 1.044777, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 338367/400000: episode: 1198, duration: 21.116s, episode steps: 275, steps per second:  13, episode reward:  8.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.069 [0.000, 5.000],  loss: 0.011412, mae: 0.821585, mean_q: 1.009863, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 338607/400000: episode: 1199, duration: 17.261s, episode steps: 240, steps per second:  14, episode reward:  8.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.011905, mae: 0.839105, mean_q: 1.030285, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 338858/400000: episode: 1200, duration: 18.747s, episode steps: 251, steps per second:  13, episode reward:  7.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 1.753 [0.000, 5.000],  loss: 0.010672, mae: 0.818697, mean_q: 1.005241, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 339447/400000: episode: 1201, duration: 43.862s, episode steps: 589, steps per second:  13, episode reward: 15.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.333 [0.000, 5.000],  loss: 0.011503, mae: 0.823144, mean_q: 1.011051, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 339751/400000: episode: 1202, duration: 21.543s, episode steps: 304, steps per second:  14, episode reward:  8.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.980 [0.000, 5.000],  loss: 0.011434, mae: 0.820258, mean_q: 1.006301, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 340012/400000: episode: 1203, duration: 20.371s, episode steps: 261, steps per second:  13, episode reward:  8.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.337 [0.000, 5.000],  loss: 0.010771, mae: 0.810558, mean_q: 0.995782, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 340397/400000: episode: 1204, duration: 28.402s, episode steps: 385, steps per second:  14, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.012088, mae: 0.848795, mean_q: 1.039771, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 340972/400000: episode: 1205, duration: 41.895s, episode steps: 575, steps per second:  14, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.976 [0.000, 5.000],  loss: 0.011488, mae: 0.864783, mean_q: 1.060748, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 341408/400000: episode: 1206, duration: 31.662s, episode steps: 436, steps per second:  14, episode reward: 10.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.012192, mae: 0.852414, mean_q: 1.043590, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 341658/400000: episode: 1207, duration: 19.440s, episode steps: 250, steps per second:  13, episode reward:  9.000, mean reward:  0.036 [ 0.000,  1.000], mean action: 1.456 [0.000, 5.000],  loss: 0.012844, mae: 0.890839, mean_q: 1.095241, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 341904/400000: episode: 1208, duration: 17.719s, episode steps: 246, steps per second:  14, episode reward:  9.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 1.772 [0.000, 5.000],  loss: 0.011806, mae: 0.888124, mean_q: 1.091791, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 342184/400000: episode: 1209, duration: 20.536s, episode steps: 280, steps per second:  14, episode reward:  8.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.986 [0.000, 5.000],  loss: 0.013329, mae: 0.866689, mean_q: 1.063123, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 342449/400000: episode: 1210, duration: 20.084s, episode steps: 265, steps per second:  13, episode reward:  9.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.902 [0.000, 5.000],  loss: 0.012746, mae: 0.886993, mean_q: 1.089474, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 342721/400000: episode: 1211, duration: 19.578s, episode steps: 272, steps per second:  14, episode reward:  9.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.013809, mae: 0.864245, mean_q: 1.059255, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 343107/400000: episode: 1212, duration: 27.932s, episode steps: 386, steps per second:  14, episode reward: 10.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.062 [0.000, 5.000],  loss: 0.012584, mae: 0.856130, mean_q: 1.050619, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 343278/400000: episode: 1213, duration: 12.828s, episode steps: 171, steps per second:  13, episode reward:  3.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.357 [0.000, 5.000],  loss: 0.013103, mae: 0.860518, mean_q: 1.056328, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 343510/400000: episode: 1214, duration: 18.310s, episode steps: 232, steps per second:  13, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.116 [0.000, 5.000],  loss: 0.013780, mae: 0.865383, mean_q: 1.059439, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 343706/400000: episode: 1215, duration: 14.268s, episode steps: 196, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.485 [0.000, 5.000],  loss: 0.012345, mae: 0.846220, mean_q: 1.039505, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 343935/400000: episode: 1216, duration: 16.434s, episode steps: 229, steps per second:  14, episode reward:  5.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.012060, mae: 0.849067, mean_q: 1.042583, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 344219/400000: episode: 1217, duration: 20.005s, episode steps: 284, steps per second:  14, episode reward: 10.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 2.056 [0.000, 5.000],  loss: 0.012328, mae: 0.865354, mean_q: 1.059430, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 344415/400000: episode: 1218, duration: 14.470s, episode steps: 196, steps per second:  14, episode reward:  5.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.367 [0.000, 5.000],  loss: 0.013707, mae: 0.822077, mean_q: 1.005889, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 344679/400000: episode: 1219, duration: 19.799s, episode steps: 264, steps per second:  13, episode reward: 10.000, mean reward:  0.038 [ 0.000,  1.000], mean action: 2.231 [0.000, 5.000],  loss: 0.013044, mae: 0.848323, mean_q: 1.039220, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 344946/400000: episode: 1220, duration: 18.938s, episode steps: 267, steps per second:  14, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.067 [0.000, 5.000],  loss: 0.012644, mae: 0.871343, mean_q: 1.068893, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 345218/400000: episode: 1221, duration: 20.725s, episode steps: 272, steps per second:  13, episode reward:  7.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 1.713 [0.000, 5.000],  loss: 0.013083, mae: 0.878811, mean_q: 1.077779, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 345624/400000: episode: 1222, duration: 29.395s, episode steps: 406, steps per second:  14, episode reward:  9.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.241 [0.000, 5.000],  loss: 0.011060, mae: 0.860655, mean_q: 1.054595, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 345929/400000: episode: 1223, duration: 23.200s, episode steps: 305, steps per second:  13, episode reward:  8.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 3.016 [0.000, 5.000],  loss: 0.012539, mae: 0.858117, mean_q: 1.051459, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 346201/400000: episode: 1224, duration: 19.128s, episode steps: 272, steps per second:  14, episode reward:  8.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.013084, mae: 0.860244, mean_q: 1.053571, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 346779/400000: episode: 1225, duration: 41.608s, episode steps: 578, steps per second:  14, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.083 [0.000, 5.000],  loss: 0.012223, mae: 0.848765, mean_q: 1.038925, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 347184/400000: episode: 1226, duration: 29.546s, episode steps: 405, steps per second:  14, episode reward: 11.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 1.810 [0.000, 5.000],  loss: 0.014858, mae: 0.888341, mean_q: 1.085726, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 347380/400000: episode: 1227, duration: 14.582s, episode steps: 196, steps per second:  13, episode reward:  5.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 1.913 [0.000, 5.000],  loss: 0.010194, mae: 0.868727, mean_q: 1.063256, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 347646/400000: episode: 1228, duration: 20.536s, episode steps: 266, steps per second:  13, episode reward:  5.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.711 [0.000, 5.000],  loss: 0.012767, mae: 0.869502, mean_q: 1.066107, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 348233/400000: episode: 1229, duration: 42.499s, episode steps: 587, steps per second:  14, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.814 [0.000, 5.000],  loss: 0.011413, mae: 0.854786, mean_q: 1.049419, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 348434/400000: episode: 1230, duration: 14.597s, episode steps: 201, steps per second:  14, episode reward:  6.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.338 [0.000, 5.000],  loss: 0.011688, mae: 0.858977, mean_q: 1.053059, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 348698/400000: episode: 1231, duration: 18.850s, episode steps: 264, steps per second:  14, episode reward:  9.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.867 [0.000, 5.000],  loss: 0.011080, mae: 0.874380, mean_q: 1.070799, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 348915/400000: episode: 1232, duration: 16.739s, episode steps: 217, steps per second:  13, episode reward:  6.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.770 [0.000, 5.000],  loss: 0.012924, mae: 0.868497, mean_q: 1.062501, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 349160/400000: episode: 1233, duration: 18.071s, episode steps: 245, steps per second:  14, episode reward:  9.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: 0.011787, mae: 0.890531, mean_q: 1.091514, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 349793/400000: episode: 1234, duration: 45.883s, episode steps: 633, steps per second:  14, episode reward: 18.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 1.923 [0.000, 5.000],  loss: 0.012183, mae: 0.884410, mean_q: 1.082469, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 350487/400000: episode: 1235, duration: 50.891s, episode steps: 694, steps per second:  14, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.282 [0.000, 5.000],  loss: 0.012238, mae: 0.900276, mean_q: 1.102695, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 350736/400000: episode: 1236, duration: 18.126s, episode steps: 249, steps per second:  14, episode reward:  9.000, mean reward:  0.036 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.012897, mae: 0.892899, mean_q: 1.092309, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 350977/400000: episode: 1237, duration: 19.056s, episode steps: 241, steps per second:  13, episode reward:  7.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 1.739 [0.000, 5.000],  loss: 0.013145, mae: 0.867203, mean_q: 1.062280, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 351406/400000: episode: 1238, duration: 30.751s, episode steps: 429, steps per second:  14, episode reward:  9.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.821 [0.000, 5.000],  loss: 0.012100, mae: 0.899047, mean_q: 1.101268, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 351908/400000: episode: 1239, duration: 37.523s, episode steps: 502, steps per second:  13, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.713 [0.000, 5.000],  loss: 0.012268, mae: 0.895480, mean_q: 1.097304, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 352144/400000: episode: 1240, duration: 17.318s, episode steps: 236, steps per second:  14, episode reward:  9.000, mean reward:  0.038 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.008466, mae: 0.889951, mean_q: 1.092007, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 353655/400000: episode: 1241, duration: 110.401s, episode steps: 1511, steps per second:  14, episode reward: 31.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.332 [0.000, 5.000],  loss: 0.011625, mae: 0.890010, mean_q: 1.089985, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 353889/400000: episode: 1242, duration: 17.042s, episode steps: 234, steps per second:  14, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.667 [0.000, 5.000],  loss: 0.011671, mae: 0.881334, mean_q: 1.080803, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 354242/400000: episode: 1243, duration: 25.842s, episode steps: 353, steps per second:  14, episode reward:  9.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.819 [0.000, 5.000],  loss: 0.012413, mae: 0.873976, mean_q: 1.067056, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 354615/400000: episode: 1244, duration: 27.068s, episode steps: 373, steps per second:  14, episode reward: 10.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 1.678 [0.000, 5.000],  loss: 0.012472, mae: 0.882607, mean_q: 1.080216, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 354844/400000: episode: 1245, duration: 16.707s, episode steps: 229, steps per second:  14, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 1.908 [0.000, 5.000],  loss: 0.014196, mae: 0.898074, mean_q: 1.098933, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 355082/400000: episode: 1246, duration: 18.582s, episode steps: 238, steps per second:  13, episode reward:  7.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.055 [0.000, 5.000],  loss: 0.013146, mae: 0.883432, mean_q: 1.081194, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 355368/400000: episode: 1247, duration: 20.250s, episode steps: 286, steps per second:  14, episode reward: 10.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.011948, mae: 0.884156, mean_q: 1.084458, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 355779/400000: episode: 1248, duration: 31.020s, episode steps: 411, steps per second:  13, episode reward: 10.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.981 [0.000, 5.000],  loss: 0.013258, mae: 0.890600, mean_q: 1.092013, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 355995/400000: episode: 1249, duration: 16.472s, episode steps: 216, steps per second:  13, episode reward:  6.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.681 [0.000, 5.000],  loss: 0.012977, mae: 0.877682, mean_q: 1.074572, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 356316/400000: episode: 1250, duration: 22.595s, episode steps: 321, steps per second:  14, episode reward: 12.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 2.025 [0.000, 5.000],  loss: 0.013236, mae: 0.888232, mean_q: 1.086579, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 356553/400000: episode: 1251, duration: 18.620s, episode steps: 237, steps per second:  13, episode reward:  8.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.190 [0.000, 5.000],  loss: 0.013266, mae: 0.898229, mean_q: 1.098167, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 356840/400000: episode: 1252, duration: 20.306s, episode steps: 287, steps per second:  14, episode reward: 10.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 1.923 [0.000, 5.000],  loss: 0.012961, mae: 0.882176, mean_q: 1.081672, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 357120/400000: episode: 1253, duration: 21.549s, episode steps: 280, steps per second:  13, episode reward: 10.000, mean reward:  0.036 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.012730, mae: 0.915509, mean_q: 1.119952, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 357395/400000: episode: 1254, duration: 19.385s, episode steps: 275, steps per second:  14, episode reward:  8.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.625 [0.000, 5.000],  loss: 0.010411, mae: 0.890016, mean_q: 1.089483, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 357786/400000: episode: 1255, duration: 28.416s, episode steps: 391, steps per second:  14, episode reward: 11.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.330 [0.000, 5.000],  loss: 0.014381, mae: 0.902889, mean_q: 1.103170, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 358016/400000: episode: 1256, duration: 17.542s, episode steps: 230, steps per second:  13, episode reward:  8.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 2.322 [0.000, 5.000],  loss: 0.012086, mae: 0.906332, mean_q: 1.111771, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 358263/400000: episode: 1257, duration: 18.065s, episode steps: 247, steps per second:  14, episode reward:  8.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.134 [0.000, 5.000],  loss: 0.011497, mae: 0.888421, mean_q: 1.087402, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 358499/400000: episode: 1258, duration: 16.813s, episode steps: 236, steps per second:  14, episode reward:  4.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.284 [0.000, 5.000],  loss: 0.012487, mae: 0.899397, mean_q: 1.099065, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 358759/400000: episode: 1259, duration: 19.281s, episode steps: 260, steps per second:  13, episode reward:  8.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.646 [0.000, 5.000],  loss: 0.012498, mae: 0.885509, mean_q: 1.083434, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 359013/400000: episode: 1260, duration: 19.076s, episode steps: 254, steps per second:  13, episode reward:  8.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 1.776 [0.000, 5.000],  loss: 0.013760, mae: 0.900306, mean_q: 1.100960, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 359264/400000: episode: 1261, duration: 17.887s, episode steps: 251, steps per second:  14, episode reward:  7.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.013779, mae: 0.893894, mean_q: 1.092692, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 359496/400000: episode: 1262, duration: 17.489s, episode steps: 232, steps per second:  13, episode reward:  5.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.185 [0.000, 5.000],  loss: 0.013140, mae: 0.913508, mean_q: 1.118434, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 359765/400000: episode: 1263, duration: 19.811s, episode steps: 269, steps per second:  14, episode reward:  9.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.013055, mae: 0.899210, mean_q: 1.100363, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 360008/400000: episode: 1264, duration: 17.399s, episode steps: 243, steps per second:  14, episode reward:  7.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 1.675 [0.000, 5.000],  loss: 0.013924, mae: 0.898915, mean_q: 1.102731, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 361171/400000: episode: 1265, duration: 84.144s, episode steps: 1163, steps per second:  14, episode reward: 18.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.733 [0.000, 5.000],  loss: 0.013130, mae: 0.887332, mean_q: 1.084814, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 361527/400000: episode: 1266, duration: 25.969s, episode steps: 356, steps per second:  14, episode reward: 11.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.014177, mae: 0.904678, mean_q: 1.105011, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 361872/400000: episode: 1267, duration: 25.553s, episode steps: 345, steps per second:  14, episode reward:  9.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.229 [0.000, 5.000],  loss: 0.011612, mae: 0.884371, mean_q: 1.081814, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 362195/400000: episode: 1268, duration: 24.164s, episode steps: 323, steps per second:  13, episode reward:  8.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.266 [0.000, 5.000],  loss: 0.013589, mae: 0.891868, mean_q: 1.091659, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 362415/400000: episode: 1269, duration: 16.158s, episode steps: 220, steps per second:  14, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.318 [0.000, 5.000],  loss: 0.014178, mae: 0.898031, mean_q: 1.099894, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 362650/400000: episode: 1270, duration: 17.090s, episode steps: 235, steps per second:  14, episode reward:  8.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.213 [0.000, 5.000],  loss: 0.014303, mae: 0.879500, mean_q: 1.077364, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 362910/400000: episode: 1271, duration: 20.006s, episode steps: 260, steps per second:  13, episode reward:  9.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 2.196 [0.000, 5.000],  loss: 0.011540, mae: 0.879996, mean_q: 1.076911, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 363112/400000: episode: 1272, duration: 14.806s, episode steps: 202, steps per second:  14, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.658 [0.000, 5.000],  loss: 0.016453, mae: 0.886860, mean_q: 1.083861, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 363498/400000: episode: 1273, duration: 28.348s, episode steps: 386, steps per second:  14, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.184 [0.000, 5.000],  loss: 0.013210, mae: 0.884865, mean_q: 1.080615, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 363901/400000: episode: 1274, duration: 29.634s, episode steps: 403, steps per second:  14, episode reward: 10.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.012267, mae: 0.883168, mean_q: 1.082590, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 364144/400000: episode: 1275, duration: 17.995s, episode steps: 243, steps per second:  14, episode reward:  8.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 1.988 [0.000, 5.000],  loss: 0.011236, mae: 0.859316, mean_q: 1.051534, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 364419/400000: episode: 1276, duration: 20.515s, episode steps: 275, steps per second:  13, episode reward:  5.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.931 [0.000, 5.000],  loss: 0.012210, mae: 0.879218, mean_q: 1.075495, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 364921/400000: episode: 1277, duration: 37.022s, episode steps: 502, steps per second:  14, episode reward: 12.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.888 [0.000, 5.000],  loss: 0.013141, mae: 0.889486, mean_q: 1.087609, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 365729/400000: episode: 1278, duration: 58.099s, episode steps: 808, steps per second:  14, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.917 [0.000, 5.000],  loss: 0.013749, mae: 0.913233, mean_q: 1.117799, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 366121/400000: episode: 1279, duration: 28.570s, episode steps: 392, steps per second:  14, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.742 [0.000, 5.000],  loss: 0.012466, mae: 0.905855, mean_q: 1.109998, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 366404/400000: episode: 1280, duration: 21.251s, episode steps: 283, steps per second:  13, episode reward:  8.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.013599, mae: 0.933914, mean_q: 1.144849, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 366698/400000: episode: 1281, duration: 21.124s, episode steps: 294, steps per second:  14, episode reward:  7.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: 0.013257, mae: 0.937968, mean_q: 1.149403, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 367074/400000: episode: 1282, duration: 27.425s, episode steps: 376, steps per second:  14, episode reward:  9.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.646 [0.000, 5.000],  loss: 0.013405, mae: 0.931829, mean_q: 1.140144, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 367350/400000: episode: 1283, duration: 21.093s, episode steps: 276, steps per second:  13, episode reward:  8.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.663 [0.000, 5.000],  loss: 0.012290, mae: 0.933685, mean_q: 1.142538, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 367610/400000: episode: 1284, duration: 18.445s, episode steps: 260, steps per second:  14, episode reward:  6.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.011829, mae: 0.914252, mean_q: 1.118102, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 367944/400000: episode: 1285, duration: 24.898s, episode steps: 334, steps per second:  13, episode reward:  8.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.931 [0.000, 5.000],  loss: 0.014386, mae: 0.924384, mean_q: 1.130464, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 368183/400000: episode: 1286, duration: 17.041s, episode steps: 239, steps per second:  14, episode reward:  8.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 3.640 [0.000, 5.000],  loss: 0.012750, mae: 0.925898, mean_q: 1.134380, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 368384/400000: episode: 1287, duration: 14.935s, episode steps: 201, steps per second:  13, episode reward:  6.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 3.607 [0.000, 5.000],  loss: 0.013563, mae: 0.931832, mean_q: 1.138773, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 368751/400000: episode: 1288, duration: 26.788s, episode steps: 367, steps per second:  14, episode reward: 12.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.259 [0.000, 5.000],  loss: 0.013866, mae: 0.941676, mean_q: 1.150953, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 368871/400000: episode: 1289, duration: 9.472s, episode steps: 120, steps per second:  13, episode reward:  1.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 1.275 [0.000, 5.000],  loss: 0.012965, mae: 0.967670, mean_q: 1.184333, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 369146/400000: episode: 1290, duration: 19.313s, episode steps: 275, steps per second:  14, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.145 [0.000, 5.000],  loss: 0.013740, mae: 0.930818, mean_q: 1.139488, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 369350/400000: episode: 1291, duration: 15.051s, episode steps: 204, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.181 [0.000, 5.000],  loss: 0.013501, mae: 0.928699, mean_q: 1.136502, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 369627/400000: episode: 1292, duration: 20.916s, episode steps: 277, steps per second:  13, episode reward:  8.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.011660, mae: 0.929197, mean_q: 1.136377, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 369916/400000: episode: 1293, duration: 21.125s, episode steps: 289, steps per second:  14, episode reward:  6.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.263 [0.000, 5.000],  loss: 0.013880, mae: 0.932770, mean_q: 1.141001, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 370320/400000: episode: 1294, duration: 30.654s, episode steps: 404, steps per second:  13, episode reward: 11.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.126 [0.000, 5.000],  loss: 0.011915, mae: 0.923536, mean_q: 1.130536, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 370443/400000: episode: 1295, duration: 8.246s, episode steps: 123, steps per second:  15, episode reward:  2.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 3.894 [0.000, 5.000],  loss: 0.010801, mae: 0.927422, mean_q: 1.138264, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 370723/400000: episode: 1296, duration: 21.204s, episode steps: 280, steps per second:  13, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 3.539 [0.000, 5.000],  loss: 0.011813, mae: 0.929822, mean_q: 1.139068, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 370995/400000: episode: 1297, duration: 19.342s, episode steps: 272, steps per second:  14, episode reward:  7.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.901 [0.000, 5.000],  loss: 0.013498, mae: 0.939117, mean_q: 1.150623, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 371285/400000: episode: 1298, duration: 22.024s, episode steps: 290, steps per second:  13, episode reward:  6.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 3.731 [0.000, 5.000],  loss: 0.014160, mae: 0.915062, mean_q: 1.118299, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 371652/400000: episode: 1299, duration: 26.863s, episode steps: 367, steps per second:  14, episode reward: 10.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.074 [0.000, 5.000],  loss: 0.014500, mae: 0.915220, mean_q: 1.119164, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 371904/400000: episode: 1300, duration: 18.188s, episode steps: 252, steps per second:  14, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.897 [0.000, 5.000],  loss: 0.013374, mae: 0.926079, mean_q: 1.132309, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 372165/400000: episode: 1301, duration: 20.410s, episode steps: 261, steps per second:  13, episode reward:  8.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.762 [0.000, 5.000],  loss: 0.013852, mae: 0.957247, mean_q: 1.172413, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 372425/400000: episode: 1302, duration: 18.431s, episode steps: 260, steps per second:  14, episode reward:  9.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 3.042 [0.000, 5.000],  loss: 0.016263, mae: 0.934685, mean_q: 1.141123, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 372688/400000: episode: 1303, duration: 19.054s, episode steps: 263, steps per second:  14, episode reward:  6.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.954 [0.000, 5.000],  loss: 0.013382, mae: 0.943334, mean_q: 1.154603, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 372888/400000: episode: 1304, duration: 15.635s, episode steps: 200, steps per second:  13, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.535 [0.000, 5.000],  loss: 0.010996, mae: 0.915024, mean_q: 1.120682, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 373294/400000: episode: 1305, duration: 29.783s, episode steps: 406, steps per second:  14, episode reward: 10.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.013554, mae: 0.938973, mean_q: 1.149658, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 373560/400000: episode: 1306, duration: 19.035s, episode steps: 266, steps per second:  14, episode reward:  7.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.992 [0.000, 5.000],  loss: 0.012545, mae: 0.924131, mean_q: 1.134262, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 373788/400000: episode: 1307, duration: 16.727s, episode steps: 228, steps per second:  14, episode reward:  7.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 3.136 [0.000, 5.000],  loss: 0.014061, mae: 0.915482, mean_q: 1.124454, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 374069/400000: episode: 1308, duration: 21.588s, episode steps: 281, steps per second:  13, episode reward:  9.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 1.840 [0.000, 5.000],  loss: 0.013145, mae: 0.936377, mean_q: 1.147714, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 374583/400000: episode: 1309, duration: 37.844s, episode steps: 514, steps per second:  14, episode reward: 13.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.113 [0.000, 5.000],  loss: 0.015415, mae: 0.971845, mean_q: 1.189310, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 375007/400000: episode: 1310, duration: 30.563s, episode steps: 424, steps per second:  14, episode reward:  9.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.012797, mae: 0.948212, mean_q: 1.158195, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 375423/400000: episode: 1311, duration: 29.982s, episode steps: 416, steps per second:  14, episode reward: 10.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.356 [0.000, 5.000],  loss: 0.014105, mae: 0.968124, mean_q: 1.183077, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 375840/400000: episode: 1312, duration: 30.176s, episode steps: 417, steps per second:  14, episode reward:  9.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.094 [0.000, 5.000],  loss: 0.013757, mae: 0.955798, mean_q: 1.168249, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 376179/400000: episode: 1313, duration: 24.834s, episode steps: 339, steps per second:  14, episode reward:  7.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.071 [0.000, 5.000],  loss: 0.012929, mae: 0.970825, mean_q: 1.188273, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 376446/400000: episode: 1314, duration: 20.414s, episode steps: 267, steps per second:  13, episode reward:  9.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.012760, mae: 0.948911, mean_q: 1.163819, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 376915/400000: episode: 1315, duration: 33.327s, episode steps: 469, steps per second:  14, episode reward: 10.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.631 [0.000, 5.000],  loss: 0.012527, mae: 0.959140, mean_q: 1.172129, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 377122/400000: episode: 1316, duration: 15.077s, episode steps: 207, steps per second:  14, episode reward:  6.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 3.000 [0.000, 5.000],  loss: 0.013822, mae: 0.955632, mean_q: 1.167096, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 377338/400000: episode: 1317, duration: 15.897s, episode steps: 216, steps per second:  14, episode reward:  8.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 2.657 [0.000, 5.000],  loss: 0.013118, mae: 0.981018, mean_q: 1.198385, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 377529/400000: episode: 1318, duration: 14.389s, episode steps: 191, steps per second:  13, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.013169, mae: 0.958074, mean_q: 1.170601, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 377788/400000: episode: 1319, duration: 19.412s, episode steps: 259, steps per second:  13, episode reward:  9.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 3.263 [0.000, 5.000],  loss: 0.012591, mae: 0.959346, mean_q: 1.173930, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 378042/400000: episode: 1320, duration: 18.205s, episode steps: 254, steps per second:  14, episode reward:  9.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 2.217 [0.000, 5.000],  loss: 0.015066, mae: 0.974550, mean_q: 1.189149, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 378449/400000: episode: 1321, duration: 29.615s, episode steps: 407, steps per second:  14, episode reward: 10.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.978 [0.000, 5.000],  loss: 0.012929, mae: 0.958711, mean_q: 1.172172, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 378716/400000: episode: 1322, duration: 20.510s, episode steps: 267, steps per second:  13, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.337 [0.000, 5.000],  loss: 0.013843, mae: 0.968158, mean_q: 1.181522, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 378991/400000: episode: 1323, duration: 19.395s, episode steps: 275, steps per second:  14, episode reward:  9.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.793 [0.000, 5.000],  loss: 0.013019, mae: 0.952886, mean_q: 1.162930, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 379202/400000: episode: 1324, duration: 15.731s, episode steps: 211, steps per second:  13, episode reward:  6.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.062 [0.000, 5.000],  loss: 0.016057, mae: 0.945358, mean_q: 1.153710, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 379573/400000: episode: 1325, duration: 26.730s, episode steps: 371, steps per second:  14, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.013637, mae: 0.958123, mean_q: 1.172231, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 379813/400000: episode: 1326, duration: 18.152s, episode steps: 240, steps per second:  13, episode reward:  8.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.013 [0.000, 5.000],  loss: 0.016292, mae: 0.966352, mean_q: 1.178996, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 380044/400000: episode: 1327, duration: 16.536s, episode steps: 231, steps per second:  14, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 1.658 [0.000, 5.000],  loss: 0.013737, mae: 0.967612, mean_q: 1.181177, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 380277/400000: episode: 1328, duration: 16.755s, episode steps: 233, steps per second:  14, episode reward:  8.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.015919, mae: 0.972572, mean_q: 1.188083, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 380545/400000: episode: 1329, duration: 20.466s, episode steps: 268, steps per second:  13, episode reward:  7.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.791 [0.000, 5.000],  loss: 0.010490, mae: 0.951996, mean_q: 1.166339, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 380728/400000: episode: 1330, duration: 13.444s, episode steps: 183, steps per second:  14, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 1.661 [0.000, 5.000],  loss: 0.013824, mae: 0.952020, mean_q: 1.162779, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 381332/400000: episode: 1331, duration: 43.763s, episode steps: 604, steps per second:  14, episode reward: 13.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.093 [0.000, 5.000],  loss: 0.012383, mae: 0.951705, mean_q: 1.162583, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 381600/400000: episode: 1332, duration: 19.221s, episode steps: 268, steps per second:  14, episode reward:  9.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.291 [0.000, 5.000],  loss: 0.015178, mae: 0.954542, mean_q: 1.165563, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 382035/400000: episode: 1333, duration: 32.957s, episode steps: 435, steps per second:  13, episode reward:  9.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.625 [0.000, 5.000],  loss: 0.014230, mae: 0.946133, mean_q: 1.155210, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 382306/400000: episode: 1334, duration: 19.104s, episode steps: 271, steps per second:  14, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.012181, mae: 0.962781, mean_q: 1.176579, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 382663/400000: episode: 1335, duration: 26.047s, episode steps: 357, steps per second:  14, episode reward:  8.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.168 [0.000, 5.000],  loss: 0.012111, mae: 0.947712, mean_q: 1.157896, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 382953/400000: episode: 1336, duration: 21.858s, episode steps: 290, steps per second:  13, episode reward:  6.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.697 [0.000, 5.000],  loss: 0.012200, mae: 0.978288, mean_q: 1.195140, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 383202/400000: episode: 1337, duration: 17.870s, episode steps: 249, steps per second:  14, episode reward:  8.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.100 [0.000, 5.000],  loss: 0.011162, mae: 0.980891, mean_q: 1.198616, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 383466/400000: episode: 1338, duration: 18.722s, episode steps: 264, steps per second:  14, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 3.102 [0.000, 5.000],  loss: 0.012133, mae: 0.958074, mean_q: 1.170588, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 383791/400000: episode: 1339, duration: 24.057s, episode steps: 325, steps per second:  14, episode reward:  8.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.160 [0.000, 5.000],  loss: 0.012740, mae: 0.965050, mean_q: 1.177530, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 384462/400000: episode: 1340, duration: 49.084s, episode steps: 671, steps per second:  14, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.121 [0.000, 5.000],  loss: 0.012763, mae: 0.956312, mean_q: 1.167005, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 384722/400000: episode: 1341, duration: 18.263s, episode steps: 260, steps per second:  14, episode reward:  9.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 2.746 [0.000, 5.000],  loss: 0.011194, mae: 0.948498, mean_q: 1.157704, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 384965/400000: episode: 1342, duration: 17.487s, episode steps: 243, steps per second:  14, episode reward:  7.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.202 [0.000, 5.000],  loss: 0.012927, mae: 0.987711, mean_q: 1.204926, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 385342/400000: episode: 1343, duration: 27.732s, episode steps: 377, steps per second:  14, episode reward: 12.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 3.127 [0.000, 5.000],  loss: 0.012415, mae: 0.965054, mean_q: 1.179759, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 385638/400000: episode: 1344, duration: 22.234s, episode steps: 296, steps per second:  13, episode reward:  7.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.905 [0.000, 5.000],  loss: 0.014058, mae: 0.970210, mean_q: 1.186696, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 386221/400000: episode: 1345, duration: 42.429s, episode steps: 583, steps per second:  14, episode reward: 13.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.803 [0.000, 5.000],  loss: 0.012880, mae: 0.968597, mean_q: 1.182427, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 386464/400000: episode: 1346, duration: 17.402s, episode steps: 243, steps per second:  14, episode reward:  9.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 2.819 [0.000, 5.000],  loss: 0.012376, mae: 0.953386, mean_q: 1.165237, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 386713/400000: episode: 1347, duration: 19.476s, episode steps: 249, steps per second:  13, episode reward:  9.000, mean reward:  0.036 [ 0.000,  1.000], mean action: 3.305 [0.000, 5.000],  loss: 0.012192, mae: 0.977228, mean_q: 1.192388, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 387018/400000: episode: 1348, duration: 21.262s, episode steps: 305, steps per second:  14, episode reward:  8.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.012635, mae: 0.946295, mean_q: 1.155755, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 387518/400000: episode: 1349, duration: 36.760s, episode steps: 500, steps per second:  14, episode reward: 12.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.013091, mae: 0.957813, mean_q: 1.170384, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 387755/400000: episode: 1350, duration: 16.775s, episode steps: 237, steps per second:  14, episode reward:  5.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.654 [0.000, 5.000],  loss: 0.013680, mae: 0.955550, mean_q: 1.167580, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 388024/400000: episode: 1351, duration: 20.764s, episode steps: 269, steps per second:  13, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.717 [0.000, 5.000],  loss: 0.014944, mae: 0.974588, mean_q: 1.186897, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 388242/400000: episode: 1352, duration: 15.919s, episode steps: 218, steps per second:  14, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 3.353 [0.000, 5.000],  loss: 0.011054, mae: 0.949990, mean_q: 1.161571, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 388506/400000: episode: 1353, duration: 19.015s, episode steps: 264, steps per second:  14, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.879 [0.000, 5.000],  loss: 0.012520, mae: 0.974118, mean_q: 1.187898, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 388779/400000: episode: 1354, duration: 20.909s, episode steps: 273, steps per second:  13, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.938 [0.000, 5.000],  loss: 0.012513, mae: 0.951449, mean_q: 1.161396, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 389010/400000: episode: 1355, duration: 16.628s, episode steps: 231, steps per second:  14, episode reward:  7.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 1.892 [0.000, 5.000],  loss: 0.013346, mae: 0.953303, mean_q: 1.162294, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 389250/400000: episode: 1356, duration: 17.095s, episode steps: 240, steps per second:  14, episode reward:  7.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 3.067 [0.000, 5.000],  loss: 0.012805, mae: 0.979460, mean_q: 1.197798, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 389622/400000: episode: 1357, duration: 27.020s, episode steps: 372, steps per second:  14, episode reward: 10.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.013055, mae: 0.954894, mean_q: 1.168190, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 390006/400000: episode: 1358, duration: 27.957s, episode steps: 384, steps per second:  14, episode reward: 10.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 1.924 [0.000, 5.000],  loss: 0.013987, mae: 0.961583, mean_q: 1.174598, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 390259/400000: episode: 1359, duration: 19.388s, episode steps: 253, steps per second:  13, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.850 [0.000, 5.000],  loss: 0.013931, mae: 0.968032, mean_q: 1.183026, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 390536/400000: episode: 1360, duration: 19.524s, episode steps: 277, steps per second:  14, episode reward:  8.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.643 [0.000, 5.000],  loss: 0.013045, mae: 0.957211, mean_q: 1.169292, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 390816/400000: episode: 1361, duration: 21.180s, episode steps: 280, steps per second:  13, episode reward:  8.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: 0.014013, mae: 0.954563, mean_q: 1.168114, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 391086/400000: episode: 1362, duration: 19.029s, episode steps: 270, steps per second:  14, episode reward:  7.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.285 [0.000, 5.000],  loss: 0.014564, mae: 0.951915, mean_q: 1.164066, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 391356/400000: episode: 1363, duration: 20.474s, episode steps: 270, steps per second:  13, episode reward:  9.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.737 [0.000, 5.000],  loss: 0.009430, mae: 0.975595, mean_q: 1.195214, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 391881/400000: episode: 1364, duration: 37.816s, episode steps: 525, steps per second:  14, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.644 [0.000, 5.000],  loss: 0.013034, mae: 0.973475, mean_q: 1.191578, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 392424/400000: episode: 1365, duration: 39.690s, episode steps: 543, steps per second:  14, episode reward: 14.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.215 [0.000, 5.000],  loss: 0.012989, mae: 0.972067, mean_q: 1.189032, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 392710/400000: episode: 1366, duration: 21.734s, episode steps: 286, steps per second:  13, episode reward:  8.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: 0.011990, mae: 0.966227, mean_q: 1.182316, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 393076/400000: episode: 1367, duration: 26.838s, episode steps: 366, steps per second:  14, episode reward:  8.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 3.098 [0.000, 5.000],  loss: 0.011328, mae: 0.981312, mean_q: 1.199226, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 393456/400000: episode: 1368, duration: 27.859s, episode steps: 380, steps per second:  14, episode reward: 12.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.774 [0.000, 5.000],  loss: 0.011001, mae: 0.974728, mean_q: 1.193308, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 393754/400000: episode: 1369, duration: 21.357s, episode steps: 298, steps per second:  14, episode reward:  8.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 3.094 [0.000, 5.000],  loss: 0.012979, mae: 0.976786, mean_q: 1.194670, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 393880/400000: episode: 1370, duration: 9.279s, episode steps: 126, steps per second:  14, episode reward:  1.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: 0.011292, mae: 0.980396, mean_q: 1.199240, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 394138/400000: episode: 1371, duration: 19.665s, episode steps: 258, steps per second:  13, episode reward:  8.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.632 [0.000, 5.000],  loss: 0.011917, mae: 0.978504, mean_q: 1.197304, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 394369/400000: episode: 1372, duration: 16.686s, episode steps: 231, steps per second:  14, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 3.203 [0.000, 5.000],  loss: 0.012021, mae: 0.980579, mean_q: 1.199183, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 394569/400000: episode: 1373, duration: 14.510s, episode steps: 200, steps per second:  14, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.920 [0.000, 5.000],  loss: 0.012492, mae: 0.991333, mean_q: 1.211067, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 394951/400000: episode: 1374, duration: 27.623s, episode steps: 382, steps per second:  14, episode reward: 10.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.223 [0.000, 5.000],  loss: 0.012336, mae: 0.966184, mean_q: 1.178987, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 395177/400000: episode: 1375, duration: 16.680s, episode steps: 226, steps per second:  14, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.012773, mae: 0.980900, mean_q: 1.196374, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 395840/400000: episode: 1376, duration: 48.715s, episode steps: 663, steps per second:  14, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.988 [0.000, 5.000],  loss: 0.013297, mae: 0.973567, mean_q: 1.189494, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 396215/400000: episode: 1377, duration: 27.305s, episode steps: 375, steps per second:  14, episode reward: 12.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.667 [0.000, 5.000],  loss: 0.013455, mae: 0.972169, mean_q: 1.185975, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 396418/400000: episode: 1378, duration: 14.880s, episode steps: 203, steps per second:  14, episode reward:  7.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.011642, mae: 0.968080, mean_q: 1.181943, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 396682/400000: episode: 1379, duration: 18.603s, episode steps: 264, steps per second:  14, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: 0.011166, mae: 0.959205, mean_q: 1.173126, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 396907/400000: episode: 1380, duration: 16.183s, episode steps: 225, steps per second:  14, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.011930, mae: 0.982788, mean_q: 1.202527, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 397751/400000: episode: 1381, duration: 61.921s, episode steps: 844, steps per second:  14, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.916 [0.000, 5.000],  loss: 0.011090, mae: 0.971775, mean_q: 1.186713, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 398152/400000: episode: 1382, duration: 29.176s, episode steps: 401, steps per second:  14, episode reward: 11.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.012992, mae: 0.979344, mean_q: 1.197431, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 398375/400000: episode: 1383, duration: 16.070s, episode steps: 223, steps per second:  14, episode reward:  7.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.224 [0.000, 5.000],  loss: 0.010808, mae: 0.965774, mean_q: 1.182136, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 398637/400000: episode: 1384, duration: 20.337s, episode steps: 262, steps per second:  13, episode reward:  7.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.011088, mae: 0.963308, mean_q: 1.177755, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 399131/400000: episode: 1385, duration: 34.878s, episode steps: 494, steps per second:  14, episode reward: 14.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.011790, mae: 0.978245, mean_q: 1.194644, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 399686/400000: episode: 1386, duration: 40.499s, episode steps: 555, steps per second:  14, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.703 [0.000, 5.000],  loss: 0.012320, mae: 0.986007, mean_q: 1.204148, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cut/dqn_SpaceInvaders-v0_weights.h5f\n",
            "done, took 25508.304 seconds\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f413f1986d0>"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint_path = os.path.join(checkpoint_dir, 'cut/dqn_SpaceInvaders-v0_weights.h5f')\n",
        "reward_log_path = os.path.join(checkpoint_dir, 'logs/episode_rewards_cut.npy')\n",
        "\n",
        "checkpoint_callback = SaveCheckpointCallback(interval=10000, path_template=checkpoint_path, reward_log_path=reward_log_path)\n",
        "\n",
        "dqn.fit(env,\n",
        "        nb_steps=nb_steps,\n",
        "        visualize=False,\n",
        "        verbose=2,\n",
        "        callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "2-B0Ju5PlaXA",
        "outputId": "31196e4c-d911-4d26-beb2-1f3b90305304"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "episode_rewards = np.load('logs/episode_rewards_cut.npy')\n",
        "\n",
        "plt.plot(episode_rewards)\n",
        "plt.xlabel('Episodio')\n",
        "plt.ylabel('Reward total')\n",
        "plt.title('Evolución del entrenamiento')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVznFIXzlcD5"
      },
      "outputs": [],
      "source": [
        "# Guardar\n",
        "import pickle\n",
        "\n",
        "# Suponiendo que `memory` es tu SequentialMemory\n",
        "with open('sequential_memory_cut.pkl', 'wb') as f:\n",
        "    pickle.dump(memory, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2gp5LHiAYef"
      },
      "outputs": [],
      "source": [
        "env = gym.make(env_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDHkowdllubK",
        "outputId": "59345d92-c7a4-462b-c7a7-9942b05c1180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 50 episodes ...\n",
            "Episode 1: reward: 13.000, steps: 677\n",
            "Episode 2: reward: 25.000, steps: 925\n",
            "Episode 3: reward: 12.000, steps: 495\n",
            "Episode 4: reward: 24.000, steps: 1296\n",
            "Episode 5: reward: 17.000, steps: 1028\n",
            "Episode 6: reward: 10.000, steps: 531\n",
            "Episode 7: reward: 15.000, steps: 626\n",
            "Episode 8: reward: 15.000, steps: 914\n",
            "Episode 9: reward: 10.000, steps: 486\n",
            "Episode 10: reward: 14.000, steps: 953\n",
            "Episode 11: reward: 11.000, steps: 602\n",
            "Episode 12: reward: 26.000, steps: 1287\n",
            "Episode 13: reward: 14.000, steps: 956\n",
            "Episode 14: reward: 20.000, steps: 944\n",
            "Episode 15: reward: 12.000, steps: 663\n",
            "Episode 16: reward: 17.000, steps: 1266\n",
            "Episode 17: reward: 26.000, steps: 1752\n",
            "Episode 18: reward: 15.000, steps: 1296\n",
            "Episode 19: reward: 7.000, steps: 413\n",
            "Episode 20: reward: 16.000, steps: 838\n",
            "Episode 21: reward: 13.000, steps: 731\n",
            "Episode 22: reward: 10.000, steps: 596\n",
            "Episode 23: reward: 14.000, steps: 951\n",
            "Episode 24: reward: 11.000, steps: 601\n",
            "Episode 25: reward: 13.000, steps: 671\n",
            "Episode 26: reward: 28.000, steps: 1046\n",
            "Episode 27: reward: 10.000, steps: 563\n",
            "Episode 28: reward: 24.000, steps: 945\n",
            "Episode 29: reward: 20.000, steps: 945\n",
            "Episode 30: reward: 12.000, steps: 1012\n",
            "Episode 31: reward: 17.000, steps: 1088\n",
            "Episode 32: reward: 11.000, steps: 686\n",
            "Episode 33: reward: 22.000, steps: 858\n",
            "Episode 34: reward: 16.000, steps: 1318\n",
            "Episode 35: reward: 23.000, steps: 1166\n",
            "Episode 36: reward: 13.000, steps: 842\n",
            "Episode 37: reward: 10.000, steps: 628\n",
            "Episode 38: reward: 10.000, steps: 543\n",
            "Episode 39: reward: 22.000, steps: 1374\n",
            "Episode 40: reward: 22.000, steps: 879\n",
            "Episode 41: reward: 23.000, steps: 1325\n",
            "Episode 42: reward: 16.000, steps: 894\n",
            "Episode 43: reward: 11.000, steps: 515\n",
            "Episode 44: reward: 10.000, steps: 955\n",
            "Episode 45: reward: 15.000, steps: 710\n",
            "Episode 46: reward: 27.000, steps: 1241\n",
            "Episode 47: reward: 10.000, steps: 614\n",
            "Episode 48: reward: 24.000, steps: 996\n",
            "Episode 49: reward: 23.000, steps: 1068\n",
            "Episode 50: reward: 11.000, steps: 677\n"
          ]
        }
      ],
      "source": [
        "# Testing part to calculate the mean reward\n",
        "weights_filename = checkpoint_dir + '/cut/dqn_{}_weights.h5f'.format(env_name)\n",
        "dqn.load_weights(weights_filename)\n",
        "env = Monitor(env, './video', force=True)\n",
        "history = dqn.test(env, nb_episodes=50, visualize=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKO5uy6Ll2MZ",
        "outputId": "9d658fef-c39f-4d2f-9aef-22cacece8eb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recompensa promedio: 16.2\n"
          ]
        }
      ],
      "source": [
        "# Access episode rewards\n",
        "episode_rewards = history.history['episode_reward']\n",
        "\n",
        "# Calcular el promedio\n",
        "promedio = np.mean(episode_rewards)\n",
        "\n",
        "print(f\"Recompensa promedio: {promedio}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento parte 2"
      ],
      "metadata": {
        "id": "BNZom_vaHyEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(env_name)\n",
        "env = LifeTerminatingWrapper(env)"
      ],
      "metadata": {
        "id": "saHuuPGS6lrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploracion 1 a 0.1, # steps -> 400k\n",
        "nb_steps = 200000\n",
        "nb_steps_annealing = 180000\n",
        "nb_steps_warmup=40000\n",
        "\n",
        "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(),\n",
        "                              attr='eps',\n",
        "                              value_max=0.4, #0.22 # 0.24 # 0.35\n",
        "                              value_min=0.1, # 0.08\n",
        "                              value_test=0.0,\n",
        "                              nb_steps=nb_steps_annealing)\n",
        "\n",
        "\n",
        "dqn = DQNAgent(model=model,\n",
        "               nb_actions=nb_actions,\n",
        "               policy=policy,\n",
        "               memory=memory,\n",
        "               processor=processor,\n",
        "               nb_steps_warmup=nb_steps_warmup, #30000\n",
        "               enable_double_dqn=True,\n",
        "               gamma=0.99, # 0.99\n",
        "               target_model_update=8500,\n",
        "               train_interval=4,\n",
        "               delta_clip=1.0) # si el loss no baja, probar bajarlo a 0.5\n",
        "\n",
        "dqn.compile(Adam(learning_rate=0.0001), metrics=['mae']) # antes 0.00025"
      ],
      "metadata": {
        "id": "w8kxvvvmHXrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_filename = checkpoint_dir + '/cut/dqn_{}_weights.h5f'.format(env_name)\n",
        "dqn.load_weights(weights_filename)"
      ],
      "metadata": {
        "id": "1yxP_Xp5KWsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(checkpoint_dir, 'cutv3/dqn_SpaceInvaders-v0_weights.h5f')\n",
        "reward_log_path = os.path.join(checkpoint_dir, 'logs/episode_rewards_cutv3.npy')\n",
        "\n",
        "checkpoint_callback = SaveCheckpointCallback(interval=10000, path_template=checkpoint_path, reward_log_path=reward_log_path)\n",
        "\n",
        "dqn.fit(env,\n",
        "        nb_steps=nb_steps,\n",
        "        visualize=False,\n",
        "        verbose=2,\n",
        "        callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUzQZbl9H1fa",
        "outputId": "1dfbb881-2522-46a2-e687-f78e136e7207"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for 200000 steps ...\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    397/200000: episode: 1, duration: 2.655s, episode steps: 397, steps per second: 150, episode reward: 10.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "    786/200000: episode: 2, duration: 2.376s, episode steps: 389, steps per second: 164, episode reward: 10.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.308 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   1049/200000: episode: 3, duration: 1.693s, episode steps: 263, steps per second: 155, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   1648/200000: episode: 4, duration: 4.960s, episode steps: 599, steps per second: 121, episode reward: 18.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.302 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   1939/200000: episode: 5, duration: 1.839s, episode steps: 291, steps per second: 158, episode reward:  9.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.842 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   2284/200000: episode: 6, duration: 2.133s, episode steps: 345, steps per second: 162, episode reward:  8.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   2534/200000: episode: 7, duration: 1.563s, episode steps: 250, steps per second: 160, episode reward:  7.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.660 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   3041/200000: episode: 8, duration: 3.057s, episode steps: 507, steps per second: 166, episode reward: 16.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   3591/200000: episode: 9, duration: 4.809s, episode steps: 550, steps per second: 114, episode reward: 15.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   3857/200000: episode: 10, duration: 1.685s, episode steps: 266, steps per second: 158, episode reward:  6.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.718 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   4099/200000: episode: 11, duration: 1.563s, episode steps: 242, steps per second: 155, episode reward:  9.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   4368/200000: episode: 12, duration: 1.695s, episode steps: 269, steps per second: 159, episode reward:  7.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.770 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   4652/200000: episode: 13, duration: 1.800s, episode steps: 284, steps per second: 158, episode reward:  6.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.711 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   4990/200000: episode: 14, duration: 2.130s, episode steps: 338, steps per second: 159, episode reward:  7.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   5290/200000: episode: 15, duration: 2.759s, episode steps: 300, steps per second: 109, episode reward:  9.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.810 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   5562/200000: episode: 16, duration: 3.069s, episode steps: 272, steps per second:  89, episode reward:  8.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.353 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   5959/200000: episode: 17, duration: 4.459s, episode steps: 397, steps per second:  89, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.325 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   6365/200000: episode: 18, duration: 2.460s, episode steps: 406, steps per second: 165, episode reward:  9.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.643 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   6640/200000: episode: 19, duration: 1.773s, episode steps: 275, steps per second: 155, episode reward: 10.000, mean reward:  0.036 [ 0.000,  1.000], mean action: 2.844 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   6991/200000: episode: 20, duration: 3.297s, episode steps: 351, steps per second: 106, episode reward:  8.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.644 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   7271/200000: episode: 21, duration: 1.940s, episode steps: 280, steps per second: 144, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   7557/200000: episode: 22, duration: 1.768s, episode steps: 286, steps per second: 162, episode reward:  8.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   7800/200000: episode: 23, duration: 1.553s, episode steps: 243, steps per second: 156, episode reward:  9.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 2.658 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   8184/200000: episode: 24, duration: 2.348s, episode steps: 384, steps per second: 164, episode reward: 10.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   8447/200000: episode: 25, duration: 1.643s, episode steps: 263, steps per second: 160, episode reward:  9.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.821 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   8777/200000: episode: 26, duration: 2.404s, episode steps: 330, steps per second: 137, episode reward:  8.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   8895/200000: episode: 27, duration: 1.177s, episode steps: 118, steps per second: 100, episode reward:  1.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.805 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   9145/200000: episode: 28, duration: 2.197s, episode steps: 250, steps per second: 114, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.756 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   9841/200000: episode: 29, duration: 4.212s, episode steps: 696, steps per second: 165, episode reward: 18.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  10062/200000: episode: 30, duration: 1.406s, episode steps: 221, steps per second: 157, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  10462/200000: episode: 31, duration: 2.382s, episode steps: 400, steps per second: 168, episode reward: 11.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.665 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  10691/200000: episode: 32, duration: 1.425s, episode steps: 229, steps per second: 161, episode reward:  8.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  10814/200000: episode: 33, duration: 1.180s, episode steps: 123, steps per second: 104, episode reward:  1.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.935 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  11193/200000: episode: 34, duration: 3.303s, episode steps: 379, steps per second: 115, episode reward: 10.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  11438/200000: episode: 35, duration: 1.653s, episode steps: 245, steps per second: 148, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.820 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  12025/200000: episode: 36, duration: 3.665s, episode steps: 587, steps per second: 160, episode reward: 14.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.068 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  12284/200000: episode: 37, duration: 1.631s, episode steps: 259, steps per second: 159, episode reward:  8.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.722 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  12503/200000: episode: 38, duration: 1.420s, episode steps: 219, steps per second: 154, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.680 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  12707/200000: episode: 39, duration: 1.414s, episode steps: 204, steps per second: 144, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.946 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  12972/200000: episode: 40, duration: 2.593s, episode steps: 265, steps per second: 102, episode reward:  7.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  13260/200000: episode: 41, duration: 2.165s, episode steps: 288, steps per second: 133, episode reward:  8.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.712 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  13503/200000: episode: 42, duration: 1.554s, episode steps: 243, steps per second: 156, episode reward:  5.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.601 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  13861/200000: episode: 43, duration: 2.253s, episode steps: 358, steps per second: 159, episode reward:  9.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  14168/200000: episode: 44, duration: 1.941s, episode steps: 307, steps per second: 158, episode reward:  9.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.697 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  14426/200000: episode: 45, duration: 1.618s, episode steps: 258, steps per second: 159, episode reward:  9.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  14710/200000: episode: 46, duration: 1.957s, episode steps: 284, steps per second: 145, episode reward:  9.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.757 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  14951/200000: episode: 47, duration: 2.255s, episode steps: 241, steps per second: 107, episode reward:  6.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.278 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  15207/200000: episode: 48, duration: 2.097s, episode steps: 256, steps per second: 122, episode reward:  8.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  15443/200000: episode: 49, duration: 1.497s, episode steps: 236, steps per second: 158, episode reward:  5.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.237 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  15775/200000: episode: 50, duration: 2.092s, episode steps: 332, steps per second: 159, episode reward:  5.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.380 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  16017/200000: episode: 51, duration: 1.557s, episode steps: 242, steps per second: 155, episode reward:  5.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  16440/200000: episode: 52, duration: 2.617s, episode steps: 423, steps per second: 162, episode reward: 13.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.161 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  16691/200000: episode: 53, duration: 1.732s, episode steps: 251, steps per second: 145, episode reward:  5.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.964 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  16945/200000: episode: 54, duration: 2.419s, episode steps: 254, steps per second: 105, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  17311/200000: episode: 55, duration: 2.657s, episode steps: 366, steps per second: 138, episode reward: 11.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.134 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  17895/200000: episode: 56, duration: 3.581s, episode steps: 584, steps per second: 163, episode reward: 15.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.009 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  18161/200000: episode: 57, duration: 1.715s, episode steps: 266, steps per second: 155, episode reward:  7.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.778 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  18681/200000: episode: 58, duration: 3.200s, episode steps: 520, steps per second: 162, episode reward: 13.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.012 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  18875/200000: episode: 59, duration: 1.862s, episode steps: 194, steps per second: 104, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.995 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  19188/200000: episode: 60, duration: 2.591s, episode steps: 313, steps per second: 121, episode reward:  7.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  19579/200000: episode: 61, duration: 2.453s, episode steps: 391, steps per second: 159, episode reward: 12.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.662 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  19846/200000: episode: 62, duration: 1.682s, episode steps: 267, steps per second: 159, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  20171/200000: episode: 63, duration: 2.058s, episode steps: 325, steps per second: 158, episode reward:  9.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  20641/200000: episode: 64, duration: 2.866s, episode steps: 470, steps per second: 164, episode reward: 13.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.221 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  20859/200000: episode: 65, duration: 2.029s, episode steps: 218, steps per second: 107, episode reward:  8.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 2.679 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  21382/200000: episode: 66, duration: 4.278s, episode steps: 523, steps per second: 122, episode reward: 15.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  21888/200000: episode: 67, duration: 3.187s, episode steps: 506, steps per second: 159, episode reward: 16.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.233 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  22406/200000: episode: 68, duration: 3.156s, episode steps: 518, steps per second: 164, episode reward: 15.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  22823/200000: episode: 69, duration: 3.078s, episode steps: 417, steps per second: 135, episode reward: 12.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  23072/200000: episode: 70, duration: 2.384s, episode steps: 249, steps per second: 104, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.715 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  23318/200000: episode: 71, duration: 1.592s, episode steps: 246, steps per second: 155, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  23525/200000: episode: 72, duration: 1.316s, episode steps: 207, steps per second: 157, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.957 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  23753/200000: episode: 73, duration: 1.471s, episode steps: 228, steps per second: 155, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.592 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  24028/200000: episode: 74, duration: 1.694s, episode steps: 275, steps per second: 162, episode reward:  4.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  24230/200000: episode: 75, duration: 1.282s, episode steps: 202, steps per second: 158, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 3.084 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  24436/200000: episode: 76, duration: 1.342s, episode steps: 206, steps per second: 153, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 3.102 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  25400/200000: episode: 77, duration: 7.096s, episode steps: 964, steps per second: 136, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.631 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  25759/200000: episode: 78, duration: 2.252s, episode steps: 359, steps per second: 159, episode reward: 10.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.270 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  25964/200000: episode: 79, duration: 1.313s, episode steps: 205, steps per second: 156, episode reward:  6.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.654 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  26215/200000: episode: 80, duration: 1.604s, episode steps: 251, steps per second: 156, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.625 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  26461/200000: episode: 81, duration: 1.598s, episode steps: 246, steps per second: 154, episode reward:  2.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.663 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  26725/200000: episode: 82, duration: 2.074s, episode steps: 264, steps per second: 127, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.966 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  26985/200000: episode: 83, duration: 2.484s, episode steps: 260, steps per second: 105, episode reward:  7.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  27196/200000: episode: 84, duration: 1.619s, episode steps: 211, steps per second: 130, episode reward:  2.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  27484/200000: episode: 85, duration: 1.788s, episode steps: 288, steps per second: 161, episode reward:  8.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  27713/200000: episode: 86, duration: 1.479s, episode steps: 229, steps per second: 155, episode reward:  5.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.895 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  27978/200000: episode: 87, duration: 1.674s, episode steps: 265, steps per second: 158, episode reward:  6.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.698 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  29188/200000: episode: 88, duration: 8.577s, episode steps: 1210, steps per second: 141, episode reward: 26.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.274 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  29596/200000: episode: 89, duration: 2.554s, episode steps: 408, steps per second: 160, episode reward: 10.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.326 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  29851/200000: episode: 90, duration: 1.626s, episode steps: 255, steps per second: 157, episode reward:  9.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  30234/200000: episode: 91, duration: 2.425s, episode steps: 383, steps per second: 158, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.355 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  30428/200000: episode: 92, duration: 1.253s, episode steps: 194, steps per second: 155, episode reward:  1.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  30727/200000: episode: 93, duration: 2.078s, episode steps: 299, steps per second: 144, episode reward:  8.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  30924/200000: episode: 94, duration: 1.958s, episode steps: 197, steps per second: 101, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.934 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  31165/200000: episode: 95, duration: 2.073s, episode steps: 241, steps per second: 116, episode reward:  9.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  31433/200000: episode: 96, duration: 1.761s, episode steps: 268, steps per second: 152, episode reward:  9.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  31692/200000: episode: 97, duration: 1.633s, episode steps: 259, steps per second: 159, episode reward:  6.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.664 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  32222/200000: episode: 98, duration: 3.258s, episode steps: 530, steps per second: 163, episode reward: 16.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  32456/200000: episode: 99, duration: 1.528s, episode steps: 234, steps per second: 153, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  32746/200000: episode: 100, duration: 2.146s, episode steps: 290, steps per second: 135, episode reward:  3.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.803 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  32999/200000: episode: 101, duration: 2.450s, episode steps: 253, steps per second: 103, episode reward:  8.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.644 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  33277/200000: episode: 102, duration: 1.936s, episode steps: 278, steps per second: 144, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.698 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  33521/200000: episode: 103, duration: 1.575s, episode steps: 244, steps per second: 155, episode reward:  6.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.754 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  33732/200000: episode: 104, duration: 1.332s, episode steps: 211, steps per second: 158, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.749 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  34008/200000: episode: 105, duration: 1.734s, episode steps: 276, steps per second: 159, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.913 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  34130/200000: episode: 106, duration: 0.836s, episode steps: 122, steps per second: 146, episode reward:  1.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.656 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  34493/200000: episode: 107, duration: 2.251s, episode steps: 363, steps per second: 161, episode reward:  9.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  34830/200000: episode: 108, duration: 2.726s, episode steps: 337, steps per second: 124, episode reward:  6.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  35072/200000: episode: 109, duration: 2.259s, episode steps: 242, steps per second: 107, episode reward:  7.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.897 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  35390/200000: episode: 110, duration: 2.000s, episode steps: 318, steps per second: 159, episode reward: 10.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.884 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  35607/200000: episode: 111, duration: 1.443s, episode steps: 217, steps per second: 150, episode reward:  6.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 3.028 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  35841/200000: episode: 112, duration: 1.491s, episode steps: 234, steps per second: 157, episode reward:  7.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.697 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  36457/200000: episode: 113, duration: 3.841s, episode steps: 616, steps per second: 160, episode reward: 18.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  36969/200000: episode: 114, duration: 4.376s, episode steps: 512, steps per second: 117, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.277 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  37255/200000: episode: 115, duration: 1.976s, episode steps: 286, steps per second: 145, episode reward:  9.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.710 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  37593/200000: episode: 116, duration: 2.088s, episode steps: 338, steps per second: 162, episode reward: 10.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  37884/200000: episode: 117, duration: 1.801s, episode steps: 291, steps per second: 162, episode reward:  8.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  38415/200000: episode: 118, duration: 3.196s, episode steps: 531, steps per second: 166, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.324 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  38680/200000: episode: 119, duration: 1.725s, episode steps: 265, steps per second: 154, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  39050/200000: episode: 120, duration: 3.478s, episode steps: 370, steps per second: 106, episode reward:  9.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.214 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  39481/200000: episode: 121, duration: 2.860s, episode steps: 431, steps per second: 151, episode reward:  9.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.274 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  39974/200000: episode: 122, duration: 3.016s, episode steps: 493, steps per second: 163, episode reward: 13.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.197 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  40199/200000: episode: 123, duration: 14.347s, episode steps: 225, steps per second:  16, episode reward:  8.000, mean reward:  0.036 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.017600, mae: 1.040625, mean_q: 1.271350, mean_eps: 0.333167\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  40458/200000: episode: 124, duration: 16.663s, episode steps: 259, steps per second:  16, episode reward:  9.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 2.815 [0.000, 5.000],  loss: 0.015329, mae: 1.025893, mean_q: 1.254379, mean_eps: 0.332787\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  40758/200000: episode: 125, duration: 20.586s, episode steps: 300, steps per second:  15, episode reward:  8.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.290 [0.000, 5.000],  loss: 0.013716, mae: 1.005662, mean_q: 1.228180, mean_eps: 0.332320\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  41156/200000: episode: 126, duration: 25.745s, episode steps: 398, steps per second:  15, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.221 [0.000, 5.000],  loss: 0.016210, mae: 1.035054, mean_q: 1.265694, mean_eps: 0.331740\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  41415/200000: episode: 127, duration: 17.480s, episode steps: 259, steps per second:  15, episode reward:  6.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.247 [0.000, 5.000],  loss: 0.017964, mae: 1.015748, mean_q: 1.239872, mean_eps: 0.331193\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  41675/200000: episode: 128, duration: 16.543s, episode steps: 260, steps per second:  16, episode reward:  8.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.646 [0.000, 5.000],  loss: 0.014388, mae: 1.038483, mean_q: 1.268783, mean_eps: 0.330760\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  41888/200000: episode: 129, duration: 14.104s, episode steps: 213, steps per second:  15, episode reward:  8.000, mean reward:  0.038 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.014944, mae: 1.050852, mean_q: 1.281871, mean_eps: 0.330367\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  42458/200000: episode: 130, duration: 36.988s, episode steps: 570, steps per second:  15, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.123 [0.000, 5.000],  loss: 0.014633, mae: 1.038292, mean_q: 1.265620, mean_eps: 0.329713\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  42699/200000: episode: 131, duration: 16.250s, episode steps: 241, steps per second:  15, episode reward:  4.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.320 [0.000, 5.000],  loss: 0.011530, mae: 1.033023, mean_q: 1.259322, mean_eps: 0.329037\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  43118/200000: episode: 132, duration: 27.462s, episode steps: 419, steps per second:  15, episode reward: 12.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.014495, mae: 1.029111, mean_q: 1.251715, mean_eps: 0.328487\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  43690/200000: episode: 133, duration: 35.977s, episode steps: 572, steps per second:  16, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.016412, mae: 1.037506, mean_q: 1.263441, mean_eps: 0.327660\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  44248/200000: episode: 134, duration: 37.041s, episode steps: 558, steps per second:  15, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.366 [0.000, 5.000],  loss: 0.014631, mae: 1.046952, mean_q: 1.274480, mean_eps: 0.326720\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  44517/200000: episode: 135, duration: 22.249s, episode steps: 269, steps per second:  12, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.013013, mae: 1.031990, mean_q: 1.256566, mean_eps: 0.326030\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  45157/200000: episode: 136, duration: 41.580s, episode steps: 640, steps per second:  15, episode reward: 17.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.061 [0.000, 5.000],  loss: 0.013825, mae: 1.048742, mean_q: 1.277882, mean_eps: 0.325270\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  45612/200000: episode: 137, duration: 29.699s, episode steps: 455, steps per second:  15, episode reward:  9.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.224 [0.000, 5.000],  loss: 0.012017, mae: 1.027181, mean_q: 1.249738, mean_eps: 0.324360\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  45885/200000: episode: 138, duration: 18.878s, episode steps: 273, steps per second:  14, episode reward:  7.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 1.692 [0.000, 5.000],  loss: 0.012262, mae: 1.028924, mean_q: 1.254793, mean_eps: 0.323753\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  46149/200000: episode: 139, duration: 16.832s, episode steps: 264, steps per second:  16, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 3.015 [0.000, 5.000],  loss: 0.012832, mae: 1.038388, mean_q: 1.263679, mean_eps: 0.323303\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  46437/200000: episode: 140, duration: 17.961s, episode steps: 288, steps per second:  16, episode reward:  7.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.819 [0.000, 5.000],  loss: 0.011739, mae: 1.039250, mean_q: 1.265185, mean_eps: 0.322843\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  46682/200000: episode: 141, duration: 15.721s, episode steps: 245, steps per second:  16, episode reward:  7.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 3.343 [0.000, 5.000],  loss: 0.013664, mae: 1.039649, mean_q: 1.267256, mean_eps: 0.322400\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  47223/200000: episode: 142, duration: 36.242s, episode steps: 541, steps per second:  15, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 3.039 [0.000, 5.000],  loss: 0.014445, mae: 1.037047, mean_q: 1.262102, mean_eps: 0.321747\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  47508/200000: episode: 143, duration: 18.538s, episode steps: 285, steps per second:  15, episode reward:  9.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.832 [0.000, 5.000],  loss: 0.013884, mae: 1.026989, mean_q: 1.250796, mean_eps: 0.321060\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  47883/200000: episode: 144, duration: 24.786s, episode steps: 375, steps per second:  15, episode reward: 10.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: 0.014835, mae: 1.020459, mean_q: 1.243155, mean_eps: 0.320510\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  48139/200000: episode: 145, duration: 16.282s, episode steps: 256, steps per second:  16, episode reward:  9.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 2.707 [0.000, 5.000],  loss: 0.012568, mae: 1.043018, mean_q: 1.269220, mean_eps: 0.319983\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  48418/200000: episode: 146, duration: 17.756s, episode steps: 279, steps per second:  16, episode reward:  9.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 3.129 [0.000, 5.000],  loss: 0.013778, mae: 1.050666, mean_q: 1.280218, mean_eps: 0.319537\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  48632/200000: episode: 147, duration: 14.520s, episode steps: 214, steps per second:  15, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.631 [0.000, 5.000],  loss: 0.014164, mae: 1.017635, mean_q: 1.237711, mean_eps: 0.319127\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  49203/200000: episode: 148, duration: 37.551s, episode steps: 571, steps per second:  15, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 3.084 [0.000, 5.000],  loss: 0.013334, mae: 1.029590, mean_q: 1.252477, mean_eps: 0.318473\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  49414/200000: episode: 149, duration: 13.863s, episode steps: 211, steps per second:  15, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.161 [0.000, 5.000],  loss: 0.014663, mae: 1.037715, mean_q: 1.262248, mean_eps: 0.317820\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  49712/200000: episode: 150, duration: 18.754s, episode steps: 298, steps per second:  16, episode reward:  8.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: 0.017254, mae: 1.047367, mean_q: 1.277447, mean_eps: 0.317397\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  49917/200000: episode: 151, duration: 13.565s, episode steps: 205, steps per second:  15, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.107 [0.000, 5.000],  loss: 0.010385, mae: 1.026224, mean_q: 1.254763, mean_eps: 0.316977\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  50161/200000: episode: 152, duration: 16.300s, episode steps: 244, steps per second:  15, episode reward:  4.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.011939, mae: 1.035329, mean_q: 1.261934, mean_eps: 0.316600\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  50404/200000: episode: 153, duration: 17.304s, episode steps: 243, steps per second:  14, episode reward:  6.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.350 [0.000, 5.000],  loss: 0.013637, mae: 1.029079, mean_q: 1.255664, mean_eps: 0.316197\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  50599/200000: episode: 154, duration: 12.213s, episode steps: 195, steps per second:  16, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.692 [0.000, 5.000],  loss: 0.014205, mae: 1.027559, mean_q: 1.250023, mean_eps: 0.315833\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  50943/200000: episode: 155, duration: 22.484s, episode steps: 344, steps per second:  15, episode reward:  8.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.692 [0.000, 5.000],  loss: 0.014730, mae: 1.026048, mean_q: 1.247862, mean_eps: 0.315383\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  51181/200000: episode: 156, duration: 15.966s, episode steps: 238, steps per second:  15, episode reward:  5.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.370 [0.000, 5.000],  loss: 0.013240, mae: 1.024178, mean_q: 1.245982, mean_eps: 0.314897\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  51425/200000: episode: 157, duration: 16.674s, episode steps: 244, steps per second:  15, episode reward:  8.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 1.893 [0.000, 5.000],  loss: 0.012326, mae: 1.038485, mean_q: 1.263785, mean_eps: 0.314493\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  51705/200000: episode: 158, duration: 25.896s, episode steps: 280, steps per second:  11, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.186 [0.000, 5.000],  loss: 0.012514, mae: 1.023678, mean_q: 1.245179, mean_eps: 0.314057\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  51827/200000: episode: 159, duration: 9.239s, episode steps: 122, steps per second:  13, episode reward:  2.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.010157, mae: 1.059101, mean_q: 1.289564, mean_eps: 0.313723\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  52115/200000: episode: 160, duration: 19.675s, episode steps: 288, steps per second:  15, episode reward:  8.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.013783, mae: 1.047457, mean_q: 1.272267, mean_eps: 0.313383\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  52527/200000: episode: 161, duration: 28.642s, episode steps: 412, steps per second:  14, episode reward: 11.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.114 [0.000, 5.000],  loss: 0.014098, mae: 1.043840, mean_q: 1.267916, mean_eps: 0.312800\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  52755/200000: episode: 162, duration: 15.364s, episode steps: 228, steps per second:  15, episode reward:  5.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.987 [0.000, 5.000],  loss: 0.011754, mae: 1.037658, mean_q: 1.262468, mean_eps: 0.312267\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  53050/200000: episode: 163, duration: 20.667s, episode steps: 295, steps per second:  14, episode reward:  6.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.011162, mae: 1.015020, mean_q: 1.237288, mean_eps: 0.311830\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  53424/200000: episode: 164, duration: 24.670s, episode steps: 374, steps per second:  15, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 1.719 [0.000, 5.000],  loss: 0.014100, mae: 1.050578, mean_q: 1.277922, mean_eps: 0.311273\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  53719/200000: episode: 165, duration: 25.681s, episode steps: 295, steps per second:  11, episode reward:  7.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.854 [0.000, 5.000],  loss: 0.010472, mae: 1.024499, mean_q: 1.248923, mean_eps: 0.310717\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  53934/200000: episode: 166, duration: 14.962s, episode steps: 215, steps per second:  14, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 1.800 [0.000, 5.000],  loss: 0.010245, mae: 1.033581, mean_q: 1.258389, mean_eps: 0.310290\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  54166/200000: episode: 167, duration: 15.425s, episode steps: 232, steps per second:  15, episode reward:  8.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.181 [0.000, 5.000],  loss: 0.011570, mae: 1.026365, mean_q: 1.251308, mean_eps: 0.309917\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  54374/200000: episode: 168, duration: 14.059s, episode steps: 208, steps per second:  15, episode reward:  6.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.163 [0.000, 5.000],  loss: 0.011657, mae: 1.018999, mean_q: 1.241132, mean_eps: 0.309550\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  54581/200000: episode: 169, duration: 14.035s, episode steps: 207, steps per second:  15, episode reward:  4.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 3.005 [0.000, 5.000],  loss: 0.014284, mae: 1.039517, mean_q: 1.264282, mean_eps: 0.309203\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  54876/200000: episode: 170, duration: 20.929s, episode steps: 295, steps per second:  14, episode reward:  6.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.258 [0.000, 5.000],  loss: 0.011274, mae: 1.023302, mean_q: 1.244690, mean_eps: 0.308787\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  55138/200000: episode: 171, duration: 16.978s, episode steps: 262, steps per second:  15, episode reward:  8.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.969 [0.000, 5.000],  loss: 0.011977, mae: 1.029853, mean_q: 1.251670, mean_eps: 0.308323\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  55412/200000: episode: 172, duration: 17.857s, episode steps: 274, steps per second:  15, episode reward:  7.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 3.026 [0.000, 5.000],  loss: 0.014774, mae: 1.037266, mean_q: 1.260622, mean_eps: 0.307877\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  55659/200000: episode: 173, duration: 16.158s, episode steps: 247, steps per second:  15, episode reward:  7.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 3.049 [0.000, 5.000],  loss: 0.011524, mae: 1.032650, mean_q: 1.258685, mean_eps: 0.307443\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  55914/200000: episode: 174, duration: 18.146s, episode steps: 255, steps per second:  14, episode reward:  8.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.741 [0.000, 5.000],  loss: 0.012202, mae: 1.054221, mean_q: 1.287025, mean_eps: 0.307023\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  56435/200000: episode: 175, duration: 34.373s, episode steps: 521, steps per second:  15, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: 0.011589, mae: 1.035154, mean_q: 1.260114, mean_eps: 0.306377\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  56823/200000: episode: 176, duration: 26.806s, episode steps: 388, steps per second:  14, episode reward: 10.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.157 [0.000, 5.000],  loss: 0.013031, mae: 1.042940, mean_q: 1.267378, mean_eps: 0.305620\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  57108/200000: episode: 177, duration: 18.731s, episode steps: 285, steps per second:  15, episode reward:  8.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 1.905 [0.000, 5.000],  loss: 0.009716, mae: 1.025055, mean_q: 1.247627, mean_eps: 0.305060\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  57611/200000: episode: 178, duration: 34.275s, episode steps: 503, steps per second:  15, episode reward: 12.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.738 [0.000, 5.000],  loss: 0.012987, mae: 1.023924, mean_q: 1.245686, mean_eps: 0.304403\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  57825/200000: episode: 179, duration: 15.013s, episode steps: 214, steps per second:  14, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: 0.013301, mae: 1.041599, mean_q: 1.268481, mean_eps: 0.303803\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  58108/200000: episode: 180, duration: 18.253s, episode steps: 283, steps per second:  16, episode reward:  9.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.873 [0.000, 5.000],  loss: 0.011020, mae: 1.032070, mean_q: 1.257169, mean_eps: 0.303390\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  58399/200000: episode: 181, duration: 18.577s, episode steps: 291, steps per second:  16, episode reward:  6.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.011116, mae: 1.014357, mean_q: 1.237556, mean_eps: 0.302913\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  58966/200000: episode: 182, duration: 38.131s, episode steps: 567, steps per second:  15, episode reward: 13.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.360 [0.000, 5.000],  loss: 0.013199, mae: 1.031124, mean_q: 1.256102, mean_eps: 0.302197\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  59181/200000: episode: 183, duration: 14.252s, episode steps: 215, steps per second:  15, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.930 [0.000, 5.000],  loss: 0.012704, mae: 1.021282, mean_q: 1.245586, mean_eps: 0.301543\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  60972/200000: episode: 184, duration: 117.752s, episode steps: 1791, steps per second:  15, episode reward: 34.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.882 [0.000, 5.000],  loss: 0.012849, mae: 1.049140, mean_q: 1.278536, mean_eps: 0.299873\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  61221/200000: episode: 185, duration: 17.093s, episode steps: 249, steps per second:  15, episode reward:  7.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: 0.009510, mae: 1.034489, mean_q: 1.260723, mean_eps: 0.298173\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  61989/200000: episode: 186, duration: 50.914s, episode steps: 768, steps per second:  15, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.013012, mae: 1.058626, mean_q: 1.289467, mean_eps: 0.297323\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  62230/200000: episode: 187, duration: 15.764s, episode steps: 241, steps per second:  15, episode reward:  9.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 3.253 [0.000, 5.000],  loss: 0.013313, mae: 1.071163, mean_q: 1.304812, mean_eps: 0.296483\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  62505/200000: episode: 188, duration: 18.218s, episode steps: 275, steps per second:  15, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.012792, mae: 1.026592, mean_q: 1.250527, mean_eps: 0.296053\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  62777/200000: episode: 189, duration: 19.574s, episode steps: 272, steps per second:  14, episode reward:  7.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.783 [0.000, 5.000],  loss: 0.009684, mae: 1.015742, mean_q: 1.239161, mean_eps: 0.295597\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  63156/200000: episode: 190, duration: 28.218s, episode steps: 379, steps per second:  13, episode reward: 10.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.011984, mae: 1.035869, mean_q: 1.262838, mean_eps: 0.295057\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  63475/200000: episode: 191, duration: 23.986s, episode steps: 319, steps per second:  13, episode reward:  7.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.147 [0.000, 5.000],  loss: 0.011128, mae: 1.053386, mean_q: 1.284694, mean_eps: 0.294477\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  63750/200000: episode: 192, duration: 21.037s, episode steps: 275, steps per second:  13, episode reward:  9.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 3.233 [0.000, 5.000],  loss: 0.011844, mae: 1.054969, mean_q: 1.287698, mean_eps: 0.293980\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  64186/200000: episode: 193, duration: 32.286s, episode steps: 436, steps per second:  14, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.972 [0.000, 5.000],  loss: 0.012222, mae: 1.051810, mean_q: 1.281526, mean_eps: 0.293387\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  64318/200000: episode: 194, duration: 10.263s, episode steps: 132, steps per second:  13, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.091 [0.000, 5.000],  loss: 0.014355, mae: 1.021536, mean_q: 1.244318, mean_eps: 0.292913\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  64583/200000: episode: 195, duration: 18.896s, episode steps: 265, steps per second:  14, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: 0.010761, mae: 1.054661, mean_q: 1.286715, mean_eps: 0.292583\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  64824/200000: episode: 196, duration: 17.506s, episode steps: 241, steps per second:  14, episode reward:  7.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 1.996 [0.000, 5.000],  loss: 0.012094, mae: 1.056031, mean_q: 1.289056, mean_eps: 0.292163\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  65428/200000: episode: 197, duration: 44.304s, episode steps: 604, steps per second:  14, episode reward: 13.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.233 [0.000, 5.000],  loss: 0.011061, mae: 1.054461, mean_q: 1.285364, mean_eps: 0.291460\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  65548/200000: episode: 198, duration: 9.713s, episode steps: 120, steps per second:  12, episode reward:  2.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.917 [0.000, 5.000],  loss: 0.011056, mae: 1.041738, mean_q: 1.272668, mean_eps: 0.290857\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  65838/200000: episode: 199, duration: 23.331s, episode steps: 290, steps per second:  12, episode reward:  9.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 1.952 [0.000, 5.000],  loss: 0.010540, mae: 1.033261, mean_q: 1.260593, mean_eps: 0.290513\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  66387/200000: episode: 200, duration: 38.926s, episode steps: 549, steps per second:  14, episode reward: 14.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.228 [0.000, 5.000],  loss: 0.012809, mae: 1.056497, mean_q: 1.288665, mean_eps: 0.289813\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  66626/200000: episode: 201, duration: 18.442s, episode steps: 239, steps per second:  13, episode reward:  6.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 3.134 [0.000, 5.000],  loss: 0.012579, mae: 1.049728, mean_q: 1.280592, mean_eps: 0.289157\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  66823/200000: episode: 202, duration: 14.371s, episode steps: 197, steps per second:  14, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 3.244 [0.000, 5.000],  loss: 0.011446, mae: 1.078276, mean_q: 1.315792, mean_eps: 0.288793\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  67060/200000: episode: 203, duration: 17.460s, episode steps: 237, steps per second:  14, episode reward:  8.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.338 [0.000, 5.000],  loss: 0.010568, mae: 1.054249, mean_q: 1.286213, mean_eps: 0.288433\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  67328/200000: episode: 204, duration: 19.443s, episode steps: 268, steps per second:  14, episode reward:  7.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 1.914 [0.000, 5.000],  loss: 0.012875, mae: 1.075675, mean_q: 1.311422, mean_eps: 0.288013\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  67719/200000: episode: 205, duration: 29.156s, episode steps: 391, steps per second:  13, episode reward: 10.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 1.877 [0.000, 5.000],  loss: 0.011749, mae: 1.053102, mean_q: 1.283577, mean_eps: 0.287463\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  67918/200000: episode: 206, duration: 15.240s, episode steps: 199, steps per second:  13, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.894 [0.000, 5.000],  loss: 0.011742, mae: 1.020496, mean_q: 1.246845, mean_eps: 0.286970\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  68249/200000: episode: 207, duration: 24.245s, episode steps: 331, steps per second:  14, episode reward: 10.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.293 [0.000, 5.000],  loss: 0.010820, mae: 1.071548, mean_q: 1.306614, mean_eps: 0.286527\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  68448/200000: episode: 208, duration: 14.809s, episode steps: 199, steps per second:  13, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.884 [0.000, 5.000],  loss: 0.011036, mae: 1.084862, mean_q: 1.322921, mean_eps: 0.286087\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  68726/200000: episode: 209, duration: 21.787s, episode steps: 278, steps per second:  13, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.701 [0.000, 5.000],  loss: 0.011830, mae: 1.086344, mean_q: 1.323160, mean_eps: 0.285690\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  69117/200000: episode: 210, duration: 29.134s, episode steps: 391, steps per second:  13, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.012051, mae: 1.094659, mean_q: 1.333970, mean_eps: 0.285130\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  69482/200000: episode: 211, duration: 27.299s, episode steps: 365, steps per second:  13, episode reward: 10.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.012994, mae: 1.094355, mean_q: 1.334420, mean_eps: 0.284500\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  69767/200000: episode: 212, duration: 20.196s, episode steps: 285, steps per second:  14, episode reward:  9.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.586 [0.000, 5.000],  loss: 0.012868, mae: 1.070278, mean_q: 1.306383, mean_eps: 0.283960\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  70046/200000: episode: 213, duration: 21.627s, episode steps: 279, steps per second:  13, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.706 [0.000, 5.000],  loss: 0.011548, mae: 1.073002, mean_q: 1.308921, mean_eps: 0.283490\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  70640/200000: episode: 214, duration: 43.434s, episode steps: 594, steps per second:  14, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.889 [0.000, 5.000],  loss: 0.011150, mae: 1.069707, mean_q: 1.307417, mean_eps: 0.282763\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  70902/200000: episode: 215, duration: 18.867s, episode steps: 262, steps per second:  14, episode reward:  8.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.744 [0.000, 5.000],  loss: 0.010773, mae: 1.083430, mean_q: 1.321290, mean_eps: 0.282050\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  71019/200000: episode: 216, duration: 9.389s, episode steps: 117, steps per second:  12, episode reward:  2.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 3.154 [0.000, 5.000],  loss: 0.013192, mae: 1.075881, mean_q: 1.309751, mean_eps: 0.281733\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  71754/200000: episode: 217, duration: 54.296s, episode steps: 735, steps per second:  14, episode reward: 19.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.012033, mae: 1.070086, mean_q: 1.304940, mean_eps: 0.281023\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  72367/200000: episode: 218, duration: 45.374s, episode steps: 613, steps per second:  14, episode reward: 19.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.012192, mae: 1.086516, mean_q: 1.324579, mean_eps: 0.279900\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  72822/200000: episode: 219, duration: 33.111s, episode steps: 455, steps per second:  14, episode reward: 12.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: 0.012194, mae: 1.098712, mean_q: 1.338107, mean_eps: 0.279010\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  73397/200000: episode: 220, duration: 42.770s, episode steps: 575, steps per second:  13, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.270 [0.000, 5.000],  loss: 0.011443, mae: 1.100232, mean_q: 1.342661, mean_eps: 0.278150\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  73870/200000: episode: 221, duration: 36.094s, episode steps: 473, steps per second:  13, episode reward: 11.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.696 [0.000, 5.000],  loss: 0.012893, mae: 1.088543, mean_q: 1.326161, mean_eps: 0.277277\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  74089/200000: episode: 222, duration: 16.240s, episode steps: 219, steps per second:  13, episode reward:  7.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.012019, mae: 1.079796, mean_q: 1.316350, mean_eps: 0.276700\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  74307/200000: episode: 223, duration: 15.989s, episode steps: 218, steps per second:  14, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.904 [0.000, 5.000],  loss: 0.011468, mae: 1.066754, mean_q: 1.302657, mean_eps: 0.276337\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  74800/200000: episode: 224, duration: 37.103s, episode steps: 493, steps per second:  13, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.757 [0.000, 5.000],  loss: 0.010843, mae: 1.079785, mean_q: 1.319544, mean_eps: 0.275747\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  75358/200000: episode: 225, duration: 41.082s, episode steps: 558, steps per second:  14, episode reward: 15.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.217 [0.000, 5.000],  loss: 0.012268, mae: 1.075903, mean_q: 1.312288, mean_eps: 0.274870\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  75609/200000: episode: 226, duration: 18.178s, episode steps: 251, steps per second:  14, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.223 [0.000, 5.000],  loss: 0.011941, mae: 1.084354, mean_q: 1.325298, mean_eps: 0.274193\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  75995/200000: episode: 227, duration: 28.383s, episode steps: 386, steps per second:  14, episode reward: 10.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.012859, mae: 1.060279, mean_q: 1.295967, mean_eps: 0.273663\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  76225/200000: episode: 228, duration: 16.527s, episode steps: 230, steps per second:  14, episode reward:  5.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.687 [0.000, 5.000],  loss: 0.012986, mae: 1.062515, mean_q: 1.295651, mean_eps: 0.273150\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  76478/200000: episode: 229, duration: 19.266s, episode steps: 253, steps per second:  13, episode reward:  8.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 3.032 [0.000, 5.000],  loss: 0.011171, mae: 1.086325, mean_q: 1.325242, mean_eps: 0.272747\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  77060/200000: episode: 230, duration: 42.740s, episode steps: 582, steps per second:  14, episode reward: 14.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.012502, mae: 1.143097, mean_q: 1.394899, mean_eps: 0.272053\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  77331/200000: episode: 231, duration: 19.392s, episode steps: 271, steps per second:  14, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.010672, mae: 1.129135, mean_q: 1.376380, mean_eps: 0.271343\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  77827/200000: episode: 232, duration: 37.149s, episode steps: 496, steps per second:  13, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.135 [0.000, 5.000],  loss: 0.012228, mae: 1.124234, mean_q: 1.370129, mean_eps: 0.270703\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  78020/200000: episode: 233, duration: 14.534s, episode steps: 193, steps per second:  13, episode reward:  4.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.014688, mae: 1.120717, mean_q: 1.370490, mean_eps: 0.270130\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  78301/200000: episode: 234, duration: 20.018s, episode steps: 281, steps per second:  14, episode reward: 10.000, mean reward:  0.036 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.012770, mae: 1.127877, mean_q: 1.375314, mean_eps: 0.269733\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  78764/200000: episode: 235, duration: 34.362s, episode steps: 463, steps per second:  13, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.175 [0.000, 5.000],  loss: 0.011568, mae: 1.132882, mean_q: 1.381205, mean_eps: 0.269113\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  79073/200000: episode: 236, duration: 22.415s, episode steps: 309, steps per second:  14, episode reward: 10.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.673 [0.000, 5.000],  loss: 0.012398, mae: 1.108354, mean_q: 1.351734, mean_eps: 0.268470\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  79323/200000: episode: 237, duration: 17.805s, episode steps: 250, steps per second:  14, episode reward:  8.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.084 [0.000, 5.000],  loss: 0.011230, mae: 1.108040, mean_q: 1.352299, mean_eps: 0.268003\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  79522/200000: episode: 238, duration: 14.724s, episode steps: 199, steps per second:  14, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.769 [0.000, 5.000],  loss: 0.010943, mae: 1.107194, mean_q: 1.351322, mean_eps: 0.267630\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  79786/200000: episode: 239, duration: 19.815s, episode steps: 264, steps per second:  13, episode reward: 10.000, mean reward:  0.038 [ 0.000,  1.000], mean action: 2.951 [0.000, 5.000],  loss: 0.011741, mae: 1.115957, mean_q: 1.361561, mean_eps: 0.267243\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  80021/200000: episode: 240, duration: 16.783s, episode steps: 235, steps per second:  14, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.102 [0.000, 5.000],  loss: 0.010016, mae: 1.135703, mean_q: 1.388763, mean_eps: 0.266827\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  80296/200000: episode: 241, duration: 17.918s, episode steps: 275, steps per second:  15, episode reward:  8.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.007 [0.000, 5.000],  loss: 0.013135, mae: 1.121140, mean_q: 1.367242, mean_eps: 0.266403\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  80543/200000: episode: 242, duration: 17.645s, episode steps: 247, steps per second:  14, episode reward:  9.000, mean reward:  0.036 [ 0.000,  1.000], mean action: 2.093 [0.000, 5.000],  loss: 0.011698, mae: 1.104146, mean_q: 1.347684, mean_eps: 0.265970\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  81196/200000: episode: 243, duration: 42.885s, episode steps: 653, steps per second:  15, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.812 [0.000, 5.000],  loss: 0.012667, mae: 1.124261, mean_q: 1.371560, mean_eps: 0.265220\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  81325/200000: episode: 244, duration: 8.110s, episode steps: 129, steps per second:  16, episode reward:  1.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 1.488 [0.000, 5.000],  loss: 0.011497, mae: 1.160775, mean_q: 1.415139, mean_eps: 0.264567\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  81627/200000: episode: 245, duration: 20.781s, episode steps: 302, steps per second:  15, episode reward:  8.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.012296, mae: 1.109833, mean_q: 1.354079, mean_eps: 0.264207\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  81889/200000: episode: 246, duration: 17.450s, episode steps: 262, steps per second:  15, episode reward:  9.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.141 [0.000, 5.000],  loss: 0.013258, mae: 1.106857, mean_q: 1.348324, mean_eps: 0.263737\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  82112/200000: episode: 247, duration: 14.947s, episode steps: 223, steps per second:  15, episode reward:  7.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.314 [0.000, 5.000],  loss: 0.014437, mae: 1.109911, mean_q: 1.351412, mean_eps: 0.263333\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  82410/200000: episode: 248, duration: 21.114s, episode steps: 298, steps per second:  14, episode reward:  8.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.644 [0.000, 5.000],  loss: 0.013885, mae: 1.123452, mean_q: 1.371061, mean_eps: 0.262900\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  82692/200000: episode: 249, duration: 18.262s, episode steps: 282, steps per second:  15, episode reward:  8.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.773 [0.000, 5.000],  loss: 0.011222, mae: 1.130487, mean_q: 1.379875, mean_eps: 0.262417\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  83154/200000: episode: 250, duration: 30.613s, episode steps: 462, steps per second:  15, episode reward: 11.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.010352, mae: 1.120957, mean_q: 1.367820, mean_eps: 0.261797\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  83430/200000: episode: 251, duration: 19.998s, episode steps: 276, steps per second:  14, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.009254, mae: 1.117307, mean_q: 1.363152, mean_eps: 0.261180\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  83828/200000: episode: 252, duration: 26.127s, episode steps: 398, steps per second:  15, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.709 [0.000, 5.000],  loss: 0.011347, mae: 1.118480, mean_q: 1.362153, mean_eps: 0.260620\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  84133/200000: episode: 253, duration: 20.712s, episode steps: 305, steps per second:  15, episode reward:  6.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.010671, mae: 1.078509, mean_q: 1.314952, mean_eps: 0.260033\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  84346/200000: episode: 254, duration: 14.207s, episode steps: 213, steps per second:  15, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.897 [0.000, 5.000],  loss: 0.011166, mae: 1.112927, mean_q: 1.356023, mean_eps: 0.259600\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  84627/200000: episode: 255, duration: 17.881s, episode steps: 281, steps per second:  16, episode reward:  6.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.107 [0.000, 5.000],  loss: 0.011529, mae: 1.134858, mean_q: 1.383429, mean_eps: 0.259190\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  84843/200000: episode: 256, duration: 14.429s, episode steps: 216, steps per second:  15, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.010899, mae: 1.115978, mean_q: 1.360649, mean_eps: 0.258777\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  85431/200000: episode: 257, duration: 39.715s, episode steps: 588, steps per second:  15, episode reward: 14.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.711 [0.000, 5.000],  loss: 0.012799, mae: 1.131584, mean_q: 1.379787, mean_eps: 0.258107\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  85985/200000: episode: 258, duration: 38.036s, episode steps: 554, steps per second:  15, episode reward: 18.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 3.020 [0.000, 5.000],  loss: 0.010790, mae: 1.121029, mean_q: 1.367451, mean_eps: 0.257153\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  86256/200000: episode: 259, duration: 17.783s, episode steps: 271, steps per second:  15, episode reward:  9.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.218 [0.000, 5.000],  loss: 0.012375, mae: 1.122181, mean_q: 1.368751, mean_eps: 0.256467\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  86556/200000: episode: 260, duration: 21.508s, episode steps: 300, steps per second:  14, episode reward:  9.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 3.110 [0.000, 5.000],  loss: 0.012406, mae: 1.121235, mean_q: 1.367220, mean_eps: 0.255993\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  86802/200000: episode: 261, duration: 16.408s, episode steps: 246, steps per second:  15, episode reward:  9.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 2.858 [0.000, 5.000],  loss: 0.009734, mae: 1.149531, mean_q: 1.403371, mean_eps: 0.255537\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  87200/200000: episode: 262, duration: 26.883s, episode steps: 398, steps per second:  15, episode reward: 10.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 3.364 [0.000, 5.000],  loss: 0.013061, mae: 1.129223, mean_q: 1.377996, mean_eps: 0.255000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  87503/200000: episode: 263, duration: 19.758s, episode steps: 303, steps per second:  15, episode reward:  5.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.158 [0.000, 5.000],  loss: 0.012377, mae: 1.120120, mean_q: 1.366074, mean_eps: 0.254417\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  87764/200000: episode: 264, duration: 18.836s, episode steps: 261, steps per second:  14, episode reward:  7.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.356 [0.000, 5.000],  loss: 0.010735, mae: 1.114177, mean_q: 1.359331, mean_eps: 0.253947\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  88292/200000: episode: 265, duration: 35.051s, episode steps: 528, steps per second:  15, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.081 [0.000, 5.000],  loss: 0.012784, mae: 1.115978, mean_q: 1.360329, mean_eps: 0.253290\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  88490/200000: episode: 266, duration: 13.430s, episode steps: 198, steps per second:  15, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.227 [0.000, 5.000],  loss: 0.012026, mae: 1.126158, mean_q: 1.371140, mean_eps: 0.252683\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  88765/200000: episode: 267, duration: 18.820s, episode steps: 275, steps per second:  15, episode reward:  3.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.040 [0.000, 5.000],  loss: 0.012622, mae: 1.128573, mean_q: 1.375359, mean_eps: 0.252287\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  89050/200000: episode: 268, duration: 18.627s, episode steps: 285, steps per second:  15, episode reward:  9.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 1.909 [0.000, 5.000],  loss: 0.010614, mae: 1.111877, mean_q: 1.356504, mean_eps: 0.251820\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  89278/200000: episode: 269, duration: 15.202s, episode steps: 228, steps per second:  15, episode reward:  7.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.011309, mae: 1.117621, mean_q: 1.362157, mean_eps: 0.251393\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  89532/200000: episode: 270, duration: 16.818s, episode steps: 254, steps per second:  15, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.013610, mae: 1.131944, mean_q: 1.378685, mean_eps: 0.250993\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  89826/200000: episode: 271, duration: 20.834s, episode steps: 294, steps per second:  14, episode reward:  9.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.735 [0.000, 5.000],  loss: 0.012412, mae: 1.137533, mean_q: 1.385358, mean_eps: 0.250537\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  90050/200000: episode: 272, duration: 14.893s, episode steps: 224, steps per second:  15, episode reward:  7.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.621 [0.000, 5.000],  loss: 0.009835, mae: 1.137318, mean_q: 1.387767, mean_eps: 0.250103\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  90309/200000: episode: 273, duration: 16.947s, episode steps: 259, steps per second:  15, episode reward:  9.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 3.255 [0.000, 5.000],  loss: 0.012508, mae: 1.130972, mean_q: 1.377273, mean_eps: 0.249700\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  90566/200000: episode: 274, duration: 16.754s, episode steps: 257, steps per second:  15, episode reward:  7.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.027 [0.000, 5.000],  loss: 0.013321, mae: 1.142545, mean_q: 1.393064, mean_eps: 0.249270\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  90691/200000: episode: 275, duration: 8.982s, episode steps: 125, steps per second:  14, episode reward:  1.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.048 [0.000, 5.000],  loss: 0.011241, mae: 1.154496, mean_q: 1.408216, mean_eps: 0.248953\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  91412/200000: episode: 276, duration: 47.509s, episode steps: 721, steps per second:  15, episode reward: 17.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.011941, mae: 1.145615, mean_q: 1.395669, mean_eps: 0.248250\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  91681/200000: episode: 277, duration: 19.191s, episode steps: 269, steps per second:  14, episode reward:  7.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.230 [0.000, 5.000],  loss: 0.010407, mae: 1.123182, mean_q: 1.369191, mean_eps: 0.247423\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  92083/200000: episode: 278, duration: 26.710s, episode steps: 402, steps per second:  15, episode reward: 10.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.109 [0.000, 5.000],  loss: 0.011897, mae: 1.117524, mean_q: 1.362749, mean_eps: 0.246863\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  92744/200000: episode: 279, duration: 43.373s, episode steps: 661, steps per second:  15, episode reward: 16.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.177 [0.000, 5.000],  loss: 0.010910, mae: 1.123799, mean_q: 1.370729, mean_eps: 0.245980\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  93677/200000: episode: 280, duration: 62.607s, episode steps: 933, steps per second:  15, episode reward: 25.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.179 [0.000, 5.000],  loss: 0.011354, mae: 1.127780, mean_q: 1.375316, mean_eps: 0.244650\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  93985/200000: episode: 281, duration: 21.796s, episode steps: 308, steps per second:  14, episode reward: 10.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.649 [0.000, 5.000],  loss: 0.011875, mae: 1.182899, mean_q: 1.442062, mean_eps: 0.243613\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  94267/200000: episode: 282, duration: 18.172s, episode steps: 282, steps per second:  16, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.012355, mae: 1.153436, mean_q: 1.406112, mean_eps: 0.243123\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  94396/200000: episode: 283, duration: 9.866s, episode steps: 129, steps per second:  13, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.984 [0.000, 5.000],  loss: 0.011631, mae: 1.133112, mean_q: 1.381379, mean_eps: 0.242783\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  94590/200000: episode: 284, duration: 13.914s, episode steps: 194, steps per second:  14, episode reward:  5.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.247 [0.000, 5.000],  loss: 0.013062, mae: 1.186789, mean_q: 1.447689, mean_eps: 0.242513\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  95090/200000: episode: 285, duration: 34.094s, episode steps: 500, steps per second:  15, episode reward: 12.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.008 [0.000, 5.000],  loss: 0.013873, mae: 1.156328, mean_q: 1.410580, mean_eps: 0.241933\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  95432/200000: episode: 286, duration: 25.282s, episode steps: 342, steps per second:  14, episode reward:  9.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.962 [0.000, 5.000],  loss: 0.013251, mae: 1.171487, mean_q: 1.430856, mean_eps: 0.241233\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  95950/200000: episode: 287, duration: 39.377s, episode steps: 518, steps per second:  13, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.006 [0.000, 5.000],  loss: 0.011444, mae: 1.150410, mean_q: 1.403665, mean_eps: 0.240517\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  96070/200000: episode: 288, duration: 8.503s, episode steps: 120, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 1.600 [0.000, 5.000],  loss: 0.014422, mae: 1.167043, mean_q: 1.421413, mean_eps: 0.239983\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  96351/200000: episode: 289, duration: 21.441s, episode steps: 281, steps per second:  13, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.292 [0.000, 5.000],  loss: 0.013905, mae: 1.166767, mean_q: 1.420213, mean_eps: 0.239650\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  96747/200000: episode: 290, duration: 29.560s, episode steps: 396, steps per second:  13, episode reward: 10.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.012390, mae: 1.164263, mean_q: 1.418948, mean_eps: 0.239087\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  97231/200000: episode: 291, duration: 36.938s, episode steps: 484, steps per second:  13, episode reward: 11.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.901 [0.000, 5.000],  loss: 0.012635, mae: 1.144708, mean_q: 1.396768, mean_eps: 0.238353\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  97776/200000: episode: 292, duration: 38.188s, episode steps: 545, steps per second:  14, episode reward: 14.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.651 [0.000, 5.000],  loss: 0.012240, mae: 1.151818, mean_q: 1.405156, mean_eps: 0.237497\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  98001/200000: episode: 293, duration: 16.360s, episode steps: 225, steps per second:  14, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.191 [0.000, 5.000],  loss: 0.012088, mae: 1.131826, mean_q: 1.382522, mean_eps: 0.236853\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  98407/200000: episode: 294, duration: 30.503s, episode steps: 406, steps per second:  13, episode reward: 10.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.746 [0.000, 5.000],  loss: 0.012889, mae: 1.144329, mean_q: 1.394202, mean_eps: 0.236327\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  98600/200000: episode: 295, duration: 14.962s, episode steps: 193, steps per second:  13, episode reward:  6.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 3.171 [0.000, 5.000],  loss: 0.011479, mae: 1.162430, mean_q: 1.416504, mean_eps: 0.235830\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  98792/200000: episode: 296, duration: 15.098s, episode steps: 192, steps per second:  13, episode reward:  4.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.047 [0.000, 5.000],  loss: 0.011011, mae: 1.170704, mean_q: 1.426257, mean_eps: 0.235510\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  99030/200000: episode: 297, duration: 17.678s, episode steps: 238, steps per second:  13, episode reward:  5.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.996 [0.000, 5.000],  loss: 0.010052, mae: 1.150169, mean_q: 1.405166, mean_eps: 0.235150\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  99398/200000: episode: 298, duration: 27.785s, episode steps: 368, steps per second:  13, episode reward: 14.000, mean reward:  0.038 [ 0.000,  1.000], mean action: 2.147 [0.000, 5.000],  loss: 0.011558, mae: 1.139985, mean_q: 1.390604, mean_eps: 0.234643\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  99937/200000: episode: 299, duration: 40.613s, episode steps: 539, steps per second:  13, episode reward: 16.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.636 [0.000, 5.000],  loss: 0.011993, mae: 1.150559, mean_q: 1.403208, mean_eps: 0.233887\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 100230/200000: episode: 300, duration: 21.437s, episode steps: 293, steps per second:  14, episode reward:  7.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.877 [0.000, 5.000],  loss: 0.011125, mae: 1.138097, mean_q: 1.387305, mean_eps: 0.233193\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 100496/200000: episode: 301, duration: 20.569s, episode steps: 266, steps per second:  13, episode reward:  6.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.053 [0.000, 5.000],  loss: 0.012373, mae: 1.146149, mean_q: 1.397249, mean_eps: 0.232730\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 100999/200000: episode: 302, duration: 35.271s, episode steps: 503, steps per second:  14, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.280 [0.000, 5.000],  loss: 0.012734, mae: 1.163351, mean_q: 1.417205, mean_eps: 0.232090\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 101588/200000: episode: 303, duration: 40.619s, episode steps: 589, steps per second:  15, episode reward: 21.000, mean reward:  0.036 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.012159, mae: 1.141539, mean_q: 1.392368, mean_eps: 0.231180\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 101781/200000: episode: 304, duration: 14.136s, episode steps: 193, steps per second:  14, episode reward:  5.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.140 [0.000, 5.000],  loss: 0.011874, mae: 1.128194, mean_q: 1.375820, mean_eps: 0.230527\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 102323/200000: episode: 305, duration: 38.691s, episode steps: 542, steps per second:  14, episode reward: 14.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.000 [0.000, 5.000],  loss: 0.012445, mae: 1.182639, mean_q: 1.442058, mean_eps: 0.229913\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 102567/200000: episode: 306, duration: 16.478s, episode steps: 244, steps per second:  15, episode reward:  9.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 3.000 [0.000, 5.000],  loss: 0.010449, mae: 1.161888, mean_q: 1.418121, mean_eps: 0.229260\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 102823/200000: episode: 307, duration: 18.754s, episode steps: 256, steps per second:  14, episode reward:  5.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.016 [0.000, 5.000],  loss: 0.011426, mae: 1.209735, mean_q: 1.475111, mean_eps: 0.228843\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 103036/200000: episode: 308, duration: 14.405s, episode steps: 213, steps per second:  15, episode reward:  7.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.013566, mae: 1.203657, mean_q: 1.470468, mean_eps: 0.228453\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 103328/200000: episode: 309, duration: 19.210s, episode steps: 292, steps per second:  15, episode reward:  5.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.151 [0.000, 5.000],  loss: 0.012150, mae: 1.199586, mean_q: 1.464130, mean_eps: 0.228033\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 103786/200000: episode: 310, duration: 29.916s, episode steps: 458, steps per second:  15, episode reward:  9.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.886 [0.000, 5.000],  loss: 0.012042, mae: 1.183286, mean_q: 1.446645, mean_eps: 0.227407\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 104030/200000: episode: 311, duration: 16.537s, episode steps: 244, steps per second:  15, episode reward:  6.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.266 [0.000, 5.000],  loss: 0.012436, mae: 1.191661, mean_q: 1.455407, mean_eps: 0.226820\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 104228/200000: episode: 312, duration: 13.061s, episode steps: 198, steps per second:  15, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.298 [0.000, 5.000],  loss: 0.015508, mae: 1.195029, mean_q: 1.457957, mean_eps: 0.226453\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 104475/200000: episode: 313, duration: 17.456s, episode steps: 247, steps per second:  14, episode reward:  8.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.239 [0.000, 5.000],  loss: 0.011357, mae: 1.199880, mean_q: 1.464507, mean_eps: 0.226083\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 104918/200000: episode: 314, duration: 28.960s, episode steps: 443, steps per second:  15, episode reward: 11.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.126 [0.000, 5.000],  loss: 0.011601, mae: 1.219104, mean_q: 1.490066, mean_eps: 0.225507\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 105255/200000: episode: 315, duration: 20.820s, episode steps: 337, steps per second:  16, episode reward:  5.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.920 [0.000, 5.000],  loss: 0.013485, mae: 1.198789, mean_q: 1.463468, mean_eps: 0.224857\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 105458/200000: episode: 316, duration: 13.458s, episode steps: 203, steps per second:  15, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.453 [0.000, 5.000],  loss: 0.012768, mae: 1.165247, mean_q: 1.425403, mean_eps: 0.224407\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 105823/200000: episode: 317, duration: 24.174s, episode steps: 365, steps per second:  15, episode reward: 10.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.337 [0.000, 5.000],  loss: 0.011615, mae: 1.194635, mean_q: 1.459362, mean_eps: 0.223933\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 106212/200000: episode: 318, duration: 25.707s, episode steps: 389, steps per second:  15, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.918 [0.000, 5.000],  loss: 0.010666, mae: 1.213126, mean_q: 1.481359, mean_eps: 0.223307\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 106544/200000: episode: 319, duration: 20.828s, episode steps: 332, steps per second:  16, episode reward:  8.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.030 [0.000, 5.000],  loss: 0.010460, mae: 1.194993, mean_q: 1.457642, mean_eps: 0.222707\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 106798/200000: episode: 320, duration: 18.141s, episode steps: 254, steps per second:  14, episode reward:  8.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 3.406 [0.000, 5.000],  loss: 0.013153, mae: 1.192211, mean_q: 1.453922, mean_eps: 0.222217\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 107273/200000: episode: 321, duration: 30.812s, episode steps: 475, steps per second:  15, episode reward: 11.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.116 [0.000, 5.000],  loss: 0.012119, mae: 1.202053, mean_q: 1.464763, mean_eps: 0.221607\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 107507/200000: episode: 322, duration: 14.997s, episode steps: 234, steps per second:  16, episode reward:  9.000, mean reward:  0.038 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.010748, mae: 1.211365, mean_q: 1.476652, mean_eps: 0.221017\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 108383/200000: episode: 323, duration: 56.920s, episode steps: 876, steps per second:  15, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 1.813 [0.000, 5.000],  loss: 0.010975, mae: 1.196645, mean_q: 1.459804, mean_eps: 0.220093\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 108842/200000: episode: 324, duration: 29.707s, episode steps: 459, steps per second:  15, episode reward: 11.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.662 [0.000, 5.000],  loss: 0.012265, mae: 1.205678, mean_q: 1.469604, mean_eps: 0.218980\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 109298/200000: episode: 325, duration: 29.462s, episode steps: 456, steps per second:  15, episode reward: 11.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.010942, mae: 1.187386, mean_q: 1.449004, mean_eps: 0.218217\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 109585/200000: episode: 326, duration: 19.636s, episode steps: 287, steps per second:  15, episode reward:  8.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.666 [0.000, 5.000],  loss: 0.012716, mae: 1.191866, mean_q: 1.453644, mean_eps: 0.217597\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 109804/200000: episode: 327, duration: 14.242s, episode steps: 219, steps per second:  15, episode reward:  8.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 1.854 [0.000, 5.000],  loss: 0.012778, mae: 1.178908, mean_q: 1.434256, mean_eps: 0.217177\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 110101/200000: episode: 328, duration: 19.073s, episode steps: 297, steps per second:  16, episode reward:  9.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 1.714 [0.000, 5.000],  loss: 0.010837, mae: 1.190932, mean_q: 1.451924, mean_eps: 0.216747\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 110362/200000: episode: 329, duration: 17.354s, episode steps: 261, steps per second:  15, episode reward:  8.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.012373, mae: 1.187959, mean_q: 1.448258, mean_eps: 0.216280\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 111132/200000: episode: 330, duration: 49.778s, episode steps: 770, steps per second:  15, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.011683, mae: 1.211745, mean_q: 1.477940, mean_eps: 0.215423\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 111356/200000: episode: 331, duration: 14.785s, episode steps: 224, steps per second:  15, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.562 [0.000, 5.000],  loss: 0.011502, mae: 1.254071, mean_q: 1.530670, mean_eps: 0.214597\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 111587/200000: episode: 332, duration: 15.090s, episode steps: 231, steps per second:  15, episode reward:  5.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.597 [0.000, 5.000],  loss: 0.011310, mae: 1.232444, mean_q: 1.502968, mean_eps: 0.214217\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 111868/200000: episode: 333, duration: 19.742s, episode steps: 281, steps per second:  14, episode reward:  6.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.014491, mae: 1.206859, mean_q: 1.470367, mean_eps: 0.213790\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 112248/200000: episode: 334, duration: 23.956s, episode steps: 380, steps per second:  16, episode reward: 10.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.234 [0.000, 5.000],  loss: 0.012072, mae: 1.187427, mean_q: 1.447310, mean_eps: 0.213240\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 112854/200000: episode: 335, duration: 39.484s, episode steps: 606, steps per second:  15, episode reward: 20.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.012340, mae: 1.203897, mean_q: 1.468133, mean_eps: 0.212417\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 113120/200000: episode: 336, duration: 18.879s, episode steps: 266, steps per second:  14, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.012351, mae: 1.219811, mean_q: 1.487517, mean_eps: 0.211690\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 113338/200000: episode: 337, duration: 14.311s, episode steps: 218, steps per second:  15, episode reward:  3.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.151 [0.000, 5.000],  loss: 0.011919, mae: 1.225830, mean_q: 1.494600, mean_eps: 0.211287\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 113747/200000: episode: 338, duration: 26.605s, episode steps: 409, steps per second:  15, episode reward: 10.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 3.105 [0.000, 5.000],  loss: 0.010444, mae: 1.218401, mean_q: 1.487989, mean_eps: 0.210763\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 114020/200000: episode: 339, duration: 17.951s, episode steps: 273, steps per second:  15, episode reward:  9.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 3.154 [0.000, 5.000],  loss: 0.010621, mae: 1.210074, mean_q: 1.478481, mean_eps: 0.210197\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 114416/200000: episode: 340, duration: 26.263s, episode steps: 396, steps per second:  15, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.012804, mae: 1.214901, mean_q: 1.483235, mean_eps: 0.209640\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 114995/200000: episode: 341, duration: 38.775s, episode steps: 579, steps per second:  15, episode reward: 17.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.140 [0.000, 5.000],  loss: 0.011471, mae: 1.211833, mean_q: 1.483932, mean_eps: 0.208827\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 115213/200000: episode: 342, duration: 14.674s, episode steps: 218, steps per second:  15, episode reward:  6.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 1.775 [0.000, 5.000],  loss: 0.012347, mae: 1.234597, mean_q: 1.505553, mean_eps: 0.208160\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 115395/200000: episode: 343, duration: 12.236s, episode steps: 182, steps per second:  15, episode reward:  2.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 1.791 [0.000, 5.000],  loss: 0.009693, mae: 1.192834, mean_q: 1.455490, mean_eps: 0.207827\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 115655/200000: episode: 344, duration: 18.351s, episode steps: 260, steps per second:  14, episode reward:  9.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.011677, mae: 1.185449, mean_q: 1.444048, mean_eps: 0.207460\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 116049/200000: episode: 345, duration: 27.271s, episode steps: 394, steps per second:  14, episode reward: 10.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.094 [0.000, 5.000],  loss: 0.011972, mae: 1.215153, mean_q: 1.482674, mean_eps: 0.206913\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 116479/200000: episode: 346, duration: 29.469s, episode steps: 430, steps per second:  15, episode reward:  9.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: 0.011841, mae: 1.236120, mean_q: 1.508231, mean_eps: 0.206227\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 117058/200000: episode: 347, duration: 38.899s, episode steps: 579, steps per second:  15, episode reward: 14.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.002 [0.000, 5.000],  loss: 0.011321, mae: 1.210080, mean_q: 1.477642, mean_eps: 0.205387\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 117303/200000: episode: 348, duration: 16.179s, episode steps: 245, steps per second:  15, episode reward:  9.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 3.020 [0.000, 5.000],  loss: 0.012099, mae: 1.239171, mean_q: 1.512142, mean_eps: 0.204700\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 117516/200000: episode: 349, duration: 14.705s, episode steps: 213, steps per second:  14, episode reward:  6.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 3.047 [0.000, 5.000],  loss: 0.011779, mae: 1.193526, mean_q: 1.457098, mean_eps: 0.204320\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 117871/200000: episode: 350, duration: 24.375s, episode steps: 355, steps per second:  15, episode reward: 10.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.654 [0.000, 5.000],  loss: 0.010938, mae: 1.222249, mean_q: 1.491023, mean_eps: 0.203847\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 118515/200000: episode: 351, duration: 42.863s, episode steps: 644, steps per second:  15, episode reward: 16.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.775 [0.000, 5.000],  loss: 0.011395, mae: 1.218285, mean_q: 1.486928, mean_eps: 0.203013\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 119117/200000: episode: 352, duration: 40.437s, episode steps: 602, steps per second:  15, episode reward: 13.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.011971, mae: 1.236825, mean_q: 1.507919, mean_eps: 0.201973\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 119337/200000: episode: 353, duration: 14.578s, episode steps: 220, steps per second:  15, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 1.859 [0.000, 5.000],  loss: 0.011078, mae: 1.279449, mean_q: 1.562142, mean_eps: 0.201287\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 119931/200000: episode: 354, duration: 39.792s, episode steps: 594, steps per second:  15, episode reward: 15.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.751 [0.000, 5.000],  loss: 0.012403, mae: 1.241677, mean_q: 1.514512, mean_eps: 0.200610\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 120302/200000: episode: 355, duration: 23.527s, episode steps: 371, steps per second:  16, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.012781, mae: 1.257663, mean_q: 1.532995, mean_eps: 0.199807\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 120826/200000: episode: 356, duration: 35.121s, episode steps: 524, steps per second:  15, episode reward: 15.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.324 [0.000, 5.000],  loss: 0.011944, mae: 1.247594, mean_q: 1.522166, mean_eps: 0.199060\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 121209/200000: episode: 357, duration: 25.563s, episode steps: 383, steps per second:  15, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: 0.010660, mae: 1.241419, mean_q: 1.513743, mean_eps: 0.198303\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 121494/200000: episode: 358, duration: 17.863s, episode steps: 285, steps per second:  16, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.147 [0.000, 5.000],  loss: 0.011871, mae: 1.251819, mean_q: 1.526488, mean_eps: 0.197747\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 121902/200000: episode: 359, duration: 26.846s, episode steps: 408, steps per second:  15, episode reward: 10.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.248 [0.000, 5.000],  loss: 0.009520, mae: 1.228738, mean_q: 1.498481, mean_eps: 0.197170\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 122147/200000: episode: 360, duration: 15.940s, episode steps: 245, steps per second:  15, episode reward:  8.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.012796, mae: 1.255380, mean_q: 1.531839, mean_eps: 0.196627\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 122568/200000: episode: 361, duration: 27.765s, episode steps: 421, steps per second:  15, episode reward:  9.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.185 [0.000, 5.000],  loss: 0.011928, mae: 1.234956, mean_q: 1.508640, mean_eps: 0.196073\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 122864/200000: episode: 362, duration: 20.815s, episode steps: 296, steps per second:  14, episode reward:  7.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.625 [0.000, 5.000],  loss: 0.011132, mae: 1.264644, mean_q: 1.545204, mean_eps: 0.195477\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 123398/200000: episode: 363, duration: 34.101s, episode steps: 534, steps per second:  16, episode reward: 14.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.013193, mae: 1.259633, mean_q: 1.536899, mean_eps: 0.194783\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 123682/200000: episode: 364, duration: 19.422s, episode steps: 284, steps per second:  15, episode reward: 10.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 2.225 [0.000, 5.000],  loss: 0.012046, mae: 1.235991, mean_q: 1.508925, mean_eps: 0.194100\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 123902/200000: episode: 365, duration: 15.357s, episode steps: 220, steps per second:  14, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.877 [0.000, 5.000],  loss: 0.012471, mae: 1.270313, mean_q: 1.552169, mean_eps: 0.193680\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 124124/200000: episode: 366, duration: 14.659s, episode steps: 222, steps per second:  15, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.266 [0.000, 5.000],  loss: 0.014075, mae: 1.269760, mean_q: 1.547610, mean_eps: 0.193313\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 124415/200000: episode: 367, duration: 20.284s, episode steps: 291, steps per second:  14, episode reward:  6.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.320 [0.000, 5.000],  loss: 0.012148, mae: 1.252862, mean_q: 1.528848, mean_eps: 0.192887\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 124767/200000: episode: 368, duration: 24.471s, episode steps: 352, steps per second:  14, episode reward:  9.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.304 [0.000, 5.000],  loss: 0.012699, mae: 1.255369, mean_q: 1.532810, mean_eps: 0.192350\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 125013/200000: episode: 369, duration: 16.037s, episode steps: 246, steps per second:  15, episode reward:  7.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.313 [0.000, 5.000],  loss: 0.010650, mae: 1.249070, mean_q: 1.526664, mean_eps: 0.191850\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 125548/200000: episode: 370, duration: 35.689s, episode steps: 535, steps per second:  15, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.012066, mae: 1.268278, mean_q: 1.547926, mean_eps: 0.191200\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 125993/200000: episode: 371, duration: 29.461s, episode steps: 445, steps per second:  15, episode reward: 10.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.040 [0.000, 5.000],  loss: 0.011453, mae: 1.243154, mean_q: 1.515692, mean_eps: 0.190383\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 126220/200000: episode: 372, duration: 15.006s, episode steps: 227, steps per second:  15, episode reward:  3.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.264 [0.000, 5.000],  loss: 0.011641, mae: 1.218630, mean_q: 1.485902, mean_eps: 0.189823\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 126637/200000: episode: 373, duration: 27.805s, episode steps: 417, steps per second:  15, episode reward:  9.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.820 [0.000, 5.000],  loss: 0.012460, mae: 1.276757, mean_q: 1.555573, mean_eps: 0.189287\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 126934/200000: episode: 374, duration: 18.899s, episode steps: 297, steps per second:  16, episode reward:  7.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.236 [0.000, 5.000],  loss: 0.013512, mae: 1.265631, mean_q: 1.540795, mean_eps: 0.188690\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 127288/200000: episode: 375, duration: 23.928s, episode steps: 354, steps per second:  15, episode reward: 11.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.805 [0.000, 5.000],  loss: 0.011841, mae: 1.245946, mean_q: 1.518309, mean_eps: 0.188150\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 127791/200000: episode: 376, duration: 32.702s, episode steps: 503, steps per second:  15, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: 0.010999, mae: 1.261130, mean_q: 1.539682, mean_eps: 0.187437\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 128176/200000: episode: 377, duration: 26.178s, episode steps: 385, steps per second:  15, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.011787, mae: 1.298031, mean_q: 1.583713, mean_eps: 0.186697\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 128731/200000: episode: 378, duration: 37.551s, episode steps: 555, steps per second:  15, episode reward: 14.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.222 [0.000, 5.000],  loss: 0.012522, mae: 1.279898, mean_q: 1.562867, mean_eps: 0.185913\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 128996/200000: episode: 379, duration: 17.271s, episode steps: 265, steps per second:  15, episode reward:  9.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.619 [0.000, 5.000],  loss: 0.010687, mae: 1.292758, mean_q: 1.576824, mean_eps: 0.185230\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 129371/200000: episode: 380, duration: 25.138s, episode steps: 375, steps per second:  15, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.816 [0.000, 5.000],  loss: 0.011294, mae: 1.295234, mean_q: 1.579225, mean_eps: 0.184697\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 129551/200000: episode: 381, duration: 12.194s, episode steps: 180, steps per second:  15, episode reward:  3.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.010886, mae: 1.301935, mean_q: 1.589123, mean_eps: 0.184233\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 129739/200000: episode: 382, duration: 12.669s, episode steps: 188, steps per second:  15, episode reward:  4.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.745 [0.000, 5.000],  loss: 0.011706, mae: 1.295331, mean_q: 1.579892, mean_eps: 0.183927\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 130015/200000: episode: 383, duration: 18.060s, episode steps: 276, steps per second:  15, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.087 [0.000, 5.000],  loss: 0.013052, mae: 1.280587, mean_q: 1.561630, mean_eps: 0.183540\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 130239/200000: episode: 384, duration: 14.763s, episode steps: 224, steps per second:  15, episode reward:  6.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.011435, mae: 1.298982, mean_q: 1.584259, mean_eps: 0.183123\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 130354/200000: episode: 385, duration: 8.495s, episode steps: 115, steps per second:  14, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 3.313 [0.000, 5.000],  loss: 0.012797, mae: 1.270599, mean_q: 1.549659, mean_eps: 0.182840\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 130559/200000: episode: 386, duration: 13.597s, episode steps: 205, steps per second:  15, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.985 [0.000, 5.000],  loss: 0.012846, mae: 1.277655, mean_q: 1.559895, mean_eps: 0.182573\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 130951/200000: episode: 387, duration: 26.706s, episode steps: 392, steps per second:  15, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.013173, mae: 1.297740, mean_q: 1.582214, mean_eps: 0.182077\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 131442/200000: episode: 388, duration: 31.877s, episode steps: 491, steps per second:  15, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.680 [0.000, 5.000],  loss: 0.011366, mae: 1.285894, mean_q: 1.568942, mean_eps: 0.181340\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 131735/200000: episode: 389, duration: 18.732s, episode steps: 293, steps per second:  16, episode reward:  8.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.011638, mae: 1.307559, mean_q: 1.593484, mean_eps: 0.180687\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 132124/200000: episode: 390, duration: 26.191s, episode steps: 389, steps per second:  15, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.992 [0.000, 5.000],  loss: 0.012513, mae: 1.294769, mean_q: 1.578086, mean_eps: 0.180120\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 132301/200000: episode: 391, duration: 12.261s, episode steps: 177, steps per second:  14, episode reward:  3.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.774 [0.000, 5.000],  loss: 0.009994, mae: 1.258388, mean_q: 1.539462, mean_eps: 0.179647\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 132556/200000: episode: 392, duration: 16.852s, episode steps: 255, steps per second:  15, episode reward:  8.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 3.067 [0.000, 5.000],  loss: 0.011589, mae: 1.295966, mean_q: 1.579486, mean_eps: 0.179287\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 133041/200000: episode: 393, duration: 33.236s, episode steps: 485, steps per second:  15, episode reward: 12.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.167 [0.000, 5.000],  loss: 0.010931, mae: 1.306765, mean_q: 1.594419, mean_eps: 0.178670\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 133352/200000: episode: 394, duration: 20.167s, episode steps: 311, steps per second:  15, episode reward:  6.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.012913, mae: 1.289605, mean_q: 1.575302, mean_eps: 0.178007\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 133581/200000: episode: 395, duration: 15.257s, episode steps: 229, steps per second:  15, episode reward:  7.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 1.572 [0.000, 5.000],  loss: 0.012793, mae: 1.279681, mean_q: 1.561206, mean_eps: 0.177557\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 133946/200000: episode: 396, duration: 24.822s, episode steps: 365, steps per second:  15, episode reward: 10.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.148 [0.000, 5.000],  loss: 0.012959, mae: 1.323576, mean_q: 1.612752, mean_eps: 0.177060\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 134513/200000: episode: 397, duration: 37.914s, episode steps: 567, steps per second:  15, episode reward: 13.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.347 [0.000, 5.000],  loss: 0.010420, mae: 1.273744, mean_q: 1.554561, mean_eps: 0.176283\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 134762/200000: episode: 398, duration: 16.181s, episode steps: 249, steps per second:  15, episode reward:  7.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.904 [0.000, 5.000],  loss: 0.013118, mae: 1.296621, mean_q: 1.580097, mean_eps: 0.175603\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 135082/200000: episode: 399, duration: 21.967s, episode steps: 320, steps per second:  15, episode reward: 10.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 1.809 [0.000, 5.000],  loss: 0.012965, mae: 1.290829, mean_q: 1.575736, mean_eps: 0.175130\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 135324/200000: episode: 400, duration: 16.214s, episode steps: 242, steps per second:  15, episode reward:  6.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.099 [0.000, 5.000],  loss: 0.012319, mae: 1.304477, mean_q: 1.592814, mean_eps: 0.174663\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 135691/200000: episode: 401, duration: 24.720s, episode steps: 367, steps per second:  15, episode reward: 12.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: 0.011023, mae: 1.305736, mean_q: 1.592179, mean_eps: 0.174157\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 136059/200000: episode: 402, duration: 23.854s, episode steps: 368, steps per second:  15, episode reward: 12.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.715 [0.000, 5.000],  loss: 0.012475, mae: 1.314093, mean_q: 1.601285, mean_eps: 0.173543\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 136351/200000: episode: 403, duration: 20.904s, episode steps: 292, steps per second:  14, episode reward:  6.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.753 [0.000, 5.000],  loss: 0.011478, mae: 1.314523, mean_q: 1.604729, mean_eps: 0.172993\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 136750/200000: episode: 404, duration: 27.358s, episode steps: 399, steps per second:  15, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 3.361 [0.000, 5.000],  loss: 0.011663, mae: 1.327623, mean_q: 1.619192, mean_eps: 0.172417\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 137109/200000: episode: 405, duration: 23.840s, episode steps: 359, steps per second:  15, episode reward:  9.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.710 [0.000, 5.000],  loss: 0.011875, mae: 1.310655, mean_q: 1.598213, mean_eps: 0.171783\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 137403/200000: episode: 406, duration: 20.234s, episode steps: 294, steps per second:  15, episode reward:  9.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.857 [0.000, 5.000],  loss: 0.011406, mae: 1.304994, mean_q: 1.591508, mean_eps: 0.171240\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 138007/200000: episode: 407, duration: 40.797s, episode steps: 604, steps per second:  15, episode reward: 17.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.012318, mae: 1.319602, mean_q: 1.609649, mean_eps: 0.170493\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 138422/200000: episode: 408, duration: 27.649s, episode steps: 415, steps per second:  15, episode reward: 13.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.383 [0.000, 5.000],  loss: 0.011075, mae: 1.315301, mean_q: 1.603337, mean_eps: 0.169643\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 138940/200000: episode: 409, duration: 33.865s, episode steps: 518, steps per second:  15, episode reward: 16.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.384 [0.000, 5.000],  loss: 0.011670, mae: 1.298653, mean_q: 1.582441, mean_eps: 0.168867\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 139182/200000: episode: 410, duration: 17.337s, episode steps: 242, steps per second:  14, episode reward:  8.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.011184, mae: 1.302485, mean_q: 1.587116, mean_eps: 0.168233\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 139679/200000: episode: 411, duration: 32.234s, episode steps: 497, steps per second:  15, episode reward: 12.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.805 [0.000, 5.000],  loss: 0.012408, mae: 1.319343, mean_q: 1.609015, mean_eps: 0.167617\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 139920/200000: episode: 412, duration: 15.913s, episode steps: 241, steps per second:  15, episode reward:  6.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.237 [0.000, 5.000],  loss: 0.013607, mae: 1.328995, mean_q: 1.621126, mean_eps: 0.167003\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 140159/200000: episode: 413, duration: 15.776s, episode steps: 239, steps per second:  15, episode reward:  6.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.010369, mae: 1.326479, mean_q: 1.617469, mean_eps: 0.166603\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 140409/200000: episode: 414, duration: 17.324s, episode steps: 250, steps per second:  14, episode reward:  8.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 1.868 [0.000, 5.000],  loss: 0.011730, mae: 1.315132, mean_q: 1.604463, mean_eps: 0.166193\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 140522/200000: episode: 415, duration: 7.479s, episode steps: 113, steps per second:  15, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.743 [0.000, 5.000],  loss: 0.009783, mae: 1.315472, mean_q: 1.609707, mean_eps: 0.165890\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 140860/200000: episode: 416, duration: 23.127s, episode steps: 338, steps per second:  15, episode reward:  9.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.011481, mae: 1.338344, mean_q: 1.632532, mean_eps: 0.165517\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 141254/200000: episode: 417, duration: 26.351s, episode steps: 394, steps per second:  15, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.632 [0.000, 5.000],  loss: 0.012275, mae: 1.311999, mean_q: 1.599397, mean_eps: 0.164907\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 141518/200000: episode: 418, duration: 17.158s, episode steps: 264, steps per second:  15, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.883 [0.000, 5.000],  loss: 0.011957, mae: 1.324770, mean_q: 1.614870, mean_eps: 0.164357\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 141724/200000: episode: 419, duration: 14.031s, episode steps: 206, steps per second:  15, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.087 [0.000, 5.000],  loss: 0.012518, mae: 1.298444, mean_q: 1.585340, mean_eps: 0.163967\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 141963/200000: episode: 420, duration: 15.645s, episode steps: 239, steps per second:  15, episode reward:  6.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.105 [0.000, 5.000],  loss: 0.013205, mae: 1.339285, mean_q: 1.630002, mean_eps: 0.163597\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 142540/200000: episode: 421, duration: 38.670s, episode steps: 577, steps per second:  15, episode reward: 13.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.678 [0.000, 5.000],  loss: 0.012781, mae: 1.310256, mean_q: 1.598401, mean_eps: 0.162917\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 142925/200000: episode: 422, duration: 25.848s, episode steps: 385, steps per second:  15, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.455 [0.000, 5.000],  loss: 0.012774, mae: 1.332371, mean_q: 1.625704, mean_eps: 0.162113\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 143151/200000: episode: 423, duration: 14.805s, episode steps: 226, steps per second:  15, episode reward:  6.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.212 [0.000, 5.000],  loss: 0.012050, mae: 1.305005, mean_q: 1.591932, mean_eps: 0.161603\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 143486/200000: episode: 424, duration: 21.232s, episode steps: 335, steps per second:  16, episode reward:  9.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 1.884 [0.000, 5.000],  loss: 0.012106, mae: 1.320362, mean_q: 1.610194, mean_eps: 0.161137\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 143755/200000: episode: 425, duration: 18.951s, episode steps: 269, steps per second:  14, episode reward:  7.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 1.695 [0.000, 5.000],  loss: 0.011343, mae: 1.325462, mean_q: 1.615932, mean_eps: 0.160633\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 144290/200000: episode: 426, duration: 35.119s, episode steps: 535, steps per second:  15, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 3.146 [0.000, 5.000],  loss: 0.011937, mae: 1.299988, mean_q: 1.584593, mean_eps: 0.159963\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 144681/200000: episode: 427, duration: 26.373s, episode steps: 391, steps per second:  15, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.992 [0.000, 5.000],  loss: 0.011781, mae: 1.384824, mean_q: 1.687794, mean_eps: 0.159190\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 144951/200000: episode: 428, duration: 17.327s, episode steps: 270, steps per second:  16, episode reward:  9.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.019 [0.000, 5.000],  loss: 0.011977, mae: 1.362781, mean_q: 1.660056, mean_eps: 0.158640\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 145233/200000: episode: 429, duration: 20.011s, episode steps: 282, steps per second:  14, episode reward:  8.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 1.890 [0.000, 5.000],  loss: 0.012278, mae: 1.381129, mean_q: 1.683257, mean_eps: 0.158180\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 145367/200000: episode: 430, duration: 7.896s, episode steps: 134, steps per second:  17, episode reward:  0.000, mean reward:  0.000 [ 0.000,  0.000], mean action: 2.366 [0.000, 5.000],  loss: 0.011988, mae: 1.413062, mean_q: 1.720518, mean_eps: 0.157833\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 146046/200000: episode: 431, duration: 45.680s, episode steps: 679, steps per second:  15, episode reward: 21.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.246 [0.000, 5.000],  loss: 0.011739, mae: 1.364488, mean_q: 1.663595, mean_eps: 0.157157\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 146291/200000: episode: 432, duration: 16.068s, episode steps: 245, steps per second:  15, episode reward:  7.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 3.041 [0.000, 5.000],  loss: 0.010701, mae: 1.350640, mean_q: 1.651295, mean_eps: 0.156387\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 146526/200000: episode: 433, duration: 15.493s, episode steps: 235, steps per second:  15, episode reward:  5.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.694 [0.000, 5.000],  loss: 0.012377, mae: 1.337507, mean_q: 1.629794, mean_eps: 0.155987\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 146785/200000: episode: 434, duration: 16.781s, episode steps: 259, steps per second:  15, episode reward:  8.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.351 [0.000, 5.000],  loss: 0.012440, mae: 1.375474, mean_q: 1.673556, mean_eps: 0.155573\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 147019/200000: episode: 435, duration: 15.159s, episode steps: 234, steps per second:  15, episode reward:  5.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.966 [0.000, 5.000],  loss: 0.010800, mae: 1.368039, mean_q: 1.664980, mean_eps: 0.155163\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 147297/200000: episode: 436, duration: 19.484s, episode steps: 278, steps per second:  14, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.176 [0.000, 5.000],  loss: 0.012291, mae: 1.350032, mean_q: 1.642272, mean_eps: 0.154737\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 147659/200000: episode: 437, duration: 22.469s, episode steps: 362, steps per second:  16, episode reward: 10.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.376 [0.000, 5.000],  loss: 0.010820, mae: 1.370955, mean_q: 1.671237, mean_eps: 0.154203\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 148057/200000: episode: 438, duration: 26.563s, episode steps: 398, steps per second:  15, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.055 [0.000, 5.000],  loss: 0.011568, mae: 1.381739, mean_q: 1.683881, mean_eps: 0.153570\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 148310/200000: episode: 439, duration: 17.366s, episode steps: 253, steps per second:  15, episode reward:  5.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.067 [0.000, 5.000],  loss: 0.011106, mae: 1.386613, mean_q: 1.693650, mean_eps: 0.153027\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 148560/200000: episode: 440, duration: 17.307s, episode steps: 250, steps per second:  14, episode reward:  7.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 3.000 [0.000, 5.000],  loss: 0.012049, mae: 1.352253, mean_q: 1.652317, mean_eps: 0.152610\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 149270/200000: episode: 441, duration: 46.510s, episode steps: 710, steps per second:  15, episode reward: 18.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: 0.011445, mae: 1.354342, mean_q: 1.652244, mean_eps: 0.151810\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 149628/200000: episode: 442, duration: 24.493s, episode steps: 358, steps per second:  15, episode reward:  7.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.176 [0.000, 5.000],  loss: 0.011884, mae: 1.376574, mean_q: 1.676542, mean_eps: 0.150920\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 150016/200000: episode: 443, duration: 26.458s, episode steps: 388, steps per second:  15, episode reward: 11.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.670 [0.000, 5.000],  loss: 0.012772, mae: 1.369527, mean_q: 1.667897, mean_eps: 0.150300\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 150455/200000: episode: 444, duration: 29.088s, episode steps: 439, steps per second:  15, episode reward: 11.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.984 [0.000, 5.000],  loss: 0.012084, mae: 1.359975, mean_q: 1.656155, mean_eps: 0.149610\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 150687/200000: episode: 445, duration: 15.379s, episode steps: 232, steps per second:  15, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.216 [0.000, 5.000],  loss: 0.010415, mae: 1.376552, mean_q: 1.678060, mean_eps: 0.149050\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 150963/200000: episode: 446, duration: 17.867s, episode steps: 276, steps per second:  15, episode reward:  8.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.116 [0.000, 5.000],  loss: 0.012492, mae: 1.385092, mean_q: 1.686096, mean_eps: 0.148627\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 151216/200000: episode: 447, duration: 18.392s, episode steps: 253, steps per second:  14, episode reward:  9.000, mean reward:  0.036 [ 0.000,  1.000], mean action: 2.028 [0.000, 5.000],  loss: 0.012323, mae: 1.369653, mean_q: 1.671033, mean_eps: 0.148187\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 151479/200000: episode: 448, duration: 17.245s, episode steps: 263, steps per second:  15, episode reward:  7.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.011897, mae: 1.379508, mean_q: 1.681611, mean_eps: 0.147757\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 151651/200000: episode: 449, duration: 11.805s, episode steps: 172, steps per second:  15, episode reward:  4.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.634 [0.000, 5.000],  loss: 0.012135, mae: 1.347706, mean_q: 1.644519, mean_eps: 0.147393\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 151909/200000: episode: 450, duration: 17.346s, episode steps: 258, steps per second:  15, episode reward:  7.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.275 [0.000, 5.000],  loss: 0.012144, mae: 1.331874, mean_q: 1.623808, mean_eps: 0.147033\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 152177/200000: episode: 451, duration: 17.370s, episode steps: 268, steps per second:  15, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.201 [0.000, 5.000],  loss: 0.012395, mae: 1.355674, mean_q: 1.652923, mean_eps: 0.146593\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 152373/200000: episode: 452, duration: 13.301s, episode steps: 196, steps per second:  15, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.770 [0.000, 5.000],  loss: 0.011927, mae: 1.388918, mean_q: 1.690643, mean_eps: 0.146207\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 152790/200000: episode: 453, duration: 27.481s, episode steps: 417, steps per second:  15, episode reward: 10.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.995 [0.000, 5.000],  loss: 0.012019, mae: 1.387910, mean_q: 1.689493, mean_eps: 0.145697\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 153042/200000: episode: 454, duration: 17.287s, episode steps: 252, steps per second:  15, episode reward:  8.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.635 [0.000, 5.000],  loss: 0.011742, mae: 1.371950, mean_q: 1.671209, mean_eps: 0.145140\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 153298/200000: episode: 455, duration: 17.884s, episode steps: 256, steps per second:  14, episode reward:  6.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.355 [0.000, 5.000],  loss: 0.010650, mae: 1.393846, mean_q: 1.697653, mean_eps: 0.144717\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 153697/200000: episode: 456, duration: 26.911s, episode steps: 399, steps per second:  15, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.012711, mae: 1.370721, mean_q: 1.669109, mean_eps: 0.144170\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 153932/200000: episode: 457, duration: 15.515s, episode steps: 235, steps per second:  15, episode reward:  9.000, mean reward:  0.038 [ 0.000,  1.000], mean action: 2.255 [0.000, 5.000],  loss: 0.011412, mae: 1.351311, mean_q: 1.648356, mean_eps: 0.143643\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 154293/200000: episode: 458, duration: 24.562s, episode steps: 361, steps per second:  15, episode reward: 10.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.778 [0.000, 5.000],  loss: 0.013188, mae: 1.384763, mean_q: 1.686633, mean_eps: 0.143147\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 154566/200000: episode: 459, duration: 17.650s, episode steps: 273, steps per second:  15, episode reward:  7.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.267 [0.000, 5.000],  loss: 0.009663, mae: 1.364708, mean_q: 1.663952, mean_eps: 0.142617\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 154837/200000: episode: 460, duration: 17.771s, episode steps: 271, steps per second:  15, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 3.000 [0.000, 5.000],  loss: 0.010485, mae: 1.361147, mean_q: 1.658692, mean_eps: 0.142163\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 155455/200000: episode: 461, duration: 40.952s, episode steps: 618, steps per second:  15, episode reward: 14.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.317 [0.000, 5.000],  loss: 0.010535, mae: 1.390196, mean_q: 1.694452, mean_eps: 0.141423\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 155701/200000: episode: 462, duration: 16.177s, episode steps: 246, steps per second:  15, episode reward:  7.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.009916, mae: 1.400513, mean_q: 1.708209, mean_eps: 0.140703\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 156528/200000: episode: 463, duration: 54.846s, episode steps: 827, steps per second:  15, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.918 [0.000, 5.000],  loss: 0.010790, mae: 1.381342, mean_q: 1.685344, mean_eps: 0.139810\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 156911/200000: episode: 464, duration: 25.977s, episode steps: 383, steps per second:  15, episode reward: 10.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.201 [0.000, 5.000],  loss: 0.012124, mae: 1.387225, mean_q: 1.690362, mean_eps: 0.138803\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 157157/200000: episode: 465, duration: 16.697s, episode steps: 246, steps per second:  15, episode reward:  8.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.013179, mae: 1.360565, mean_q: 1.656219, mean_eps: 0.138277\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 157687/200000: episode: 466, duration: 35.360s, episode steps: 530, steps per second:  15, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.285 [0.000, 5.000],  loss: 0.011463, mae: 1.370788, mean_q: 1.670099, mean_eps: 0.137630\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 157926/200000: episode: 467, duration: 16.070s, episode steps: 239, steps per second:  15, episode reward:  6.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.272 [0.000, 5.000],  loss: 0.014606, mae: 1.397898, mean_q: 1.703211, mean_eps: 0.136990\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 158450/200000: episode: 468, duration: 35.833s, episode steps: 524, steps per second:  15, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.246 [0.000, 5.000],  loss: 0.012020, mae: 1.373993, mean_q: 1.674671, mean_eps: 0.136353\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 158781/200000: episode: 469, duration: 20.984s, episode steps: 331, steps per second:  16, episode reward: 10.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.011228, mae: 1.378880, mean_q: 1.678980, mean_eps: 0.135640\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 159044/200000: episode: 470, duration: 18.750s, episode steps: 263, steps per second:  14, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: 0.012981, mae: 1.372300, mean_q: 1.673104, mean_eps: 0.135147\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 159431/200000: episode: 471, duration: 24.942s, episode steps: 387, steps per second:  16, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 3.160 [0.000, 5.000],  loss: 0.014146, mae: 1.386071, mean_q: 1.689146, mean_eps: 0.134607\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 159827/200000: episode: 472, duration: 25.982s, episode steps: 396, steps per second:  15, episode reward: 11.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.639 [0.000, 5.000],  loss: 0.011751, mae: 1.395022, mean_q: 1.701479, mean_eps: 0.133953\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 160044/200000: episode: 473, duration: 14.906s, episode steps: 217, steps per second:  15, episode reward:  8.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 2.829 [0.000, 5.000],  loss: 0.010809, mae: 1.360335, mean_q: 1.658886, mean_eps: 0.133443\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 160280/200000: episode: 474, duration: 16.998s, episode steps: 236, steps per second:  14, episode reward:  6.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.814 [0.000, 5.000],  loss: 0.011576, mae: 1.384446, mean_q: 1.688574, mean_eps: 0.133067\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 160626/200000: episode: 475, duration: 22.181s, episode steps: 346, steps per second:  16, episode reward: 11.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.012064, mae: 1.364284, mean_q: 1.663952, mean_eps: 0.132580\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 160838/200000: episode: 476, duration: 14.267s, episode steps: 212, steps per second:  15, episode reward:  6.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.693 [0.000, 5.000],  loss: 0.009892, mae: 1.367159, mean_q: 1.666549, mean_eps: 0.132113\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 161164/200000: episode: 477, duration: 22.687s, episode steps: 326, steps per second:  14, episode reward:  9.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.353 [0.000, 5.000],  loss: 0.013025, mae: 1.382141, mean_q: 1.684014, mean_eps: 0.131667\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 161436/200000: episode: 478, duration: 18.131s, episode steps: 272, steps per second:  15, episode reward: 10.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.012762, mae: 1.399364, mean_q: 1.704222, mean_eps: 0.131170\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 161707/200000: episode: 479, duration: 19.270s, episode steps: 271, steps per second:  14, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.491 [0.000, 5.000],  loss: 0.013214, mae: 1.360854, mean_q: 1.657125, mean_eps: 0.130717\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 161969/200000: episode: 480, duration: 17.224s, episode steps: 262, steps per second:  15, episode reward:  8.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.298 [0.000, 5.000],  loss: 0.010026, mae: 1.391454, mean_q: 1.695444, mean_eps: 0.130270\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 162232/200000: episode: 481, duration: 17.278s, episode steps: 263, steps per second:  15, episode reward:  9.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 1.825 [0.000, 5.000],  loss: 0.011828, mae: 1.401833, mean_q: 1.707412, mean_eps: 0.129833\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 162522/200000: episode: 482, duration: 20.212s, episode steps: 290, steps per second:  14, episode reward:  9.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.034 [0.000, 5.000],  loss: 0.012123, mae: 1.397101, mean_q: 1.701669, mean_eps: 0.129373\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 163042/200000: episode: 483, duration: 33.830s, episode steps: 520, steps per second:  15, episode reward: 15.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.012079, mae: 1.382298, mean_q: 1.684487, mean_eps: 0.128697\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 163167/200000: episode: 484, duration: 9.001s, episode steps: 125, steps per second:  14, episode reward:  2.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.012079, mae: 1.403051, mean_q: 1.710368, mean_eps: 0.128160\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 163433/200000: episode: 485, duration: 17.359s, episode steps: 266, steps per second:  15, episode reward:  9.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.012348, mae: 1.397076, mean_q: 1.699432, mean_eps: 0.127833\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 163964/200000: episode: 486, duration: 36.045s, episode steps: 531, steps per second:  15, episode reward: 22.000, mean reward:  0.041 [ 0.000,  1.000], mean action: 3.288 [0.000, 5.000],  loss: 0.011625, mae: 1.388909, mean_q: 1.693200, mean_eps: 0.127170\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 164232/200000: episode: 487, duration: 18.029s, episode steps: 268, steps per second:  15, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.060 [0.000, 5.000],  loss: 0.012035, mae: 1.405077, mean_q: 1.713866, mean_eps: 0.126507\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 164965/200000: episode: 488, duration: 48.907s, episode steps: 733, steps per second:  15, episode reward: 22.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.660 [0.000, 5.000],  loss: 0.011617, mae: 1.413067, mean_q: 1.722452, mean_eps: 0.125670\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 165337/200000: episode: 489, duration: 24.794s, episode steps: 372, steps per second:  15, episode reward: 10.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.780 [0.000, 5.000],  loss: 0.011883, mae: 1.395893, mean_q: 1.702549, mean_eps: 0.124747\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 165728/200000: episode: 490, duration: 26.700s, episode steps: 391, steps per second:  15, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.174 [0.000, 5.000],  loss: 0.011337, mae: 1.408699, mean_q: 1.717203, mean_eps: 0.124113\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 165925/200000: episode: 491, duration: 13.816s, episode steps: 197, steps per second:  14, episode reward:  8.000, mean reward:  0.041 [ 0.000,  1.000], mean action: 3.360 [0.000, 5.000],  loss: 0.012422, mae: 1.408957, mean_q: 1.716346, mean_eps: 0.123623\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 166199/200000: episode: 492, duration: 19.272s, episode steps: 274, steps per second:  14, episode reward:  7.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.099 [0.000, 5.000],  loss: 0.010574, mae: 1.370544, mean_q: 1.670533, mean_eps: 0.123230\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 166481/200000: episode: 493, duration: 18.789s, episode steps: 282, steps per second:  15, episode reward:  8.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.021 [0.000, 5.000],  loss: 0.011362, mae: 1.401932, mean_q: 1.710577, mean_eps: 0.122767\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 166716/200000: episode: 494, duration: 15.618s, episode steps: 235, steps per second:  15, episode reward:  9.000, mean reward:  0.038 [ 0.000,  1.000], mean action: 2.800 [0.000, 5.000],  loss: 0.011651, mae: 1.418753, mean_q: 1.727728, mean_eps: 0.122337\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 167230/200000: episode: 495, duration: 35.184s, episode steps: 514, steps per second:  15, episode reward: 14.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.014 [0.000, 5.000],  loss: 0.012278, mae: 1.391827, mean_q: 1.695909, mean_eps: 0.121713\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 167510/200000: episode: 496, duration: 18.033s, episode steps: 280, steps per second:  16, episode reward:  9.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.586 [0.000, 5.000],  loss: 0.011019, mae: 1.403516, mean_q: 1.710125, mean_eps: 0.121050\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 168090/200000: episode: 497, duration: 38.779s, episode steps: 580, steps per second:  15, episode reward: 14.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.012873, mae: 1.390594, mean_q: 1.694587, mean_eps: 0.120333\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 168386/200000: episode: 498, duration: 18.998s, episode steps: 296, steps per second:  16, episode reward:  8.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.297 [0.000, 5.000],  loss: 0.013054, mae: 1.443134, mean_q: 1.759066, mean_eps: 0.119603\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 168675/200000: episode: 499, duration: 19.830s, episode steps: 289, steps per second:  15, episode reward:  7.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.789 [0.000, 5.000],  loss: 0.013021, mae: 1.388365, mean_q: 1.693102, mean_eps: 0.119117\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 168944/200000: episode: 500, duration: 18.154s, episode steps: 269, steps per second:  15, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.249 [0.000, 5.000],  loss: 0.011363, mae: 1.389555, mean_q: 1.695268, mean_eps: 0.118653\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 169176/200000: episode: 501, duration: 15.630s, episode steps: 232, steps per second:  15, episode reward:  8.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.629 [0.000, 5.000],  loss: 0.013821, mae: 1.388934, mean_q: 1.691361, mean_eps: 0.118237\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 169409/200000: episode: 502, duration: 15.712s, episode steps: 233, steps per second:  15, episode reward:  8.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.777 [0.000, 5.000],  loss: 0.011674, mae: 1.395562, mean_q: 1.700535, mean_eps: 0.117847\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 169661/200000: episode: 503, duration: 16.727s, episode steps: 252, steps per second:  15, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.937 [0.000, 5.000],  loss: 0.010754, mae: 1.403178, mean_q: 1.711231, mean_eps: 0.117440\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 170066/200000: episode: 504, duration: 27.059s, episode steps: 405, steps per second:  15, episode reward: 11.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.067 [0.000, 5.000],  loss: 0.012014, mae: 1.397527, mean_q: 1.703822, mean_eps: 0.116893\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 170613/200000: episode: 505, duration: 37.130s, episode steps: 547, steps per second:  15, episode reward: 15.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.199 [0.000, 5.000],  loss: 0.012848, mae: 1.421121, mean_q: 1.733824, mean_eps: 0.116100\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 170812/200000: episode: 506, duration: 13.503s, episode steps: 199, steps per second:  15, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.013566, mae: 1.450118, mean_q: 1.766728, mean_eps: 0.115480\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 171098/200000: episode: 507, duration: 18.990s, episode steps: 286, steps per second:  15, episode reward:  9.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.133 [0.000, 5.000],  loss: 0.014369, mae: 1.410261, mean_q: 1.719424, mean_eps: 0.115077\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 171370/200000: episode: 508, duration: 19.382s, episode steps: 272, steps per second:  14, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.743 [0.000, 5.000],  loss: 0.010399, mae: 1.389507, mean_q: 1.695041, mean_eps: 0.114610\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 171648/200000: episode: 509, duration: 18.328s, episode steps: 278, steps per second:  15, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.763 [0.000, 5.000],  loss: 0.012547, mae: 1.395126, mean_q: 1.701059, mean_eps: 0.114153\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 171894/200000: episode: 510, duration: 16.378s, episode steps: 246, steps per second:  15, episode reward:  8.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.711 [0.000, 5.000],  loss: 0.013420, mae: 1.421329, mean_q: 1.733259, mean_eps: 0.113717\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 172426/200000: episode: 511, duration: 36.340s, episode steps: 532, steps per second:  15, episode reward: 15.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.357 [0.000, 5.000],  loss: 0.011190, mae: 1.430146, mean_q: 1.744466, mean_eps: 0.113067\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 172728/200000: episode: 512, duration: 20.018s, episode steps: 302, steps per second:  15, episode reward:  8.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.106 [0.000, 5.000],  loss: 0.013624, mae: 1.415989, mean_q: 1.724347, mean_eps: 0.112373\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 173410/200000: episode: 513, duration: 46.808s, episode steps: 682, steps per second:  15, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.317 [0.000, 5.000],  loss: 0.011032, mae: 1.425029, mean_q: 1.735796, mean_eps: 0.111553\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 173630/200000: episode: 514, duration: 14.832s, episode steps: 220, steps per second:  15, episode reward:  7.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.227 [0.000, 5.000],  loss: 0.010578, mae: 1.364488, mean_q: 1.663512, mean_eps: 0.110800\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 174086/200000: episode: 515, duration: 30.473s, episode steps: 456, steps per second:  15, episode reward:  9.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.011134, mae: 1.404421, mean_q: 1.711315, mean_eps: 0.110237\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 174366/200000: episode: 516, duration: 18.629s, episode steps: 280, steps per second:  15, episode reward:  8.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.207 [0.000, 5.000],  loss: 0.012042, mae: 1.428804, mean_q: 1.739998, mean_eps: 0.109623\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 175025/200000: episode: 517, duration: 45.272s, episode steps: 659, steps per second:  15, episode reward: 19.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.168 [0.000, 5.000],  loss: 0.011855, mae: 1.410923, mean_q: 1.719079, mean_eps: 0.108840\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 175503/200000: episode: 518, duration: 31.394s, episode steps: 478, steps per second:  15, episode reward: 11.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.011864, mae: 1.432721, mean_q: 1.744925, mean_eps: 0.107893\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 175770/200000: episode: 519, duration: 17.384s, episode steps: 267, steps per second:  15, episode reward:  9.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.697 [0.000, 5.000],  loss: 0.012149, mae: 1.439526, mean_q: 1.752777, mean_eps: 0.107273\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 176005/200000: episode: 520, duration: 16.086s, episode steps: 235, steps per second:  15, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.723 [0.000, 5.000],  loss: 0.012408, mae: 1.406703, mean_q: 1.715048, mean_eps: 0.106853\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 176283/200000: episode: 521, duration: 19.163s, episode steps: 278, steps per second:  15, episode reward:  9.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: 0.012214, mae: 1.408267, mean_q: 1.714590, mean_eps: 0.106427\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 176564/200000: episode: 522, duration: 18.538s, episode steps: 281, steps per second:  15, episode reward:  9.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.783 [0.000, 5.000],  loss: 0.011105, mae: 1.431738, mean_q: 1.745571, mean_eps: 0.105963\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 176967/200000: episode: 523, duration: 27.035s, episode steps: 403, steps per second:  15, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.027 [0.000, 5.000],  loss: 0.012557, mae: 1.409155, mean_q: 1.717339, mean_eps: 0.105393\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 177259/200000: episode: 524, duration: 20.288s, episode steps: 292, steps per second:  14, episode reward:  8.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.911 [0.000, 5.000],  loss: 0.012938, mae: 1.424203, mean_q: 1.735714, mean_eps: 0.104813\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 177517/200000: episode: 525, duration: 17.126s, episode steps: 258, steps per second:  15, episode reward:  7.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.907 [0.000, 5.000],  loss: 0.010990, mae: 1.389654, mean_q: 1.694754, mean_eps: 0.104353\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 177914/200000: episode: 526, duration: 26.708s, episode steps: 397, steps per second:  15, episode reward: 10.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.209 [0.000, 5.000],  loss: 0.012159, mae: 1.403081, mean_q: 1.708498, mean_eps: 0.103807\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 178118/200000: episode: 527, duration: 13.824s, episode steps: 204, steps per second:  15, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.324 [0.000, 5.000],  loss: 0.011067, mae: 1.438079, mean_q: 1.750579, mean_eps: 0.103307\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 178344/200000: episode: 528, duration: 15.199s, episode steps: 226, steps per second:  15, episode reward:  4.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.012189, mae: 1.404352, mean_q: 1.709909, mean_eps: 0.102950\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 178608/200000: episode: 529, duration: 17.445s, episode steps: 264, steps per second:  15, episode reward:  7.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.845 [0.000, 5.000],  loss: 0.014911, mae: 1.426750, mean_q: 1.740385, mean_eps: 0.102543\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 178924/200000: episode: 530, duration: 22.276s, episode steps: 316, steps per second:  14, episode reward:  8.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.905 [0.000, 5.000],  loss: 0.013505, mae: 1.453905, mean_q: 1.772871, mean_eps: 0.102060\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 179333/200000: episode: 531, duration: 27.520s, episode steps: 409, steps per second:  15, episode reward: 10.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.010999, mae: 1.461036, mean_q: 1.780726, mean_eps: 0.101453\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 179596/200000: episode: 532, duration: 17.384s, episode steps: 263, steps per second:  15, episode reward:  9.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.012045, mae: 1.406662, mean_q: 1.713318, mean_eps: 0.100893\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 180080/200000: episode: 533, duration: 32.478s, episode steps: 484, steps per second:  15, episode reward: 14.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.006 [0.000, 5.000],  loss: 0.012547, mae: 1.421508, mean_q: 1.731783, mean_eps: 0.100284\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 180459/200000: episode: 534, duration: 25.491s, episode steps: 379, steps per second:  15, episode reward: 11.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.720 [0.000, 5.000],  loss: 0.012277, mae: 1.411766, mean_q: 1.720229, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 180729/200000: episode: 535, duration: 19.420s, episode steps: 270, steps per second:  14, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.970 [0.000, 5.000],  loss: 0.014230, mae: 1.420571, mean_q: 1.729914, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 181126/200000: episode: 536, duration: 26.675s, episode steps: 397, steps per second:  15, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.972 [0.000, 5.000],  loss: 0.011667, mae: 1.412163, mean_q: 1.719306, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 181378/200000: episode: 537, duration: 16.906s, episode steps: 252, steps per second:  15, episode reward:  7.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.306 [0.000, 5.000],  loss: 0.011374, mae: 1.392542, mean_q: 1.694755, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 181827/200000: episode: 538, duration: 30.080s, episode steps: 449, steps per second:  15, episode reward: 10.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.013233, mae: 1.438992, mean_q: 1.752232, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 182024/200000: episode: 539, duration: 13.806s, episode steps: 197, steps per second:  14, episode reward:  6.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.218 [0.000, 5.000],  loss: 0.011540, mae: 1.413488, mean_q: 1.722877, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 182607/200000: episode: 540, duration: 39.435s, episode steps: 583, steps per second:  15, episode reward: 17.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.671 [0.000, 5.000],  loss: 0.014418, mae: 1.441396, mean_q: 1.754265, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 182893/200000: episode: 541, duration: 18.771s, episode steps: 286, steps per second:  15, episode reward:  5.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.013688, mae: 1.449704, mean_q: 1.765041, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 183139/200000: episode: 542, duration: 16.691s, episode steps: 246, steps per second:  15, episode reward:  9.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 2.817 [0.000, 5.000],  loss: 0.012049, mae: 1.425529, mean_q: 1.738055, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 183717/200000: episode: 543, duration: 38.904s, episode steps: 578, steps per second:  15, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.728 [0.000, 5.000],  loss: 0.013412, mae: 1.444530, mean_q: 1.757938, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 183989/200000: episode: 544, duration: 19.619s, episode steps: 272, steps per second:  14, episode reward: 10.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.012558, mae: 1.436272, mean_q: 1.747598, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 184423/200000: episode: 545, duration: 28.703s, episode steps: 434, steps per second:  15, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.122 [0.000, 5.000],  loss: 0.012633, mae: 1.421903, mean_q: 1.731176, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 184652/200000: episode: 546, duration: 15.420s, episode steps: 229, steps per second:  15, episode reward:  4.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.011960, mae: 1.419341, mean_q: 1.728991, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 185069/200000: episode: 547, duration: 28.160s, episode steps: 417, steps per second:  15, episode reward: 10.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.011521, mae: 1.393203, mean_q: 1.696068, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 185336/200000: episode: 548, duration: 17.573s, episode steps: 267, steps per second:  15, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.012964, mae: 1.413632, mean_q: 1.720879, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 185566/200000: episode: 549, duration: 15.680s, episode steps: 230, steps per second:  15, episode reward:  7.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.952 [0.000, 5.000],  loss: 0.013413, mae: 1.445144, mean_q: 1.759737, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 185824/200000: episode: 550, duration: 18.651s, episode steps: 258, steps per second:  14, episode reward:  7.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.171 [0.000, 5.000],  loss: 0.012821, mae: 1.402995, mean_q: 1.710958, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 186304/200000: episode: 551, duration: 32.101s, episode steps: 480, steps per second:  15, episode reward: 17.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 2.040 [0.000, 5.000],  loss: 0.011975, mae: 1.410701, mean_q: 1.718178, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 186814/200000: episode: 552, duration: 35.375s, episode steps: 510, steps per second:  14, episode reward: 14.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.304 [0.000, 5.000],  loss: 0.012983, mae: 1.442197, mean_q: 1.760734, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 187035/200000: episode: 553, duration: 14.956s, episode steps: 221, steps per second:  15, episode reward:  7.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.186 [0.000, 5.000],  loss: 0.009654, mae: 1.416928, mean_q: 1.727175, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 187264/200000: episode: 554, duration: 15.577s, episode steps: 229, steps per second:  15, episode reward:  7.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.175 [0.000, 5.000],  loss: 0.010446, mae: 1.427452, mean_q: 1.741063, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 187764/200000: episode: 555, duration: 33.240s, episode steps: 500, steps per second:  15, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.608 [0.000, 5.000],  loss: 0.013094, mae: 1.412916, mean_q: 1.720891, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 188281/200000: episode: 556, duration: 36.044s, episode steps: 517, steps per second:  14, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.642 [0.000, 5.000],  loss: 0.012471, mae: 1.443318, mean_q: 1.758446, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 188884/200000: episode: 557, duration: 40.696s, episode steps: 603, steps per second:  15, episode reward: 19.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 1.650 [0.000, 5.000],  loss: 0.013176, mae: 1.409405, mean_q: 1.718065, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 189133/200000: episode: 558, duration: 17.184s, episode steps: 249, steps per second:  14, episode reward:  9.000, mean reward:  0.036 [ 0.000,  1.000], mean action: 3.124 [0.000, 5.000],  loss: 0.012968, mae: 1.432413, mean_q: 1.746238, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 189373/200000: episode: 559, duration: 15.972s, episode steps: 240, steps per second:  15, episode reward:  8.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.012877, mae: 1.444039, mean_q: 1.762039, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 190033/200000: episode: 560, duration: 44.954s, episode steps: 660, steps per second:  15, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.162 [0.000, 5.000],  loss: 0.013086, mae: 1.423948, mean_q: 1.736281, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 190317/200000: episode: 561, duration: 19.242s, episode steps: 284, steps per second:  15, episode reward:  8.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: 0.011293, mae: 1.434717, mean_q: 1.749150, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 190937/200000: episode: 562, duration: 41.479s, episode steps: 620, steps per second:  15, episode reward: 20.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.198 [0.000, 5.000],  loss: 0.011836, mae: 1.424373, mean_q: 1.737002, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 191059/200000: episode: 563, duration: 8.431s, episode steps: 122, steps per second:  14, episode reward:  1.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.336 [0.000, 5.000],  loss: 0.011559, mae: 1.458555, mean_q: 1.776386, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 191420/200000: episode: 564, duration: 23.716s, episode steps: 361, steps per second:  15, episode reward:  9.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.670 [0.000, 5.000],  loss: 0.012927, mae: 1.437474, mean_q: 1.749763, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 191953/200000: episode: 565, duration: 36.887s, episode steps: 533, steps per second:  14, episode reward: 13.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.929 [0.000, 5.000],  loss: 0.013560, mae: 1.430718, mean_q: 1.742058, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 192235/200000: episode: 566, duration: 18.346s, episode steps: 282, steps per second:  15, episode reward:  4.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.011840, mae: 1.416787, mean_q: 1.728404, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 192512/200000: episode: 567, duration: 20.098s, episode steps: 277, steps per second:  14, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.971 [0.000, 5.000],  loss: 0.013356, mae: 1.432749, mean_q: 1.746070, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 192738/200000: episode: 568, duration: 15.311s, episode steps: 226, steps per second:  15, episode reward:  6.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 1.788 [0.000, 5.000],  loss: 0.012593, mae: 1.395943, mean_q: 1.701996, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 193122/200000: episode: 569, duration: 26.013s, episode steps: 384, steps per second:  15, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.680 [0.000, 5.000],  loss: 0.011760, mae: 1.440159, mean_q: 1.755656, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 193388/200000: episode: 570, duration: 17.478s, episode steps: 266, steps per second:  15, episode reward: 10.000, mean reward:  0.038 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.013588, mae: 1.404893, mean_q: 1.708042, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 193614/200000: episode: 571, duration: 15.149s, episode steps: 226, steps per second:  15, episode reward:  9.000, mean reward:  0.040 [ 0.000,  1.000], mean action: 2.146 [0.000, 5.000],  loss: 0.011933, mae: 1.422809, mean_q: 1.733553, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 194000/200000: episode: 572, duration: 26.111s, episode steps: 386, steps per second:  15, episode reward: 11.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.192 [0.000, 5.000],  loss: 0.013267, mae: 1.438953, mean_q: 1.753191, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 194285/200000: episode: 573, duration: 19.055s, episode steps: 285, steps per second:  15, episode reward:  9.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.011 [0.000, 5.000],  loss: 0.010294, mae: 1.438472, mean_q: 1.752025, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 194840/200000: episode: 574, duration: 37.385s, episode steps: 555, steps per second:  15, episode reward: 14.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.822 [0.000, 5.000],  loss: 0.013107, mae: 1.418839, mean_q: 1.727889, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 195226/200000: episode: 575, duration: 26.570s, episode steps: 386, steps per second:  15, episode reward: 12.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.712 [0.000, 5.000],  loss: 0.010408, mae: 1.424478, mean_q: 1.736432, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 195587/200000: episode: 576, duration: 24.703s, episode steps: 361, steps per second:  15, episode reward:  9.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.119 [0.000, 5.000],  loss: 0.010932, mae: 1.433856, mean_q: 1.745667, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 195804/200000: episode: 577, duration: 14.872s, episode steps: 217, steps per second:  15, episode reward:  8.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 2.737 [0.000, 5.000],  loss: 0.011827, mae: 1.440871, mean_q: 1.755369, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 197111/200000: episode: 578, duration: 86.613s, episode steps: 1307, steps per second:  15, episode reward: 26.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.120 [0.000, 5.000],  loss: 0.011997, mae: 1.438867, mean_q: 1.752060, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 197316/200000: episode: 579, duration: 13.957s, episode steps: 205, steps per second:  15, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.624 [0.000, 5.000],  loss: 0.013768, mae: 1.455125, mean_q: 1.773692, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 197522/200000: episode: 580, duration: 14.132s, episode steps: 206, steps per second:  15, episode reward:  5.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.403 [0.000, 5.000],  loss: 0.010872, mae: 1.439770, mean_q: 1.754200, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 198197/200000: episode: 581, duration: 46.410s, episode steps: 675, steps per second:  15, episode reward: 16.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.738 [0.000, 5.000],  loss: 0.012107, mae: 1.427771, mean_q: 1.739155, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 198441/200000: episode: 582, duration: 16.028s, episode steps: 244, steps per second:  15, episode reward:  9.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 2.893 [0.000, 5.000],  loss: 0.010340, mae: 1.440742, mean_q: 1.757983, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 199397/200000: episode: 583, duration: 64.110s, episode steps: 956, steps per second:  15, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.238 [0.000, 5.000],  loss: 0.012660, mae: 1.438549, mean_q: 1.753052, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 199798/200000: episode: 584, duration: 26.817s, episode steps: 401, steps per second:  15, episode reward: 10.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.239 [0.000, 5.000],  loss: 0.012648, mae: 1.422884, mean_q: 1.732503, mean_eps: 0.100000\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv3/dqn_SpaceInvaders-v0_weights.h5f\n",
            "done, took 11184.945 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7cc25c8d3ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "episode_rewards = np.load('logs/episode_rewards_cutv3.npy')\n",
        "\n",
        "plt.plot(episode_rewards)\n",
        "plt.xlabel('Episodio')\n",
        "plt.ylabel('Reward total')\n",
        "plt.title('Evolución del entrenamiento')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c4HweY_0J43Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "0cbd6e89-2376-4aa5-83ec-42c76361deaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjYAAAHHCAYAAACskBIUAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAzMBJREFUeJzsnXecF8X9/1/7KVe5OzpIr0oREFEUFSlKO2OiaOxG/EaN+dmiUSNJLNhINDEmhliisRtjNxpEEARFKdIRBQFBeufu4I67T9vfH5/bz2dmd3Z3dj/7acf7+Xgon/t8dmdnZ2dn3vNuo6iqqoIgCIIgCKIJ4Mt2BQiCIAiCILyCBBuCIAiCIJoMJNgQBEEQBNFkIMGGIAiCIIgmAwk2BEEQBEE0GUiwIQiCIAiiyUCCDUEQBEEQTQYSbAiCIAiCaDKQYEMQRwn/+te/8PTTT2e7GgRBEGmFBBuCyACKouC+++5LW/kjR47EyJEjTX9/8803ccstt+Dkk09OWx1YXnjhBSiKgs2bNzs+97777oOiKN5XijBg128IIh8hwYY4atAmW7P/Fi5cmO0qpoX169fj+uuvxxtvvIETTzwx29XJaR5++GG899572a5Gk+LLL7/Efffdh6qqqmxXhThKCGS7AgSRae6//350797d8H2vXr2yUBtvmDlzpulvK1euxPPPP48JEyZksEb5ycMPP4wLL7wQ5513XrarkhGs+o1XfPnll5gyZQomTZqE5s2bp/16BEGCDXHUMWHCBJx00knZroanFBQUmP524YUXZrAmRw+1tbUoLS3NdjVSwqrfEES+QqYogmAIh8No2bIlrr76asNvNTU1KCoqwu233574bs+ePfj5z3+Odu3aoaioCIMGDcKLL75oe51JkyahW7duhu/N/EteeeUVDB06FCUlJWjRogXOPPNMbrUt8pWQqdvmzZuhKAr+9Kc/4ZlnnkHPnj1RWFiIk08+GV999ZXtfQDAmjVrMHr0aBQXF6NTp0548MEHEYvFhMd+9NFHGD58OEpLS1FWVoZzzjkHa9askbqOiEWLFmH8+PGoqKhASUkJRowYgS+++II7RmvTDRs2JLQGFRUVuPrqq1FXV5c4TlEU1NbW4sUXX0yYJydNmsSV8c033+Cyyy5DixYtcMYZZyTOfeWVVzBkyBAUFxejZcuWuOSSS7B161auHiNHjsTxxx+Pb775BqNGjUJJSQk6duyIRx55hDsuFArhnnvuwZAhQ1BRUYHS0lIMHz4cn376KXcc++ymTZuGHj16oKSkBGPHjsXWrVuhqioeeOABdOrUCcXFxfjJT36CAwcOGOqk7zcNDQ2499570atXLxQWFqJz586488470dDQwB2nKApuvPFGvPfeezj++ONRWFiI/v37Y8aMGVzb33HHHQCA7t27J9pV872KRCJ44IEHEv2uW7du+O1vf2u4FkE4gTQ2xFFHdXU19u3bx32nKApatWqFYDCI888/H++88w6efvppbkX73nvvoaGhAZdccgkA4MiRIxg5ciQ2bNiAG2+8Ed27d8ebb76JSZMmoaqqCrfccosn9Z0yZQruu+8+nHbaabj//vtRUFCARYsWYc6cORg7dqzwHKd1e+2113Do0CH84he/gKIoeOSRRzBx4kR8//33CAaDpnXbtWsXRo0ahUgkgrvuugulpaV45plnUFxcbDj25ZdfxlVXXYVx48bhj3/8I+rq6vDkk0/ijDPOwPLly4WCnhVz5szBhAkTMGTIENx7773w+Xx4/vnnMXr0aHz++ecYOnQod/xFF12E7t27Y+rUqVi2bBmeffZZtG3bFn/84x8T9bvmmmswdOhQXHfddQCAnj17cmX89Kc/Re/evfHwww9DVVUAwEMPPYS7774bF110Ea655hrs3bsXTzzxBM4880wsX76cM78cPHgQ48ePx8SJE3HRRRfhrbfewm9+8xsMGDAgYSqsqanBs88+i0svvRTXXnstDh06hOeeew7jxo3D4sWLccIJJ3B1evXVVxEKhXDTTTfhwIEDeOSRR3DRRRdh9OjRmDt3Ln7zm99gw4YNeOKJJ3D77bfjX//6l2mbxmIx/PjHP8b8+fNx3XXXoW/fvli9ejX+8pe/4LvvvjP4H82fPx/vvPMO/t//+38oKyvD3/72N1xwwQXYsmULWrVqhYkTJ+K7777Dv//9b/zlL39B69atAQBt2rQBAFxzzTV48cUXceGFF+LXv/41Fi1ahKlTp+Lbb7/Fu+++K9ELCEKAShBHCc8//7wKQPhfYWFh4riPP/5YBaB+8MEH3PmVlZVqjx49En8//vjjKgD1lVdeSXwXCoXUYcOGqc2aNVNramoS3wNQ77333sTfV111ldq1a1dDHe+9916VfS3Xr1+v+nw+9fzzz1ej0Sh3bCwWS3weMWKEOmLECMd127RpkwpAbdWqlXrgwIHEse+//76wDfT86le/UgGoixYtSny3Z88etaKiQgWgbtq0SVVVVT106JDavHlz9dprr+XO37Vrl1pRUcF9r28DEbFYTO3du7c6btw4rh3q6urU7t27q2PGjDGU93//939cGeeff77aqlUr7rvS0lL1qquuMlxPK+PSSy/lvt+8ebPq9/vVhx56iPt+9erVaiAQ4L4fMWKECkB96aWXEt81NDSo7du3Vy+44ILEd5FIRG1oaODKO3jwoNquXTvuHrRn16ZNG7Wqqirx/eTJk1UA6qBBg9RwOJz4/tJLL1ULCgrU+vp6rk5sv3n55ZdVn8+nfv7559z1n3rqKRWA+sUXXyS+A6AWFBSoGzZsSHy3cuVKFYD6xBNPJL579NFHub6gsWLFChWAes0113Df33777SoAdc6cOSpBuIFMUcRRx7Rp0zBr1izuv48++ijx++jRo9G6dWv85z//SXx38OBBzJo1CxdffHHiu+nTp6N9+/a49NJLE98Fg0HcfPPNOHz4MObNm5dyXd977z3EYjHcc8898Pn419UqJNpp3S6++GK0aNEi8ffw4cMBAN9//71l/aZPn45TTz2V0460adMGl19+OXfcrFmzUFVVhUsvvRT79u1L/Of3+3HKKacYzCx2rFixAuvXr8dll12G/fv3J8qrra3FWWedhc8++8xgDrv++uu5v4cPH479+/ejpqZG+rr6Mt555x3EYjFcdNFF3H21b98evXv3NtxXs2bNcMUVVyT+LigowNChQ7l29vv9CU1hLBbDgQMHEIlEcNJJJ2HZsmWGOv30pz9FRUVF4u9TTjkFAHDFFVcgEAhw34dCIWzfvt30/t5880307dsXffr04e5n9OjRAGC4n7PPPpvTag0cOBDl5eW2/QaI9x0AuO2227jvf/3rXwMA/ve//9mWQRAiyBRFHHUMHTrU0nk4EAjgggsuwGuvvYaGhgYUFhbinXfeQTgc5gSbH374Ab179zYIHH379k38niobN26Ez+dDv379HJ3ntG5dunTh/taEnIMHD9peR5tIWY477jju7/Xr1wNAYoLUU15ebnkdPVp5V111lekx1dXVnLBmdY+y19dH061fvx6qqqJ3797C4/VmvE6dOhkE0hYtWmDVqlXcdy+++CL+/Oc/Y+3atQiHw6bXB4z3pQk5nTt3Fn5v9UzXr1+Pb7/9NmEq0rNnzx7LawPx+7HrN0C87/h8PkM0Yvv27dG8eXNP3h/i6IQEG4IQcMkll+Dpp5/GRx99hPPOOw9vvPEG+vTpg0GDBnlSvpm2JRqNelK+U/x+v/B7tdGPJFU07cnLL7+M9u3bG35nNQtOynv00UcNPicazZo14/724h71vkOxWAyKouCjjz4Slu+mDq+88gomTZqE8847D3fccQfatm0Lv9+PqVOnYuPGjYZzzcp0c7+xWAwDBgzAY489JvxdLyx50aaUjJHwGhJsCELAmWeeiWOOOQb/+c9/cMYZZ2DOnDn43e9+xx3TtWtXrFq1CrFYjNOMrF27NvG7GS1atBAmLNOvUnv27IlYLIZvvvnGdAIXkUrdnNC1a9eE9oRl3bp13N+auaJt27Y4++yzU76uVl55ebkn5Wk4nWR79uwJVVXRvXt3HHvssZ7U4a233kKPHj3wzjvvcPW59957PSnfip49e2LlypU466yzPBM4zMrp2rUrYrEY1q9fn9AkAsDu3btRVVXlWR8ljj7Ix4YgBPh8Plx44YX44IMP8PLLLyMSiXBmKACorKzErl27OF+cSCSCJ554As2aNcOIESNMy+/Zsyeqq6s5E8TOnTsNkSDnnXcefD4f7r//foPPiNWqOJW6OaGyshILFy7E4sWLE9/t3bsXr776KnfcuHHjUF5ejocffpgzrbDnOGHIkCHo2bMn/vSnP+Hw4cMpl6dRWlrqKEPuxIkT4ff7MWXKFMPzUFUV+/fvd1wHTQvClrdo0SIsWLDAcVlOueiii7B9+3b885//NPx25MgR1NbWOi5Ty/Wjb9fKykoAwOOPP859r2mLzjnnHMfXIgiANDbEUchHH32U0FywnHbaaejRo0fi74svvhhPPPEE7r33XgwYMIBbVQLAddddh6effhqTJk3C0qVL0a1bN7z11lv44osv8Pjjj6OsrMy0Dpdccgl+85vf4Pzzz8fNN9+cCH0+9thjOQfRXr164Xe/+x0eeOABDB8+HBMnTkRhYSG++uordOjQAVOnThWWn0rdnHDnnXfi5Zdfxvjx43HLLbckwr01jZFGeXk5nnzySVx55ZU48cQTcckll6BNmzbYsmUL/ve//+H000/H3//+d+nr+nw+PPvss5gwYQL69++Pq6++Gh07dsT27dvx6aefory8HB988IHj+xkyZAg++eQTPPbYY+jQoQO6d+8u9CHS6NmzJx588EFMnjwZmzdvxnnnnYeysjJs2rQJ7777Lq677jou75EMP/rRj/DOO+/g/PPPxznnnINNmzbhqaeeQr9+/YRCnJdceeWVeOONN3D99dfj008/xemnn45oNIq1a9fijTfewMcff+w4ueWQIUMAAL/73e9wySWXIBgM4txzz8WgQYNw1VVX4ZlnnkFVVRVGjBiBxYsX48UXX8R5552HUaNGpeMWiaOBLEVjEUTGsQr3BqA+//zz3PGxWEzt3LmzCkB98MEHhWXu3r1bvfrqq9XWrVurBQUF6oABAwzlqKox3FtVVXXmzJnq8ccfrxYUFKjHHXec+sorr5iGOv/rX/9SBw8erBYWFqotWrRQR4wYoc6aNSvxuz5sV7ZuWsjwo48+KlVnEatWrVJHjBihFhUVqR07dlQfeOAB9bnnnhOG+H766afquHHj1IqKCrWoqEjt2bOnOmnSJHXJkiWJY2TCvTWWL1+uTpw4UW3VqpVaWFiodu3aVb3ooovU2bNnG8rbu3cvd67WH9g6rl27Vj3zzDPV4uJiFUAi9NusDI23335bPeOMM9TS0lK1tLRU7dOnj3rDDTeo69atSxwzYsQItX///oZz9aH/sVhMffjhh9WuXbuqhYWF6uDBg9UPP/zQcJzZs/v0009VAOqbb74pvN+vvvqKq5O+34RCIfWPf/yj2r9//0R/GzJkiDplyhS1uro6cRwA9YYbbjDcT9euXQ0h8w888IDasWNH1efzcW0eDofVKVOmqN27d1eDwaDauXNndfLkyVxIOkE4RVFVj7wDCYIgCIIgsgz52BAEQRAE0WQgwYYgCIIgiCYDCTYEQRAEQTQZSLAhCIIgCKLJQIINQRAEQRBNBhJsCIIgCIJoMjT5BH2xWAw7duxAWVkZ7UlCEARBEHmCqqo4dOgQOnToYNjQ14omL9js2LHDsHEbQRAEQRD5wdatW9GpUyfp45u8YKOljt+6dSvKy8s9KzccDmPmzJkYO3YsgsGgZ+U2dajdnENt5hxqM3dQuzmH2swdMu1WU1ODzp07O94CpskLNpr5qby83HPBpqSkBOXl5dSZHUDt5hxqM+dQm7mD2s051GbucNJuTt1Isuo8/OSTT2LgwIEJoWPYsGH46KOPEr+PHDkSiqJw/11//fVZrDFBEARBELlMVjU2nTp1wh/+8Af07t0bqqrixRdfxE9+8hMsX74c/fv3BwBce+21uP/++xPnlJSUZKu6BEEQBEHkOFkVbM4991zu74ceeghPPvkkFi5cmBBsSkpK0L59+2xUjyAIgiCIPCNnfGyi0SjefPNN1NbWYtiwYYnvX331Vbzyyito3749zj33XNx9992WWpuGhgY0NDQk/q6pqQEQt+eFw2HP6quV5WWZRwPUbs6hNnMOtZk7qN2cQ23mDpl2c9umiqqqqqszPWL16tUYNmwY6uvr0axZM7z22muorKwEADzzzDPo2rUrOnTogFWrVuE3v/kNhg4dinfeece0vPvuuw9TpkwxfP/aa6+RGYsgCIIg8oS6ujpcdtllqK6udhT8k3XBJhQKYcuWLaiursZbb72FZ599FvPmzUO/fv0Mx86ZMwdnnXUWNmzYgJ49ewrLE2lsOnfujH379nkeFTVr1iyMGTOGPOEdQO3mHGoz51CbuYPazTnUZu6Qabeamhq0bt3asWCTdVNUQUEBevXqBQAYMmQIvvrqK/z1r3/F008/bTj2lFNOAQBLwaawsBCFhYWG74PBYFo6XbrKbepQuzmH2sw51GbuoHZzDrWZO6zazW175txeUbFYjNO4sKxYsQIAcMwxx2SwRgRBEARB5AtZ1dhMnjwZEyZMQJcuXXDo0CG89tprmDt3Lj7++GNs3Lgx4W/TqlUrrFq1CrfeeivOPPNMDBw4MJvVJgiCIAgiR8mqYLNnzx787Gc/w86dO1FRUYGBAwfi448/xpgxY7B161Z88sknePzxx1FbW4vOnTvjggsuwO9///tsVpkgCIIgiBwmq4LNc889Z/pb586dMW/evAzWhiAIgiCIfCfnfGwIgiAIgiDcQoINQWSQUCSGcDSW7WoQBEE0WUiwIYgMEYnGMGzqbAz/46eIxbKaPoogCKLJkvU8NgRxtLDnUAP214YAAHXhKJoV0utHEAThNaSxIQiCIAiiyUCCDUEQBEEQTQYSbAgiC2R5izaCIIgmCwk2BEEQBEE0GUiwIYgsoChKtqtAEATRJCHBhiCyAJmiCIIg0gMJNgRBEARBNBlIsCGILECmKIIgiPRAgg1BZAEyRREEQaQHEmwIIkOwShoSawiCINIDCTYEkSFISUMQBJF+SLAhiCxAQg5BEER6IMGGILIBCTYEQRBpgQQbgsgQvI8NSTYEQRDpgAQbgsgQZH4iCIJIPyTYEEQWICGHIAgiPZBgQxAZgsK9CYIg0g8JNgSRBShBH0EQRHogwYYgCIIgiCYDCTYEkSFYJQ3pawiCINIDCTYEkSFYYYYsUQRBEOmBBBuCyAKUx4YgCCI9kGBDEBmCHIYJgiDSDwk2BJEhOLmGZByCIIi0QIINQWQBkmsIgiDSAwk2BJEFyCpFEASRHkiwIYgMQcIMQRBE+iHBhiAyBBsJRVFRBEEQ6YEEG4LIAqS9IQiCSA8k2BBEhqDMwwRBEOmHBBuCyBAkzBAEQaQfEmwIIgtQsj6CIIj0QIINQWQIVpghuYYgCCI9kGBDEBmCZBmCIIj0k1XB5sknn8TAgQNRXl6O8vJyDBs2DB999FHi9/r6etxwww1o1aoVmjVrhgsuuAC7d+/OYo0JgiAIgshlsirYdOrUCX/4wx+wdOlSLFmyBKNHj8ZPfvITrFmzBgBw66234oMPPsCbb76JefPmYceOHZg4cWI2q0wQruGiokh9QxAEkRYC2bz4ueeey/390EMP4cknn8TChQvRqVMnPPfcc3jttdcwevRoAMDzzz+Pvn37YuHChTj11FOzUWWCSAFK0EcQBJFusirYsESjUbz55puora3FsGHDsHTpUoTDYZx99tmJY/r06YMuXbpgwYIFpoJNQ0MDGhoaEn/X1NQAAMLhMMLhsGf11cryssyjgaO53ULhSOJzOByRboOjuc3cQm3mDmo351CbuUOm3dy2adYFm9WrV2PYsGGor69Hs2bN8O6776Jfv35YsWIFCgoK0Lx5c+74du3aYdeuXablTZ06FVOmTDF8P3PmTJSUlHhdfcyaNcvzMo8GjsZ221UHaK/c3Llz0abY2flHY5ulCrWZO6jdnENt5g6rdqurq3NVZtYFm+OOOw4rVqxAdXU13nrrLVx11VWYN2+e6/ImT56M2267LfF3TU0NOnfujLFjx6K8vNyLKgOIS5KzZs3CmDFjEAwGPSu3qXM0t9v63YcxdeWXAIARI0egW6tSqfOO5jZzC7WZO6jdnENt5g6ZdtMsLk7JumBTUFCAXr16AQCGDBmCr776Cn/9619x8cUXIxQKoaqqitPa7N69G+3btzctr7CwEIWFhYbvg8FgWjpduspt6hyN7eYPJF83vz/g+P6PxjZLFWozd1C7OYfazB1W7ea2PXMuj00sFkNDQwOGDBmCYDCI2bNnJ35bt24dtmzZgmHDhmWxhgRBEARB5CpZ1dhMnjwZEyZMQJcuXXDo0CG89tprmDt3Lj7++GNUVFTg5z//OW677Ta0bNkS5eXluOmmmzBs2DCKiCLyEpWLiiIIgiDSQVYFmz179uBnP/sZdu7ciYqKCgwcOBAff/wxxowZAwD4y1/+Ap/PhwsuuAANDQ0YN24c/vGPf2SzygThGspjQxAEkX6yKtg899xzlr8XFRVh2rRpmDZtWoZqRBCZgiQbgiCIdJBzPjYE0VQhLQ1BEET6IcGGIDIE52NDQg5BEERaIMGGILIAyTUEQRDpgQQbgsgQ5DxMEASRfkiwIQiCIAiiyUCCDUFkAdrdmyAIIj2QYEMQGYJMUQRBEOmHBBuCyBAUFUUQBJF+SLAhiAxBwgxBEET6IcGGILIA+dgQBEGkBxJsCCJDsKIMaW8IgiDSAwk2BJEhVJJmCIIg0g4JNgRBEARBNBlIsCGIDEGmKIIgiPRDgg1BZAgujw05DxMEQaQFEmwIIguQxoYgCCI9kGBDEBmDpBmCIIh0Q4INQWQI3hRFEARBpAMSbAgiC1DoN0EQRHogwYYgMoRq8pkgCILwDhJsCCJDkJKGIAgi/ZBgQxAZgjU/kZBDEASRHkiwIYisQJINQRBEOiDBhiAyBGUeJgiCSD8k2BBEhiBhhiAIIv2QYEMQWYBkHIIgiPRAgg1BZAh2fyjS3hAEQaQHEmwIIlOQMEMQBJF2SLAhiCxAmYcJgiDSAwk2BJEhKPMwQRBE+iHBhiAyBLcJJkk2BEEQaYEEG8ITojGaqQmCIJo6+TDWk2BDpMzWA3UYNGUmpk7/NttVyWm4qCgyRhEEkWds3leLgfd9jEc/XpvtqlhCgg2RMk/MWY/DDRE8/dn32a5KTqOSkw1BEHnMn2auQ20oimmfbsx2VSwhwYYgMgTJNQRBEOmHBBuCIAiCIJoMJNgQRIZgc9dQVBRBEER6IMGGSBkFSrarkBfwpiiSbAiCINIBCTYEkQVIY0MQBJEesirYTJ06FSeffDLKysrQtm1bnHfeeVi3bh13zMiRI6EoCvff9ddfn6UaE0QKkDBDEASRdrIq2MybNw833HADFi5ciFmzZiEcDmPs2LGora3ljrv22muxc+fOxH+PPPJIlmpMEO7h89gQBEEQ6SCQzYvPmDGD+/uFF15A27ZtsXTpUpx55pmJ70tKStC+fftMV4+QRCEXG8fQJpjWRGMqDtWH0bykINtVIQiikXwZtbIq2Oiprq4GALRs2ZL7/tVXX8Urr7yC9u3b49xzz8Xdd9+NkpISYRkNDQ1oaGhI/F1TUwMACIfDCIfDntVVK8vLMvOVWCyW+GzXHkdzu4Uj0cTnSCQi3QZHY5td8a+vsGjTQUy/8TT0btfM8flHY5t5AbWbc46mNlMdjPV2yLSb22soao4sHWOxGH784x+jqqoK8+fPT3z/zDPPoGvXrujQoQNWrVqF3/zmNxg6dCjeeecdYTn33XcfpkyZYvj+tddeMxWGiNR4faMPC/bErZp/HRbJcm1yl68PKPjnOj8A4Bd9oujXIidevZzklgXxNdfIY2I4v1vM5miCIDLBC9/5sHx/5sb6uro6XHbZZaiurkZ5ebn0eTkj2Pzyl7/ERx99hPnz56NTp06mx82ZMwdnnXUWNmzYgJ49exp+F2lsOnfujH379jlqGDvC4TBmzZqFMWPGIBgMelZuPvK799bgjaXbAQDrHxhreezR3G6z1+7B9a+uAAD888rBGHlsG6nzjsY26333TADAz0/virvGH+f4/KOxzbyA2s05R1Ob3fz6Sny0ZjcA+7HeDpl2q6mpQevWrR0LNjlhirrxxhvx4Ycf4rPPPrMUagDglFNOAQBTwaawsBCFhYWG74PBYFo6XbrKzSf8/qQPumxbHI3t5vcHmM9+x/d/dLaZ83ZiORrbzAuo3ZxzNLSZz+d8rLfDqt3cXiOrgo2qqrjpppvw7rvvYu7cuejevbvtOStWrAAAHHPMMWmuHUF4C2Uedg75pRME4ZSsCjY33HADXnvtNbz//vsoKyvDrl27AAAVFRUoLi7Gxo0b8dprr6GyshKtWrXCqlWrcOutt+LMM8/EwIEDs1l1giAyAUk2BEE4JKuCzZNPPgkgnoSP5fnnn8ekSZNQUFCATz75BI8//jhqa2vRuXNnXHDBBfj973+fhdoSRGpwWyqQxkYK2q6DIAinZN0UZUXnzp0xb968DNWGcA9NPjKw3Z3kGoIgiPRAe0URRMZgfWxItJHBRzIzQeQM+bJ5Lwk2BEHkLJTVmiAIp5BgQxAZgkxRBEEQ6YcEGyJlaFUtBzkPO4echwmCcAoJNgSRFUiykYGEZoIgnEKCDUFkCNLSOIfkGoLIHfJlDCPBhiAyhArKPOwYUtkQBOEQEmyIlKGpxzkk18hBfYsgCKeQYEMQGYK0NARBEOmHBBuCyBAUFeUcH5miCCJnyJdxiwQbgsgC+ZLBM9uQXEMQhFNIsCFs2VF1BHPX7THdBoAmHznY9suXlQ9BEES+QYINYctpf5iDSc9/hbnr9ma7KsRRBsnMBEE4hQQbQpqF3+/PdhXyGtpSwTmkDSQIwikk2BBEFqDdvc1h20YhyYYgCIeQYENIYzYV034+cpDDsBwk8xEEkQok2BBEhqAJW44Yp7HJYkUIguDIl8UZCTaENGQ+8Q5qSnNi1DYEQaQACTYEkSF452Gavc1gNTaUoI8gcod8WZCRYENIY9apae6RgzIPy8GZorJYD4Ig8hMSbAiCyCnIFEUQRCoEsl0BIn+g+SY1KPOwHOQ8TGSTmvow3l66DW3LihCJxfCTEzpmu0qEQ0iwIYgMoZp8JnhiMdYURZINkVkmv70a/1u9M/F3n/blOK59WRZrRDiFTFGENKY+NpmtRpOAIszMYU1RpLEhMs2sb3dzf287WJelmhBuIcGGIDIFyTJSxEjoIwgiBUiwIYgMwYZ409RtDgk2BEGkAgk2hDSUeyU1VHKykSIWYz6TkENkGeqCSfKlKUiwIVKGNip0DgmJ5sQoeozIJqrln0c1+fI+kmBDSJMvnTpXoeaTgxNsslgPgiDyExJsCE+haB9zuC0VqJlMYduGTFEEQThFKo9NixYtpM0NBw4cSKlCRH6jqhSiKwNN1+aQKYrIJnozMS3W8g8pwebxxx9PczWIpkJMVeGjzDZCuKgoGitNiXq4p8Jby7Yjqiq44tSunpVJuOPNJVvREInRsyDSjpRgc9VVV6W7HkQeILNyofnaHBJm5GDlmlgKQk4kBkx+dw0AYPzx7dG6WWGqVSNc0hCJ4o63VgEAJhzfHq3oWRBpJKUtFerr6xEKhbjvysvLU6oQkd/Q5C0HRUWZo3rkPBxlTj4SiqZQEpEqrBauLhRFqyzWxSn0puYfjp2Ha2trceONN6Jt27YoLS1FixYtuP+IpovMC04TtjlcGhtqJlNiHjlZUxPnDvm05xe9m/mPY8HmzjvvxJw5c/Dkk0+isLAQzz77LKZMmYIOHTrgpZdeSkcdiRzBdK8oxf4YAlzjUDOZw67uU4qKoj2nCA+gMY0lPxrDsSnqgw8+wEsvvYSRI0fi6quvxvDhw9GrVy907doVr776Ki6//PJ01JPIE2gQIFLFqzw27LmURJIgjh4ca2wOHDiAHj16AIj702jh3WeccQY+++wzb2tH5BQyZiYyRZnDtQxJgKaoHtnsOMHGdSmEF1BEIJFJHAs2PXr0wKZNmwAAffr0wRtvvAEgrslp3ry5o7KmTp2Kk08+GWVlZWjbti3OO+88rFu3jjumvr4eN9xwA1q1aoVmzZrhggsuwO7du01KJLINDVrmcAn6sleNnIfV2KQS+U19MXfIp2dhrGoeVZ4A4EKwufrqq7Fy5UoAwF133YVp06ahqKgIt956K+644w5HZc2bNw833HADFi5ciFmzZiEcDmPs2LGora1NHHPrrbfigw8+wJtvvol58+Zhx44dmDhxotNqEx5g6mPDrIcpU6w5lOhLDt4U5ZHGhlQ2WSWfez69tknypS0c+9jceuutic9nn3021q5di6VLl6JXr14YOHCgo7JmzJjB/f3CCy+gbdu2WLp0Kc4880xUV1fjueeew2uvvYbRo0cDAJ5//nn07dsXCxcuxKmnnuq0+kSayZN+n3XyZYDIBl5lHuZNUSTZZBPVI2GVIGRwLNi89NJLuPjii1FYGE+w1LVrV3Tt2hWhUAgvvfQSfvazn7muTHV1NQCgZcuWAIClS5ciHA7j7LPPThzTp08fdOnSBQsWLBAKNg0NDWhoaEj8XVNTAwAIh8MIh8Ou66ZHK8vLMnOdaCwmvN9YLJkjJBwKI+w3L+NobDeNSDTKfZZtg6OtzULhSOKzk3ZiCYfDnFAUCocRtuqYLmkIR/H797/BqOPaoHJAe8/LzzTp6mtseeFIJKf7sl6zatcH8/n9/HLjfryxZDvu/lEftCotsD0+psYSn1O9X5l2c3sNx4LN1VdfjfHjx6Nt27bc94cOHcLVV1/tWrCJxWL41a9+hdNPPx3HH388AGDXrl0oKCgw+O60a9cOu3btEpYzdepUTJkyxfD9zJkzUVJS4qpuVsyaNcvzMnOPeDfZsmULpk/fbPh102YfNKvmzFmzUCLRq46OduNZs1MBEJ9c16xZg+kHvnZ0/tHSZhtqAK3Pbdz4PaZP3+CqHHZ6mj1nDlqmIdntnB0K3v/Bj/dW7gS2LvP+AlnC675WFwG0Zzr307loU+xp8Z6iqn6w7ubLli1D7Ad7LVM+vp+3LIg/k127duBnvWM2RwN79iTH+unTp3tSB6t2q6urc1WmY8FGVVVh6OS2bdtQUVHhqhIAcMMNN+Drr7/G/PnzXZcBAJMnT8Ztt92W+LumpgadO3fG2LFjPc2KHA6HMWvWLIwZMwbBYNCzcnORWxbMBAB06dIFlZX9DL+v+Ggd5u38AQBw1tlno0WJueR/NLWbnj0LfsC7m+PO8f369UPlMLk9c462Nlu06QCeWLMEANC9Rw9UjjvWcRnhcBhvfpgcMEeNGoWOzb2fTVfNWAf8EO/7lZWVnpefadLV16qPhDH5q08BACNHjkTXVt4vMr3iVwtnclLx4MGDMeF4c21cPr+f2tiulLZEZeVQ2+PfO7AMaw7uA5B6f5dpN83i4hRpwWbw4MFQFAWKouCss85CIJA8NRqNYtOmTRg/fryrStx444348MMP8dlnn6FTp06J79u3b49QKISqqipOa7N79260by/uaIWFhQkzGUswGExLp0tXubmIz+cT3qvPl/RBDwTk2uNoajcNn8/PfXZ6/0dLmylMOymK4vqe2fWn3x9IS9uxfb8pPRuv+1ognJQU/IH0PIt0EZCsbz6/nz5FPLbrURTv+7tVu7m9hrRgc9555wEAVqxYgXHjxqFZs2aJ3woKCtCtWzdccMEFji6uqipuuukmvPvuu5g7dy66d+/O/T5kyBAEg0HMnj07Ufa6deuwZcsWDBs2zNG1iNSRceSkyB9zvNoDqanjmfMwNXJOkm9jRJ5V1x1NzLdeWrC59957AQDdunXDxRdfjKKiopQvfsMNN+C1117D+++/j7KysoTfTEVFBYqLi1FRUYGf//znuO2229CyZUuUl5fjpptuwrBhwygiKoeg/CzOybfBPZPEPOpP7LnpSkNAj1EOaqfcponJNc59bK666ioA8Yilb7/9FgDQv39/DB482PHFn3zySQBxmyvL888/j0mTJgEA/vKXv8Dn8+GCCy5AQ0MDxo0bh3/84x+Or0V4gXh0YsM3KY8NkSp8gr4U8th4tJkmkTqqyedcRN9XKDw9/3As2OzZsweXXHIJ5s6dm/B7qaqqwqhRo/D666+jTZs20mXJrFqLioowbdo0TJs2zWlVCY8xe1xqPo1aWYQmVznUNOSxoabPLqShJDKJ48zDN910Ew4dOoQ1a9bgwIEDOHDgAL7++mvU1NTg5ptvTkcdiTyChi85aJw3J2ofdSoFv+VUmkxRaSm16eHR9l9Emmhqmbkda2xmzJiBTz75BH379k18169fP0ybNg1jx471tHJEbmGusaEN7mTgNgKkKdGUdJiiUtlzikgd3iyYXw8jz6qbVvLl2TnW2MRiMWEIVjAYRCzm0VKLyCsy4aTZFMhU0yzfchBjHpuH86Z9gf2HG+xPyDG8EpT50Yj6ZTbhhfr8wuv6fr29GudN+wILv9/vccn2LN50AOdN+wKrtlVx3ze1LUccCzajR4/GLbfcgh07diS+2759O2699VacddZZnlaOyC3MtAwUFeWcdAo5H6/ZjfV7DmPF1ios3nQgfRdKEzFO05LbzsMkx0vi0TNtClz53CKs2FqFS55ZmPFrX/T0AqzYWoXL/7mI+96NKSqXtTeOBZu///3vqKmpQbdu3dCzZ0/07NkT3bt3R01NDZ544ol01JHIcbjVWA539myTKWdW9hlE8tAGE415s7on5+HcIZ99bLwe0w7WZX9PqUMNEfuDBOTLc3TsY9O5c2csW7YMn3zyCdauXQsA6Nu3L7dRJdE0kYmKyuXOnm0y1U5e+ahki3Qk6MvHdmhK5PMYkW/1dYMrjY331fAM17t7jxkzBmPGjEl8HwqF8Prrr6e0uzeRn+SLFJ9tMuUwzD6DaB5qbLxyNM1EvyQncDnyOddVvtXXDW58bOLvZm765jg2RV199dWorq42fK/t7k00Xcxeb97HpukPAl6QznbinbnTdpm0kQ6NzVEwN+U0+dz++Vz3dJLLzeJYsEnX7t5EPkPh3jJkaqLlTDB5KNnwPjYeaWxyehhu+uRz5GS+1dcN7pyHva+HV+TE7t5E7iITektRUbkFO4lHc3n0McGr/DMZMUXlX/NmhXzOdZVv9c0UubxYyOru3kTuI2NmIifN3CLffWy8MkVxm2nmXzM0KfJ5jPB6AleUptEfc/kesrq7N5H7yPRdlUxRUvCr1jT62OR9VFTyM5mimh759iTycG3gGJF7ST7j2MfmqquuIqGGYX9tCMMfmYPHZn3nSXm/fmMlKv/6OUKR3MjiLDMx8oekPgrc8Noy/OTv8xHxatOgHCFjPjbM52xobB79eC2GPzIHB2tDrs73znlYYT67L4dIHbu+v/dQA8744xw8/ok346iXeL04yEURQrZO+fIeORZsCJ7n5m/G1gNH8LfZ6z0p7+1l2/DNzhp8uXGfJ+WlikxH9tqX4X+rdmLltmqs3GaMvmsqpHN8yLYpatqnG7H1wBE8/+VmV+fHPNJs5bPDalPDLonnP+ZuwLaDR/D4J96Mo17iddfJZ+1IvqT2IMEmRdI1YOZKn+FU+BLOw17Oo00ti3Gm7iZnTIMuLx7zKvMwObXnDHbPIpej97weh3JRrHGXoC93nxkJNoQlchobb8JzjeU2LbIR7p3NqCifz90QHvNIUM5MVFRT66XpgdOe5bAQIyLPqusKN29qLnd9EmwIaUz7cZom7Fx+cVIlnasddiDOZlSU36XK3TNTlMe+X4R7OMf5LNbDDZ5rbHJRZeOCXH6OUlFRt912m3SBjz32mOvKELlHpn1sMhU5lA0yZyJioqKyKNi419h4MwmyrudHw6o7l8lnfyfqO2JyeXyWEmyWL1/O/b1s2TJEIhEcd9xxAIDvvvsOfr8fQ4YM8b6GRFaR2bnby/BiPtS3aZGpcSBnTFGuNTbJz7m/VxThmDxrNO+johTkWiO4cWjOrTvgkRJsPv3008Tnxx57DGVlZXjxxRfRokULAMDBgwdx9dVXY/jw4empJZE1nGpsUr9ejji+pgHV5LPn12F9VLJpinJp6E7PXlFNrDPlGeTIzdBUTFE5/CAdDz1//vOfMXXq1IRQAwAtWrTAgw8+iD//+c+eVu5oJlf6vsxk7KVTrFfJ2XKedCboy5EtFdxqbLzqT5kSJAkZvNPqZpqmmMdG/2q6qlMOP0bHgk1NTQ327t1r+H7v3r04dOiQJ5UicgeZla6X9vOYh0u7+nA0tyIwmHs7Eo6m7TJeRRWlit+hj00sphqeWSr9yYs0/kdC1s/JrFi78/IJL+4ln3daz6UhRI/ds6kPR6XG8FTCvXOxrzsWbM4//3xcffXVeOedd7Bt2zZs27YNb7/9Nn7+859j4sSJ6ajjUUMuqstl/BS8jHjwSq6pqguh7z0zcPEzC1KskXew9/PPzzfh5QWb03OdLJqi2Os5FWwueWYh+t4zA/uZjMWp1D7VoKj/fLUFfe+ZgbeWbpO7XmPDT/t0A/reMwOzv93t/KI5xksLNqPvPTPwwcodKZWTz87D3ifo86ac+z/4Bn3vmYFlWw4Kf99/uAH97pmBK59bbKyDy2vqXQVmf7sbfe+ZgSfnbnRZYnpwLNg89dRTmDBhAi677DJ07doVXbt2xWWXXYbx48fjH//4RzrqmNN4mUUyF993GUGDF36809ikUtSctXugqsBXm8UvfS5w9/tr0lIuZ4rKsGATjiVjkZy+G4s3H4CqAp8wAoFnPjYuzv/N26sBALe/uVLqeK2pH/14XeP5q1xcNbe4p7GP3vTv5TZHWpPPPjbpcR5OnX99sQkA8NhM8TYU07/ehZgKzN8gk8XeXZ3ueCvex/84Y62r89OF9CaYABCNRrFkyRI89NBDePTRR7FxY1xK69mzJ0pLS9NSwaOJnFzJyFTJw0HLq5VdLuaKyNjjzWJUVCTKaGzcRkWxmYdzPiqKN5v5uQkiBzthlpCJrsxV8jWPTdBCY6pfdLgzReUujgQbv9+PsWPH4ttvv0X37t0xcODAdNXrqCQXO4pUuLeHg5ZXOUy8WhV5SaacoTnhMNMaG2bjUrdRUVGP+gDva5T+dtBfIheF62yRzz42+VZfDaemYKfksoDqeOg5/vjj8f3336ejLkc97OCbKxulSYV7ezhoqUxWtVx+cXIZtt0yrbEJR1Pvw1GP+kCmo6JyUuOaI+SzYOP12iBTI3vQYmWhr4Ob3b1VB+dlGseCzYMPPojbb78dH374IXbu3Imamhruv6MNLx9sLubdkJkcvLSfezU55IhcyJGpR8pvqZCZa2pEGB8bt32Y7QPe7RWVnsa3mrBzsAtmDb3JLp/I9fqajXUBf/IHu/4vO17mzAa7NjgyRQFAZWUlAODHP/4xtyJTVRWKoiAazb3Qr3whFzuKXLi3d53dK1NULpIFF5uMm6JYHxu3l2YdnlOKisqww2qTzruUIvnsPOx1fTOljQ8wpqhITEWQEXTcVoF/jmpOLiABF4INm4WY8JacNEWZ/sF87aEvA+cXkcsJJHIYL7e4cArrY+P22ulxHk5/O+i7a468wjlHrmijZfHcedjT0swJ+JIGmVAkZmOakqsV1xQ5/BgdCzYjRoxIRz3yFi+fbS6qPGMSk6SX0SdehSrnimDIkrG9opjPGY+KYpPruXx+nPNwKqaoDPh1cNox3UVy0YE9W+S3j01+OtmwpqhQJIbSQrYK7qKiOO18Y0m5iGPBRqOurg5btmxBKBTivj/aI6V219SjrCiAkgLnTZstBYWqqti8vw7dWpUYBQKJAUmvnhSVv+VAHbq0LJGoS/JzSuHers9MHxkzVWRR68VrbNyVwZuinBey73ADfGosbeHeew7Vo6QggGaF/DsuGxV1JBRFTX0Y7cqLvKtUBjhYG0KL0gJX5/I+Nl7VyMiOqiNo1awAhQG/Z2V6Ud9YTMXWg3JjoFewY3nYI2c7to9XHwnjYF3I/OAs4th5eO/evfjRj36EsrIy9O/fH4MHD+b+O9pgx649NfU45eHZGDZ1jrvCsiTYTPt0A0b9aS6enGfMHmm1IhUeJThk6kdrMeLRufiHRHZK9hqZdnxNOxmTa9ioqMxcU4P3sUndedhpEdVHwjjpwU9w4kNz0rJT/IHaEIY+NBsD7/vY8JusyeKMP87BKQ/PxraDdR7VKjMMfmAWQhF3L6Xd4scLvt5ejdP+MAc/+tt8T8v1Qiie8sEajHh0Lv71xeaMLbrY96hB/9z0e0XJamyYthj7l88yngBUFseCza9+9StUVVVh0aJFKC4uxowZM/Diiy+id+/e+O9//5uOOuYNy7ZUAYgPrm7IlinqT42ZKx+Zsc7wm1TmYU7LYvz9mc/i6QG0jKxWcBE9HiXoyzebfqowgUmZdx6Opa6x4cxZDp/dNzuSkZlyQrkzVm2raiyv8RoWfd9srtC2jJi/XiYjbG5RU+9ubOOfhTd10fPfxm0f1u857Gm5XowfLy74AQDwSAYz9LL1DtmsEqV9bHLZsYbBsb1kzpw5eP/993HSSSfB5/Oha9euGDNmDMrLyzF16lScc8456ahnXtC8JJj4fCQURXGBM3VoLvrYyCXoEx/vBq8cR1miMZWzN2eLTD3drG6pEE39+aXij9EQSUZlpsOvw6oYp+9vNnded4vbbNL8HkMCc7XrGiVJl1ud51sqZMj/j13g6E1R7veKcl+fTOJYY1NbW4u2bdsCAFq0aJHY6XvAgAFYtmyZt7XLM4qCSUHmgAvbYy72GTttTPwYb5w99een5DzMvLq5oi3NlOaIa8MsbqnghVDltARW5c6fmy7Jxrzv201g+Rj157bGmbjTdDlre+47nKE1FiuQuTUh6smXHutYsDnuuOOwbl3cpDBo0CA8/fTT2L59O5566ikcc8wxnlcw12E7aZQRkQ/WOhdsZCKQMg3vgCmjsUn1et5MjOxzyZW2zBQyzyxdhD0wRbE4rT87gHM+Np7JNXxBsRSyJEfyULBx+y7ZBQVkX59qTr5mHmbrrRdsDMKVtI9NfvRZx6aoW265BTt37gQA3HvvvRg/fjxeffVVFBQU4IUXXvC6fnkFu1o94EKwycUcAXxOFLNjwByToinKo7LY9zRXBJuMhXt7pPVygxfOwyzOTVFiwcarZtDXxypLst3KPFcdL61wr2XyTqtrRrq2RvJy/MhkFgonPjbSZXpSSvpxrLG54oorMGnSJADAkCFD8MMPP+Crr77C1q1bcfHFFzsq67PPPsO5556LDh06QFEUvPfee9zvkyZNgqIo3H/jx493WuWMwQ5UbsLgvBQQZNEPrnqJXMp52PQP56QjKipXJpCM+diwbZjhW49EU99SgcW5KSrpY8N2n3Q5PfKRV86ukSsCtxPcvkoyJu1UycHUVUIy5mNjpbHR57GRLDNfuqxjwUa/AWZJSQlOPPFEtG7d2vHFa2trMWjQIEybNs30mPHjx2Pnzp2J//797387vk6mCDM9yY3Gxqs9cpygj+CqqY+YHmtqiuK2QUit4l5t4MibolKpUf7B3m7G89jEvBVMnU7+DeHkRfnNNFOvi6gcK42m3fyVj6Yot+9kJsyj6fKxyXUB1ExQsvOxYZ+DrLCV2y2RxLEpqlevXujUqRNGjBiBkSNHYsSIEejVq5eri0+YMAETJkywPKawsBDt27d3VX6mYVerqfrYZMqWqRfADtaGUFGcjO5yGlmSarW921KBcR7OkQkkc6Yobx14nRDxYEsFFqdFhLjrM3vZpVwTcTncYkTX1qKJVrU4Ph/wos7peg/yJirK09LM5wq23mGd6lZR+LFWXmOTH33WscZm69atmDp1KoqLi/HII4/g2GOPRadOnXD55Zfj2Wef9byCc+fORdu2bXHcccfhl7/8Jfbv3+/5NVKBHbzYFZirqKg0qWs37DmM7/eKczvoTWb6esvsyutlvdNhjsuVFVemckCwV4nqhOXFmw44zrMUjalYsHE/ahvMtXkaEQ/CvVkcm6JYjQ1bjkd9QB+2bNXfRRMte3xdKIovN+7Dd7sPYYPHuVe8Qu+34oXzcLreg1QFhgO1ISz94YDheye3fLA2hCWbD3D9ZM2O6sRnBUrGTGZsvUOCzamXbTmYUpm5jGONTceOHXH55Zfj8ssvBwCsX78eDz30EF599VW8/vrruOaaazyr3Pjx4zFx4kR0794dGzduxG9/+1tMmDABCxYsgN8vzhHT0NCAhoaGxN81NfGEXeFwGOGwu+RSIrSyorFkh2kIJcs/cLjB8fVCzPGRSMST+taFIjj7sXkAgG/uO9uwEdq+miPc33trjiAcbpb4OxxOTmaxWExYpxgTGmJXb+03s2PYNghHoq7bIBJJ1rshFEY47FiG9xy2nTRk7s+uzayuE40mn9n7K3fi9rdWo3OLYsy5bbhUWQDwzOeb8OjM9RjSpTlev3ao5bH17POLyj8/01WnSZ8z4wjzDrJCRCp9CWDe9yj/vkcZDVGDboxRVdVwTdYk8I+5G7ls3CvvHu1qKxYv0fc1v09BjBFWQy7H0XCEHduMz4Lts6FQyJUfCluGmzqe/ofZOBI2vqORqHUfZNts5J8+R/WRCP555WCMPLYNdlQdwTlMJmT9bXkyJwn6GQCEmTHwSAP/3OpCUfz0qQVMEXLvWUw1ty87vReZcc1t+zh+i+rq6jB//nzMnTsXc+fOxfLly9GnTx/ceOONGDlypKtKmHHJJZckPg8YMAADBw5Ez549MXfuXJx11lnCc6ZOnYopU6YYvp85cyZKSrzfp2Pzps3QFF9Lly0HEBe4tm7fienTtzsqa+8RQHskS5ctQ/SH1MXjAw3JMj+cPgOFOnlw+X4FWp0BYMHiJajfmLzuHqZO+/YfwPTp04313ueD1gZLli5FaJO+3sluNmvWLO5fPdtqk8ev+eYbTK9aY3F35qxg7uuT2bNR4W6LG0/ZtCnZThqi9jTDrM307NmTvM7+AwcT13h+bfz7rQePOLru88v9ABQs3VJle97Kncl2X79+I6aH1ktdIy6EGIejqqpqR3Vduzl576xgs2LFCgS3L5cuJ06yPlodVh1I3t/06R9h+87k9T79dC7aFifPq6urM9Q9FOXLZXnnfzPRslD4U8bR+poaiz97jU/nzkO7YuflbagGtPtetXo1mu1Zxf2++YdkO/5v+keuIpw2bGWfjXyf0TgSFj+XLVu2YPr0zbbnz5o1C9VH4mW8OHMp6jbEsOYgP75GIhE0qBFobeqmnkni19q7d6+wnBV7ktdevnI1Snevglnf27FjB6ZP32Z7xepqvj+wuL0Xq3Gtrs7dtiOOBZvmzZujRYsWuPzyy3HXXXdh+PDhaNGihauLO6VHjx5o3bo1NmzYYCrYTJ48Gbfddlvi75qaGnTu3Bljx45FeXm5Z3UJh8OYNWsWunXvBuzYAgA4fuAgYP3XAIC27dqhstLZ3lmb99fiwRVfAAAGDx6MCcen7lu05UAdsCy+Yhg3bqxhRRhbtRP4bnXi7+MHnoDKQcl8RJv21eKhxjq1aNkSlZUnG67x711fYX1NXK154oknYmy/dtzvtyyYmfg8ZswYzJo1C2PGjEEwGISeNTtq8OiqhQCA3sf2QeWZ3R3db4LVu4Dv4oPnyFGjcUxF9jccXPK/tcCuLdx3lZWVtudpfc2szfS8sWcpUB032ZY3r0Bl5akAgPcOLMOag/ukr6vxp7WfA/VHpM7b/eUPwOZ4nqvuPXqgctyxUteIxlTcutA4wJVXlKOycph0XRd98A2wMz5As24FgwYNQuUJHaTLAfh+q9134JvdeG7dSgDAuPHj8fGbq4D9ewAAI0aMQPfWpYnzSktKUVl5Blfm4YYIsFi8l9yoUaPQsbkLqcFD9H3triWfIMJoMc4YfiZ6t21mUYKYRZsO4IlvlgAA+h9/PCpP7sz9vuTDb/H5rq0A4u2q1yzLsPHTjZixLa4Bc9K/NdjnzdKpc2dUVvY3PY9tMyz4FADQvXs3VFb2QfG6vXhmbVKgDgQCKCrw41A45Lqe+vq2adMGlZVDDL/XLdsObIwvDHv36YfK07qa3mPHDh1RWTnA9ppPbVoA1B4S/ub0XmTGNc3i4hTHgk1lZSXmz5+P119/Hbt27cKuXbswcuRIHHus3ACWCtu2bcP+/fstEwEWFhaisNC47AkGg1KTglN8vuQLqHKrccXx9Xz+5ONQfH5P6utnyvT5A4YyFR+vwompfL39Ab6LCOvE6Fd9NvXWfjN7Hj7GxKj4fK7bQGHK8fm9actU8QnU607qJduHWTW+yjxPRUn2TyfXZfVvdufFmNWck+enmIRQqaqz9yjMuBJwzpEpvk/auawJ3B8I8H1f9375fMa6+yzclPyC9zNbaH1N32fdvkv8e20sgx1H/YEAgi525w4w1/C2HeX6IHtMsLGdAqL7YNrUi3r6TN4ztk2jNu+R3y/5rlqYCN3ei9W45rZMx2Lxe++9h3379mHGjBkYNmwYZs6cieHDhyd8b5xw+PBhrFixAitWrAAAbNq0CStWrMCWLVtw+PBh3HHHHVi4cCE2b96M2bNn4yc/+Ql69eqFcePGOa122mAHz1Q27wP0YdPewDqPihwd9VEzDboJRiYqSibXjSzcJpgpeCLz0Sep1Cj/MMve7IXjpx1cVJSD52d2pNMa15tmHvbKeZj/bHUN0RRg1adz0THTp7MJuX6X+Hhv60NdtkO6fHLdDENmCicFfD3T6WDP+ZjZboIpea1c7KQCXHuqDRgwAJFIBKFQCPX19fj444/xn//8B6+++qp0GUuWLMGoUaMSf2smpKuuugpPPvkkVq1ahRdffBFVVVXo0KEDxo4diwceeECokckWfGhtaunk1bQMxNbhpfq8FGFDvgOJqCjueo6ryJflUahyNpId2pGpWpjdu9tmcNIXw1zmYflrmEfcOav0kVBSZcOaotIR7q1CtV6MCGYLS8EmB7OE6DU2roVjrgybY90KNkxVVVX1LBGem+eiFwhZ9Dm20rU/rz6PTb4IJV7gWLB57LHHMHfuXMyfPx+HDh3CoEGDcOaZZ+K6667D8OHykRYAMHLkSMvG/vjjj51WL+PwUnFqq+N07G3DCuqiOumFHX3qbalQbg9DOb1aZXMZjHPkhc72lgpuL+9EQInE3OWxkdEGylAfFgs26ZAZYjqNjcz9Wh2TI92Uw6/X2HgR7m1ThttrsIJMNKYi4JHE4KY6Vrug8xv0qvCnqGsyO5vLPByNWb/H0ntFydYquzgWbP79739jxIgRCUGmoqIiHfXKG9iX0O2gLjrHKy0Dq4IUTfD67/QZKvmU8WL4XDfO68iV5ZFAkg4zRL5gJtS5bQcnfdHzvaIcSiRHGMHGq33HuProyuQT9PHHiuYKq2zDuaJZZNErHtxqUdnnaFeCF+0Qialw4aYjxE199AKhGdGYiqBH9dTD7RUViVk+O9mszbnYR0U4Fmy++uqrdNQjbzH1sXFhi3aa5VcGtk6iMvV9XW+L5QYkiQR9qQoRvI9NKuWwJq0UKuQh2UjQ50U/cjKXudVaeqWxYU1RMkK5U/j3wfleUVZ+R7k4aRhNUe7KcZLE0+01eBOPd23ppihRoACAxj0PUytbFravxTU2Xiw08gNXWcs+//xzXHHFFRg2bBi2b4/nann55Zcxf/58mzObHpyGIWVTlPj8Q/VhvLV0m+OMsQDvzCmS2A2mqIgL52HHtTLHK62V6lE5XuKmGrtr6vHeih0QbPVicaHkx6iFYFsXiuCtpdts9zVzIqxGXPqZmT0jq2d3qD6MN5ds5d6LehONzdtLt2H/4Qakil6I5zMR88eyppFlWw7i8/V7LVfNrAB+oDaEt5ZuQ13IPtszACzZfABfbtgndawT0uFjY9ef3CyOvt97GNNX70z87eVWIqKx+LPv9mLed3tNz7HS2LC/yGqlP123Byu3Vkkdq6HfBNPq2Vm5I9WHo3h76TbsqanPG+23Y43N22+/jSuvvBKXX345li9fnsjyW11djYcffjjFhEP5B7cfR8pRUeLPt7+5Eh+v2Y0zerXGK9ec4qhMuxW0ISrKQrCRcfBMtd/zmpZUBJvk51zZ3dsNP3piPvYeasC4Tj78WPIc2aio+/67Bm8s2YaBnSrw3xv5fCssjkxRnNbSgcbG4fcAcNsbKzHrm934YNVOvPR/8YzIR0x8bJb8cBBXPrcY029x5gdoVZ+4j415+7JzxcR/fAkA+Pe1p5qWzQqFP/vXIny9vQZLNh/AHy4YaFmnaEzFhY1ZZFfcMwbNS7zLRmnYUsGtKcrBGOFmDBn953nc316+82x97nxrFT76elfi7wWTR6N1iXEaNRNsFPACr8y7tWV/Ha5+Pm4p2fyHcyRrbXQetmoSq2o8MWc9pn26ER2bF6MwmP0M7jI4ruWDDz6Ip556Cv/85z+5GPPTTz8dy5Yt87Ry+QBnioqmGBXF2aGTnz9esxsAMN/FioxbQQtW/foXy9oUJb4GP9inOKB4JJCkwxE7VdxUY++h+MLhm4PyDoYywigAfLAyvsJdta3a9Jh4GdKX5iY+Z6Yo5+rAWd/E34vPmJUzL8jxx3+z012yL646Op8l9p0yamwa68FUZJduCxMWtqyvt8fr+sHKHbZ1Yt/Zg3XebRsjwpPdvQUP1dMxBB4LNkztWKEGAHZV1yePY+ptZorSIyMobqtyl32XW9ypquuIvNnfxhNQbq86kje2KMeCzbp163DmmWcavq+oqEBVVZUXdcorzMKTU42K8uq9tHPm1Hd2K1OUzCaYqWts7K8nVw7zXHJEsslUNdjLWJmiZHHyHHgNhvw1zA512gc4H600t7edxiZZD3aMMC9PxrlfXI/03aj++q4vZTO2OfHBkcHLd97KX5LVvrDaStnEyTL3ykZYiQQhMxlKv/O8lRnJqrnYLNC5MZLa41iwad++PTZs2GD4fv78+ejRo4cnlconzBP0uSnLO5OOhuOoKBeetqrJZzd4Z4pKTcjMNZzsnWM22WYiQZ9bwdRsbz2nNeafu/cJQnhBUbWckLVIE/acqMUsKfpN5hWwirRKFX3RnkRFCYrgx77c0tjI9mN2EalpbOxOlakna9ZyMj7r30Xr5JDmvwWZsPl88bFxLNhce+21uOWWW7Bo0SIoioIdO3bg1Vdfxe23345f/vKX6ahjTmM2EbvpALImBCdEbOqkXwEYTFEydfJwUHK74jeWw3zOGR+bzNTDzL/I9WLbrcbGkY+NvTbQ8fWdnSpZfvKzCv07Ia5shBNszMsW/SbT9tE0qqb0z9CTPDaCdvJaW+2tKcocVnRmzf6aMGKohuJciGO1QnYZhFn0kaGWPjYW5chqbHJJ6HHsPHzXXXchFovhrLPOQl1dHc4880wUFhbi9ttvx0033ZSOOuY0Zmmr3bxY6dhSga+T8Xetmn6fgmhMNZqiHPrYpOxi45FA4pWA5CWptI0T3QN7mah+JnaBE7U+72Mjfw2zSzidSKOSQoQMimKsl96HyKqfafMRK3hYtaUwatGhxsZr7aS+PG8S9Il+9/YenKbbsDbTmP/GmoHYQI2kYCN6pnL9QYPV1urHZyv0beo2OWRBwCd1XExNXxZlpzgWbBRFwe9+9zvccccd2LBhAw4fPox+/fqhWbNmOHLkCIqLs7s7baZRmUEl4jKdvOgcr6RfWR+booAPtaGoy6go5nOKIhkX0ZNCG5hpLfIVR9nhTUyabp+Ns7Bt9rMTjY3J9w6rzPVXZ6caUJCsl5aiXy/IyGgG2ZV81ELaEgs2Ehobl5FoMujr5HavKH7xY6wj309TJ+KwolbNJtukIpOg6Hk49SfiwrZdmqKiMRvBxqKcAkZjY1VGNKZKJyZMN65jtwoKCtCvXz8MHToUwWAQjz32GLp37+5l3fICMx8bd6Yoe+2IU7hB1WLgLC6Ip780RkWx9RNfQ0arIws7HnmlsckVFWlWNDZe9ClHgo2766WySmfHUn417LpIA1pX1GdyttKyaiYE9r0LW1RKJMjLNAv7jnvtb6O/vuuoKBsNqlsTphmpaPr0WGpsmDdTtAGsqL2cmsm5/hORvy+9f517HxtZjU1ujLOAA8GmoaEBkydPxkknnYTTTjsN7733HgDg+eefR/fu3fGXv/wFt956a7rqmbPwdsxUt1QQl5sK7EAqKjKhsWnM622MijIfuEXlplprr6KZOI1NjrxwqWizXCpsPNoryoHmxa3GxuRQmTIC3IoSws9u0O89pC9T1WtsVHHkCStsWK243U7ovPnNY42N7n7cLhLsFkhep2dwaoa06mdWTcq2D5/HTKsHf7IC52Y3VnANRaOG32X2iorGVMt2tapFMCAnJuSSZlxasLnnnnvw5JNPolu3bti8eTN++tOf4rrrrsNf/vIXPPbYY9i8eTN+85vfpLOuOQnbWcIpDjBeamxeXfQD5q7bw60iHv/kO+ysTubRWPj9fjw7fxMARrCx0NjImKJSFcj0L6Oej1bvxLvLt0mUY71CzDTbDtbhjSX29daY8fVOvLMsebwTU5TXUVFOznM7yabiPBxkVDZeamy4DLGaYGPhY6OqfH0V3bkA0BA2TkwabrUt7HlOywhFYvjH3A34ers4l5H+2VsJDF9vr8a0TzcI/UDsxgivfWycmqLc7uHFLmZFZn9bHxuHGhu9q4AV+lQkVtc6Eori73PWY/3uQ4bf2Kgoq3bNJY2NtI/Nm2++iZdeegk//vGP8fXXX2PgwIGIRCJYuXKlZ9vD5yPsw2SFCDfPWEaIkOHr7dX43btfAwB+f07fxPez1+7BpmcXYc6vRwIALnlmYeK34kbBRq/qtHP609c71b5tNcBFYyp++Wo8CeQZvdqgTVmhaTm5FhX108bMsDKoqorrX9Enu3Sn/fBiFeXMx8alQGnat+wL8ZsINqlrbJKfo4KJSq+xUVWxdpCdNBsc+tjIIBtOLuKLjfvwyIx1+HLDfmFWc31xVuPSj56Ib6njUxT8cmRP0+NEJXi1lUqiDIcaG/dtn/wsGv+tAjb0n81g+4+mgZfRnBn7qvk5c9buwZy1e/Cnmd8ZshuzPjZ1IXPB3K3/VTqQ1ths27YNQ4YMAQAcf/zxKCwsxK233npUCzWAufSd6l5RqbzbbDZMvU3/+721wnOKGlNlG1Xl9vfkZTQXL5Dwv7H+P4cbrPfQ8XqgTJWdzDOxQzTIuvWxianJ55OJZnDrAG82wMsM/MF0maJgNEXp33GryJNEVBRrSrBYcbvtp6ymIOJQTVXTuM+W2fvkJirq6x0i7Y/1CsnzcG+Hbel2c1K2P4ii00TlOh2b2Kg6rf/I3B6n/VatnYet8DELhyMWgk2umPwBB4JNNBpFQUFyD5JAIIBmzZqlpVL5hJnzcMpRUR4FfEckjc3mPjbiz6ak2LmtoqLY9nUy0eeS7VcGkVrcyfpBL1BoxWXCidqtSSEVU1TAnx6NDdvJtD7Em1SMkxQrjGvPjNPYWAg2bk1RqfjYaO+72XnaO3hcuzIAcs/ULupJdCnV4i83ONVcWZqiLHMPsdoU45Y6+vZSFIW7PTkfG4FgY3uWcdHt9n2ImQhvenJpnJU2RamqikmTJqGwMK7+r6+vx/XXX4/S0lLuuHfeecfbGuY4Xm6pYBc54IawZEEyPjZmE6PdoOUEKxMSK6TZTfRu86nkAqK+k4peNKaq8EPJSHpAtz4u5q+LfSEBn6+xDN5BMuWoKLYsYZSLqluM8PevaXwighW3CLcm01SiojSNrmhSYttTEx5l1kkiQYBvNTsthv017PDSedhqkcn2B5HGRhwV5UwQFQlPcgImf023godsn8oFzbiGtGBz1VVXcX9fccUVnlcmH2GfeVgQ7ucEx9oRCWQ1NsUyGhuTc/lw7xQ1NtzEyJdlF+HFko4Is3Sg5UdhSdUUJfJNCvozY4qKcn3YicZGjMxrpE26+mNTF7KNE5Uxjw3f94XblghW3CK88bFxqrGJmxbETq7Jz1rkmZTpxI3GJgXTsaifOW0Hq+OtiuK0GVG+L+h/F5Unc6us4Kpp/HiTp3h0iOn6hdtxULYt81Jj8/zzz6ezHnkL7zyc2qojHX4hstJ2wsdGN/DK1ElG+JHFajXD5eSxaZ9c87ExQ1WN2iehYOPIFMX/rd2/V+ZN62u7a3ezhYCMcBQwyfKaqsaGe7dNoqK4CTsGbs8rsSnKwkchG1FRjQsfYXI55ua0yDOZBZvQFGW3V1RM/FkGUbt5KdhY9UHOsTdmNEXZJV10qrHRnpdjH5uY6tq5V7ZP5ZJg4zpBHxGH7WCppjZPx/wru7dIIirKYq8os/qxX6d6D9wAp/exicoPCGYmwlzDboXvBv3ZIv+QdMEnWku9PJkqa6Yoo6NrCtdVeTOTNqHrV9ucxgb88xSFe1tqbDxYUTv1LdG0oCKBhS3XTCsmQqyRYT9bT/aOk+uJ3iGnZVgKNnLnicK99cK1fpsOpz42YYHGxgyD/5fr/iXXp3Jp/UiCTYqYR0WlVpZXIcpmURL68osaMw9HYir3G7vSMquSlzko2LP1gw0rdNlFf3gpbKUTUXuJBmVnCfp0E3xM+95JzdzBjoFOJhezQ2XeA23SNWqqpC9vWx+zqCiZyYNPsOa9KSoVjY1m2rAzH2mRZzLPVJinxuSz1XeyiOZdp+On1X1ZJ+8zE2zM68GPqenT2Oh9Nt0KzrKRdnkZFUWIMfWxcfGQ9Y6IGqlE1JutEMO60aAo4E+eww6+3G2I78nL7mzlRMjvkmx9Vafq3mwhGpRTNkXpy0uYotKPfssBWUyjosyOZ8o28/+IpeBybRaRp0+iyT4/VdUvChrLYk1R4XT42LjffFcbH0STF9sGmrlPLn+K8TvVpl+ksjgSJY1zKuC59bHhhUo2j42msRFpp+TKFl0j5Ehjw3yOibNiy9CkfWwIMWxnSX2XXe80Hxoim/7D079Fj9Z8NJsWFQXEBRvtb7YWpv2WFchSrDY3wFlpbASDWSgSw/0frsH2g0fw6bq9yXIyvJJ4/otNaIjEcHK3Fnhr6Xb8ZvxxpscKNTYpOg/rpYGoYFJOF24j++z61ptLtmLltipEY8CFQzphQMeKxCHapOvlwGqWv0W/95ZB0FGN58huqeBaY+Mwj83+ww3408x1uOikzlyUTTSm4sHpa7F8nQ9dT6hBj3bliXM04fGe99fglO6tcFz7MtPy7fqZ6DadTvbcuYIm/c9XWzDvuz2IxlRcdFJnDO7SwrIMS1OU5bWTv4bTlXmY6TPJ55X8vaouhMnvrMKFQzpjSNfkffIRiqrr3e6bdFQUIcbUFOVikDLzlmd3GXaKaCB95rPvDd8VMvuBsFoeGXuwyn1OrXNzDm8OfWyWbD6AVxZuEZSZuRcuHI3hwf99K+33IFzRCQ5PJSoqk/cvmthlMJsMtTLueGtV4rt/L96CNVPGJf5OOg87qak1+mcg2isqpvfDUfnnqZUhSrAmvKYnPjb2Zdzz3zX436qd+Pfirbjy1K6J877eXo0XF2wB4MPLi7bg7h/1T5zDptU/b9oX+PaB8ablC01RNosfr31sPvl2T+LzvxdvNWTTNZTh0nmYT9AnyGMjMkU5fEdEeZDYOi3bUoVlW6oM92lwHj6KNDZkikoR9lnyqkg3ZYnVtalkd7ZSfbME/Epil2QzHxuze/Iy/46Vn5Fdvg6z5GeZfN/C0ZjhBd+8r870eFVQZZE2KhVTlCj3Rbq0N27zkUgoAzlYAUHz//DynkQh8wDfJ4U+NgKtbboT9Dn1sfluV3I/IDZBXz2zj1V9OMY9P81BGwCOWOx3pZWlx86vhF/UOWsHp/tCibA2RUkKNiLnYV3VDH5gElUXOZ/LdBW99tuLPElWkGDThDBzHnPjSMWtapjvU0nOZqX6ZvEpSmLPHb26XUNKY5OyYJP8bJXHxi6MkiWTL5x+CwvAWiixS+DlBv3pkcT+Muw1UrqEKXq7vizmQrP4+5AgWaOX96R/LkmNDSv0G/3iYoJ3J7N5bOzfd7aOWjtGVVWnbeITugV88qOQ2MfG+pxUFkdeRN9ZjddWdTfb3Tvx7HUnG7OCO9PYOEnQpzdFuX0/ZPtlLpmiSLBJEfZZimysTjBTx6biPCyrsfH7GMFG4ABp/IP5mhvcU+zcnGmP/4nzJRC8bGYvYCZ8SzRECRF9Fg9Q7GNjPM7Ji6p/BtqKi/02XcKeSGMhg50pSg8rIFj5M7hFr0nTJijOr17lHTL1IeLacxAlWBPhfkXtTGPDNlNCsImphog27d58Cr9fkH35Ao2NzQLJzlRlhRfRONZ7RVlcm9PYGBO06svVFyVTd5FgLHPLvCkqhagoacHGVfFpgQSbFOF9bIw2VieYraiVFHQ2VrsJs/gVBX5FINhI2L5lzFWyWK34w1z0h/G+zNo8kxob0SDgs3jLRAOqUPWbQoI+0Y7A6VpdZcwUxU0i2r/e3ZOMxiamGhcjopQPXFSURYI+93tFOYuKYo9gTVERXTnRhGCTHBtkEGps2M+C31PysUl57wzrtpf3sRE8e4PGRr5sUbnJcG9nGhtVJR8bwgG8j41YIJDFSwFBo8HGHq7h8ymJVZmZxsZ08uFWW6lVXK8+ZbGL/jB7cTPtY6PHWmMj+C5F52FTU5TFMV7h1lfC9FBVXI5YYyNzHdnVp71go6pGh3+R8CgK15W5pixONTacKYoRbPSBEFpR8bFBvj5ijQw7pli/u144DzvFSii2NEXZ+NjoyzX2K/u6iXaHl+vrTBlqCj42koIjmaKaEOabYDovS58TI4FDhY3Ihm6HTzFJTc9pkUw0Nqr4sxtiFtdjVb1OfGwy+cKJBgEr528vsqbq0U/eCU2XxLNMFbcZn81MmHotiAYrQGqXdJrszArDhCTU2Oidh8X+aaIEa6nUzeo8mTLYOvPh3vwx2j37FGvh3FC+0HmYLVtUJ+ZYh83gNNuysAyLi8o6D/N9UjX8Hv/e/HwzRBobxz42sfT72JDGpgnBaWwcpPwXlyXWlDg1RLGXduNjw2meHGqRUu3alnlsbFamZm2eWVOUSGNjfrw4lb2xDCd3oD9WpLFJV5ZQtzvcm81NKsQToVsfG7f+Atp5+slf7zsi2hKE1+SaX9Otjxg77shsocL52GgJ+mIq1+8ijAbHryjOBBtRdW0El1TMpG7zs7BY9QtLwYb5TWSK0herL0tGgyhKF+AmQZ/7zNZyDeylKThVSLBJEW71o+sATs0y3KqG6SROnYfdaWySg1fUZCA2ux19krJUsDJFhSPWGhuza2fWFGW8mJV/gqzzsCN/Ff2kLLDLi8LMvUAUFSSDXmPDZroVtZFQsHEYOmt5nN5k0Pg3906rRu2mMCpK8h00q5udMOZUY8MJNkyKfm5iZiZCNmJSBqEpilsgWb+7zjU2EpO8zTGWpijJawtNUXpBRn++Ux8bG+dhs4UF6wzuFLfvTDYhwSZFrFSoTidUtuM9O38TPl0bTzLl1HmY7dCyPjZ+nyLM4MqP2yYrSpNru4FbAeujomzy2Ji9gFqdvt5ejSufW4Svt1c7rteri37AdS8tsXT+BFyYoiTvIxUh4bJnF+HLDfssn9Ot/1nheMX1h4/W4u73vjatJ3uNHVVH8LN/LcbcdXsgQn9/7KaLovbgnIcTq2OJSUL3fNbuqsGVzy3C8i0HmbqouOvtVdxxv383fp96c7O1acqosbGsG3McK0eY+TgcrA3hyucW4aHp3wrLMEPkYwPw2p6ommxXn09xtLjS2uhf8zfhhleXIRKNOUrQ97N/LcYdb66UnohlJt59hxvwfy98hfdXbMefZ67D5HdWS5tNpX1sJHb3NoZ721ZdaO4yqxObi4jXfgN36vq0DI9/8h027zfPw2VWz2xDgk2KWL18Tid5fb+4+oWvADjX2PBRGA40NjbOw2b91sQlxxXsNfTaJj6PjSgqykSwaSz0sn8uxOfr9+GnTy1wXK/fvfs1Zn6zG28u2WZ5nF5rB9iYogRVFic4k0drhgJ/8vW+7NlFlg6a7y7fjoWb9ktfIxyN4al5G/Hywh+w7WBy4DPTuN31zmp89t1eTHr+K6nyg4y3qmglWBcyDuBypij++Vzx7GJ8vn4fzv/Hl4nvNu49jM/X7+OO2151BPsPNxh8wPi/xYsCNynpWdOPqE8BwJcb9xvq6VZjA/BCDutM7FOstY5m5d//4Tf43+qd+N/qnbaLH32131y6DTuq66WuJ6MpeOTjdZizdg9ueX0FnpizAf9evAUb99Ymy3BriuKEDqNWSl83/WXCEuOzaBNVszqxyRPZbhOKxnCoPmJ7LT2Pf7Je+lhyHm5CyHZ6GbzqF2w5MjZ3gPexMctQaybEqXYGdAew167XaZtY52HRZGGaoK/x+5rGF9suc6oVtQ3Wg4Node04j43EwG+FdmxBgH+9ef8Po2ZHVggG+ElQtKux/nq7qo9YlqdvBz+Twl8UznuwLmS4ptPVLxBfyesJRcQF1UdiBj84fbSPyPndjfMl22fMNDYi7aFMBIuZxsZMsPEzEZMy6J9l9ZEw97eohqKxRZQTSoRM+24RaB24+7UYt7SfRBpNvYOu/nv9Ofq61ttogAH+mdr52BxhBH6zYwoDctO+7NyRuF6azNtuIMEmRazeKadzvFlHdOo87CY6y+9D0nk4yg/edmV5qbFRrQQbG18Cs/p5qSG18zUQJuizymMj9LFJzXlYO5rd3wfQq8qNJTrJLssOeuwkbJ4Dybo8gymKaTSREHuwlhVsVMP1zJDRnuifcWlBfEPYsE6wEWlshKYoyXBZUx8bkwlGuCO3VObh5Gf2OTboBButPoqE87CV8284anSytqqThqymS0awOWSzIJHR2IjqYxZqb2aK0sMKIjJ1CzU+c7Ni2TFTdEzzkqC0YON0AUg+Nk0IL01RZmU53SvKjUqQTcLFh6zyZQkd/1K8Ngs/6KrcwBu2yWNj6mPjoWRjJ9iEBddy7mNjPM6Rj03jsUE//3rrI3r0vltOHERFzrvxa4uFGTuhQ/8rK5SJ2uhAbVILkJhEJBpJLryWfwCa5iuk2wdM79isqvq9orRrOtc8mKXqZxGZqOSEAbHGRr9liVaFeFSUdYlmfnlAXDDjtbrG88UCvneCjZ2mVcbHRriYMllsJbR1Nn1Sv3gTIXYeNtHYmPjYaAR8PmntW72E0MVCUVFNCKtn6ViwMfme7YZOM07KwkY+8Pl0+ONERds5BjpBfz774tvlsXGalt8NrjQ2FoKNqGrCAdS+askyG//VCzb6nCvGSCTjcMBvxpr8nl3di5wm9dezewT6Z8e2s0glzpmiGi8qIz/ITPz6JHoJwSbCO8HGYsa+L8pjI615MDFrONPYyIwPyc9mpig2f5BPse/33D5TumcZifEaG1ENRf3Dy8RwqQk2msbG+BzM9unSqmRXNRmtCL+lQvx4s2LtTFFBv3zoPmlsjmKsXiqnAqypxMv0Q6cDlyx8HhvmBTWULRyWTI93GmKoL599uVznsWF8BVLFblAQhXtbXTYtUVGNB+t9bER72bCI2oc9jHNoNdGkmTko200++uqwQplYY2M0Rckl6LOXfvTPUKuLXmNjdAxVdYuCxlW7Q82DIX+TyQQvEvicRkWxZYeizCKCdR72KbZaY4P/FneNmITzsHuNjcw9p2aKMj/G3BQl9+yPhJw5D4ej1n39iI0pKuC3176JypKBoqIa+eyzz3DuueeiQ4cOUBQF7733Hve7qqq45557cMwxx6C4uBhnn3021q+X99LOBJYaG4cPWkKu8UzdrofT2FistO1WWzIaHiv0glA98+LzGhv5vaK0Ip34kLCw7WlXhmhV5ziPjXDgdxCV0viv3sdGr02RSSPAO7Qmv2ejaUT5O/TXs+8Geu0RY4oStIdIsJHpa6lqbMycReP1MPGxcSjYGLYSMRHGnAj3LGzxITMBlRVsJPaK0mubDPldbLR3Qo2Nh4nhRFtZWOXMEh1nF7Ag3CfMplM619g0Og+bNA3vYyPQ2Ph80q4NMv4/LBQV1UhtbS0GDRqEadOmCX9/5JFH8Le//Q1PPfUUFi1ahNLSUowbNw719XJhgJnAUx8biWNk3nU3iZj8PjZBH1sn46rUcD2La6ca8s6++HZ74phGRTUeqzfNyMIOinb2aad5bISrV5HGxvKq4vP1GhurHCymdeFMUcn74HwzJExRdv1A/zOrPRK1KSvYaOe6yWMjgtVcAMmweTvBRlVVnUlGfJwZZqt8szqLTFRONTYs+ighraj42CBfpqqqXD3CsfRqbLzYikImQZ+ddlWksbETuhz72DgI9xYdkl6NjaPD00ogmxefMGECJkyYIPxNVVU8/vjj+P3vf4+f/OQnAICXXnoJ7dq1w3vvvYdLLrkkk1U1xdrHxllZMs7D8VWM37IcNy+63wcmQZ/RVmz2d/w7ZlDT/ebYHGdlikpxr6iA353Ghl3V2q1cxZtgmh8vah+x0GZ5WY6kxsZKsDFm9LVTtbP3EZbR2HATh3WdrUxRopU7H+4t1nSIkHk39OHemoAYjsa4eor2ARJvgik34kdMzAxmYbciE5WMqc2smcyjouwFer3TtL5/2PnYiN5dN4kNnSC7eWjSx8ZasBFFBHodFRW2yTzMmrbEkY8+aR8bGaGLJZc0NlkVbKzYtGkTdu3ahbPPPjvxXUVFBU455RQsWLDAVLBpaGhAQ0MyN0VNTQ0AIBwOIxwOC89xw/0ffoM3l/hRHzXXHoXCYYTD/OTy/sqdeHLe9/j7JYPQq20zPP3ZJny4aidevPokhAU5Da5+fhGXB6IhFEaRtVyDcNR5npZYNJpwDg2FI4m2ikR423QoFIZf58rK9udoNMq1c0j3cmi/6Z/FgdoQrnp+CTYwSbMA4LxpX6BdWSHO6N0KRYHkjYfCUUMZ+mtpRCLxY1nzxpXPLsSzV56IR2etx9IfDuLl/zvZNAyyrj7Zn9SY8bosDWGRLd/8hf9mexXuensVbhjZA+cOPKbxPoxlqIi32dOfbcK/v9oKBcAlJ3fGpGFdcOXzSzCoUwV+V9knfmzj5fRmM3biH//4Z4aJ8ZJnFqJzi2KUFQVw29m98PBH6/Crs3olfvcpSuLe6+qTbVAfCiW+56JEVBUvffk9Xl64BdurknlsRO0XjvDfsTJZQ8h4PJugb/P+Olzx7ELcMLKH4Tg9DSHzceC8afNxctcW6HdMGfd9sLEd6xrCiDDvVoOuHDYDMBAf6D9ftxuvLNxiWy8AmPnNbpz957l47KcDue/rmTp/t/sQbnp9FW4e3VPYT8KRmOH+DtaF8LPnl+Lcge1x3fDupguofy9O1jMaUxFuLN8HQNUJTPpr1DPPKBqL4UhDUvAMhSNcu0Wj8Tr+cKAO17+yHD8/o5tQsyF6Vre/tRrVR8J45orBiMRUTHphKZdozwlvLdmCO99aib9fMkg49ibvR0U4HEY9c08aYWa8Y8uINN6jXS6eOt09Lvz+AO794Bvc/+N+OKV7S7y/YgeXhLEhGsP+mjqc+/f5wvK27D+M8X+Zh4kndhQKuQGfffqQcDiMrzYfxP+9sMTmSP15EUdzrNlcIDrGKTkr2OzatQsA0K5dO+77du3aJX4TMXXqVEyZMsXw/cyZM1FSUuJZ/TZu9qE+am3a+OST2WheyH93+4J4k9/84nzc2D+Gl1f4sfuIgqffmY199YBeG/PpOj6z6MczZ6FZ0Lpua3YohnLsWLjgS1Qd8AHwYemy5VC3xAea5fv4sj76+GODYBUK+aG9Lms3bML06RuTv0UBtpvNmjWL+1fj3c0+rN0tbs/dhxrw9rIdGNY2Bs16un7DRkyP8P5Wa7eL73vT5h8wffomRJh6fr5hP55/5yM8uzJet0df+xgnthYP+AcakvewfMVKBHesEB4HACt2GeuwZctWmFl97/0gPhne9uZq+LctBwCs3G0sI6bG2+xPC5Jt+adZ67H/h7VYvtWP5VurMRjfAwDCkfh9Vh/cz13XLEsqy9aDcQHkmpfjdbn5P8k07NFIBNOnTwcAfHswWccvFy7GwbXx8hrCyTYOhyO457/8ZA8gUQbLhmqA7SeHq6sS5cz9/AvYDVXzN+xHm8ge2PX7+V9+iZ3cLhDJcldsrcaKrdW4vGeUK6em6gAAHxYvWYY9exVobbp8xSrL60XCEVz1wldwkolqw95a3PzSl9w5X3y5EHvWxNv34cbx4ldvrMLoDsn3QWPHrl2G9v1giw9rd/mwdtchdDr0baJ/WFF3pB4LFi4C4Eft4cNY/91a7l7116gJAVpb1tU34OOZnyT+3rDpB9TuVhPn79y5E9Onb8fT3/qwocqHye+uQZsi1VCnBYsWo2odrwl6v/F9ff7tj3CgQcHizc7GOZZ/fxXPIn7zi/PRr0WyfnrqG0KYPn069hxJ3qPGlq3bMGtWXCDcs3cftOexc2f8Oeza7YOVx8f2Xfu4tryl8f2+4l9L8NdhkcR8oRGKxPC7l2ablvnUZ5sAAA9/tA49y4xteqimGvUhGL5nmT59Ou5abN9H9KxcvRrN9jjftkE/F7DU1clt56AnZwUbt0yePBm33XZb4u+amhp07twZY8eORXl5uWfXObGqFhP+Nh+Hw+YPf+SoUejQvJj77pYFMwEAZc1borJyKO5b+SmAMHr2HYCWdWFgi7Vz9KjRZ6FNWaHlMTvmbwZ++E7qPjSGn3EGFtatx/qa/RgwcBAqT+gAAIis3AmsX504bvRZY9C8hJes7l4+B4jGV3flrY9BZeWgxG+1DRFg8ZzE32PGjMGsWbMwZswYBIPJchb89xtgp/V2BS3bdgD2xIXaLt26obJRQ6Gxae73wJYNhvM6demCysp+eHTt56gKJTUHQ4edDqxcBADcPev5YX8dsCy+Quo/YAAqh3QyreOeBT8Am9Zx33Xo1AnYu8Py3gCgsrISAHBw8Vbge14gUBFvOyz4lPu+/4BBwHfxmfrsseNREPDht0tnoyEaxTHt2uK7al4wToVAMIDKynEAgMJv9wBrVwAABg85CaOPawMAmLx0NtC4Ovf5/UIblHafLIs2HcAT3yRXiJ2PaYMNNfG6Dz7pFGDNUtv69Tq2D7DZ+v05eeipOLVHy8Tf2vvI0vf4AcDGbxJ/H9OuDdbX7Ef/AQOxceVOoPoAAOC4fv2B79eaXsvn9yMWdu544CsqBQ4nB/SThg7F6T1bAWhsX8Tbt0vXbsAOXhvUqnUbVFYO4b5bNn0tsD1+XGVlJe786hNb22AgWICThg4Avl2Giopy9Ot7DN5nxhT9M9xVUw8s/Sxe/0AQI0aNSPzd9piO6NuxHNgcfy/atW+PysoT8PruJUBVvC2LS0qAej479YlDTsKoxn4FNPoALfwEAHDKaWfEtbtrVyNVWrRshd69WwM/mPQdnx+VleOwfs9hYMWX3E/tj+mAMWP6YtasWaho0RKororfc7t2qKwcjLf3LQWqzLcqKSmvQGXlqYm/2f5YWVkp7J/tO3cDttlrAVu0bAEcquK+a9OqJSLV9TjQYJ4J3Oy6VnzyqzPQsrQAZUXyIkU4HBbOBSyaxcUpOSvYtG/fHgCwe/duHHPMMYnvd+/ejRNOOMH0vMLCQhQWGif+YDBo2niu6te8FB1KVHxXbS7Y+PwB02uWFATg8wcSZqbqhigUqxS1EmUmUJw7yRYEgwho+n+fP3ENv1+3imF+02DX/lVHItzvfp2GV/tN/zwUiTofZvcHgmKoh1kZihI/tkDnc3IolKx5IGDerjG2XMV4/yyqYJUju4mpVq7oPlQVwuuqzLG1YRWlxcGEH0hR0P1qVghThyizYlThS3xvFhXFIroPn4+va3FBAEG/gnBURUQ2Ikym3/t8tu9PVHe9wmB8mIxC4Z6v/jg9bqNfDQn5lGSdWRNcTNCvYqrxvfAx40owGJQLUlABpfGZ+H0KggF+qjBcw580i0WiKqAkn2dDRNU933gdg4xpWVgnhX9WUTDmLPhQb7L1hVPKiwssN+QLRVUEg8FEe7Cw4xD/PJTGtrbuI/XhmGl/NPteVlYWXbsg4LdNe+FmnuzVvsLxOez1nLaBHTmbx6Z79+5o3749Zs+enfiupqYGixYtwrBhw7JYsyQFNq1n5UtVFPSj5kg4MfixKeKtkHGQdOPExe0VxTrB6YYcoSMkcwjr1Bmvi+5Qk7rJRHIdYvw6hI58NlFReudhts2t/Olk95QBTBw6HT4PJwn6WP+r/Y33oz0zt1FgZrC14nOeiKOiZPf60ZcNxCORNEFU1olRJuIp1XBv9lnqN2nV49aXUn99MwdUUV+TcVSWedeiqpo4TioqinPEjXGRckfCUWGAQZApVFRt/X3rw57tku7JUl4UsIzo0Ryp7QIWhJmH7ZyHXexbVy8p2Qidhx0k6MtnsqqxOXz4MDZsSJoONm3ahBUrVqBly5bo0qULfvWrX+HBBx9E79690b17d9x9993o0KEDzjvvvOxVmsFOsNF3LHbTuuICPw4wQsCB2jDKi+ylU9GGgIbruoyKSiboY737+eNEkwf7zQGdgGbckkF8fRlhjN2d1irzsE/Rhx3H/9VrTvR1NYOdwKI2k5nbbLB2x5s1D3sPmqCmHavXUKUKl9iNWS1ze4tJaGxE6O8v6PehIOBDbSgqPfjLRATJvD96gUVrx3A0xt2fKDcKi9soEb3AYiaMiQRHrxJ4xify+GeFyXFlXibvv8X2Cf3z09qQXWgIN8HUCzY6ofKwR4JNWVHAtu+EozHxXlHsNi8CAd/ueTiNPALEm5+KECbo8/ksF3FNhawKNkuWLMGoUaMSf2u+MVdddRVeeOEF3HnnnaitrcV1112HqqoqnHHGGZgxYwaKioqyVWWOoM28oV+pV9UlV9dBv8JpDA7WhdClpb1zs5zGxvYQA+Z7RfHHiUJP2UHpYF0IqqomQtT1dTEb7GXmAFawsQq9DPp9XOiqJujp99ZhtUtWqxheY2NdR9GK2ekEJ3rGZiWw96AJyokVsdcaG6YSDVxiN+swfKmydXdYEPAl6t8gK9jI5LFxo7Fh8tjwDthpEmwkNDbFQb/tpozCsnXCmRnc7t6K/X51+jqyk299OCpM4hnws+ZM+zJVplkawlFuPEiFksKAbd9piMRMkoJaa2zs+oDTJHhaXWQQLXBltlTIpT2f3JJVwWbkyJGWL5miKLj//vtx//33Z7BW8hTYuDDo741dXTdEYtzfB2pDhsFdhMzE4WbPDnNTFI9o4GS/CUdVHG6IoKzI6HMR/1t8fZl3iTVFWe3uXaAXbLQ8FDqpZL8LU5TdSy80D0jueaPhZOdykcZGeyDBgLdLM/ZRsm0i2tXYKfrzCgK+hAlIVmMjI7TIvD/66/GZh5Pf22tsbC8lRK8xEt1XRXFQKFjJaAhk6hXfHqJRsPFJTIb6/FPMhH0kFOXGNu1YzhTlQmOjN3u7JRZTodrcXygSs9XGRjnNpfF3EZqZzslGx7JaHtFxAb99HhtZwSmXyVkfm3zA3hTF/81qaOpDUe7FPFgXklYR2+Em8zC7pQJviuLLEmts+L8Pcjsv61ZdKfjY1IZYvw7R5N84YOoz7jYeqlfd7zuUzE9j5eDLJRuzaX+RecBuZa/HzBQl+p5ta23H6/T52Ii1Fdo9u+l3ibJ15xb4GcHGZD8dQ54eKR8b+2eh991I7hXFJzW0E2zcou8vmqaA7VsVxUHhRCv6jhXGnQiJCROuothqHvRdnL3OEb3GpvHfALcfmKhMc81VQzgmbUq2IxxVpUxRrvaKMmm20sZVcUy199XSIyt41Am0QUGfYmuK2l/bIPzei732MgUJNikQ9NmrfTWiMZXzqTkSjiYmIqBRY+Mwc2o0pqL6SBjVR8K8ucTFUtEnq7ER+tjoNFOaSURVUXOET7Akqhqr9pYlJLAza+1t3CNJM0Xx1/hhfzKkVlpjY1NPkeAj6+yX2CvIxHlYJCAd0AnHUWZC0m+pkCoxtXF1q6pcm2gDrWy308oAko6Z+lMLAozzsIlPgT7qS0aAZNvY7H3TmwdYjQ2/aWR6VPb6dtTeOXYiLysKCCdEUd9h+19tg5xgo6pJAc9vIdiY9Vn2OvsON+i2XYn/y76nInNjROewy9bhSDjqmcYmEovZvqOhiNjHxswUlcgibfJSlBQmjSXVdWGDdsWnmI/jshqb2pDRVCfjPLz/sLhd9eNqLpOz4d75gJ3G5py/zceKe8bgn59/j5cX/ICLTuqc+C0u2CQl40P1ESnJPTFJR2OY8NfPsWHPYQDxFdxHtwxHh+bFrlTgfkZjExUtrxoRrXi1w1uUBHGwLpy4r9veWIl3l28X1l/jraXbcM/7X6OkwFlX/HjNbry+eAsuGdoFAHDv+1/jxQU/AIg7yHHXjGmmKL7u63YfSny2emVDDnxIRJPrgu/N81iwDJs6GzNvPVO8H5cq1hCwWsAXvtyMD1ftTNTRa+fhaEzF2Mc/Q/vyIpzQuXni+wf/9y3Ki4I4b3BHqXIq//Y5WpQU4MSuzTHt03gyR31uJl5jYybY+HCYWVzKvD+RqIq3l27D3e9/jX9cfqLwGP2EoNXjX19s4r5Pl8ZGTzSm4i+zvsNfZyfzrCz54aDwWL0fGcBrT0b9aa70de98O55szecTT9BvfLUV932wBs9edZIh8OGG15YlPteHY3hsVjIHTmKLE+Y9FU3CL365GQ//71u8+H9DcVK3lty7Vx+OctrKVFi76xAWbzpgeYx+Z3cNs72iFm8+gN++u9pUIAz6FAR8CiIxFUMfno3CgA8v//yUxO9+n2IqwKzaVm1ZV406gRAb8Ptgl1Vk32Gxxibo86HeND4ztyCNTQrY+dgAwBtLtmL++n2oqY9g3nd7E98fCfEaGwA4YCIps2gvz67q+oRQA8TDftfsiCczcuO06PMl90Hi9jzRSTYiHxLtG82vRlut6YWaeN34v29/cyXqQlHDyzS+f3vbOt/1TjI5lybUAEZNhSZsWPm6yGps7E1R7lfxew414M0l28QrQ4iFpkM6swnbjl6bogBgw57DmL9hnyEy4863V3H9rt8x5skw1+46hAXf708INQCw9xD//IOMxsYsCqQwwL+AMir6SEzFrxv73KTnvxIew6rwbx97LApMVqpOTQgsTrT6kZjKCTV62KADUR9xE1Ks4VOAEce24Uwq2rty59urUBeK4v9e+MpW4BcJgbzfjfGc73YfRm0omnjP2WvEx09vNDZ2Qg0Qr78oCstsrygAeG3RFtN2OVgX5rZwaYjEsJBZACmKwj23rq1K0KkFn+zVts6CvhD0KSgJWi8iWafsksZJ7tKhnVFsMuFNOq2bo3plAhJsUsAuKgqI2461DrqD2S+nXqBK3S/xomovijb5NSsMYGi3eCbV5Jb2zidXv6IkNrrjN3PjjxNO3I1fFTKbBQJiYUHWD2Ng5wq8d8Pphu8HMZoCM/QqU639tdXs53eOwpQf99edZZWgy4HzsOSGh2bUhaLi3b1VsenDSmvgdtNPGUQRKeyjffP6YfjuwQmuBz1WY6OZCfT9qVD3AspoUGR8bDTB5p4f9cONo3ubmvT00UsaS39/Nvf3yd1a4KNbhnPfBRwInXZCw53jj8P/bj4DgNgfyU1IscbMW0fgujN78nloVP49rg/HHAUsmDnzm6H5UrGC84G6UEoCm1NYZ+UJx7fH01fGsztbCTaA9S7c+n7FCmp+RUloKouCPsy9fSQqilNPMBv0+9Ci1LocbSExtFtLrJkyDpumVmLqxIFoUVJgOPZnw7riPsNYmn1IsEkBO1MUEO/Y2gvIOr/GTVHOBZvkoBAfwAJ+JTHAa0nT3EZFBQSCjf5dFU3c2sqL9UUAxDthy8pcPkVJrBZY2gm2k9Cv6PWaCm2A0AbSoN8n0GaYV8xJgr5UNDZAvF+Y+dg4NX2kMxFX9RGjGYAdxP0+BQUBn0H4kIUN99aeX1CnQy/SaWxk2sdsjywWzbdE689mJj0zjU2hzvfHpyiGSSzoQGVjpyUM+HwJU65IiHETUqyhrdL1fVJfJbMFS+tmxvdVO1TmWQBJXyr2mjurzDcfdouV6TbERLG2KC1gUmMkj7Hb/dtwPV2fYBe6rCmqOOiHoniTWC/g96FlqVFAYdEWEgUBHxRFSURs6bfSAdI7xqQCCTYpIDNmR6KqcBV1hImK0jQM+01sm/rygOSgEPD5uDwbgLuMp6zzsJUpSug8rNPYaAO+TzB4y5rJfEr8hdYj2ieLzQ8ECASbcDx3hzbwBPyKQZthZVVwkqdFRiNgRX04Kg6pN/GxsSKFICVb7AQbbbzTRy7JIgr31j8zvdAkZYqSMB9pGhvtvdJH2WmInodPMZqZ/D7FMGk609hY1znoVxLvij7Lr/adW7R6GxyaDRFL4vPbCt7XxOJM8l3R7o1993ZUm+915JZWzcwn/HA0lvBna1lSAL9fGyutxwar4UI/Th3QpZ84wgg2gNgPySlBvyLUvLBoApVe8y06jwSbJoiUKUpVhauoeiZcsWurUgDm3ugs+kEh6Fe4cFTAXVSUn1kRWCXoE00M2iGaz4OVxkbWFOVTFOFeR3rBRlVVg+ZLP4nohYWgz2d4aa00MU4izmRXoWYcCUXNnYdT8Onwmpp6gWDDVE/rS36J/c9E8KaoRsFGJzG40djI5LqpC7nX2IhyvmjaKxYn/k+2Ghu/j5v89X3QG8FGp7GJgdvw0Oy9aNWswCDoaUXJajdLEqHRjGBTlVnBJhSJ4UDjAorT2DBdwGuNTcIU1Xj/XmwhEfA509iwiExYuRoBToJNCtiFewNxnwzRwBKKxhJ+Cj3bxAUbmQFIe1ESGhu/YjABud0rSlsRW4V7GzboQ1JYKdBpbET1cCJziZzV9ILN4YaIYZ8t/cr+SCjKDaIBv2IaOSXCiWDjZH8kEbWhiDiPDZwLNjIJH91ia4pqHPhT0tjo9orSazmK9D42Eu0jExKe0Nhogo0jjY3xfn2KUWNj5pAswi4/T9CnoIixi+vHkfoUTFHavevfj6iqcqYJszGnwO8zrPS1I2XzO2maOfa92CexCHRKy1KjdkkjFGE0NqVBYWoMkWbNUrDR9Qk2ysvPOA8nNDaSofpWBGQ0NhGt//Pjb3PBeTmqsCHBJhVk0oTUm/hMaPgUoFujxkaGhPOwlrPF5/NEsFGU5KDMrTx0ZVlrbPh6OHGm0+NTFBQJGriVbvA5WBvmcrkAIlNUlPMNCvgVo8bG4hk1ODJFxX8vlOkcAqqPhE1V2jlliqqTM0W5TerFb4LZ6E+mK0sfFSWlsZHQEuhNUWbPUnQ9WY2NE1OUjMamwO9LtLVeQ5ySxqax3nqNZjSqonlxcqIzey8CfgUtdBoCNaF1luugoYh7TbQTWltoMkJRxsempIBJZmodMWklvFk5D/t0PjYALPfGkl1ABP2KhMbGzBRFPjZHBUHmmZqt6uw2amteUiB0sDNDHxUVYExR2kvkxs0jnseGvwYgmaBP87FpfAG1eojMO/LOw+LBXy8YHagLGTQ2IsGGrXfQ5zNobKxMUeyGj/a7e8fvvUxiQ1MRB2pDphqbVM1cXlIjiIrSqq0wewu51dgEGR8bbQVpMEUZfGzsJ3AnUWuab42Z2Ug0acVNuvx3PsVYhpOINbsJPeCPO3gm/GxC3gk2Cc2Ergp6jY1Igxevmw8t9RqbhPOw3LPQJlq3e2/JYjXhhyLJqKiWpQXCdhEnRzRve73Ghn1OPtbHRiKviCjQQkTA5zMImno0XzW9QC/W2JBg0+Rgn7uZtK/PM6KnRUnQtqOxRNV4xtQ9h+ob6+BLdMC9hxoQiToLvdSI7xVltKfriwrHYmiIRHGoPgxVVTmHZ9aJed/hBqHGQHbrCJHjMQBDJuODtSF8u+sQ912Bbo+kUCSWaC+fEi9bP7HsP8xnft5/uAENkShq6sOJaDOAVz1X14UTg/Oh+nj2UE2AKi9yl/vyYG0IewVO5DEV2F0jjgTJlVTnWr9hV3EpaWx0Cfr8fr1gkx6NDVsHwMIUJZiYfQKNjU8xagidJE+002xo0WJFjAOxRiymSme+tkJvijpYF+ImtW0HxT4vQZ9i8M2INvrFyT4L7X70uY68ppXFAnNXdT2nsUlqt2P4fm8ttteKF231Fn3SKjN4PNw7fq7I11BPaaH5eMP2vbjzsPWiSxPG9H1U7DxsW7WsQJmHU6CQ6W8VJQXYUW2ceKps0n63LC1AS5u8AizRmIr7P/wGz3+xGUC8o2ovyMsLf8DaXTXoLLFLuB6F2d3baq+oSFTFhMc/x/f7anHZKV3w2qItid80W/h7K3bgn59vEl7nJ/9YiO5lfvzoHPv6iNAPHnPW7uHqAIhX2OMf/xxAUgukP+aPM9bim501eOLSwXhzyVbc8daqxG/j+rdLfNbaZv/hBpzxx08xtHtLPHnFiRh8/yy0KC1Ah+bxJFplLnNO7KiuF/ajiKrgrnfXCM8pLwrgoMA0JDMgeklyN+jks0vFxyYR7q2pxvXh3q4EG/lJ3tZ52MQUpe+68e/4L51obOzqrJVVXMC3F+DdhoZ67dhZf57H/f3HGWtNz9VrQpZvqcKJD8ySvvaRUBTPfLYRD083v4YMQb9iqvX0KbDME/NnJnNyy9KChJCz9cARjPvbFzCbSq36pJVg4/MpCSd2mffYSqsT8PkQjib91FgTooikKYqvX2uBczWZopog5UHgJ4OOwcQTO6KzSVZIfXZhPS1KChxNQJGYmhBqAC0nS7JzfbX5oHSCvn9cfiLG92+PK0/tCgAJU5Sl83A0hu/31QKAQaBgNUdWbDpk/zJoR9w25lj0bFOKPu3LMHXiAJw3uANO7tYicdyXG/cZzrWKONHyh4gm3A9W7gAA/O69r7nv569PXkNrmy0H6nAkHMU3O2uwcU8tIjEVew81JDRY553QwfYevcJsQD5/cEcM7d4yY/VgTVEafpfZj4VRUfpwb93EIOU87MBPo3+HePbkgZ2a46SuLdCxeTH6tC9LliXS2DSa4dg2EGkf9aZQK8z2ytLQ3n/NFMU6C3sVSXfVad0wpGsL+wN1hGNqygJ2fThqKtSINIK/HnMs9/fEEzvi5G4t8LNh3UyvUVoYkBLCCwI+lBT4LTUkIvRCwT0/6seNU3otik9REtrpiuL4tV695hSYUWqxJQ373gR8CipKgvjpkE7o1baZ8PgGk6ioQZ2aY2y/dtx3uaqxIcEmBRQF+NOFA/DYRSeY2mf1/h8APyC3ZEIHZdCv3gJ+BQV+fuCQGbv/fe2pqBxwDJ66cggeOO94AMnQXMvMww7CF1NBWwncfFZvzP71SMz41Zm4dGgXlBQE8Ob1p+Hq07sBAHYIEnVZCTaaxsbKeVP/PNjEipqZT2uj+lCUGzg0lfzpvVrjjV8MM72Gl5gJNkVBH974xTAc2048gAHAoE4VCcEWACZP6CN93QEdK7i/NaHP55HGJpnJulETpBMG9InwvMpjAwCPXDgwMSEXF/jx1i9Pwxd3jcaMX52Ji07qZHo97d7Zuxa93042FBTt0syiCUnFAlMU+y5ffkoX6WvqKSsK4u1fnibty6ERicZSXtVb+QiJ+v6FJ3XCAz9JZsO9eXRvvHn9aZY+NMVBv/WGcY20LCmAotg74Or5/M7Ric8ndW2B/zujOzde/u6cftzxMTW5abLmo3R6r9Z47KJBwvKtngv7Dmpj46M/HYRPbhuB9wXZ3ZNRUfz75vMpeOZnJ2EMK9yQxqZpY9bR9RE7ANCxeVK706K0wNSfRITeLh1kVrYaMj42IlW4nPOw+cSgj1JJBbsm0V520aBnFUqrTShWE4uVX4gm2Gn/HglHhQ6C8cgJ02I8pdxEsFGgaafMK1IQ8HFt7UQ41SdfS/rYJL9z7WMTMOYa0v9tdB72zsfGaqLQJmozUxR7DPsdi2Ixi+qFQbvMwdq7LPKx0aJ2RA7MbnCyCAPi7Z2qD5hTwcbHbA8DJNtflPBTo7jALyWAaf6QFcVB6Tm9KOjjTEWayb6QeR6GMTymJsK/WR9Ms3uwFGyY6+jHfdE9aD5ZMv2FNDZNHDPBRjT4dWAEm5aMI5oM+qiOgM/omCiTBE802IgT9PFlWUXmuA1xFmHXJlYO15Yam8ZJ3mqyt7q0ppVgo9NE+yY1LwlmzP5sprHRLm8lxAX9Pm4ScCTYlOsFm/i/Xmhsgn5j7hd9n3UT7i1rirKaBLXbE5uijIJNQosj2RT6Z2AX1aT1d23yZAUhrZ8GfD5P+qOTRRgQb+9UL2sl2Imc9BWFF8C0Olv5oRQH/TIKm4Q/pN+noLmkH50+Kkzrt+w4VeBXuPEzEksmHmXnFrN7KLFyHvax7yPft0QCtrZQMxvP2TPIx6aJY5f0iKVD86LkeUzooAz6lzzg9xk6oEy+B9GEI9orSo+Vzd6JYKNpfsxu3e59sVIFm6XAB5IrFrcaG324PQBD5uOK4mBcYMgRwcbK7FYQ8HGTQNDvEzq/itBrirS2Ea2WnRLfUoEfxO3CvWWQNUVZCzbxeiQFueRv2v1yfkY+7TjmS4tm0Qs29qYonY8Nq7FJmPGMkYBucCqoRqIxx1oePVaaOJG2Mp66wihcWz3ToqAfMm5P7Dgvm9KhZTO9YGOMtisI+NCskM/krIWXs9c0u4dCneaVhX3/9eOeWGMjNkWJziGNTRPHic21Y/Nk1FLL0qCjF3+PzjGXjYrSkFmUiiYc4V5RurIaLEJHnQg2WhikmebEVmNjIUhaOg+78LFhiSY0Nsl20As2Wl/IVBi22QCbNEWZ14NN7AbE711/vFlUULnuuloeGfZ0J06yLIV+vzGpnc0mmDJIb7xoaYrSHctMNiJTlMjvxgpDfhNbUxTvY8OGdyc1Nt5souhUYxOJqmkV8EVjjk8n2GjXt3JiLg7KmaLYcV72tvRjlVCw8fMOyREmIaCMxoZN1KqHcx6WMC8ltlQwOZbV8lAemyaObC4anwK0r0iq8FuUFEitFDT26HKZBHzGnaplEl+JJhyfSLDRedlYJUFz4mOjrQrMJv+UNDYWg682aVtN9lYvq2amY301Dur8qLQIh0xpbMzs60lTlIWgF/AZNCz6Z2Km3SotEDvvepHHJhgwmljtNsHUsGp2pxsvCsvXiSjshKndrigqSrY/ODdFNU7cBSIfm0aNjV9x7PMlXPw47NPhWMyxMOQEkXaZzaIOMD42VqYoSadoM/OTXzEXmPVjlcgUFfQrnMYmwmpsJHxs2EStetg0CfqxUfQ4tffYrDxO8Zibcg0JNl6ht6OaURz0c3uStHRoitpdw2tsAgKNjVW2Sw3RNbXJ3ipBn1WyL7OJRoTZjs0a9j42/ADDmiWsTVHiPDYsVhNAVOdjA2RfY2M22GlXtzJBFPp5U5TfZ9xHy6yt9EO51u9YwdB1VJTAxGq3CabMNWWdh60EG4PGhqmnyMdGa19JS5RRsPEgKirAJOCURSTEOO3TcY2No1McIfM4pZyHJTU2Zm1oZeXTa2xEe5DpTVF1oWhCu8jOLWZap6DgfdGw0tiIfGwaHJmiclOyIcHGI0Q7n7K0apzsigv83Aq7hcNwby2DrkbQ5xPsZi2jsTFeU7RXlH7csNLYOMmmWh+KYdO+WqHjLWC/EtAPFs0Kk+1vbYpq1NhY+djYmKLqQhF8vaM68Z1RY6MJNqbFeIqZ2SS5rYFNVJSNxibgN24TABiFhKQWLvmdPluwLAFBtJ9+UDYTpK3ud8Oew1LXt1rB6zV6IlMU72MjEGwsmkWv+dQStZmhz2PDCkKahsrvUxxrW0TN6FSwCXvgY2OFTM4uGcGmKOhPSfsQsDjXqLHxcf8C8fewtNBYP7OIKsP1fUZne/a3xGcJH5sjdoINIwyRj00Tp5lNwqZOjQn8igv83LFlhQFHqlp98ruAXzFoKNxqbKR8bCwc+ZxobL7fV4tRf5pr+rvdSiDo96GMiYhgP1uFe2svvz6LLYulKSqmYuI/vsS0TzcmvjNobBqdBTO1mhFtFhq/fvxf26go3QpML/QGfD5hm5QX831eE6i9iIrS6sb/rTeR2a9Q9ewy2ZZCj5U/hr4pCjlTlLmPjWx/6NaKzxxuZ4rSno1dVJRTQVskIDoVbDo0L06rKaqTIDGq/nr+RPuYN0CJZLh3K8YRuEfr5ObFVm2rd1NoXxEPHmH7c4Hfhx5tjPmmjP454n7p9xnnAQ1WMNILP6Jb1ha2pgvVPNDY0JYKHqEoCn5b2Qc/7K/Dq7qMvAAw4tg26NGmGU7t0RIDO1XgilO7oFOLEiiKM6c+/eaDQb+Py4cAGIWPcwYeg4ZwFJ98u4c7T09yY7ekNKPfeM5KaHLiY7Pg+wOWv5dJ7LXUsrQgofFhhUX23u75UT8s+H4/FAB7DzfgmuHdAdhobCwG4piqYq1ub6qDTHbp03q2woUndrIt54lLB2NH1RFM/3oXurcqQV0oipnf7DY93gpzlXH8+lYaLH1UVMDEx4b9Zmi3lrhmeHeMPK4tvty4H++viGdsTjoPp+Zj89vKPsJz9WYAM6GpojhoqgmUxdoUpdfYJOuVdB4G8534PJZRx7VBwO/D/xvZE51alCCmqigO+vHeih2cBvacAcfgf6t3Jv6+Y9xxic/aRMn62CV8bCxMUU9cOhiPfrwOWw7U6e7TeKyT5zmwUwUeOv94vLd8h/Q5Y/q1Q882zfDUvI32ByN+/9VHwrjopM74avMBKIrRqV2rs5WwWhjwCc2DPduUonfbMhQGfYipwE8bkzMCwEPnD8C9/12Dq07tjBtf+cq0bM2U9JeLB2HO2r24ojEhJis4FAR8+NXZvfHtzhp8uXF/4nu9/1xFcRA3juqFv3+6gfvep9PYnNWnLQ7WhTCwU3OM698e0dg6dG5Zgr7HlHPnWeVTMtfYMJ9JsGn6XHdmTwAQCjZtyotw29jkIPTgeQMSn1NR1QZ8Rh8bvU2+rDCAP/90EPrcPSN5njBBX6MpysJwbaWxcZIDxWw3YA2ZKLMWJQX4YX98MDYTbIY0ZvnU41awEWVe1pIw3jiqF25nJhqzieyRCwfi3EHxLRd+MaJn4vuev52eDJlWxNFtHSqKDHtJ2SXSsnouIlOUQWOjK/+pK4ckns9fLxmMLzfux95DDYkJmL1tu6iood1bovL49rjvg28AAGf3bZd4j/Tvhb5eZpqAVs0KTTdllMVKy2X0sWE0NqKoKM0UZXG9rq1Kcd+Pk9lyn77yJLy/YjveW5EUCgZ3aY4Hzjs+IdiUFwVww6heid+1tmZz9fA+NuJrD+vZCv+adBLOfuwz7vtUnYf/NelktG5WKG2uKCnw458/Owkzvt5pf3AjrZoV4skrhgAARvVpKzxGxhQV8Iu1km3KCvHUlUOE53RoXox//uwkhMNhS1OU5qZw/uBOOH9wUjBi0xkUBHwoKwri6SuHYMB9M4XHaNw+7jiDYKOfByYMOAYXDkle682epwnrZvU47RZMAJmijnqsnItdRsQCiL+Q+olNv7eMXxDqKTLFaINWzCJBn6UpykPBRiYvECv8NGM0PKzQYiaiWZuizK8psulr22bo/TLMJl6zBIq85kRcP5E/jZ25xy78nQuN9SkGv5iAT+HaUT+5aStFTaB2orEJ+nkNkcg3ha0Hi9kk29phunsRVitRo48No7FRtGOSv4sS9FmtlBNlCcLurQQLTRhjc/WweWzMBO3mxUETs5N55KQMWr+T1fJoggd7XSd+e2Zol7fymwr6jZuXOsGqmmaLNHacSqSh0LW5lVmdJb6DPKs5lDrNsheaRkVJnp9NSLDJEFbOxalEz4jy2OjNRfEcFvx5VhobkY+Ndn6DR6ao6npvNDYaZYWsj02yPfSmNA0rocPSeVhQnqbF0au6zcoxSwxtNalriFaddhobK4GzUGCKEkVFse2on++0/qcJvaLkaGY0hGPcRMb5+wicmFnM2qh1s0Lh916hf6xi52FGuNN8bEwEODMM+YQCPstFkKZZY3P1RBlTlNmzCPh9llusWNUJMNduaf1O1lyhtSN7DbPtQpygXd8q71GqmZktnYdNFmns9bR3yCDMSi4W/TqNjWwEnKXGRmZLhRxV2ZBgkyGsJurUTFHG6BF9VJRf8NJKCzaN/2qTp1emqJoj1j4QMpvttWSERVZjw070MttLsERj1nvbWJnp9EKH2dhiFsjBCQQmk4XIT8Auo6ylKUq3pYI+uZlWPtuMIk0CwIZ7mx+r53BDhJtAWU2G0RTF34fZROR052WnGH1sRM7DzPESpigRhk0/Az6ddkus0WJz9WifA37jc2UR+twJ2lc0kZkJDAmNjeSNaxoV9hoVxd49S6tJOOCX0aGZY3WPzU0EG3ZsKkhobNwLNuwCRnZOsRI6ZcK9c9XHhgSbDGFtikpBsBHsqSM6Rt//RKaYRII+QR4b7RrWGhvvTFEyLwwbbcD52ARYwUa6SgDi2hera5tpgABj1IXZ4GKqRZKIJhJtI2Dnx2IdFaVwg7JoZa/vKwazZuNytV7gPGwndB1uiHDHW+XI0JdldtvpDrPX3xH7TKzy2DjVCBieg26bDsM73XjjEaHGxmc9sYv8aUSLH0ERZtGQCUdqh6Yo1tzrhcZGhqBfScklwKrPyQgn2vjq8/FjtezGpX6f96Yo88zDSXJUYUOCTaYwk9qB1DQ2IlOUoXyfYpisRYNNcq+o5Hda5mFNWKj3yMcm1agVgBcWOR8b5t4cyjXxvBsWt2GlsdJrbMxWyGZaJPZws9TnYlOUjcbGb679Kgj4+S0VBFFRdiagpNBr3P/LzhRV2xDhyucEG10TyPrYpDsEVV8+a4IV7+4d/9fp6lZklrC6N60dRVFRAQtTVPxcOY2NSIi2M0HLPg+tb7P70Zntg+Y1ZikNpM+3yDxsBueEa2K+lfUx8iv8AlfeFOVGY8NreHMREmwyhJXwkZJtV5Cgz3iMXPnaQMbug6TNwdrkaaWxcWKKEkUXOYXV2LA+Nmx7yiTw4uoVtfaxOWwhkOnNRKZ+PCbnmw1uLIVCU1RqUVGcP4hEVJS+v2rla6YoflK3rlttQ1SnheDrYlkPkzZKt93fEBUVNEZF8QKa8TtXPjY6R299EZrQERFERVk5DwNi4VjUjqLHabcZqez4pjnGs7u0W0UyeYk+pYFT3OShNA0iYAUb1z42cnWw1NjIhHvLXSbjULh3DpCKCjQoSNCnR9Y5WRvIvtt9GNVHwqgoDhp8bGot0rs7cR72AnbrgkKBAyfgXGOzYmsVvt5RY/r7fl0yPhaDxsbMFGUibOm3NpC5BiATFWU9oYWjvNnEkMdGH2ZtYgL5fP2+xt/tBTSNUDRmOlnbhXuba2wsL5k6DqOikqYoZ5cxPAeLHZwBPipq0ff78f2+2sRCRJSfCGB9O0QmToEpSuRjo3v39Ps3yU6yxUHN+Tkp2MiaYlIl4E/RedjDasafhfVGlHr0pijZe7E6zHTcYIV20tgcPaQ6gDkh4PdOY8NOmn+bvT7+oXFVUVpgLwOnGjKp0bZMLqqlTWP0S1lRgHsJ2dt1qsq++oWvhBvryWAI9zb1sRGfL7PHkllUlNUzdhIVJdor6tj2Zab1jJcRr9P2qnjuGPZ0u77d95hyru5m6nlRWWZl+xQFrZulHvJthv6yxQKhWpR5eGCn5onv9PqBLi35bMOA0QRYYJJrJXl8vOF31dTj4mcWYvI7qxP5gUQmRiCewwYQT2LHd6gwfFccNI4DrGAjygQsa+LR2rEVE9Vmp200o43kGKJxTEWRcOzq3bbM+KXofOPjA2AtmLQrLxJ+L6OxGdK1Bfe3T6exsfO707DSU5ktVPndvaUuk3FIY5MGPrrlTPx78RZce2YPPD9/E87q287yeBmp99KhnfHvxVsN32uJmaZOHIDJ76wWnis7uQ/oWIFmhQEcbohgV2MSOG0OPqlbC6zbfcj03LLCABRFQdDn42zkvdo2w8hj2+DZ+Zssrz26T1tM+XF/PDd/Eyad1k2qvt1al+KOccehU4tiw4T4+MUnYEf1EUOmzXRiFRVVWuBPaLvMnIfZMdDMvCR0HvYrmH7LcLy2aAte+HKz4Xd2wJt4YkfsrqnHFxv2J36z2ivqnAHH4ObRvfHkXPNMsPr+xW6gbSZwDe/dGj3bNMPPz+iOb3cmNWRWGhv96t3M5KQoCl6/Zijuf/0zdOnaFa8sMr43ZhzXrgyPXTzI8hj9+8pGPGq/6XMDAcAfJg5ApxbFuPjkznjww28Tv//izB6JbLQsejOeXnDWCwyaZk2/US5g1NgM7d4S/Y4px42jeyXKeuTCgaiqbUB4+xrsLe2BW8f0MZRzw6ieKCnw478rk4kD2T45cXAnRGIxToizMu2WFwUS2dS153tm79a4+aze6N+hHPO+22s4Z8SxbdC9dSkuO6WLabmn9WyFX53dG8e14wWTN34xDDPX7AIAnNqjFSIxFd/srMGIY9twGX/P7tsWXVuV4paze5teg2Vsxxg6d+2OoT1a4fpXlgGIC+1/u+QE03OG926NW87qjb7H8HUMSAg20y47EU/N25h43wO6qChZK4DZo7nopE55vQkmCTZp4Lj2ZYksor//UT/b4+1WtT8e1AFn9GojFGy0weDSoV3w6do9wrT8+r1KzPD5FNzzo3648+1Vif1pkj42Ptw1oQ/+8NFa4bnaFgh+nwIw1qpmhQH8/kf9sHp7NRZtMt9GYfKEPujcsoTLviqDlnl1OpNm3qcoOG9wR0fleIFVHpt7z+2PO99eBcA8UksuKkqgsfH50LNNvO3eWbZNuO2GRq+2zXDDqF4468/zEr9xm1b6eE3BPef2s0xsBvBh9wBQw+QoMuvbXVsln/V3jMDssxg0DRobC1NU11YluKB7DFubiVfFZkz5SX/0F2gqWPRXZbUDWh3ZSDKtOVs1K8S958bvma365Mq+wuvo+4Cdv4mVr5Xfx2vm+ncoT9RF46KTOiMcDmP69DW4rrIPgkHjgmhwlxYY3KUFZn6zK5FWgl3Zt2xWgCt1QprVJNuuvAg19Ycb66j5Iim4bcyxAIAFjLCRPKfQdpxQFAW/OvtYw/dDu7fE0O4tue/GH98+fg7z3eAuLbisznYU+IHJE47DoVDy5X7gJ/3Ru525xkdRFNw6xlhHtp+bmeLaVxThvh/3Twg2fkXhtG6pbjwqytauwZacihtFOsnRah1d2HVCn2IeNsueaiZhW4Wa6ynSbaSnMl4qVuYOLSrJ4AfR+Ddbt6DPOLOn6vDJRfZkaRWhFwDMMupKhXszz5vN6WOXx0bUjryKWjFEXeidfc3qbYZecK6uSwo2Zipx9nuz3Cz6U/2KonPKFdeHff5O8xjJmG31bcwKNlpbss/EralZf55esNGXahVar9fYpLI5KcC3MVsv0VhjtarXNoQExO0kGtPSpSXwItqHE8xdtrGMxsZwXb0pStKb2ew2rYTofNDYkGCTA9i9AD6dNM7CjttmL4GsxgZIdmi9xkZRrB35tKRo+twX2l+srblcYBlL9QUJOJyM04Fh4jEZKM2jopKfWTNEK+b5CZ2HbVZq+jBQvQ1fLxRyPjcSjamfzA41JDVGolwogPm2C5wpSu+07FN0OTRMyk5h0pYRQtjLFgZ8KCtMdmjt2qz2xIsJDjBup2HIY2OxfPbrEvTJhgObwbY9m8dGlGHd6t1u08yo7WIR+aikK+qNc/h22TyijNNOYd8ZWefhgE/h0jrIOw+Lj7MUbHI2FioJCTY5gtW7qihGh04NdvVv5iSqz3psNXhrHVoL3dVKV6BYrgK0BHn6wVg7nxW6ygSCTapaFn0ulmxgtXsw+/hMfWxMTFHs8zMzRWmIBiqjxsbH/cZv2OgsczBgLTibaQY48xcXB23yPeImHas9qxJFMF87dQOXcbpkB/aWpQU6wTL+b9DnwQTn2BRlrbGRSScgC1sW2ydFGdat+hCbf0o0GctmRPYCkcO38zKSn92OQ/r3U+q6PiWRKNPJtc2OEu1JJ7wuaWycc99990FRFO6/Pn2MDm1NAauOaGWKYiNszDQqzUt4ScJqYNCy5wo1NhaDvibYmN0HW7fyAuN0k+r7wQ4G2XjZ9JoPPZzGRsLHhi2LTSuvz24M6ExRgirwGht+5a43RcXbkRV0JDQ2VtuFmAo2YlOUaFds9ji27Uzz2Ei0tRkyEwJ7SIuSAk5ISGpsnLWhCL2QZSfYWIX16/MTpSr8s6ez/UtsijIvh80YLhK2RBN7uhYuTgV6EV4IR/r3U+ocRZ+gT1ZjI/4+301ROe883L9/f3zyySeJvwOBnK+yK+IdxDxhk5nQItpvRI8+bM9qUaqtvvQ+NgqsV4RJjQ1fuFY/doASmaJSHax4jU1KRbnCbtKRSRrIToDsJFVWlGwwu00wRQONlY9NwLC7tzgHixVWO7Gbnc87LJuYonTn6rVRpkIT29ZOfWwkfBPYNm5ZWiAUzLj09oI2kAmB1pvxjEIt/7uVtingU0w1gm5g75nNxi3KsG41+bH7emXbx8YLbYuTne3NcONjY9grSlpjY78QNZzDCTZSl8k4OS8lBAIBtG/fPtvVSDtWHTFuikr+Xhz0GzQqgIOXwEpjo/OxAaOxsYq6KDXR2IhMUSKNTco+Nlxa/sy/bY4EG1ONTfIzq9EoZ9T1otwSnMZApLHRDXh+nYaHu66iWPq5iLDS2LDCWmHAl9wB3EQzwzsHWwsyMqYopzj1sWlRWsAJFNr7GNAJi24w+NikYIrS7xVl5vskC/uOHQklfaqcCiKsxsbO8V0jfQuX1McQL/x0ZKKiROdw77m0j42zujWexZyfm5JNTpuiAGD9+vXo0KEDevTogcsvvxxbtmzJdpXSglVH9Cl8B2ejb9gVqexLYKUa18rWfGy08n2KYshAy1JmEhWlwWqTmomch1PsidmOirILiWabRSYqim3rckZjI5p4rXZ8Bvh+EfDzK3fDRpM+n2NVs2yeJD5DLa9F0mDFKv2t6p+rWZ+RcdQ2Q0aTwbZxy5IgJyRoGs6AjRZNBqc+Nlbvv0FT52FUVJ1FNnLAxsfGzhQludWDF+gFfDd4YaZxp7HRaQlT9LGxPEcRf84lclpjc8opp+CFF17Acccdh507d2LKlCkYPnw4vv76a5SVifMDNDQ0oKEhmaCqpiae/CscDiMctt5R2glaWV6VaTmxqyoQSw4eRUxn79S8MFGHskJxIfo6+hXFtN6BxoE5HFVRV9+AaGOyvVgsBkU13wCyf/tmCIfDhskoFlMRDofhZzaJE20tE4tEUmtLpn2iUbmyioK+RC6OVCkM+CyveUx5UqvRs3Wx8Fi26dh27N4qGRIbixknkUgkuWJmz9Ou4WOfWywGlSmjOABEonzbsWrAaCSMsMo/MLu2DfrF/atry2Ks2t74vRpLHBOLsvfEfs/n41FV/t5jEZN9u5iye7YyZsK1otCn2t4f234VRQGoTD2j0Vhjf2crGjOWyTwT0+vpnnVQ4eumgP9bFfQN9liu76ji+5Qd19gJ7bh2pZj5DX8+dxsW9WL7du82JcaxSiSaxuyfkRu4fqhGpa/BtpniSwqfJUHzcdYKbpEGQd8R0K5ZEIfqktu9xGJy9Y+YvENW56rsXoKS17G6htX5bsvOacFmwoQJic8DBw7EKaecgq5du+KNN97Az3/+c+E5U6dOxZQpUwzfz5w5EyUlJnmvU2DWrFmelBMJ+6FNbcPbx1DkB2Ztj08oW7f8gC9Dm6A9Ll/kCH51fBQ76xTs/3YhpjcmMS2NAJWdFdRFFLQpUhFRgX7NVUyfPr3xKoHGa4WY73ji83z8uA/+NwPfb/MB8OH777+Hb58KwLhqPLdLFPXfL8H0TUBdbfI+AKCqqgrTp0/H1i3xctD4/xv7RfH3b5JlzZk9G4JIUWm21Sbr/dm8uWgpkVH9juOBl9b78cNh8bJj5DExLN+voDoU//3iHlEEfMBnO33YWsufU3+4RtimN/UDDjQo+GHFfNw+ANh8WEHsh2WYLlA8Hj6UbLu9u3dBa6+D36/GFb0UlBcASxYvhv4ZsNc9ciRZhvb9/npAa5tVK1fAt03FtccpiKrAF5/OwtcHlESZn8yaid27ks/q4xkzGiex5FBhdp+76xWEokC/Fip3zP/rq+BQGNhYU5Uod/36dZheF0/2uJ15dlu3bMX06T8A4PsiAHy9ahV37zNmzIBoCNu0bg1mHfgaAKBuXYGfdlfQpZmKhqiCPfVAKAqsr1Gw5mC8Lud0jqI+qqBDiYpFn802lKfn253J9tqx+TvMqluXqMe27dsxffpW7GHacMWK5cBWfoLeuzf5u9m7GFMBBX6ojc9z0ZefY2NRsk0aGhq4c+siyd/0bPlhMxbWfp/4fd2332B61RrTe7Qb1xrqk/2sRdV3mNhNQa9yVXgva6uS7XV2hxhKgyrKgnH5eevKL/DrAcAPJu/F1/uT52ps/H4jpk9fb1k/N2w5DGjt8/Xq1SjdvcrR+VqbXddHQTgGLJr3ic0ZYhoOJfvG6pUr4Nu23PTYG/spqAoBG5Z+jtXMe/zZ3LloJZGbsiYEiPqMWZ8EgC3MWP7tiiVo+N7+OlZY9bW6ujpXZea0YKOnefPmOPbYY7FhwwbTYyZPnozbbrst8XdNTQ06d+6MsWPHorzcu/T64XAYs2bNwpgxY4QZOp3ywOq5qD0cl7jvmHg6DtSFMOuFpQCA7t27YfSpXfDwivkAgK7tW+OGi4cIy7nQ4hq3LJgJACguKkRl5UjhMaqq4o7Fs6CqwPBRZ+HbzzcBO7egV8+eGNazJZ5eu9RwzoNXjUFJ415Sz/ywADvqkplkK5pXoLLyVGz8dCNmbo+n5fcrwP+78Gy8+ZcvsftQXLs2duwYx/s6sXy3+xAeXbUAAHDW6NE4pkIu42ybr3fh5v+IB7AHrxiJy577CtUH4nsg3XXZGDQrDOAjwTkd2rZCZeVJrusPAM9tWYittXENY8eOHbDiQDz1++mnn4ZNK77EmDFjsHz7Ifz9myXceZWVlYnPj383H/vq67jvd9fU4/7lnwEATh4yBGP6tUUlc37ht3vwz3Ur4udMGI9P31qNFQfiGazPOSd+pNZ39NeTQTv6oelr8eWe+MzVv29fVJ7RDQCwfs9hPLLqSwBAl65dUFkZz9YdjsZw+6Lk5DDkxMF4eUOy3X90TiVuXZisl8ao00/GqV0rMGvWLIwdOwbnCN7PP81cjzWfx7f5OHf4EJzVt630/RxYtAVvb44LZWecPBgT+rfDbYvig3OHDh1QWTkQc4+sxrL98WzYWpuzvLNvGb6tim8aatWe96/6FAcbEx6OH3MW2pYVJp5FUVERKitHJI6tC0Uw+as5wnJ69+yBMwe0x2OrFwIABg44HpVDOxuOkx3X/rT2cxxoiL8XY88ejStN9j0CgOYb9+PJb+Pjxgn9j8Mvzuxueqyegm/34IXvVnDf9ezRE5Vj5bY6cMKaHTX4c2P7DD5hECpP6CB1nr7NnL0dRubVf401B+NbVpw69CSMOq6N1Hml3+3Fs+viQtDZZ8mNgfsPN+DupfMM31v1ycUffIsvdsez4FeeNQI92pRK1U+PTF/TLC5OySvB5vDhw9i4cSOuvPJK02MKCwtRWGhcrgeDQU8EkHSVy9pjiwqDKAgl1X0Bvx/FhUlTRqtmhSld0+/zWZ5fHPSjLhRFRPVBabSR+f0+FBWIzyksKECw0f4f8POrKwUKgsEgiplzfUq83VhfhcKC1NqxsKCA+SxfVoHFcUWFBfxzabxPUTuUFAZS7gd+xkbOOgkXNpYbDAYTn1nY63KRVY3flxYx2aMDfkM9/UykYVFBED6mHqJ7cnufpYyvUJCpRyHTnmzf9Pt5LUehbgNGs3q0LS9J/Gb2fhYxm7o67XtsZGab8mIUMu+mosTrX8AcUxA09g1F8JxElBUFE4JNWQn/3isKf26xYu6DUxD0c+1cKKgTi924xvoQxd9/82PZd0zU/6woLjQeq9iMX24J2DwzO7yaC9qUJQWSkkLrtmUpYfphkWSfDgbFpnirc2OMRr5d85KU79mq3dyWndPOw7fffjvmzZuHzZs348svv8T5558Pv9+PSy+9NNtV8xx9gjl2gvIpvDOpVRSK02uJYCOj+MzD4vOsUrWLoqK0Q7zMh+A287BVWwR8ijDFv8hJ0y5iRQazUFHRhooyZWiwbS9yXGZTBvh96csrKtoFG4CpM7NdVJQZMu+HPlLMCezR+lB3rSW92FIB4NsstTw2PtM+5QYzfzAR7O9OrypynlUdu4TL4UUOGi9gE17KOg/rj5V1sHZzn9VHkr48bGBDLpHTGptt27bh0ksvxf79+9GmTRucccYZWLhwIdq0kVPN5RP6DRD1uTHYFVJ5CiYbwD4CqUgf8o3GzMMmJ/pNJmSWAkESOfZIT/PYOHhZrQLJ9HXS7l8UVms36UjVhe0DXPi6+BgRdtlbzULNk9dS0hbCyQp/Zsni9Jf2+xREY1qkkVy94sKGtVM4G6XnNEKIraNeiNKERLbNU2lONgOsXdSjoihce7H4Fd1eUSmGe7Mvr93k6HTvMRZhbq70yDU5k3iOTXJoJazqCbro025u82Bt0qE3XRFqqZLTgs3rr7+e7SpkDIPGRrdyZQciNq+Jq2vZ9OZiZiNMbaCO57ERn2eVql1TBvA5FtBYpvsBT4/bQcnq2IDPJ1yZigQ8u3BvGcwynzpZaYsGGnZwFE16hnrYHuEOto18ZoKN7hyfktwsXnZ/o+ICP8I20W6paGxqmb2w9Fm9Exobm2cme8ViUQhhogxjKQETwUYf5p/qXlEsdu8b95477F0iYS5Nco1OY5qmi0iQSY2NG/3sQSb6KlfJaVPU0QRvztFlg1X47QzKUhRs7Do9u19Ucq8ouTw5xgR9xszDosunmntG0QmCslgNyn6fws1A2jVEqyhPNDa6PiCqo10ziW6dbRuhKUqiDC/gTFEmWj69tkivyfQKNzshaxxkdi/XmyC1hUDAg8zDgPN+ZfaO6rfSSLUt2bMVm2EhFY2N6HizzN2pkjMaGyY81Gz/PxFuEvS5WcWQYENIw2edNSZRC5ik2HeDrcZG4GMDXfZjM8yO4dP+e595mLPjOyjKzsdG+H0GfGzMVvy2Ghubmxf72PB/p8sUZepjY3FP6drclE9m5mwYrKqzyPGhauW7E7T1WGkCRY/JTEjTm7e9bEt786hnlwKQTo1N8nO2NtIFeL8t2aSrgHFPOBlcmaIs+n+ukNOmqKMJRTepsWOtfkuFVDU2dp1es+s/+/n32LSvNl4HyGps+GMSpii/yBSVPC5VWy2rUnWyPZCVIOAzcaTVZwYNRWKemKLMUt6zc1Wqk0hUIh9huoZ01l9E1ifKy/2NWPT7ZzmBdZ7Uk9xSwb2pi8VKYBb3zcxobFjshOlUFi2iN9DpxqZOrqaRTd8R1m/LSdu5Ma/ajW8iQhFvkpqmE9LY5AjsStrv531s/DqHzl5tm6V0LbuXpX15PFx+2ZaqhHSu1xqZIeNjo33yUjFQzuyA7UR9azcA2G1R0Kl5PLNtu3KJjIA2+EwEGC5CzkV9Wfq0N2bsNvSnTJiiTO5Jr1Ey88XR0PpVx8bn0PcYuVxVbla3Gqf3ag1AvJVEcksFXuOqZ1SfeF4bdksBEWf1aRevr2SfNnM2DQj89rzC3jxqbmq0o70gF0v6oqKSn7OxLYsGG2nkZBFbVhRAYcCH8qKAg72ijMddfLIxvxHLuYPi+X0qB+TuHo6ksckVmHfVGBUV//d/N5+Bw/URHFPhLE28HruB/Dfj+6Bnm2aY+tHaxHfFBT7L3YMTZZsMrAV+o4+Nl4HFJQUBvPv/ToOiKI7MQqwS6tdjjsWz8zeh+oi1qpWdtO4cfxxiKnB233aO62yoi4kvjV8n5Fph9mhn/3oEth88guM7Vhh+69W2GV695hS0LYsLZ+kK+DYTbAIWgo2Z35HGZ3eMwoqtVRh5XBvMWbsHp/ZoJVWXgoB77cUlJ3dBq9ICnNilheE3kSlK9L5dNrQL2jQrxOAuzS2vVTmgPZ6+cgj6d5AT2MzuxO/z6fbkSg3Op81JVJTD67QpK8QbvxiGkgI/fvREPEFpujQ2XuzM7Uk9fAo+vOkMHAlHhbulm1FSEMBr156CAr/fgfNwkl+M6IGBHZvbJqucOnEAxvVvh1HHySe1zDQk2OQI7LsqiooCgP4djJOSG+w6fatmhbjslC68YBP0S4Ueus1j4wWDBRONHewAffmpXbGj+gj+vXhr8nfBOawjd5uyQgzp2tLxde3qwgoXioMB1+z3nm2aoWcbc02fpoWIX8+2qq5gzXVmzsN6v1A7v4f2FUUYXxFfOVYOOEa6LgV+sZAlg9+nYPzx4mslo6JsnOV9CsYfb7/iVRQF4/qLjxOttg83iPf+iZu33WtOrLBrPrf+bxpDu3vzftmRK87DAIQLEBmcjkXsbTYvLsA5A+3foWaFAfxooFxW5mxBpqgcgU2Spo+K8vodkwkC0Ws9ioJ+odOsoWyDKcoYFZXwsbGvRtphV396gRKwd9D0MmyWbV7eBCP+XoQXE1a6ngurseETUCY/q3pTlElun1ThfWy8e4ZC5+EMTpKHTAQbvY9NyhobXdlW+Dy8LmDsI17BJ+hLyyVyDn4BlcWKeAwJNjkC+6r6FGfmB6fIrFCDfh83OBcX+D2Mior/m67oG2ewAqVRsBHBTrDpcsLkJg4PTFFu6+ElRSbh3pwpSueXmL6oKKZcDwUmJHxsvHEednx1kzk/4JeLanSD3Xucio+NiLT5DjNk0xSVSXgtVfbq4TUk2OQI7ICkKHxUlNcTjWx5Rbp07m6iojTs8thki5hOY6Mf0ET+JkEPV/gsZloM/fYalmV4obHJgCkqwkgwls7DTGW8bPdUoqKs0PqTXYI+L3Ca1sBJPiQvMfMdc4soZYEXOHHSb4qkbzOVzEOCTY6g9/RPqylK8qXV71Mjc57ZJCF2Hs4+qs5p26kpykvMJh6zCCm7MtySrkmviBEmQlHx5KT3seE0Nl6aotKkURGZXrPtrwHE+zbvPJxanZzcEnusN6YoDwoRYKYlbcpwz6YJ3TIJNjmCQQXvIOrAKdKCDbPCLpLM02L0sYn/K/KxyQXJRr8BpEzTsJorLwdZxeSzEx8Fb7qKeSGplM+aZ8xyYej9J9KWeyVN5Yqch7OhsdHvseT3+bKmheDuP4dNUbkSFZVJzIIU8h0SbHIUPpzS27JlBSUnOwtrGKOiGlewAjNWLrxG7CCpbSJoB3uP6cqp4XaM8WJAtrq2V0K2mWCjNzNwmisPXwSZjVvdkEjQxyVYzHxPr9DtYaV/LzNZJTPfMbekTWPD+ZvkwuiUfsjHhkgrVitVryVp2YFc72MjVbaJuYD9XrvVXFgh6AdJ/apWVEe2/dI3yLprG09MUS5/c0LYJAWywUKlMxV6BZ8nynuNDb+lgmfFS6NPHmj0HcscfBZ1L0pM/2Li6NHYiD/nOyTY5Aj6V5Vd5XkV3qhlnZ14Ykep44uYnYVltwzQTz5XnNoVAFDCCEYljdmTcuFF0mfd1RLttSgx34+LFTq6tipJS73MJttmukyk5w/mn6UX47GWD6Z9uTHra6pCgDbhn9JDnG9Dr7HR53fyitbNkpminWSqNqNfY8bjCxrfLbNNTL3gzGPbAAAmndbd8NsZjfmIrjmju6UZr1e71LKXO/HR4TU27ttCyy49wSSHUKqwdTtK5BrXmwfnOpSgL0cwag6Y3zy6xjv/7zRs3FOL4zvKZTFlfUlks/myg9jzV5+MEb3jg3DA78MXd41GQyiE1Qvmylc6zbQpK8ScX49IpLYf0rUFpt88HB1bxAdRs1d94eSzHGcGtUNGLVwY8OPzO0dBVYH9tQ2GpI1eaMFO79UaH950BrqIhLYUi1/827Ox+1A9+rQ36YO6zq7P7+QVxQXxdvT5FKn8THa89cth2LDnMAY0JlYL2GQeToVnrhyCtbsOYaAgids/f3YS1u0+hEGdKnDP+2sQ1UzBjcLb4t+ehcMNEbQtMwqt6YJbpKUwms341XD8sL/OdfI6O9jH1JQmeSuaqsaGBJscwSoqyitKCgIY0MndoCBrimJrfWLnFtwA0bF5McLhAFZrx+bIm9RDl5G3H5O+3qyOoj1svMSqbTq3jAscIsHDq25jNnmkWn6L0gK0KDUXBqOxzGhsgGQ7ekFJQQADOzVP/M3nbfK23kVBP07o3Fz4W3FB8je/TwGi8e81waZteREynQifD+d3X05ZUTBtQg3gbJuIpgJ3m03onskUlSMYNDacKSrDlREgs50CAO7lsFtgN6W8CV7jtm3S7RuQ7mdmMEWlyccm3eRChA17XdlNNNMBd/u5MJiZwAVvZa8aGYXfxqXpQIJNjmDwscmxQVzWxGG3tw9fZio1ygzZqqPb66bbITvd7aFf0bOazHwyD3DvQZY6EVsHmeSaTnCaHFAjFY1NuuEm+fzpap7RlLRUJNjkCFZ75OTwWGCAd8DL/xcl37RK6W7zdJevfw/0+Z3yBZ8DzWW6YH2HROkWMoXVXmC5xNEY7s3SlG6ZBJscwWiKYn/L3cFAj5PBIRfCvZsa6VZqpPuJpStdfqbJBVMUWwcvIr+8qEcua2yORmGGJY8UoraQYJMj6N/3fJ302VrnmjnNDfn2GNI9OGfcFJWngk5urP6Tbee1KcoJ3CIta7Wwp4n60UqTb9ppK0iwyRHydQDX4ySTZT68Rlmbklx2h3QPyOkWuK3y2OQT6UoA6AQ2wiybzsN8QsvcfaL6LORHG03plkmwyRGsXvccHgsM8A54+e88nC3cmmTS7aiabiWc/rbzqe+z5IIpKlcEG4UzReXuA2WFriagbHZMUxLmSLDJEaze93TtR2THL0f0BAD8aGAy02flgPYAgEmndQMAXHBiJ9fl58N7dPNZvQEAEwfLZWv2Ci276nHtyhydd3ljpufTe7XyvE5ANjQ2uTsRWqFlpJbdWDUdsIKN16HybvtBLvvYlBQk07q1Ki20OLJp0pSEOUrQlyPkoor2tF6tsfh3Z6E185L//dITse/HDWhbVoT/N6on2jTjBwAn410+2HTP6tsOi393luE+002XViVYdvcYlBUFgFhU+rwTOjfHV787Gy0tkuClQrqfmCFBX+69FlIUBf1Ydd9YBHxK1lbCUabxcmU1nsvP0+9TsGbKOKjIroYrW+RIF/EEEmxyhFx94fWp130+JfGdKC27E3+CfHmRMpl+nkUTTsIOBBsgvk1Eukj3BKl/D3J5hW9HeZH5fmOZIBdD5XPZFAUApYVH75TYlKLCjj6xNEdpMj422a4AkVbSPfYZTU951PlzjEguSjYEkQFIsMkRrExR+TS0OzNFEflGuu3wTcUUlQukU9vlthvE8lkF18QhjQ3hOU1HY+NEsmk6L9LRQvr3iuL/Nuv61HXykzwayo46mtI7RYJNjpBPwosVpLFp2qQ/3FuvsRG/GNR38pNc97E5miGNDeE5VmGt+RryakcTeo+OGtIf7s3/3TR7/tELyTW5S1MajkmwyREs89jk0WDgZOJrSi8S4Q2GPDYmfb8prS7zEbfNn4tpLYg4uZISwAtIsMkRmsr73pSSPBFG0r1TtV5jY2a6aEJj8FFFExnmmiRN6Z0iwSZHePpnQ+BTgD9MHJD4buLgjigt8OOikzpnsWbOOH9wR5QXBbhsxWbc9+P+CPgU/HrMsRmoGZEKd/+oH3wK8KcLB6Wl/N+M7wOfAjx43vH8DyYzYT4kdySMkI9N7nHmsW3QqrQAw3u3znZVPOPozUaUY4w6ri3WPTiB24X3sYtPQDgay+rOvE5pXlKApXePkUrhPrBTc3z7wPi8ur+jlZ+f0R0/G9Y1bc/qlyN74prh3Q3lU1RU04LkmtzjxatPRjSmItCExmESbHII0aSRj5O+kzrn4/0draT7WYnKN42KIsEmq7htf0pjk3soioKAv2m9UDSrEASRs5hqbMgUlZc01QhPIrcgwYYgiJzFzHRBGpv8hExRRCYgwYYgiJzFNCoqw/UgvIHCvYlMkBeCzbRp09CtWzcUFRXhlFNOweLFi7NdJYIgMoC58zCJNtnErSmQfGyITJDzgs1//vMf3Hbbbbj33nuxbNkyDBo0COPGjcOePXuyXTWCININmaKaFKSwITJBzgs2jz32GK699lpcffXV6NevH5566imUlJTgX//6V7arRhBEmjFzNiW5Rp50JM10HxVFkg2RfnI63DsUCmHp0qWYPHly4jufz4ezzz4bCxYsEJ7T0NCAhoaGxN81NTUAgHA4jHA47FndtLK8LPNogNrNnCAzA7HtczS3WXHQj3A0AoC//+ICv2V7HM1tpqdZYUC6HWTbrcAv7qt2+BW1yT0T6mvukGk3t22qqDnszbVjxw507NgRX375JYYNG5b4/s4778S8efOwaNEiwzn33XcfpkyZYvj+tddeQ0lJSVrrSxCpUB0C/r7Gj9PbxzDymJx9LTPK5kPAS+v9mNgthuNbqli5X8F/f/Bh0rFRdG6W7drlNqsPKHh3sw8/6x1FtzJvy959BHhmrR9jO8ZwSlv7vvrJdgWL9/pwc/8omgW9rQvRdKmrq8Nll12G6upqlJeXS5/X5AQbkcamc+fO2Ldvn6OGsSMcDmPWrFkYM2YMgkF6U2WhdnMOtZlzqM3cQe3mHGozd8i0W01NDVq3bu1YsMlpU1Tr1q3h9/uxe/du7vvdu3ejffv2wnMKCwtRWFho+D4YDKal06Wr3KYOtZtzqM2cQ23mDmo351CbucOq3dy2Z047DxcUFGDIkCGYPXt24rtYLIbZs2dzGhyCIAiCIAggxzU2AHDbbbfhqquuwkknnYShQ4fi8ccfR21tLa6++upsV40gCIIgiBwj5wWbiy++GHv37sU999yDXbt24YQTTsCMGTPQrl27bFeNIAiCIIgcI+cFGwC48cYbceONN2a7GgRBEARB5Dg57WNDEARBEAThBBJsCIIgCIJoMpBgQxAEQRBEk4EEG4IgCIIgmgwk2BAEQRAE0WQgwYYgCIIgiCYDCTYEQRAEQTQZSLAhCIIgCKLJQIINQRAEQRBNhrzIPJwKqqoCiG9/7iXhcBh1dXWoqamhHV0dQO3mHGoz51CbuYPazTnUZu6QaTdt3tbmcVmavGBz6NAhAEDnzp2zXBOCIAiCIJxy6NAhVFRUSB+vqE5FoTwjFothx44dKCsrg6IonpVbU1ODzp07Y+vWrSgvL/es3KYOtZtzqM2cQ23mDmo351CbuUOm3VRVxaFDh9ChQwf4fPKeM01eY+Pz+dCpU6e0lV9eXk6d2QXUbs6hNnMOtZk7qN2cQ23mDrt2c6Kp0SDnYYIgCIIgmgwk2BAEQRAE0WQgwcYlhYWFuPfee1FYWJjtquQV1G7OoTZzDrWZO6jdnENt5o50tluTdx4mCIIgCOLogTQ2BEEQBEE0GUiwIQiCIAiiyUCCDUEQBEEQTQYSbAiCIAiCaDKQYOOSaf+/vTuPieJ+/wD+Xlh2WeRY5FxUEAPlECEUdLtCT4iA1oKxjTXULrbRQKGFlLTFNopNYzE9TK9vtqWt0EYjESPWKkIpKC2EQxAQhABW1MZwqIgCtQjs8/vDOL+OgEd/sMtvv88rmQTm+czuZ97ZME9mZ5j//AcLFy6EpaUl1Go1amtrjT0lo/ntt9+wevVquLm5QSKR4NChQ6I6EWHbtm1QqVRQKBSIjIxEZ2enaEx/fz/i4+Nha2sLpVKJV199FUNDQwbcC8PKysrC0qVLYWNjA2dnZ8TFxaG9vV005u+//0ZycjIcHBxgbW2NtWvXore3VzTm4sWLWLVqFaysrODs7Iy33noLY2NjhtwVg9HpdAgMDBT+oZdGo8GxY8eEOud1fzt37oREIkFaWpqwjnObaPv27ZBIJKLF19dXqHNmk7t06RJeeuklODg4QKFQYMmSJairqxPqBjsWEHtoeXl5JJPJaPfu3XTmzBnatGkTKZVK6u3tNfbUjKKwsJDee+89OnjwIAGggoICUX3nzp1kZ2dHhw4doqamJnruuefI09OTbt68KYyJjo6moKAgqq6upt9//528vLxo/fr1Bt4Tw4mKiqKcnBxqaWmhxsZGWrlyJbm7u9PQ0JAwJjExkRYsWEClpaVUV1dHjz32GC1fvlyoj42NUUBAAEVGRlJDQwMVFhaSo6MjbdmyxRi7NOMOHz5MR48epY6ODmpvb6d3332XLCwsqKWlhYg4r/upra2lhQsXUmBgIKWmpgrrObeJMjMzafHixdTd3S0sly9fFuqc2UT9/f3k4eFBCQkJVFNTQ+fOnaPi4mI6e/asMMZQxwJubP6FZcuWUXJysvD7+Pg4ubm5UVZWlhFnNTvc3djo9XpydXWljz/+WFg3MDBAcrmc9u3bR0REra2tBIBOnjwpjDl27BhJJBK6dOmSweZuTH19fQSAysvLieh2RhYWFpSfny+MaWtrIwBUVVVFRLcbSjMzM+rp6RHG6HQ6srW1pZGREcPugJHY29vTd999x3ndx+DgIHl7e1NJSQk9+eSTQmPDuU0uMzOTgoKCJq1xZpN75513KDw8fMq6IY8F/FXUQ7p16xbq6+sRGRkprDMzM0NkZCSqqqqMOLPZqaurCz09PaK87OzsoFarhbyqqqqgVCoRGhoqjImMjISZmRlqamoMPmdjuH79OgBg7ty5AID6+nqMjo6KcvP19YW7u7sotyVLlsDFxUUYExUVhRs3buDMmTMGnL3hjY+PIy8vD8PDw9BoNJzXfSQnJ2PVqlWifAD+nN1LZ2cn3NzcsGjRIsTHx+PixYsAOLOpHD58GKGhoXjhhRfg7OyM4OBgfPvtt0LdkMcCbmwe0pUrVzA+Pi76wAKAi4sLenp6jDSr2etOJvfKq6enB87OzqK6VCrF3Llz/ysy1ev1SEtLQ1hYGAICAgDczkQmk0GpVIrG3p3bZLneqZmi5uZmWFtbQy6XIzExEQUFBfD39+e87iEvLw+nTp1CVlbWhBrnNjm1Wo3c3FwUFRVBp9Ohq6sLjz/+OAYHBzmzKZw7dw46nQ7e3t4oLi5GUlIS3njjDfzwww8ADHssMPmnezM22yUnJ6OlpQUVFRXGnsqs5+Pjg8bGRly/fh0HDhyAVqtFeXm5sac1a/35559ITU1FSUkJLC0tjT2d/zdiYmKEnwMDA6FWq+Hh4YH9+/dDoVAYcWazl16vR2hoKD788EMAQHBwMFpaWvD1119Dq9UadC58xuYhOTo6wtzcfMIV8L29vXB1dTXSrGavO5ncKy9XV1f09fWJ6mNjY+jv7zf5TFNSUnDkyBEcP34c8+fPF9a7urri1q1bGBgYEI2/O7fJcr1TM0UymQxeXl4ICQlBVlYWgoKC8Pnnn3NeU6ivr0dfXx8effRRSKVSSKVSlJeX44svvoBUKoWLiwvn9gCUSiUeeeQRnD17lj9rU1CpVPD39xet8/PzE77CM+SxgBubhySTyRASEoLS0lJhnV6vR2lpKTQajRFnNjt5enrC1dVVlNeNGzdQU1Mj5KXRaDAwMID6+nphTFlZGfR6PdRqtcHnbAhEhJSUFBQUFKCsrAyenp6iekhICCwsLES5tbe34+LFi6LcmpubRX8ISkpKYGtrO+EPjKnS6/UYGRnhvKYQERGB5uZmNDY2CktoaCji4+OFnzm3+xsaGsIff/wBlUrFn7UphIWFTfiXFR0dHfDw8ABg4GPBw1/7zPLy8kgul1Nubi61trbS5s2bSalUiq6A/28yODhIDQ0N1NDQQABo165d1NDQQBcuXCCi27f4KZVK+umnn+j06dMUGxs76S1+wcHBVFNTQxUVFeTt7W3St3snJSWRnZ0dnThxQnRL6V9//SWMSUxMJHd3dyorK6O6ujrSaDSk0WiE+p1bSlesWEGNjY1UVFRETk5OJntLaUZGBpWXl1NXVxedPn2aMjIySCKR0C+//EJEnNeD+uddUUSc22TS09PpxIkT1NXVRZWVlRQZGUmOjo7U19dHRJzZZGpra0kqldKOHTuos7OT9u7dS1ZWVrRnzx5hjKGOBdzY/Etffvklubu7k0wmo2XLllF1dbWxp2Q0x48fJwATFq1WS0S3b/PbunUrubi4kFwup4iICGpvbxe9xtWrV2n9+vVkbW1Ntra2tHHjRhocHDTC3hjGZHkBoJycHGHMzZs36bXXXiN7e3uysrKiNWvWUHd3t+h1zp8/TzExMaRQKMjR0ZHS09NpdHTUwHtjGK+88gp5eHiQTCYjJycnioiIEJoaIs7rQd3d2HBuE61bt45UKhXJZDKaN28erVu3TvT/WDizyf38888UEBBAcrmcfH19KTs7W1Q31LFAQkT0kGecGGOMMcZmJb7GhjHGGGMmgxsbxhhjjJkMbmwYY4wxZjK4sWGMMcaYyeDGhjHGGGMmgxsbxhhjjJkMbmwYY4wxZjK4sWGMzSrnz5+HRCJBY2PjjL1HQkIC4uLihN+feuoppKWlzdj7McYMhxsbxti0SkhIgEQimbBER0c/0PYLFixAd3c3AgICZnim/+vgwYP44IMPDPZ+jLGZIzX2BBhjpic6Oho5OTmidXK5/IG2NTc3N/gTkOfOnWvQ92OMzRw+Y8MYm3ZyuRyurq6ixd7eHgAgkUig0+kQExMDhUKBRYsW4cCBA8K2d38Vde3aNcTHx8PJyQkKhQLe3t6ipqm5uRnPPPMMFAoFHBwcsHnzZgwNDQn18fFxvPnmm1AqlXBwcMDbb7+Nu58kc/dXUdeuXcPLL78Me3t7WFlZISYmBp2dnTOQFGNsunFjwxgzuK1bt2Lt2rVoampCfHw8XnzxRbS1tU05trW1FceOHUNbWxt0Oh0cHR0BAMPDw4iKioK9vT1OnjyJ/Px8/Prrr0hJSRG2//TTT5Gbm4vdu3ejoqIC/f39KCgouOf8EhISUFdXh8OHD6OqqgpEhJUrV2J0dHT6QmCMzYz/06M8GWPsLlqtlszNzWnOnDmiZceOHUR0+8nmiYmJom3UajUlJSUREVFXVxcBoIaGBiIiWr16NW3cuHHS98rOziZ7e3saGhoS1h09epTMzMyop6eHiIhUKhV99NFHQn10dJTmz59PsbGxwrp/PvG6o6ODAFBlZaVQv3LlCikUCtq/f/+/C4UxZjB8jQ1jbNo9/fTT0Ol0onX/vI5Fo9GIahqNZsq7oJKSkrB27VqcOnUKK1asQFxcHJYvXw4AaGtrQ1BQEObMmSOMDwsLg16vR3t7OywtLdHd3Q21Wi3UpVIpQkNDJ3wddUdbWxukUqloGwcHB/j4+Ex5VokxNntwY8MYm3Zz5syBl5fXtLxWTEwMLly4gMLCQpSUlCAiIgLJycn45JNPpuX1GWOmha+xYYwZXHV19YTf/fz8phzv5OQErVaLPXv24LPPPkN2djYAwM/PD01NTRgeHhbGVlZWwszMDD4+PrCzs4NKpUJNTY1QHxsbQ319/ZTv5efnh7GxMdE2V69eRXt7O/z9/R96XxljhsVnbBhj025kZAQ9PT2idVKpVLjoNz8/H6GhoQgPD8fevXtRW1uL77//ftLX2rZtG0JCQrB48WKMjIzgyJEjQhMUHx+PzMxMaLVabN++HZcvX8brr7+ODRs2wMXFBQCQmpqKnTt3wtvbG76+vti1axcGBgamnLu3tzdiY2OxadMmfPPNN7CxsUFGRgbmzZuH2NjYaUiHMTaT+IwNY2zaFRUVQaVSiZbw8HCh/v777yMvLw+BgYH48ccfsW/fvinPhshkMmzZsgWBgYF44oknYG5ujry8PACAlZUViouL0d/fj6VLl+L5559HREQEvvrqK2H79PR0bNiwAVqtFhqNBjY2NlizZs0955+Tk4OQkBA8++yz0Gg0ICIUFhbCwsJiGtJhjM0kCU11BR1jjM0AiUSCgoIC0SMNGGNsuvAZG8YYY4yZDG5sGGOMMWYy+OJhxphB8bffjLGZxGdsGGOMMWYyuLFhjDHGmMngxoYxxhhjJoMbG8YYY4yZDG5sGGOMMWYyuLFhjDHGmMngxoYxxhhjJoMbG8YYY4yZDG5sGGOMMWYy/gfy5ynKZ37T1AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar\n",
        "import pickle\n",
        "\n",
        "# Suponiendo que `memory` es tu SequentialMemory\n",
        "with open('sequential_memory_cutv3.pkl', 'wb') as f:\n",
        "    pickle.dump(memory, f)"
      ],
      "metadata": {
        "id": "kyRS7sbTJ5ZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(env_name)"
      ],
      "metadata": {
        "id": "1A_ClTrEKEfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing part to calculate the mean reward\n",
        "weights_filename = checkpoint_dir + '/cutv3/dqn_{}_weights.h5f'.format(env_name)\n",
        "dqn.load_weights(weights_filename)\n",
        "env = Monitor(env, './video', force=True)\n",
        "history = dqn.test(env, nb_episodes=50, visualize=False)"
      ],
      "metadata": {
        "id": "OcA3Ee1uKKHF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50155d46-6f55-4aef-8547-1ad57726887d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 50 episodes ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1: reward: 22.000, steps: 1257\n",
            "Episode 2: reward: 24.000, steps: 962\n",
            "Episode 3: reward: 28.000, steps: 1093\n",
            "Episode 4: reward: 9.000, steps: 526\n",
            "Episode 5: reward: 17.000, steps: 851\n",
            "Episode 6: reward: 17.000, steps: 742\n",
            "Episode 7: reward: 24.000, steps: 1057\n",
            "Episode 8: reward: 18.000, steps: 1136\n",
            "Episode 9: reward: 14.000, steps: 643\n",
            "Episode 10: reward: 21.000, steps: 887\n",
            "Episode 11: reward: 25.000, steps: 1033\n",
            "Episode 12: reward: 28.000, steps: 1248\n",
            "Episode 13: reward: 19.000, steps: 851\n",
            "Episode 14: reward: 27.000, steps: 1230\n",
            "Episode 15: reward: 13.000, steps: 729\n",
            "Episode 16: reward: 23.000, steps: 1114\n",
            "Episode 17: reward: 12.000, steps: 695\n",
            "Episode 18: reward: 10.000, steps: 558\n",
            "Episode 19: reward: 21.000, steps: 951\n",
            "Episode 20: reward: 31.000, steps: 1811\n",
            "Episode 21: reward: 14.000, steps: 663\n",
            "Episode 22: reward: 13.000, steps: 1135\n",
            "Episode 23: reward: 15.000, steps: 655\n",
            "Episode 24: reward: 26.000, steps: 1256\n",
            "Episode 25: reward: 24.000, steps: 858\n",
            "Episode 26: reward: 16.000, steps: 943\n",
            "Episode 27: reward: 22.000, steps: 890\n",
            "Episode 28: reward: 19.000, steps: 815\n",
            "Episode 29: reward: 10.000, steps: 760\n",
            "Episode 30: reward: 16.000, steps: 968\n",
            "Episode 31: reward: 15.000, steps: 848\n",
            "Episode 32: reward: 13.000, steps: 734\n",
            "Episode 33: reward: 20.000, steps: 869\n",
            "Episode 34: reward: 12.000, steps: 544\n",
            "Episode 35: reward: 22.000, steps: 919\n",
            "Episode 36: reward: 12.000, steps: 699\n",
            "Episode 37: reward: 31.000, steps: 1467\n",
            "Episode 38: reward: 29.000, steps: 1442\n",
            "Episode 39: reward: 10.000, steps: 521\n",
            "Episode 40: reward: 12.000, steps: 642\n",
            "Episode 41: reward: 22.000, steps: 855\n",
            "Episode 42: reward: 24.000, steps: 1012\n",
            "Episode 43: reward: 19.000, steps: 1271\n",
            "Episode 44: reward: 24.000, steps: 911\n",
            "Episode 45: reward: 18.000, steps: 899\n",
            "Episode 46: reward: 28.000, steps: 1503\n",
            "Episode 47: reward: 20.000, steps: 918\n",
            "Episode 48: reward: 21.000, steps: 870\n",
            "Episode 49: reward: 22.000, steps: 1162\n",
            "Episode 50: reward: 15.000, steps: 793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access episode rewards\n",
        "episode_rewards = history.history['episode_reward']\n",
        "\n",
        "# Calcular el promedio\n",
        "promedio = np.mean(episode_rewards)\n",
        "\n",
        "print(f\"Recompensa promedio: {promedio}\")"
      ],
      "metadata": {
        "id": "WjJks1wzLFTV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54c3b19b-d178-4530-ba07-4b6eeae58e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recompensa promedio: 19.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento parte 3"
      ],
      "metadata": {
        "id": "E41TMUkd2qLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = SequentialMemory(limit=330000, window_length=WINDOW_LENGTH)"
      ],
      "metadata": {
        "id": "qHZDIkm-ven-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicamos el beneficio de utilizar todas las trazas (entrenamiento más estable)"
      ],
      "metadata": {
        "id": "x2z6i9nNudZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar\n",
        "import pickle\n",
        "\n",
        "with open('sequential_memory_cut.pkl', 'rb') as f:\n",
        "    memory = pickle.load(f)"
      ],
      "metadata": {
        "id": "qw53To9h3FkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(env_name)\n",
        "env = LifeTerminatingWrapper(env)"
      ],
      "metadata": {
        "id": "sUq0AYiC6Uhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploracion 1 a 0.1, # steps -> 400k\n",
        "nb_steps=50000\n",
        "nb_steps_annealing=50000\n",
        "nb_steps_warmup=50000\n",
        "\n",
        "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(),\n",
        "                              attr='eps',\n",
        "                              value_max=0.4, #0.22 # 0.24 # 0.35\n",
        "                              value_min=0.2, # 0.08\n",
        "                              value_test=0.0,\n",
        "                              nb_steps=nb_steps_annealing)\n",
        "\n",
        "\n",
        "dqn = DQNAgent(model=model,\n",
        "               nb_actions=nb_actions,\n",
        "               policy=policy,\n",
        "               memory=memory,\n",
        "               processor=processor,\n",
        "               nb_steps_warmup=nb_steps_warmup, #30000\n",
        "               enable_double_dqn=True,\n",
        "               gamma=0.99, # 0.99\n",
        "               target_model_update=8500,\n",
        "               train_interval=4,\n",
        "               delta_clip=1.0) # si el loss no baja, probar bajarlo a 0.5\n",
        "\n",
        "dqn.compile(Adam(learning_rate=0.0001), metrics=['mae']) # antes 0.00025"
      ],
      "metadata": {
        "id": "oOBhxrn5puH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_filename = checkpoint_dir + '/cutv3/dqn_{}_weights.h5f'.format(env_name)\n",
        "dqn.load_weights(weights_filename)"
      ],
      "metadata": {
        "id": "wEAWUHaHqTM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(checkpoint_dir, 'cutv4/dqn_SpaceInvaders-v0_weights.h5f')\n",
        "reward_log_path = os.path.join(checkpoint_dir, 'logs/episode_rewards_cutv4.npy')\n",
        "\n",
        "checkpoint_callback = SaveCheckpointCallback(interval=10000, path_template=checkpoint_path, reward_log_path=reward_log_path)\n",
        "\n",
        "dqn.fit(env,\n",
        "        nb_steps=nb_steps,\n",
        "        visualize=False,\n",
        "        verbose=2,\n",
        "        callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "id": "IK-tFSZtqXp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploracion 1 a 0.1, # steps -> 400k\n",
        "nb_steps = 50000\n",
        "nb_steps_annealing = 50000\n",
        "nb_steps_warmup=0\n",
        "\n",
        "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(),\n",
        "                              attr='eps',\n",
        "                              value_max=0.1, #0.22 # 0.24 # 0.35\n",
        "                              value_min=0.08, # 0.08\n",
        "                              value_test=0.0,\n",
        "                              nb_steps=nb_steps_annealing)\n",
        "\n",
        "\n",
        "dqn = DQNAgent(model=model,\n",
        "               nb_actions=nb_actions,\n",
        "               policy=policy,\n",
        "               memory=memory,\n",
        "               processor=processor,\n",
        "               nb_steps_warmup=nb_steps_warmup, #30000\n",
        "               enable_double_dqn=True,\n",
        "               gamma=0.99, # 0.99\n",
        "               target_model_update=8500,\n",
        "               train_interval=4,\n",
        "               delta_clip=1.0) # si el loss no baja, probar bajarlo a 0.5\n",
        "\n",
        "dqn.compile(Adam(learning_rate=0.0001), metrics=['mae']) # antes 0.00025"
      ],
      "metadata": {
        "id": "F0iL00662lIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_filename = checkpoint_dir + '/cutv3/dqn_{}_weights.h5f'.format(env_name)\n",
        "dqn.load_weights(weights_filename)"
      ],
      "metadata": {
        "id": "UAjEKxUp4_HE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = os.path.join(checkpoint_dir, 'cutv4/dqn_SpaceInvaders-v0_weights.h5f')\n",
        "reward_log_path = os.path.join(checkpoint_dir, 'logs/episode_rewards_cutv4.npy')\n",
        "\n",
        "checkpoint_callback = SaveCheckpointCallback(interval=10000, path_template=checkpoint_path, reward_log_path=reward_log_path)\n",
        "\n",
        "dqn.fit(env,\n",
        "        nb_steps=nb_steps,\n",
        "        visualize=False,\n",
        "        verbose=2,\n",
        "        callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cvg7o6B55HyX",
        "outputId": "8ea623a8-c851-4d68-ffb4-b90dd4840d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 50000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   286/50000: episode: 1, duration: 30.439s, episode steps: 286, steps per second:   9, episode reward: 10.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 3.332 [0.000, 5.000],  loss: 0.017933, mae: 1.482627, mean_q: 1.804475, mean_eps: 0.099942\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "   782/50000: episode: 2, duration: 41.960s, episode steps: 496, steps per second:  12, episode reward: 12.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.698 [0.000, 5.000],  loss: 0.014875, mae: 1.505839, mean_q: 1.832015, mean_eps: 0.099786\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  1008/50000: episode: 3, duration: 18.895s, episode steps: 226, steps per second:  12, episode reward:  8.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 1.845 [0.000, 5.000],  loss: 0.016516, mae: 1.484330, mean_q: 1.806317, mean_eps: 0.099642\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  1466/50000: episode: 4, duration: 39.516s, episode steps: 458, steps per second:  12, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.635 [0.000, 5.000],  loss: 0.016968, mae: 1.485505, mean_q: 1.806931, mean_eps: 0.099506\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  1988/50000: episode: 5, duration: 44.345s, episode steps: 522, steps per second:  12, episode reward: 13.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.623 [0.000, 5.000],  loss: 0.016417, mae: 1.484986, mean_q: 1.804729, mean_eps: 0.099310\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  2189/50000: episode: 6, duration: 17.142s, episode steps: 201, steps per second:  12, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.811 [0.000, 5.000],  loss: 0.016074, mae: 1.492680, mean_q: 1.813995, mean_eps: 0.099165\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  2483/50000: episode: 7, duration: 25.256s, episode steps: 294, steps per second:  12, episode reward:  7.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.629 [0.000, 5.000],  loss: 0.014676, mae: 1.500765, mean_q: 1.823452, mean_eps: 0.099066\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  2738/50000: episode: 8, duration: 19.733s, episode steps: 255, steps per second:  13, episode reward:  8.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 1.804 [0.000, 5.000],  loss: 0.017335, mae: 1.488711, mean_q: 1.806824, mean_eps: 0.098956\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  3015/50000: episode: 9, duration: 20.406s, episode steps: 277, steps per second:  14, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.011 [0.000, 5.000],  loss: 0.012919, mae: 1.491056, mean_q: 1.812138, mean_eps: 0.098850\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  3248/50000: episode: 10, duration: 16.366s, episode steps: 233, steps per second:  14, episode reward:  8.000, mean reward:  0.034 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.015002, mae: 1.491367, mean_q: 1.811175, mean_eps: 0.098748\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  3499/50000: episode: 11, duration: 18.119s, episode steps: 251, steps per second:  14, episode reward:  8.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.853 [0.000, 5.000],  loss: 0.013807, mae: 1.492028, mean_q: 1.812574, mean_eps: 0.098651\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  3697/50000: episode: 12, duration: 14.305s, episode steps: 198, steps per second:  14, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.763 [0.000, 5.000],  loss: 0.017202, mae: 1.491876, mean_q: 1.809677, mean_eps: 0.098561\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  4073/50000: episode: 13, duration: 26.485s, episode steps: 376, steps per second:  14, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.229 [0.000, 5.000],  loss: 0.015092, mae: 1.500508, mean_q: 1.823621, mean_eps: 0.098446\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  4266/50000: episode: 14, duration: 13.471s, episode steps: 193, steps per second:  14, episode reward:  6.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.119 [0.000, 5.000],  loss: 0.013120, mae: 1.474469, mean_q: 1.792924, mean_eps: 0.098332\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  5032/50000: episode: 15, duration: 54.139s, episode steps: 766, steps per second:  14, episode reward: 19.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.258 [0.000, 5.000],  loss: 0.015620, mae: 1.496843, mean_q: 1.817645, mean_eps: 0.098141\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  5653/50000: episode: 16, duration: 44.242s, episode steps: 621, steps per second:  14, episode reward: 16.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.188 [0.000, 5.000],  loss: 0.015700, mae: 1.465389, mean_q: 1.778395, mean_eps: 0.097863\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  5916/50000: episode: 17, duration: 19.576s, episode steps: 263, steps per second:  13, episode reward:  7.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 3.190 [0.000, 5.000],  loss: 0.013736, mae: 1.470465, mean_q: 1.785124, mean_eps: 0.097686\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  6348/50000: episode: 18, duration: 30.342s, episode steps: 432, steps per second:  14, episode reward: 11.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 3.111 [0.000, 5.000],  loss: 0.014874, mae: 1.481013, mean_q: 1.797330, mean_eps: 0.097548\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  6675/50000: episode: 19, duration: 23.063s, episode steps: 327, steps per second:  14, episode reward:  8.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.902 [0.000, 5.000],  loss: 0.014340, mae: 1.501937, mean_q: 1.823884, mean_eps: 0.097396\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  6855/50000: episode: 20, duration: 11.903s, episode steps: 180, steps per second:  15, episode reward:  1.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 3.511 [0.000, 5.000],  loss: 0.015446, mae: 1.490625, mean_q: 1.808864, mean_eps: 0.097294\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  7099/50000: episode: 21, duration: 17.847s, episode steps: 244, steps per second:  14, episode reward:  6.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.152 [0.000, 5.000],  loss: 0.014775, mae: 1.463430, mean_q: 1.776279, mean_eps: 0.097210\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  7315/50000: episode: 22, duration: 14.995s, episode steps: 216, steps per second:  14, episode reward:  6.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.241 [0.000, 5.000],  loss: 0.014806, mae: 1.495644, mean_q: 1.815732, mean_eps: 0.097118\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  7515/50000: episode: 23, duration: 13.953s, episode steps: 200, steps per second:  14, episode reward:  4.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.745 [0.000, 5.000],  loss: 0.014134, mae: 1.496897, mean_q: 1.817246, mean_eps: 0.097034\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  7791/50000: episode: 24, duration: 18.698s, episode steps: 276, steps per second:  15, episode reward:  9.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.116 [0.000, 5.000],  loss: 0.015906, mae: 1.466426, mean_q: 1.777793, mean_eps: 0.096939\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  8356/50000: episode: 25, duration: 40.523s, episode steps: 565, steps per second:  14, episode reward: 16.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.015002, mae: 1.474745, mean_q: 1.790780, mean_eps: 0.096771\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  8532/50000: episode: 26, duration: 13.710s, episode steps: 176, steps per second:  13, episode reward:  4.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.807 [0.000, 5.000],  loss: 0.017688, mae: 1.520748, mean_q: 1.845186, mean_eps: 0.096623\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  8937/50000: episode: 27, duration: 28.409s, episode steps: 405, steps per second:  14, episode reward: 11.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 1.768 [0.000, 5.000],  loss: 0.015451, mae: 1.479449, mean_q: 1.795189, mean_eps: 0.096506\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  9663/50000: episode: 28, duration: 50.973s, episode steps: 726, steps per second:  14, episode reward: 20.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.208 [0.000, 5.000],  loss: 0.015311, mae: 1.487544, mean_q: 1.806249, mean_eps: 0.096280\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "  9923/50000: episode: 29, duration: 17.552s, episode steps: 260, steps per second:  15, episode reward:  7.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.619 [0.000, 5.000],  loss: 0.014059, mae: 1.484625, mean_q: 1.804244, mean_eps: 0.096083\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 10511/50000: episode: 30, duration: 41.380s, episode steps: 588, steps per second:  14, episode reward: 16.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.013961, mae: 1.488325, mean_q: 1.808057, mean_eps: 0.095914\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 10758/50000: episode: 31, duration: 17.146s, episode steps: 247, steps per second:  14, episode reward:  8.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.340 [0.000, 5.000],  loss: 0.014011, mae: 1.490589, mean_q: 1.808542, mean_eps: 0.095746\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 11181/50000: episode: 32, duration: 29.371s, episode steps: 423, steps per second:  14, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.014953, mae: 1.463290, mean_q: 1.774224, mean_eps: 0.095612\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 11465/50000: episode: 33, duration: 21.222s, episode steps: 284, steps per second:  13, episode reward:  8.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.015900, mae: 1.489162, mean_q: 1.805304, mean_eps: 0.095470\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 11750/50000: episode: 34, duration: 19.797s, episode steps: 285, steps per second:  14, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 1.681 [0.000, 5.000],  loss: 0.011882, mae: 1.472789, mean_q: 1.788299, mean_eps: 0.095357\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 11981/50000: episode: 35, duration: 17.005s, episode steps: 231, steps per second:  14, episode reward:  7.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.281 [0.000, 5.000],  loss: 0.014452, mae: 1.462599, mean_q: 1.773936, mean_eps: 0.095254\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 12834/50000: episode: 36, duration: 59.598s, episode steps: 853, steps per second:  14, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.896 [0.000, 5.000],  loss: 0.016588, mae: 1.475993, mean_q: 1.790725, mean_eps: 0.095037\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 13088/50000: episode: 37, duration: 17.041s, episode steps: 254, steps per second:  15, episode reward:  7.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.650 [0.000, 5.000],  loss: 0.016940, mae: 1.469398, mean_q: 1.781743, mean_eps: 0.094816\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 13214/50000: episode: 38, duration: 9.446s, episode steps: 126, steps per second:  13, episode reward:  1.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: 0.014640, mae: 1.484123, mean_q: 1.800198, mean_eps: 0.094740\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 13941/50000: episode: 39, duration: 48.633s, episode steps: 727, steps per second:  15, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.717 [0.000, 5.000],  loss: 0.014580, mae: 1.471741, mean_q: 1.784912, mean_eps: 0.094569\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 14194/50000: episode: 40, duration: 17.949s, episode steps: 253, steps per second:  14, episode reward:  8.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.862 [0.000, 5.000],  loss: 0.016855, mae: 1.503161, mean_q: 1.824253, mean_eps: 0.094373\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 14437/50000: episode: 41, duration: 17.247s, episode steps: 243, steps per second:  14, episode reward:  8.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.011924, mae: 1.448956, mean_q: 1.758224, mean_eps: 0.094274\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 15038/50000: episode: 42, duration: 41.153s, episode steps: 601, steps per second:  15, episode reward: 15.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.014792, mae: 1.480505, mean_q: 1.793203, mean_eps: 0.094105\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 15287/50000: episode: 43, duration: 16.513s, episode steps: 249, steps per second:  15, episode reward:  9.000, mean reward:  0.036 [ 0.000,  1.000], mean action: 2.936 [0.000, 5.000],  loss: 0.015041, mae: 1.454740, mean_q: 1.763024, mean_eps: 0.093935\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 15776/50000: episode: 44, duration: 33.160s, episode steps: 489, steps per second:  15, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.933 [0.000, 5.000],  loss: 0.012571, mae: 1.478666, mean_q: 1.793160, mean_eps: 0.093788\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 15999/50000: episode: 45, duration: 15.815s, episode steps: 223, steps per second:  14, episode reward:  7.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.045 [0.000, 5.000],  loss: 0.015497, mae: 1.467928, mean_q: 1.778633, mean_eps: 0.093646\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 16446/50000: episode: 46, duration: 30.761s, episode steps: 447, steps per second:  15, episode reward: 11.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.013550, mae: 1.459702, mean_q: 1.769435, mean_eps: 0.093511\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 16788/50000: episode: 47, duration: 22.354s, episode steps: 342, steps per second:  15, episode reward: 13.000, mean reward:  0.038 [ 0.000,  1.000], mean action: 2.146 [0.000, 5.000],  loss: 0.012817, mae: 1.504079, mean_q: 1.824020, mean_eps: 0.093354\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 17064/50000: episode: 48, duration: 20.072s, episode steps: 276, steps per second:  14, episode reward:  9.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.016627, mae: 1.472156, mean_q: 1.782251, mean_eps: 0.093230\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 17284/50000: episode: 49, duration: 15.240s, episode steps: 220, steps per second:  14, episode reward:  5.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.014801, mae: 1.537461, mean_q: 1.862211, mean_eps: 0.093131\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 17653/50000: episode: 50, duration: 25.794s, episode steps: 369, steps per second:  14, episode reward: 10.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.797 [0.000, 5.000],  loss: 0.012831, mae: 1.486004, mean_q: 1.800595, mean_eps: 0.093013\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 18233/50000: episode: 51, duration: 39.784s, episode steps: 580, steps per second:  15, episode reward: 13.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.012753, mae: 1.511759, mean_q: 1.832441, mean_eps: 0.092822\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 19297/50000: episode: 52, duration: 71.684s, episode steps: 1064, steps per second:  15, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.236 [0.000, 5.000],  loss: 0.014688, mae: 1.506778, mean_q: 1.827163, mean_eps: 0.092494\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 19551/50000: episode: 53, duration: 17.274s, episode steps: 254, steps per second:  15, episode reward:  9.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.014473, mae: 1.511244, mean_q: 1.832223, mean_eps: 0.092230\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 19754/50000: episode: 54, duration: 13.985s, episode steps: 203, steps per second:  15, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.946 [0.000, 5.000],  loss: 0.012726, mae: 1.488848, mean_q: 1.808724, mean_eps: 0.092139\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 19989/50000: episode: 55, duration: 16.126s, episode steps: 235, steps per second:  15, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.179 [0.000, 5.000],  loss: 0.014717, mae: 1.543726, mean_q: 1.872348, mean_eps: 0.092051\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 20588/50000: episode: 56, duration: 41.548s, episode steps: 599, steps per second:  14, episode reward: 15.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.014586, mae: 1.493469, mean_q: 1.811144, mean_eps: 0.091885\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 21360/50000: episode: 57, duration: 53.209s, episode steps: 772, steps per second:  15, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.014925, mae: 1.505512, mean_q: 1.825480, mean_eps: 0.091611\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 21636/50000: episode: 58, duration: 19.210s, episode steps: 276, steps per second:  14, episode reward:  8.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.196 [0.000, 5.000],  loss: 0.015967, mae: 1.501919, mean_q: 1.821008, mean_eps: 0.091402\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 22153/50000: episode: 59, duration: 35.611s, episode steps: 517, steps per second:  15, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.014915, mae: 1.498774, mean_q: 1.815449, mean_eps: 0.091242\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 22407/50000: episode: 60, duration: 16.987s, episode steps: 254, steps per second:  15, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.409 [0.000, 5.000],  loss: 0.013022, mae: 1.522675, mean_q: 1.846676, mean_eps: 0.091088\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 22676/50000: episode: 61, duration: 20.037s, episode steps: 269, steps per second:  13, episode reward:  9.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.059 [0.000, 5.000],  loss: 0.012511, mae: 1.491774, mean_q: 1.806337, mean_eps: 0.090984\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 22907/50000: episode: 62, duration: 16.035s, episode steps: 231, steps per second:  14, episode reward:  7.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 1.623 [0.000, 5.000],  loss: 0.012235, mae: 1.493178, mean_q: 1.809432, mean_eps: 0.090884\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 23265/50000: episode: 63, duration: 25.235s, episode steps: 358, steps per second:  14, episode reward: 10.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 3.045 [0.000, 5.000],  loss: 0.014500, mae: 1.480676, mean_q: 1.792587, mean_eps: 0.090766\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 23491/50000: episode: 64, duration: 15.335s, episode steps: 226, steps per second:  15, episode reward:  6.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.013296, mae: 1.531738, mean_q: 1.857349, mean_eps: 0.090649\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 23686/50000: episode: 65, duration: 13.738s, episode steps: 195, steps per second:  14, episode reward:  5.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.014702, mae: 1.499165, mean_q: 1.817271, mean_eps: 0.090565\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 23962/50000: episode: 66, duration: 18.413s, episode steps: 276, steps per second:  15, episode reward:  7.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 3.424 [0.000, 5.000],  loss: 0.013823, mae: 1.512701, mean_q: 1.831596, mean_eps: 0.090470\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 24349/50000: episode: 67, duration: 27.293s, episode steps: 387, steps per second:  14, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 3.300 [0.000, 5.000],  loss: 0.014345, mae: 1.502629, mean_q: 1.821357, mean_eps: 0.090338\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 24597/50000: episode: 68, duration: 16.818s, episode steps: 248, steps per second:  15, episode reward:  8.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.278 [0.000, 5.000],  loss: 0.017512, mae: 1.504201, mean_q: 1.821955, mean_eps: 0.090210\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 24979/50000: episode: 69, duration: 26.805s, episode steps: 382, steps per second:  14, episode reward:  9.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.730 [0.000, 5.000],  loss: 0.013201, mae: 1.478215, mean_q: 1.789656, mean_eps: 0.090085\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 25375/50000: episode: 70, duration: 27.302s, episode steps: 396, steps per second:  15, episode reward: 14.000, mean reward:  0.035 [ 0.000,  1.000], mean action: 2.336 [0.000, 5.000],  loss: 0.014324, mae: 1.512531, mean_q: 1.833083, mean_eps: 0.089930\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 25562/50000: episode: 71, duration: 13.252s, episode steps: 187, steps per second:  14, episode reward:  5.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.267 [0.000, 5.000],  loss: 0.012788, mae: 1.479756, mean_q: 1.797180, mean_eps: 0.089813\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 26233/50000: episode: 72, duration: 47.399s, episode steps: 671, steps per second:  14, episode reward: 19.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.768 [0.000, 5.000],  loss: 0.015249, mae: 1.514060, mean_q: 1.834778, mean_eps: 0.089641\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 26508/50000: episode: 73, duration: 18.565s, episode steps: 275, steps per second:  15, episode reward:  8.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.284 [0.000, 5.000],  loss: 0.011810, mae: 1.538188, mean_q: 1.865227, mean_eps: 0.089452\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 26875/50000: episode: 74, duration: 26.332s, episode steps: 367, steps per second:  14, episode reward:  9.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.308 [0.000, 5.000],  loss: 0.015095, mae: 1.525332, mean_q: 1.848682, mean_eps: 0.089324\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 27125/50000: episode: 75, duration: 16.996s, episode steps: 250, steps per second:  15, episode reward:  6.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: 0.015104, mae: 1.524834, mean_q: 1.848615, mean_eps: 0.089200\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 27352/50000: episode: 76, duration: 15.710s, episode steps: 227, steps per second:  14, episode reward:  6.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.648 [0.000, 5.000],  loss: 0.013680, mae: 1.508069, mean_q: 1.827430, mean_eps: 0.089105\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 27624/50000: episode: 77, duration: 19.960s, episode steps: 272, steps per second:  14, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.489 [0.000, 5.000],  loss: 0.012819, mae: 1.527920, mean_q: 1.854242, mean_eps: 0.089006\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 28015/50000: episode: 78, duration: 26.871s, episode steps: 391, steps per second:  15, episode reward: 10.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.013641, mae: 1.521294, mean_q: 1.844096, mean_eps: 0.088873\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 28261/50000: episode: 79, duration: 16.793s, episode steps: 246, steps per second:  15, episode reward:  8.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.012358, mae: 1.508579, mean_q: 1.826886, mean_eps: 0.088745\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 28640/50000: episode: 80, duration: 26.452s, episode steps: 379, steps per second:  14, episode reward: 10.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.839 [0.000, 5.000],  loss: 0.012468, mae: 1.508847, mean_q: 1.826282, mean_eps: 0.088620\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 28953/50000: episode: 81, duration: 20.793s, episode steps: 313, steps per second:  15, episode reward: 10.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.642 [0.000, 5.000],  loss: 0.013780, mae: 1.518467, mean_q: 1.837543, mean_eps: 0.088482\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 29384/50000: episode: 82, duration: 30.246s, episode steps: 431, steps per second:  14, episode reward: 13.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.346 [0.000, 5.000],  loss: 0.013635, mae: 1.488214, mean_q: 1.800291, mean_eps: 0.088333\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 29610/50000: episode: 83, duration: 16.531s, episode steps: 226, steps per second:  14, episode reward:  7.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 1.854 [0.000, 5.000],  loss: 0.015103, mae: 1.501433, mean_q: 1.819510, mean_eps: 0.088202\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 30116/50000: episode: 84, duration: 34.227s, episode steps: 506, steps per second:  15, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 1.557 [0.000, 5.000],  loss: 0.014284, mae: 1.512571, mean_q: 1.831196, mean_eps: 0.088055\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 30655/50000: episode: 85, duration: 37.501s, episode steps: 539, steps per second:  14, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 1.596 [0.000, 5.000],  loss: 0.012933, mae: 1.514603, mean_q: 1.837812, mean_eps: 0.087846\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 30939/50000: episode: 86, duration: 18.767s, episode steps: 284, steps per second:  15, episode reward:  8.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.979 [0.000, 5.000],  loss: 0.014766, mae: 1.514081, mean_q: 1.830932, mean_eps: 0.087682\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 31171/50000: episode: 87, duration: 16.109s, episode steps: 232, steps per second:  14, episode reward:  5.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.272 [0.000, 5.000],  loss: 0.012497, mae: 1.539630, mean_q: 1.864095, mean_eps: 0.087578\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 31542/50000: episode: 88, duration: 25.872s, episode steps: 371, steps per second:  14, episode reward: 10.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.014680, mae: 1.522611, mean_q: 1.844106, mean_eps: 0.087458\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 31746/50000: episode: 89, duration: 13.985s, episode steps: 204, steps per second:  15, episode reward:  5.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.662 [0.000, 5.000],  loss: 0.012291, mae: 1.511821, mean_q: 1.834186, mean_eps: 0.087342\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 32249/50000: episode: 90, duration: 35.737s, episode steps: 503, steps per second:  14, episode reward: 13.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 1.809 [0.000, 5.000],  loss: 0.011926, mae: 1.522091, mean_q: 1.845753, mean_eps: 0.087201\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 33428/50000: episode: 91, duration: 81.200s, episode steps: 1179, steps per second:  15, episode reward: 16.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.044 [0.000, 5.000],  loss: 0.013367, mae: 1.508709, mean_q: 1.827940, mean_eps: 0.086865\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 33628/50000: episode: 92, duration: 14.166s, episode steps: 200, steps per second:  14, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.065 [0.000, 5.000],  loss: 0.013297, mae: 1.551176, mean_q: 1.879987, mean_eps: 0.086590\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 33862/50000: episode: 93, duration: 16.009s, episode steps: 234, steps per second:  15, episode reward:  7.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.011109, mae: 1.535270, mean_q: 1.860994, mean_eps: 0.086502\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 34082/50000: episode: 94, duration: 15.116s, episode steps: 220, steps per second:  15, episode reward:  6.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.827 [0.000, 5.000],  loss: 0.012359, mae: 1.512190, mean_q: 1.833953, mean_eps: 0.086411\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 34331/50000: episode: 95, duration: 16.641s, episode steps: 249, steps per second:  15, episode reward:  8.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.084 [0.000, 5.000],  loss: 0.012073, mae: 1.552954, mean_q: 1.881778, mean_eps: 0.086318\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 34659/50000: episode: 96, duration: 23.051s, episode steps: 328, steps per second:  14, episode reward:  5.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.927 [0.000, 5.000],  loss: 0.014266, mae: 1.530370, mean_q: 1.854333, mean_eps: 0.086202\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 34854/50000: episode: 97, duration: 13.587s, episode steps: 195, steps per second:  14, episode reward:  3.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 1.523 [0.000, 5.000],  loss: 0.013803, mae: 1.528588, mean_q: 1.851766, mean_eps: 0.086098\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 35636/50000: episode: 98, duration: 53.862s, episode steps: 782, steps per second:  15, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.347 [0.000, 5.000],  loss: 0.015125, mae: 1.544228, mean_q: 1.870069, mean_eps: 0.085902\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 35829/50000: episode: 99, duration: 13.731s, episode steps: 193, steps per second:  14, episode reward:  6.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 1.969 [0.000, 5.000],  loss: 0.013040, mae: 1.530783, mean_q: 1.856221, mean_eps: 0.085707\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 36408/50000: episode: 100, duration: 39.313s, episode steps: 579, steps per second:  15, episode reward: 13.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.161 [0.000, 5.000],  loss: 0.013640, mae: 1.550121, mean_q: 1.879045, mean_eps: 0.085553\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 37213/50000: episode: 101, duration: 54.783s, episode steps: 805, steps per second:  15, episode reward: 22.000, mean reward:  0.027 [ 0.000,  1.000], mean action: 2.138 [0.000, 5.000],  loss: 0.014703, mae: 1.533027, mean_q: 1.855934, mean_eps: 0.085276\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 37593/50000: episode: 102, duration: 25.733s, episode steps: 380, steps per second:  15, episode reward: 11.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.124 [0.000, 5.000],  loss: 0.012572, mae: 1.548297, mean_q: 1.876993, mean_eps: 0.085038\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 37951/50000: episode: 103, duration: 25.193s, episode steps: 358, steps per second:  14, episode reward:  9.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.964 [0.000, 5.000],  loss: 0.014545, mae: 1.528538, mean_q: 1.852225, mean_eps: 0.084891\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 38191/50000: episode: 104, duration: 16.524s, episode steps: 240, steps per second:  15, episode reward:  4.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 1.775 [0.000, 5.000],  loss: 0.013474, mae: 1.540976, mean_q: 1.863898, mean_eps: 0.084772\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 38387/50000: episode: 105, duration: 13.792s, episode steps: 196, steps per second:  14, episode reward:  6.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.980 [0.000, 5.000],  loss: 0.013319, mae: 1.518269, mean_q: 1.838063, mean_eps: 0.084685\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 38755/50000: episode: 106, duration: 25.666s, episode steps: 368, steps per second:  14, episode reward:  9.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 1.636 [0.000, 5.000],  loss: 0.012059, mae: 1.518560, mean_q: 1.841170, mean_eps: 0.084572\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 39020/50000: episode: 107, duration: 18.829s, episode steps: 265, steps per second:  14, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 3.136 [0.000, 5.000],  loss: 0.013766, mae: 1.545805, mean_q: 1.871230, mean_eps: 0.084446\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 39515/50000: episode: 108, duration: 34.040s, episode steps: 495, steps per second:  15, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.994 [0.000, 5.000],  loss: 0.014108, mae: 1.535297, mean_q: 1.862370, mean_eps: 0.084294\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 39781/50000: episode: 109, duration: 18.057s, episode steps: 266, steps per second:  15, episode reward:  8.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.711 [0.000, 5.000],  loss: 0.013109, mae: 1.554341, mean_q: 1.883307, mean_eps: 0.084141\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 40400/50000: episode: 110, duration: 43.312s, episode steps: 619, steps per second:  14, episode reward: 18.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.012332, mae: 1.539408, mean_q: 1.866726, mean_eps: 0.083964\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 40656/50000: episode: 111, duration: 19.147s, episode steps: 256, steps per second:  13, episode reward:  8.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.266 [0.000, 5.000],  loss: 0.014057, mae: 1.540840, mean_q: 1.866652, mean_eps: 0.083790\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 40916/50000: episode: 112, duration: 17.571s, episode steps: 260, steps per second:  15, episode reward:  8.000, mean reward:  0.031 [ 0.000,  1.000], mean action: 2.765 [0.000, 5.000],  loss: 0.013109, mae: 1.543483, mean_q: 1.870659, mean_eps: 0.083686\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 41250/50000: episode: 113, duration: 23.701s, episode steps: 334, steps per second:  14, episode reward: 10.000, mean reward:  0.030 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.012093, mae: 1.512327, mean_q: 1.831170, mean_eps: 0.083567\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 41778/50000: episode: 114, duration: 34.910s, episode steps: 528, steps per second:  15, episode reward: 12.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.356 [0.000, 5.000],  loss: 0.014196, mae: 1.542549, mean_q: 1.868442, mean_eps: 0.083394\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 42021/50000: episode: 115, duration: 18.097s, episode steps: 243, steps per second:  13, episode reward:  7.000, mean reward:  0.029 [ 0.000,  1.000], mean action: 1.835 [0.000, 5.000],  loss: 0.011990, mae: 1.551643, mean_q: 1.879749, mean_eps: 0.083240\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 42213/50000: episode: 116, duration: 13.154s, episode steps: 192, steps per second:  15, episode reward:  3.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 1.693 [0.000, 5.000],  loss: 0.010104, mae: 1.507677, mean_q: 1.825706, mean_eps: 0.083153\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 42678/50000: episode: 117, duration: 32.069s, episode steps: 465, steps per second:  14, episode reward: 17.000, mean reward:  0.037 [ 0.000,  1.000], mean action: 1.673 [0.000, 5.000],  loss: 0.013290, mae: 1.536140, mean_q: 1.859443, mean_eps: 0.083022\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 43109/50000: episode: 118, duration: 30.188s, episode steps: 431, steps per second:  14, episode reward:  9.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 1.784 [0.000, 5.000],  loss: 0.012823, mae: 1.564479, mean_q: 1.894831, mean_eps: 0.082842\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 43390/50000: episode: 119, duration: 19.767s, episode steps: 281, steps per second:  14, episode reward:  6.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.014229, mae: 1.537631, mean_q: 1.860241, mean_eps: 0.082700\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 43935/50000: episode: 120, duration: 37.948s, episode steps: 545, steps per second:  14, episode reward: 15.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.266 [0.000, 5.000],  loss: 0.015044, mae: 1.570046, mean_q: 1.900709, mean_eps: 0.082535\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 44213/50000: episode: 121, duration: 20.979s, episode steps: 278, steps per second:  13, episode reward:  6.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.770 [0.000, 5.000],  loss: 0.012487, mae: 1.546409, mean_q: 1.874016, mean_eps: 0.082370\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 44606/50000: episode: 122, duration: 27.822s, episode steps: 393, steps per second:  14, episode reward: 10.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.361 [0.000, 5.000],  loss: 0.013212, mae: 1.559690, mean_q: 1.887595, mean_eps: 0.082236\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 44911/50000: episode: 123, duration: 20.836s, episode steps: 305, steps per second:  15, episode reward: 10.000, mean reward:  0.033 [ 0.000,  1.000], mean action: 1.997 [0.000, 5.000],  loss: 0.015365, mae: 1.575237, mean_q: 1.906158, mean_eps: 0.082097\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 45190/50000: episode: 124, duration: 20.547s, episode steps: 279, steps per second:  14, episode reward:  9.000, mean reward:  0.032 [ 0.000,  1.000], mean action: 2.104 [0.000, 5.000],  loss: 0.013588, mae: 1.556526, mean_q: 1.884573, mean_eps: 0.081980\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 45627/50000: episode: 125, duration: 29.833s, episode steps: 437, steps per second:  15, episode reward: 10.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.998 [0.000, 5.000],  loss: 0.015112, mae: 1.558672, mean_q: 1.887708, mean_eps: 0.081837\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 46110/50000: episode: 126, duration: 32.416s, episode steps: 483, steps per second:  15, episode reward: 10.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.012973, mae: 1.529921, mean_q: 1.852364, mean_eps: 0.081653\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 46412/50000: episode: 127, duration: 21.909s, episode steps: 302, steps per second:  14, episode reward:  5.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.013547, mae: 1.535876, mean_q: 1.862117, mean_eps: 0.081496\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 47444/50000: episode: 128, duration: 70.465s, episode steps: 1032, steps per second:  15, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.014314, mae: 1.569871, mean_q: 1.900243, mean_eps: 0.081230\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 47936/50000: episode: 129, duration: 33.114s, episode steps: 492, steps per second:  15, episode reward: 13.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.026 [0.000, 5.000],  loss: 0.014515, mae: 1.565036, mean_q: 1.894577, mean_eps: 0.080925\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 48494/50000: episode: 130, duration: 38.953s, episode steps: 558, steps per second:  14, episode reward: 13.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.708 [0.000, 5.000],  loss: 0.013270, mae: 1.543506, mean_q: 1.869982, mean_eps: 0.080714\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 49058/50000: episode: 131, duration: 38.802s, episode steps: 564, steps per second:  15, episode reward: 13.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 1.512 [0.000, 5.000],  loss: 0.013229, mae: 1.562694, mean_q: 1.891979, mean_eps: 0.080490\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 49250/50000: episode: 132, duration: 13.512s, episode steps: 192, steps per second:  14, episode reward:  2.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 0.995 [0.000, 5.000],  loss: 0.013943, mae: 1.522937, mean_q: 1.844271, mean_eps: 0.080338\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            " 49489/50000: episode: 133, duration: 16.388s, episode steps: 239, steps per second:  15, episode reward:  9.000, mean reward:  0.038 [ 0.000,  1.000], mean action: 1.937 [0.000, 5.000],  loss: 0.013277, mae: 1.602440, mean_q: 1.942056, mean_eps: 0.080252\n",
            "\n",
            "💾 Guardando pesos en: /content/gdrive/MyDrive/dqn_spaceinvaders_checkpoints/cutv4/dqn_SpaceInvaders-v0_weights.h5f\n",
            "done, took 3524.557 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7cc23dc88110>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "episode_rewards = np.load('logs/episode_rewards_cutv4.npy')\n",
        "\n",
        "plt.plot(episode_rewards)\n",
        "plt.xlabel('Episodio')\n",
        "plt.ylabel('Reward total')\n",
        "plt.title('Evolución del entrenamiento')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "A4VAada952zV",
        "outputId": "362308ed-2953-43b1-a15d-3d774ab90ee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar\n",
        "import pickle\n",
        "\n",
        "# Suponiendo que `memory` es tu SequentialMemory\n",
        "with open('sequential_memory_cutv4.pkl', 'wb') as f:\n",
        "    pickle.dump(memory, f)"
      ],
      "metadata": {
        "id": "RznMlTMO56-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(env_name)"
      ],
      "metadata": {
        "id": "kESpyuoj6DMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test"
      ],
      "metadata": {
        "id": "Z30LtwUR-ooH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing part to calculate the mean reward 02\n",
        "weights_filename = checkpoint_dir + '/cutv4/dqn_{}_weights.h5f'.format(env_name)\n",
        "dqn.load_weights(weights_filename)\n",
        "env = Monitor(env, './video', force=True)\n",
        "history = dqn.test(env, nb_episodes=50, visualize=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5P6kIxSAhvO",
        "outputId": "1a2f1fe5-472a-4369-c36b-bc7176993142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 50 episodes ...\n",
            "Episode 1: reward: 35.000, steps: 1809\n",
            "Episode 2: reward: 17.000, steps: 837\n",
            "Episode 3: reward: 21.000, steps: 800\n",
            "Episode 4: reward: 27.000, steps: 1133\n",
            "Episode 5: reward: 22.000, steps: 942\n",
            "Episode 6: reward: 19.000, steps: 1104\n",
            "Episode 7: reward: 22.000, steps: 1542\n",
            "Episode 8: reward: 29.000, steps: 1409\n",
            "Episode 9: reward: 20.000, steps: 992\n",
            "Episode 10: reward: 16.000, steps: 711\n",
            "Episode 11: reward: 34.000, steps: 1463\n",
            "Episode 12: reward: 16.000, steps: 870\n",
            "Episode 13: reward: 19.000, steps: 692\n",
            "Episode 14: reward: 23.000, steps: 1057\n",
            "Episode 15: reward: 21.000, steps: 1054\n",
            "Episode 16: reward: 20.000, steps: 663\n",
            "Episode 17: reward: 12.000, steps: 538\n",
            "Episode 18: reward: 22.000, steps: 917\n",
            "Episode 19: reward: 22.000, steps: 1084\n",
            "Episode 20: reward: 22.000, steps: 1010\n",
            "Episode 21: reward: 10.000, steps: 675\n",
            "Episode 22: reward: 11.000, steps: 643\n",
            "Episode 23: reward: 15.000, steps: 690\n",
            "Episode 24: reward: 20.000, steps: 1347\n",
            "Episode 25: reward: 27.000, steps: 995\n",
            "Episode 26: reward: 10.000, steps: 489\n",
            "Episode 27: reward: 22.000, steps: 900\n",
            "Episode 28: reward: 20.000, steps: 880\n",
            "Episode 29: reward: 27.000, steps: 1108\n",
            "Episode 30: reward: 25.000, steps: 976\n",
            "Episode 31: reward: 20.000, steps: 921\n",
            "Episode 32: reward: 16.000, steps: 704\n",
            "Episode 33: reward: 20.000, steps: 750\n",
            "Episode 34: reward: 13.000, steps: 737\n",
            "Episode 35: reward: 17.000, steps: 1278\n",
            "Episode 36: reward: 34.000, steps: 1926\n",
            "Episode 37: reward: 10.000, steps: 484\n",
            "Episode 38: reward: 19.000, steps: 883\n",
            "Episode 39: reward: 22.000, steps: 926\n",
            "Episode 40: reward: 15.000, steps: 659\n",
            "Episode 41: reward: 27.000, steps: 1110\n",
            "Episode 42: reward: 14.000, steps: 1488\n",
            "Episode 43: reward: 25.000, steps: 1309\n",
            "Episode 44: reward: 21.000, steps: 845\n",
            "Episode 45: reward: 26.000, steps: 1106\n",
            "Episode 46: reward: 26.000, steps: 1234\n",
            "Episode 47: reward: 10.000, steps: 753\n",
            "Episode 48: reward: 24.000, steps: 1158\n",
            "Episode 49: reward: 11.000, steps: 637\n",
            "Episode 50: reward: 29.000, steps: 1568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access episode rewards\n",
        "episode_rewards = history.history['episode_reward']\n",
        "\n",
        "# Calcular el promedio\n",
        "promedio = np.mean(episode_rewards)\n",
        "\n",
        "print(f\"Recompensa promedio: {promedio}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpQ0GzCjAriG",
        "outputId": "f0301258-2c21-4973-ddfa-a73e694340a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recompensa promedio: 20.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Código Edward (Después cambiamos el nombre de esta sección)"
      ],
      "metadata": {
        "id": "R2cKxphGu4_u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Código Luis (Después cambiamos el nombre de esta sección)"
      ],
      "metadata": {
        "id": "P_LoDa_fvHlS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Código Carlos (Arquitectura Dueling Network) ~Dueling Deep Q-Network:"
      ],
      "metadata": {
        "id": "lIClkG0tvIPa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EDlLcIIPUsf"
      },
      "outputs": [],
      "source": [
        "from rl.agents import DQNAgent\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FbbInVqR0sg"
      },
      "outputs": [],
      "source": [
        "def build_agent(model, actions):\n",
        "    policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1., value_min=0.01, value_test=0.005, nb_steps=1000000)\n",
        "    memory = SequentialMemory(limit=500000, window_length=4)\n",
        "    dqn = DQNAgent(model=model, memory=memory, policy=policy,\n",
        "                  enable_dueling_network=True, dueling_type='avg',\n",
        "                   nb_actions=nb_actions, nb_steps_warmup=1000,\n",
        "                   batch_size=32,\n",
        "                   processor=AtariProcessor()\n",
        "                  )\n",
        "    return dqn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnuIYPrTUE1X"
      },
      "outputs": [],
      "source": [
        "from rl.callbacks import ModelIntervalCheckpoint\n",
        "\n",
        "# Guardar el modelo cada 50,000 pasos\n",
        "checkpoint_callback = ModelIntervalCheckpoint(\n",
        "    filepath='checkpoints/dqn_weights_{step}.h5f',\n",
        "    interval=10000,  # cada 10,000 pasos\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tL513wUlUE1X"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs(\"checkpoints\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-jxyOrdR0cg"
      },
      "outputs": [],
      "source": [
        "dqn = build_agent(model, nb_actions)\n",
        "dqn.compile(Adam(learning_rate=1e-4))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La implementación del agente DQN presentada se justifica por su adecuación a entornos complejos como los videojuegos tipo Atari, donde las observaciones son visuales y secuenciales. Para ello, se emplea un procesador especializado (AtariProcessor) y una memoria de experiencia con window_length=4, lo que permite al agente capturar la dinámica temporal del entorno. El uso de la policy epsilon-greedy con decaimiento lineal favorece una exploración intensiva en las primeras etapas del entrenamiento y una explotación eficiente en las fases finales, distribuyendo el aprendizaje de forma progresiva y estable.\n",
        "\n",
        "Además, se activa la arquitectura Dueling DQN, que separa la estimación del valor del estado y la ventaja de cada acción, permitiendo al agente aprender de forma más robusta incluso en estados donde algunas acciones tienen poco efecto. Esta mejora arquitectónica, combinada con la memoria de repetición y un tamaño de lote adecuado, contribuye a reducir la varianza y mejorar la estabilidad del aprendizaje.\n",
        "\n",
        "Finalmente, el modelo se entrena con el optimizador Adam y se configura un sistema de guardado periódico que permite preservar versiones del agente a lo largo del entrenamiento, facilitando la recuperación y el análisis posterior del desempeño."
      ],
      "metadata": {
        "id": "PXY7DyFucMzb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK6SMHjHeRX2"
      },
      "source": [
        "#### Entrenamiento parte 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AR2u9_7LR0WI",
        "outputId": "f5b2e047-6e50-431c-baf7-3fa0fcbcc849"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⏱ Tiempo de inicio: 18:21:10\n",
            "Training for 300000 steps ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\curso\\anaconda3\\envs\\miar_rl\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2424: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    513/300000: episode: 1, duration: 5.703s, episode steps: 513, steps per second:  90, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\curso\\anaconda3\\envs\\miar_rl\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2424: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   1189/300000: episode: 2, duration: 51.488s, episode steps: 676, steps per second:  13, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.199296, mean_q: 0.938525, mean_eps: 0.998916\n",
            "   1706/300000: episode: 3, duration: 120.204s, episode steps: 517, steps per second:   4, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.027185, mean_q: 0.955640, mean_eps: 0.998567\n",
            "   2324/300000: episode: 4, duration: 141.814s, episode steps: 618, steps per second:   4, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.015326, mean_q: 0.961571, mean_eps: 0.998006\n",
            "   3138/300000: episode: 5, duration: 186.313s, episode steps: 814, steps per second:   4, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.012298, mean_q: 0.852844, mean_eps: 0.997297\n",
            "   3500/300000: episode: 6, duration: 82.863s, episode steps: 362, steps per second:   4, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.010441, mean_q: 0.794642, mean_eps: 0.996715\n",
            "   4131/300000: episode: 7, duration: 144.222s, episode steps: 631, steps per second:   4, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.360 [0.000, 5.000],  loss: 0.010650, mean_q: 0.847168, mean_eps: 0.996223\n",
            "   4652/300000: episode: 8, duration: 119.340s, episode steps: 521, steps per second:   4, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.010031, mean_q: 0.833450, mean_eps: 0.995653\n",
            "   5380/300000: episode: 9, duration: 166.550s, episode steps: 728, steps per second:   4, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: 0.008512, mean_q: 0.801495, mean_eps: 0.995035\n",
            "   6311/300000: episode: 10, duration: 212.658s, episode steps: 931, steps per second:   4, episode reward: 10.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.009074, mean_q: 0.757011, mean_eps: 0.994213\n",
            "   6980/300000: episode: 11, duration: 153.080s, episode steps: 669, steps per second:   4, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.009585, mean_q: 0.714388, mean_eps: 0.993421\n",
            "   7402/300000: episode: 12, duration: 96.462s, episode steps: 422, steps per second:   4, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.007699, mean_q: 0.693806, mean_eps: 0.992881\n",
            "   7765/300000: episode: 13, duration: 83.049s, episode steps: 363, steps per second:   4, episode reward:  6.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.008751, mean_q: 0.739306, mean_eps: 0.992493\n",
            "   8962/300000: episode: 14, duration: 274.595s, episode steps: 1197, steps per second:   4, episode reward: 20.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.007791, mean_q: 0.715231, mean_eps: 0.991721\n",
            "Step 10000: saving model to checkpoints/dqn_weights_10000.h5f\n",
            "  10129/300000: episode: 15, duration: 270.568s, episode steps: 1167, steps per second:   4, episode reward: 10.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.008586, mean_q: 0.662821, mean_eps: 0.990550\n",
            "  10799/300000: episode: 16, duration: 166.663s, episode steps: 670, steps per second:   4, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.011566, mean_q: 0.750392, mean_eps: 0.989641\n",
            "  11200/300000: episode: 17, duration: 105.402s, episode steps: 401, steps per second:   4, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.009164, mean_q: 0.733362, mean_eps: 0.989111\n",
            "  11893/300000: episode: 18, duration: 180.393s, episode steps: 693, steps per second:   4, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: 0.008845, mean_q: 0.765789, mean_eps: 0.988569\n",
            "  12573/300000: episode: 19, duration: 176.531s, episode steps: 680, steps per second:   4, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.008912, mean_q: 0.768963, mean_eps: 0.987890\n",
            "  13103/300000: episode: 20, duration: 134.514s, episode steps: 530, steps per second:   4, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.008193, mean_q: 0.762021, mean_eps: 0.987291\n",
            "  13743/300000: episode: 21, duration: 145.694s, episode steps: 640, steps per second:   4, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.007649, mean_q: 0.753008, mean_eps: 0.986712\n",
            "  14400/300000: episode: 22, duration: 149.834s, episode steps: 657, steps per second:   4, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.007371, mean_q: 0.767869, mean_eps: 0.986070\n",
            "  15073/300000: episode: 23, duration: 153.127s, episode steps: 673, steps per second:   4, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.007519, mean_q: 0.748557, mean_eps: 0.985411\n",
            "  15754/300000: episode: 24, duration: 154.794s, episode steps: 681, steps per second:   4, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.006628, mean_q: 0.736947, mean_eps: 0.984741\n",
            "  16931/300000: episode: 25, duration: 267.286s, episode steps: 1177, steps per second:   4, episode reward:  9.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.006886, mean_q: 0.732480, mean_eps: 0.983821\n",
            "  18176/300000: episode: 26, duration: 283.296s, episode steps: 1245, steps per second:   4, episode reward: 28.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.007468, mean_q: 0.709744, mean_eps: 0.982623\n",
            "  18801/300000: episode: 27, duration: 142.069s, episode steps: 625, steps per second:   4, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.007618, mean_q: 0.709009, mean_eps: 0.981697\n",
            "  19598/300000: episode: 28, duration: 181.696s, episode steps: 797, steps per second:   4, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.006916, mean_q: 0.694779, mean_eps: 0.980993\n",
            "  19985/300000: episode: 29, duration: 88.168s, episode steps: 387, steps per second:   4, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.006813, mean_q: 0.673920, mean_eps: 0.980407\n",
            "Step 20000: saving model to checkpoints/dqn_weights_20000.h5f\n",
            "  21111/300000: episode: 30, duration: 257.225s, episode steps: 1126, steps per second:   4, episode reward: 15.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.010249, mean_q: 0.821125, mean_eps: 0.979658\n",
            "  21840/300000: episode: 31, duration: 166.158s, episode steps: 729, steps per second:   4, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.008697, mean_q: 0.819776, mean_eps: 0.978740\n",
            "  22328/300000: episode: 32, duration: 111.442s, episode steps: 488, steps per second:   4, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.008308, mean_q: 0.808001, mean_eps: 0.978137\n",
            "  23137/300000: episode: 33, duration: 183.217s, episode steps: 809, steps per second:   4, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.007939, mean_q: 0.797738, mean_eps: 0.977495\n",
            "  24279/300000: episode: 34, duration: 257.379s, episode steps: 1142, steps per second:   4, episode reward: 11.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.007669, mean_q: 0.791415, mean_eps: 0.976530\n",
            "  25106/300000: episode: 35, duration: 186.729s, episode steps: 827, steps per second:   4, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.007848, mean_q: 0.790377, mean_eps: 0.975555\n",
            "  25757/300000: episode: 36, duration: 147.096s, episode steps: 651, steps per second:   4, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.007439, mean_q: 0.797625, mean_eps: 0.974823\n",
            "  26271/300000: episode: 37, duration: 116.185s, episode steps: 514, steps per second:   4, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.007437, mean_q: 0.789041, mean_eps: 0.974247\n",
            "  26955/300000: episode: 38, duration: 154.163s, episode steps: 684, steps per second:   4, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.007602, mean_q: 0.801001, mean_eps: 0.973654\n",
            "  27780/300000: episode: 39, duration: 186.801s, episode steps: 825, steps per second:   4, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.007182, mean_q: 0.794714, mean_eps: 0.972907\n",
            "  28596/300000: episode: 40, duration: 184.151s, episode steps: 816, steps per second:   4, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.006956, mean_q: 0.783611, mean_eps: 0.972094\n",
            "  29275/300000: episode: 41, duration: 153.453s, episode steps: 679, steps per second:   4, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.006440, mean_q: 0.797663, mean_eps: 0.971354\n",
            "  29681/300000: episode: 42, duration: 91.797s, episode steps: 406, steps per second:   4, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.006112, mean_q: 0.785129, mean_eps: 0.970817\n",
            "Step 30000: saving model to checkpoints/dqn_weights_30000.h5f\n",
            "  30350/300000: episode: 43, duration: 151.697s, episode steps: 669, steps per second:   4, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.008760, mean_q: 0.839578, mean_eps: 0.970285\n",
            "  30981/300000: episode: 44, duration: 142.056s, episode steps: 631, steps per second:   4, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.009168, mean_q: 0.908041, mean_eps: 0.969642\n",
            "  31385/300000: episode: 45, duration: 91.293s, episode steps: 404, steps per second:   4, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.624 [0.000, 5.000],  loss: 0.008591, mean_q: 0.896279, mean_eps: 0.969129\n",
            "  31770/300000: episode: 46, duration: 86.895s, episode steps: 385, steps per second:   4, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.696 [0.000, 5.000],  loss: 0.008710, mean_q: 0.909663, mean_eps: 0.968739\n",
            "  32197/300000: episode: 47, duration: 96.447s, episode steps: 427, steps per second:   4, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.008291, mean_q: 0.916325, mean_eps: 0.968337\n",
            "  32783/300000: episode: 48, duration: 132.371s, episode steps: 586, steps per second:   4, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.008237, mean_q: 0.908347, mean_eps: 0.967835\n",
            "  33481/300000: episode: 49, duration: 157.546s, episode steps: 698, steps per second:   4, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.007931, mean_q: 0.935019, mean_eps: 0.967200\n",
            "  34599/300000: episode: 50, duration: 253.727s, episode steps: 1118, steps per second:   4, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.008040, mean_q: 0.924329, mean_eps: 0.966301\n",
            "  35105/300000: episode: 51, duration: 114.120s, episode steps: 506, steps per second:   4, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.008234, mean_q: 0.918342, mean_eps: 0.965497\n",
            "  35790/300000: episode: 52, duration: 154.123s, episode steps: 685, steps per second:   4, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.007822, mean_q: 0.921513, mean_eps: 0.964907\n",
            "  36952/300000: episode: 53, duration: 261.813s, episode steps: 1162, steps per second:   4, episode reward: 19.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.007938, mean_q: 0.915890, mean_eps: 0.963993\n",
            "  38077/300000: episode: 54, duration: 253.200s, episode steps: 1125, steps per second:   4, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.007135, mean_q: 0.913929, mean_eps: 0.962861\n",
            "  38861/300000: episode: 55, duration: 176.628s, episode steps: 784, steps per second:   4, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.007685, mean_q: 0.908552, mean_eps: 0.961916\n",
            "  39363/300000: episode: 56, duration: 113.666s, episode steps: 502, steps per second:   4, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.305 [0.000, 5.000],  loss: 0.007463, mean_q: 0.904116, mean_eps: 0.961280\n",
            "  39855/300000: episode: 57, duration: 111.093s, episode steps: 492, steps per second:   4, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.007116, mean_q: 0.908187, mean_eps: 0.960788\n",
            "Step 40000: saving model to checkpoints/dqn_weights_40000.h5f\n",
            "  40328/300000: episode: 58, duration: 107.251s, episode steps: 473, steps per second:   4, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.009506, mean_q: 0.984332, mean_eps: 0.960310\n",
            "  40857/300000: episode: 59, duration: 119.558s, episode steps: 529, steps per second:   4, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.009620, mean_q: 1.016761, mean_eps: 0.959814\n",
            "  41218/300000: episode: 60, duration: 81.497s, episode steps: 361, steps per second:   4, episode reward:  6.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.009198, mean_q: 1.027224, mean_eps: 0.959373\n",
            "  41829/300000: episode: 61, duration: 138.325s, episode steps: 611, steps per second:   4, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.008870, mean_q: 1.019080, mean_eps: 0.958892\n",
            "  42612/300000: episode: 62, duration: 176.299s, episode steps: 783, steps per second:   4, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.008557, mean_q: 1.035984, mean_eps: 0.958202\n",
            "  43137/300000: episode: 63, duration: 118.266s, episode steps: 525, steps per second:   4, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: 0.008229, mean_q: 1.013755, mean_eps: 0.957555\n",
            "  43696/300000: episode: 64, duration: 127.135s, episode steps: 559, steps per second:   4, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.008323, mean_q: 1.047641, mean_eps: 0.957018\n",
            "  44300/300000: episode: 65, duration: 140.205s, episode steps: 604, steps per second:   4, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.007915, mean_q: 1.037329, mean_eps: 0.956442\n",
            "  45151/300000: episode: 66, duration: 192.182s, episode steps: 851, steps per second:   4, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.007771, mean_q: 1.025259, mean_eps: 0.955722\n",
            "  45500/300000: episode: 67, duration: 79.006s, episode steps: 349, steps per second:   4, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.007771, mean_q: 1.012975, mean_eps: 0.955128\n",
            "  46714/300000: episode: 68, duration: 273.787s, episode steps: 1214, steps per second:   4, episode reward: 22.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.008016, mean_q: 1.034028, mean_eps: 0.954355\n",
            "  47381/300000: episode: 69, duration: 150.548s, episode steps: 667, steps per second:   4, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.007708, mean_q: 1.028591, mean_eps: 0.953423\n",
            "  48391/300000: episode: 70, duration: 227.768s, episode steps: 1010, steps per second:   4, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.008055, mean_q: 1.042035, mean_eps: 0.952593\n",
            "  48779/300000: episode: 71, duration: 87.792s, episode steps: 388, steps per second:   4, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.007311, mean_q: 1.012482, mean_eps: 0.951901\n",
            "Step 50000: saving model to checkpoints/dqn_weights_50000.h5f\n",
            "  50146/300000: episode: 72, duration: 308.384s, episode steps: 1367, steps per second:   4, episode reward: 15.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.007719, mean_q: 1.038019, mean_eps: 0.951033\n",
            "  50964/300000: episode: 73, duration: 184.584s, episode steps: 818, steps per second:   4, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.010462, mean_q: 1.207531, mean_eps: 0.949951\n",
            "  51488/300000: episode: 74, duration: 118.155s, episode steps: 524, steps per second:   4, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.009286, mean_q: 1.214471, mean_eps: 0.949287\n",
            "  52537/300000: episode: 75, duration: 236.533s, episode steps: 1049, steps per second:   4, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.008986, mean_q: 1.203691, mean_eps: 0.948508\n",
            "  53210/300000: episode: 76, duration: 152.160s, episode steps: 673, steps per second:   4, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.009118, mean_q: 1.201260, mean_eps: 0.947656\n",
            "  53833/300000: episode: 77, duration: 140.866s, episode steps: 623, steps per second:   4, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.008680, mean_q: 1.180957, mean_eps: 0.947014\n",
            "  54884/300000: episode: 78, duration: 237.174s, episode steps: 1051, steps per second:   4, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.008836, mean_q: 1.195814, mean_eps: 0.946186\n",
            "  55567/300000: episode: 79, duration: 154.144s, episode steps: 683, steps per second:   4, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.008377, mean_q: 1.185224, mean_eps: 0.945327\n",
            "  56473/300000: episode: 80, duration: 204.811s, episode steps: 906, steps per second:   4, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.008764, mean_q: 1.189235, mean_eps: 0.944541\n",
            "  57368/300000: episode: 81, duration: 214.958s, episode steps: 895, steps per second:   4, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: 0.008536, mean_q: 1.176192, mean_eps: 0.943649\n",
            "  57923/300000: episode: 82, duration: 135.619s, episode steps: 555, steps per second:   4, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.007927, mean_q: 1.172882, mean_eps: 0.942931\n",
            "  58574/300000: episode: 83, duration: 165.637s, episode steps: 651, steps per second:   4, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.373 [0.000, 5.000],  loss: 0.008276, mean_q: 1.175971, mean_eps: 0.942334\n",
            "  59187/300000: episode: 84, duration: 149.771s, episode steps: 613, steps per second:   4, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.008021, mean_q: 1.176183, mean_eps: 0.941709\n",
            "Step 60000: saving model to checkpoints/dqn_weights_60000.h5f\n",
            "  60298/300000: episode: 85, duration: 255.490s, episode steps: 1111, steps per second:   4, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.008775, mean_q: 1.216901, mean_eps: 0.940855\n",
            "  60929/300000: episode: 86, duration: 142.958s, episode steps: 631, steps per second:   4, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.010522, mean_q: 1.306515, mean_eps: 0.939993\n",
            "  61547/300000: episode: 87, duration: 139.781s, episode steps: 618, steps per second:   4, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.010080, mean_q: 1.323250, mean_eps: 0.939375\n",
            "  62276/300000: episode: 88, duration: 164.459s, episode steps: 729, steps per second:   4, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: 0.009574, mean_q: 1.316605, mean_eps: 0.938708\n",
            "  63089/300000: episode: 89, duration: 183.066s, episode steps: 813, steps per second:   4, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.009031, mean_q: 1.298693, mean_eps: 0.937945\n",
            "  63541/300000: episode: 90, duration: 101.625s, episode steps: 452, steps per second:   4, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.615 [0.000, 5.000],  loss: 0.008885, mean_q: 1.316367, mean_eps: 0.937319\n",
            "  64664/300000: episode: 91, duration: 253.099s, episode steps: 1123, steps per second:   4, episode reward: 15.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.009251, mean_q: 1.318411, mean_eps: 0.936539\n",
            "  65247/300000: episode: 92, duration: 131.863s, episode steps: 583, steps per second:   4, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: 0.008577, mean_q: 1.319278, mean_eps: 0.935695\n",
            "  66117/300000: episode: 93, duration: 196.443s, episode steps: 870, steps per second:   4, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.008852, mean_q: 1.317590, mean_eps: 0.934975\n",
            "  66976/300000: episode: 94, duration: 194.058s, episode steps: 859, steps per second:   4, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.009048, mean_q: 1.317463, mean_eps: 0.934119\n",
            "  67805/300000: episode: 95, duration: 187.266s, episode steps: 829, steps per second:   4, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.008474, mean_q: 1.308948, mean_eps: 0.933284\n",
            "  68357/300000: episode: 96, duration: 124.765s, episode steps: 552, steps per second:   4, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.623 [0.000, 5.000],  loss: 0.008737, mean_q: 1.307317, mean_eps: 0.932600\n",
            "  69278/300000: episode: 97, duration: 207.758s, episode steps: 921, steps per second:   4, episode reward: 23.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.008845, mean_q: 1.309685, mean_eps: 0.931871\n",
            "  69711/300000: episode: 98, duration: 97.761s, episode steps: 433, steps per second:   4, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.008963, mean_q: 1.293679, mean_eps: 0.931201\n",
            "Step 70000: saving model to checkpoints/dqn_weights_70000.h5f\n",
            "  70215/300000: episode: 99, duration: 114.086s, episode steps: 504, steps per second:   4, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.009639, mean_q: 1.358563, mean_eps: 0.930737\n",
            "  70841/300000: episode: 100, duration: 141.298s, episode steps: 626, steps per second:   4, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.010927, mean_q: 1.431754, mean_eps: 0.930178\n",
            "  71333/300000: episode: 101, duration: 111.166s, episode steps: 492, steps per second:   4, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.010299, mean_q: 1.445152, mean_eps: 0.929624\n",
            "  72159/300000: episode: 102, duration: 186.747s, episode steps: 826, steps per second:   4, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.010064, mean_q: 1.444151, mean_eps: 0.928972\n",
            "  72904/300000: episode: 103, duration: 168.117s, episode steps: 745, steps per second:   4, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.009937, mean_q: 1.448751, mean_eps: 0.928194\n",
            "  73412/300000: episode: 104, duration: 114.509s, episode steps: 508, steps per second:   4, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.009791, mean_q: 1.459941, mean_eps: 0.927574\n",
            "  73955/300000: episode: 105, duration: 122.479s, episode steps: 543, steps per second:   4, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: 0.009609, mean_q: 1.425718, mean_eps: 0.927054\n",
            "  74379/300000: episode: 106, duration: 95.973s, episode steps: 424, steps per second:   4, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: 0.009927, mean_q: 1.453211, mean_eps: 0.926575\n",
            "  75322/300000: episode: 107, duration: 212.796s, episode steps: 943, steps per second:   4, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.009058, mean_q: 1.453135, mean_eps: 0.925898\n",
            "  76234/300000: episode: 108, duration: 206.727s, episode steps: 912, steps per second:   4, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.009867, mean_q: 1.440210, mean_eps: 0.924980\n",
            "  76744/300000: episode: 109, duration: 115.342s, episode steps: 510, steps per second:   4, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.009415, mean_q: 1.443438, mean_eps: 0.924276\n",
            "  77501/300000: episode: 110, duration: 171.325s, episode steps: 757, steps per second:   4, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.009109, mean_q: 1.462547, mean_eps: 0.923649\n",
            "  77926/300000: episode: 111, duration: 96.388s, episode steps: 425, steps per second:   4, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.009432, mean_q: 1.451476, mean_eps: 0.923064\n",
            "  78589/300000: episode: 112, duration: 150.339s, episode steps: 663, steps per second:   4, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.009001, mean_q: 1.457990, mean_eps: 0.922526\n",
            "  79278/300000: episode: 113, duration: 156.335s, episode steps: 689, steps per second:   4, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.366 [0.000, 5.000],  loss: 0.009297, mean_q: 1.445979, mean_eps: 0.921856\n",
            "Step 80000: saving model to checkpoints/dqn_weights_80000.h5f\n",
            "  80162/300000: episode: 114, duration: 200.502s, episode steps: 884, steps per second:   4, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.009552, mean_q: 1.472504, mean_eps: 0.921078\n",
            "  80634/300000: episode: 115, duration: 107.478s, episode steps: 472, steps per second:   4, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.011418, mean_q: 1.574773, mean_eps: 0.920406\n",
            "  81034/300000: episode: 116, duration: 90.743s, episode steps: 400, steps per second:   4, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.010810, mean_q: 1.556383, mean_eps: 0.919975\n",
            "  82101/300000: episode: 117, duration: 242.278s, episode steps: 1067, steps per second:   4, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.010847, mean_q: 1.562278, mean_eps: 0.919249\n",
            "  82492/300000: episode: 118, duration: 88.858s, episode steps: 391, steps per second:   4, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.010700, mean_q: 1.569720, mean_eps: 0.918527\n",
            "  83137/300000: episode: 119, duration: 146.856s, episode steps: 645, steps per second:   4, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.010619, mean_q: 1.574322, mean_eps: 0.918014\n",
            "  83516/300000: episode: 120, duration: 86.179s, episode steps: 379, steps per second:   4, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.010580, mean_q: 1.567114, mean_eps: 0.917507\n",
            "  84197/300000: episode: 121, duration: 154.761s, episode steps: 681, steps per second:   4, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.010413, mean_q: 1.576529, mean_eps: 0.916983\n",
            "  85278/300000: episode: 122, duration: 245.277s, episode steps: 1081, steps per second:   4, episode reward: 13.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.009956, mean_q: 1.580902, mean_eps: 0.916110\n",
            "  85675/300000: episode: 123, duration: 90.331s, episode steps: 397, steps per second:   4, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.009728, mean_q: 1.548338, mean_eps: 0.915379\n",
            "  86358/300000: episode: 124, duration: 155.030s, episode steps: 683, steps per second:   4, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.009254, mean_q: 1.559954, mean_eps: 0.914844\n",
            "  86783/300000: episode: 125, duration: 96.909s, episode steps: 425, steps per second:   4, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.010157, mean_q: 1.584264, mean_eps: 0.914296\n",
            "  87449/300000: episode: 126, duration: 151.398s, episode steps: 666, steps per second:   4, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.010115, mean_q: 1.582907, mean_eps: 0.913756\n",
            "  87849/300000: episode: 127, duration: 91.001s, episode steps: 400, steps per second:   4, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.640 [0.000, 5.000],  loss: 0.009477, mean_q: 1.566322, mean_eps: 0.913228\n",
            "  88312/300000: episode: 128, duration: 105.473s, episode steps: 463, steps per second:   4, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.009588, mean_q: 1.579799, mean_eps: 0.912801\n",
            "  88954/300000: episode: 129, duration: 145.565s, episode steps: 642, steps per second:   4, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.009273, mean_q: 1.578634, mean_eps: 0.912254\n",
            "  89643/300000: episode: 130, duration: 156.474s, episode steps: 689, steps per second:   4, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.008967, mean_q: 1.576318, mean_eps: 0.911595\n",
            "Step 90000: saving model to checkpoints/dqn_weights_90000.h5f\n",
            "  90335/300000: episode: 131, duration: 157.005s, episode steps: 692, steps per second:   4, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.686 [0.000, 5.000],  loss: 0.010713, mean_q: 1.616906, mean_eps: 0.910911\n",
            "  91014/300000: episode: 132, duration: 154.229s, episode steps: 679, steps per second:   4, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.011627, mean_q: 1.644978, mean_eps: 0.910233\n",
            "  91584/300000: episode: 133, duration: 129.406s, episode steps: 570, steps per second:   4, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: 0.010411, mean_q: 1.632293, mean_eps: 0.909614\n",
            "  92106/300000: episode: 134, duration: 118.741s, episode steps: 522, steps per second:   4, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.011464, mean_q: 1.628281, mean_eps: 0.909074\n",
            "  92830/300000: episode: 135, duration: 164.091s, episode steps: 724, steps per second:   4, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: 0.010477, mean_q: 1.647788, mean_eps: 0.908457\n",
            "  93532/300000: episode: 136, duration: 158.923s, episode steps: 702, steps per second:   4, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.010168, mean_q: 1.624597, mean_eps: 0.907751\n",
            "  94330/300000: episode: 137, duration: 180.590s, episode steps: 798, steps per second:   4, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.010756, mean_q: 1.648310, mean_eps: 0.907009\n",
            "  94975/300000: episode: 138, duration: 146.126s, episode steps: 645, steps per second:   4, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.010685, mean_q: 1.633640, mean_eps: 0.906295\n",
            "  95351/300000: episode: 139, duration: 85.261s, episode steps: 376, steps per second:   4, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.010238, mean_q: 1.641390, mean_eps: 0.905789\n",
            "  96017/300000: episode: 140, duration: 151.069s, episode steps: 666, steps per second:   4, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.011006, mean_q: 1.640940, mean_eps: 0.905273\n",
            "  96605/300000: episode: 141, duration: 133.765s, episode steps: 588, steps per second:   4, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.010454, mean_q: 1.634781, mean_eps: 0.904653\n",
            "  97090/300000: episode: 142, duration: 110.271s, episode steps: 485, steps per second:   4, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.009603, mean_q: 1.641718, mean_eps: 0.904121\n",
            "  97636/300000: episode: 143, duration: 124.075s, episode steps: 546, steps per second:   4, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.009620, mean_q: 1.617067, mean_eps: 0.903611\n",
            "  98358/300000: episode: 144, duration: 163.719s, episode steps: 722, steps per second:   4, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.010192, mean_q: 1.640764, mean_eps: 0.902983\n",
            "  99034/300000: episode: 145, duration: 153.668s, episode steps: 676, steps per second:   4, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.630 [0.000, 5.000],  loss: 0.010007, mean_q: 1.624236, mean_eps: 0.902291\n",
            "  99526/300000: episode: 146, duration: 111.734s, episode steps: 492, steps per second:   4, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.648 [0.000, 5.000],  loss: 0.009227, mean_q: 1.617737, mean_eps: 0.901713\n",
            "Step 100000: saving model to checkpoints/dqn_weights_100000.h5f\n",
            " 100487/300000: episode: 147, duration: 220.094s, episode steps: 961, steps per second:   4, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.011425, mean_q: 1.686135, mean_eps: 0.900994\n",
            " 101039/300000: episode: 148, duration: 125.238s, episode steps: 552, steps per second:   4, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.011164, mean_q: 1.731324, mean_eps: 0.900245\n",
            " 101817/300000: episode: 149, duration: 176.589s, episode steps: 778, steps per second:   4, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.011596, mean_q: 1.721890, mean_eps: 0.899587\n",
            " 102210/300000: episode: 150, duration: 89.252s, episode steps: 393, steps per second:   4, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.011435, mean_q: 1.723204, mean_eps: 0.899007\n",
            " 103036/300000: episode: 151, duration: 187.443s, episode steps: 826, steps per second:   4, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: 0.011375, mean_q: 1.724230, mean_eps: 0.898404\n",
            " 103659/300000: episode: 152, duration: 141.375s, episode steps: 623, steps per second:   4, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.010739, mean_q: 1.739519, mean_eps: 0.897686\n",
            " 104193/300000: episode: 153, duration: 121.857s, episode steps: 534, steps per second:   4, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.011234, mean_q: 1.739261, mean_eps: 0.897114\n",
            " 104923/300000: episode: 154, duration: 166.180s, episode steps: 730, steps per second:   4, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.010864, mean_q: 1.726351, mean_eps: 0.896488\n",
            " 105746/300000: episode: 155, duration: 186.697s, episode steps: 823, steps per second:   4, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.010412, mean_q: 1.728944, mean_eps: 0.895719\n",
            " 106380/300000: episode: 156, duration: 144.449s, episode steps: 634, steps per second:   4, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.010783, mean_q: 1.718333, mean_eps: 0.894998\n",
            " 106777/300000: episode: 157, duration: 90.387s, episode steps: 397, steps per second:   4, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.010981, mean_q: 1.718441, mean_eps: 0.894488\n",
            " 107260/300000: episode: 158, duration: 109.754s, episode steps: 483, steps per second:   4, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.010337, mean_q: 1.716060, mean_eps: 0.894052\n",
            " 108250/300000: episode: 159, duration: 225.082s, episode steps: 990, steps per second:   4, episode reward: 24.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.010791, mean_q: 1.735586, mean_eps: 0.893323\n",
            " 108947/300000: episode: 160, duration: 158.527s, episode steps: 697, steps per second:   4, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.010434, mean_q: 1.717081, mean_eps: 0.892488\n",
            "Step 110000: saving model to checkpoints/dqn_weights_110000.h5f\n",
            " 110430/300000: episode: 161, duration: 337.137s, episode steps: 1483, steps per second:   4, episode reward: 18.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.011171, mean_q: 1.749171, mean_eps: 0.891409\n",
            " 110802/300000: episode: 162, duration: 84.407s, episode steps: 372, steps per second:   4, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.011639, mean_q: 1.783375, mean_eps: 0.890491\n",
            " 111352/300000: episode: 163, duration: 124.793s, episode steps: 550, steps per second:   4, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.012361, mean_q: 1.789638, mean_eps: 0.890034\n",
            " 111972/300000: episode: 164, duration: 140.578s, episode steps: 620, steps per second:   4, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.011408, mean_q: 1.794749, mean_eps: 0.889455\n",
            " 112613/300000: episode: 165, duration: 145.767s, episode steps: 641, steps per second:   4, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.011415, mean_q: 1.796691, mean_eps: 0.888831\n",
            " 113264/300000: episode: 166, duration: 148.313s, episode steps: 651, steps per second:   4, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.011175, mean_q: 1.795518, mean_eps: 0.888191\n",
            " 114183/300000: episode: 167, duration: 209.051s, episode steps: 919, steps per second:   4, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.010987, mean_q: 1.782591, mean_eps: 0.887414\n",
            " 114984/300000: episode: 168, duration: 182.150s, episode steps: 801, steps per second:   4, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.010881, mean_q: 1.793861, mean_eps: 0.886563\n",
            " 115552/300000: episode: 169, duration: 129.186s, episode steps: 568, steps per second:   4, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.011211, mean_q: 1.791352, mean_eps: 0.885885\n",
            " 116387/300000: episode: 170, duration: 189.977s, episode steps: 835, steps per second:   4, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.010948, mean_q: 1.799380, mean_eps: 0.885191\n",
            " 117182/300000: episode: 171, duration: 180.352s, episode steps: 795, steps per second:   4, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.011085, mean_q: 1.786214, mean_eps: 0.884384\n",
            " 118141/300000: episode: 172, duration: 217.909s, episode steps: 959, steps per second:   4, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.010822, mean_q: 1.785374, mean_eps: 0.883516\n",
            " 118928/300000: episode: 173, duration: 178.690s, episode steps: 787, steps per second:   4, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.010528, mean_q: 1.783568, mean_eps: 0.882651\n",
            " 119334/300000: episode: 174, duration: 92.782s, episode steps: 406, steps per second:   4, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.010363, mean_q: 1.793375, mean_eps: 0.882061\n",
            "Step 120000: saving model to checkpoints/dqn_weights_120000.h5f\n",
            " 120042/300000: episode: 175, duration: 161.223s, episode steps: 708, steps per second:   4, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.010949, mean_q: 1.789502, mean_eps: 0.881509\n",
            " 120580/300000: episode: 176, duration: 122.479s, episode steps: 538, steps per second:   4, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.013467, mean_q: 1.860158, mean_eps: 0.880893\n",
            " 121064/300000: episode: 177, duration: 109.882s, episode steps: 484, steps per second:   4, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.011885, mean_q: 1.881030, mean_eps: 0.880387\n",
            " 121844/300000: episode: 178, duration: 177.068s, episode steps: 780, steps per second:   4, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.012244, mean_q: 1.886643, mean_eps: 0.879761\n",
            " 122462/300000: episode: 179, duration: 140.078s, episode steps: 618, steps per second:   4, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.012855, mean_q: 1.882186, mean_eps: 0.879069\n",
            " 123164/300000: episode: 180, duration: 159.800s, episode steps: 702, steps per second:   4, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.011862, mean_q: 1.880571, mean_eps: 0.878416\n",
            " 123765/300000: episode: 181, duration: 136.786s, episode steps: 601, steps per second:   4, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.586 [0.000, 5.000],  loss: 0.011853, mean_q: 1.869298, mean_eps: 0.877771\n",
            " 124550/300000: episode: 182, duration: 178.842s, episode steps: 785, steps per second:   4, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.011898, mean_q: 1.864241, mean_eps: 0.877085\n",
            " 125731/300000: episode: 183, duration: 268.131s, episode steps: 1181, steps per second:   4, episode reward: 13.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.011904, mean_q: 1.868001, mean_eps: 0.876111\n",
            " 126352/300000: episode: 184, duration: 141.308s, episode steps: 621, steps per second:   4, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.011133, mean_q: 1.860594, mean_eps: 0.875219\n",
            " 126842/300000: episode: 185, duration: 111.406s, episode steps: 490, steps per second:   4, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.592 [0.000, 5.000],  loss: 0.011191, mean_q: 1.855931, mean_eps: 0.874669\n",
            " 127481/300000: episode: 186, duration: 145.272s, episode steps: 639, steps per second:   4, episode reward:  4.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.011211, mean_q: 1.876986, mean_eps: 0.874111\n",
            " 128115/300000: episode: 187, duration: 144.414s, episode steps: 634, steps per second:   4, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.011141, mean_q: 1.879939, mean_eps: 0.873480\n",
            " 128786/300000: episode: 188, duration: 152.669s, episode steps: 671, steps per second:   4, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.010814, mean_q: 1.869587, mean_eps: 0.872834\n",
            " 129623/300000: episode: 189, duration: 190.812s, episode steps: 837, steps per second:   4, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.011412, mean_q: 1.868045, mean_eps: 0.872088\n",
            "Step 130000: saving model to checkpoints/dqn_weights_130000.h5f\n",
            " 130112/300000: episode: 190, duration: 112.203s, episode steps: 489, steps per second:   4, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.644 [0.000, 5.000],  loss: 0.011090, mean_q: 1.868236, mean_eps: 0.871432\n",
            " 130730/300000: episode: 191, duration: 140.405s, episode steps: 618, steps per second:   4, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: 0.013956, mean_q: 1.897518, mean_eps: 0.870884\n",
            " 131675/300000: episode: 192, duration: 215.458s, episode steps: 945, steps per second:   4, episode reward: 10.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.013041, mean_q: 1.898455, mean_eps: 0.870110\n",
            " 133135/300000: episode: 193, duration: 332.660s, episode steps: 1460, steps per second:   4, episode reward: 17.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.012262, mean_q: 1.892125, mean_eps: 0.868920\n",
            " 133845/300000: episode: 194, duration: 161.824s, episode steps: 710, steps per second:   4, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.012072, mean_q: 1.880063, mean_eps: 0.867845\n",
            " 134378/300000: episode: 195, duration: 121.894s, episode steps: 533, steps per second:   4, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.012158, mean_q: 1.892942, mean_eps: 0.867230\n",
            " 135026/300000: episode: 196, duration: 148.174s, episode steps: 648, steps per second:   4, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.011612, mean_q: 1.883993, mean_eps: 0.866646\n",
            " 135520/300000: episode: 197, duration: 113.126s, episode steps: 494, steps per second:   4, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.012122, mean_q: 1.874921, mean_eps: 0.866080\n",
            " 136307/300000: episode: 198, duration: 180.081s, episode steps: 787, steps per second:   4, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.012289, mean_q: 1.873885, mean_eps: 0.865446\n",
            " 137146/300000: episode: 199, duration: 191.732s, episode steps: 839, steps per second:   4, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.665 [0.000, 5.000],  loss: 0.012130, mean_q: 1.879966, mean_eps: 0.864641\n",
            " 137816/300000: episode: 200, duration: 154.551s, episode steps: 670, steps per second:   4, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.011925, mean_q: 1.877993, mean_eps: 0.863894\n",
            " 138240/300000: episode: 201, duration: 96.980s, episode steps: 424, steps per second:   4, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.011347, mean_q: 1.882937, mean_eps: 0.863353\n",
            " 139221/300000: episode: 202, duration: 225.036s, episode steps: 981, steps per second:   4, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.011372, mean_q: 1.892230, mean_eps: 0.862657\n",
            " 139867/300000: episode: 203, duration: 148.062s, episode steps: 646, steps per second:   4, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.011193, mean_q: 1.877722, mean_eps: 0.861852\n",
            "Step 140000: saving model to checkpoints/dqn_weights_140000.h5f\n",
            " 140676/300000: episode: 204, duration: 185.294s, episode steps: 809, steps per second:   4, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.013271, mean_q: 1.977254, mean_eps: 0.861132\n",
            " 141459/300000: episode: 205, duration: 178.710s, episode steps: 783, steps per second:   4, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.012952, mean_q: 1.999972, mean_eps: 0.860344\n",
            " 142001/300000: episode: 206, duration: 123.897s, episode steps: 542, steps per second:   4, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.012380, mean_q: 2.008803, mean_eps: 0.859688\n",
            " 142758/300000: episode: 207, duration: 172.709s, episode steps: 757, steps per second:   4, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.688 [0.000, 5.000],  loss: 0.012760, mean_q: 2.001748, mean_eps: 0.859045\n",
            " 143269/300000: episode: 208, duration: 116.836s, episode steps: 511, steps per second:   4, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.012395, mean_q: 1.989111, mean_eps: 0.858417\n",
            " 143986/300000: episode: 209, duration: 163.566s, episode steps: 717, steps per second:   4, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: 0.012383, mean_q: 2.003727, mean_eps: 0.857809\n",
            " 144599/300000: episode: 210, duration: 140.274s, episode steps: 613, steps per second:   4, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: 0.011955, mean_q: 2.002235, mean_eps: 0.857151\n",
            " 145752/300000: episode: 211, duration: 263.170s, episode steps: 1153, steps per second:   4, episode reward: 24.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.012337, mean_q: 2.002877, mean_eps: 0.856277\n",
            " 146387/300000: episode: 212, duration: 144.869s, episode steps: 635, steps per second:   4, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.011678, mean_q: 1.995818, mean_eps: 0.855392\n",
            " 146931/300000: episode: 213, duration: 124.359s, episode steps: 544, steps per second:   4, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.012262, mean_q: 2.010583, mean_eps: 0.854808\n",
            " 147491/300000: episode: 214, duration: 130.237s, episode steps: 560, steps per second:   4, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.380 [0.000, 5.000],  loss: 0.012362, mean_q: 2.004457, mean_eps: 0.854262\n",
            " 147979/300000: episode: 215, duration: 114.832s, episode steps: 488, steps per second:   4, episode reward: 11.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.011903, mean_q: 1.992400, mean_eps: 0.853743\n",
            " 148537/300000: episode: 216, duration: 137.964s, episode steps: 558, steps per second:   4, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.012453, mean_q: 2.014259, mean_eps: 0.853225\n",
            " 149087/300000: episode: 217, duration: 135.807s, episode steps: 550, steps per second:   4, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: 0.011521, mean_q: 1.988560, mean_eps: 0.852677\n",
            " 149707/300000: episode: 218, duration: 142.782s, episode steps: 620, steps per second:   4, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.011813, mean_q: 1.991176, mean_eps: 0.852097\n",
            "Step 150000: saving model to checkpoints/dqn_weights_150000.h5f\n",
            " 150799/300000: episode: 219, duration: 252.022s, episode steps: 1092, steps per second:   4, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.013524, mean_q: 2.141634, mean_eps: 0.851250\n",
            " 151576/300000: episode: 220, duration: 178.440s, episode steps: 777, steps per second:   4, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.014242, mean_q: 2.197016, mean_eps: 0.850325\n",
            " 152156/300000: episode: 221, duration: 133.302s, episode steps: 580, steps per second:   4, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.316 [0.000, 5.000],  loss: 0.014683, mean_q: 2.186646, mean_eps: 0.849653\n",
            " 152727/300000: episode: 222, duration: 130.397s, episode steps: 571, steps per second:   4, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.013190, mean_q: 2.190987, mean_eps: 0.849083\n",
            " 153513/300000: episode: 223, duration: 179.722s, episode steps: 786, steps per second:   4, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.013649, mean_q: 2.193911, mean_eps: 0.848412\n",
            " 153892/300000: episode: 224, duration: 86.822s, episode steps: 379, steps per second:   4, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.013791, mean_q: 2.184727, mean_eps: 0.847835\n",
            " 155104/300000: episode: 225, duration: 277.381s, episode steps: 1212, steps per second:   4, episode reward: 14.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.012886, mean_q: 2.193487, mean_eps: 0.847047\n",
            " 155750/300000: episode: 226, duration: 148.170s, episode steps: 646, steps per second:   4, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.013379, mean_q: 2.173508, mean_eps: 0.846128\n",
            " 156287/300000: episode: 227, duration: 123.580s, episode steps: 537, steps per second:   4, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.013365, mean_q: 2.177986, mean_eps: 0.845542\n",
            " 157097/300000: episode: 228, duration: 185.134s, episode steps: 810, steps per second:   4, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: 0.012819, mean_q: 2.195852, mean_eps: 0.844875\n",
            " 157798/300000: episode: 229, duration: 160.477s, episode steps: 701, steps per second:   4, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.013320, mean_q: 2.180862, mean_eps: 0.844127\n",
            " 158940/300000: episode: 230, duration: 261.403s, episode steps: 1142, steps per second:   4, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.013266, mean_q: 2.191556, mean_eps: 0.843215\n",
            " 159477/300000: episode: 231, duration: 122.958s, episode steps: 537, steps per second:   4, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.695 [0.000, 5.000],  loss: 0.012655, mean_q: 2.175429, mean_eps: 0.842384\n",
            "Step 160000: saving model to checkpoints/dqn_weights_160000.h5f\n",
            " 160138/300000: episode: 232, duration: 160.852s, episode steps: 661, steps per second:   4, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.013514, mean_q: 2.197962, mean_eps: 0.841791\n",
            " 161147/300000: episode: 233, duration: 231.818s, episode steps: 1009, steps per second:   4, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.014190, mean_q: 2.244241, mean_eps: 0.840964\n",
            " 161556/300000: episode: 234, duration: 94.007s, episode steps: 409, steps per second:   4, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.013824, mean_q: 2.222212, mean_eps: 0.840263\n",
            " 162543/300000: episode: 235, duration: 227.976s, episode steps: 987, steps per second:   4, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.014148, mean_q: 2.245799, mean_eps: 0.839571\n",
            " 163160/300000: episode: 236, duration: 142.265s, episode steps: 617, steps per second:   4, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.677 [0.000, 5.000],  loss: 0.013658, mean_q: 2.242073, mean_eps: 0.838778\n",
            " 163948/300000: episode: 237, duration: 180.802s, episode steps: 788, steps per second:   4, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.013183, mean_q: 2.239539, mean_eps: 0.838082\n",
            " 164698/300000: episode: 238, duration: 171.568s, episode steps: 750, steps per second:   4, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.013743, mean_q: 2.233332, mean_eps: 0.837321\n",
            " 165351/300000: episode: 239, duration: 154.728s, episode steps: 653, steps per second:   4, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.013344, mean_q: 2.249346, mean_eps: 0.836626\n",
            " 165718/300000: episode: 240, duration: 87.656s, episode steps: 367, steps per second:   4, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.014249, mean_q: 2.238182, mean_eps: 0.836121\n",
            " 166275/300000: episode: 241, duration: 127.872s, episode steps: 557, steps per second:   4, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.013998, mean_q: 2.237327, mean_eps: 0.835664\n",
            " 166942/300000: episode: 242, duration: 153.466s, episode steps: 667, steps per second:   4, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.013964, mean_q: 2.249140, mean_eps: 0.835058\n",
            " 167922/300000: episode: 243, duration: 225.414s, episode steps: 980, steps per second:   4, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.013110, mean_q: 2.252967, mean_eps: 0.834243\n",
            " 168543/300000: episode: 244, duration: 142.448s, episode steps: 621, steps per second:   4, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.013118, mean_q: 2.218317, mean_eps: 0.833450\n",
            " 169160/300000: episode: 245, duration: 141.471s, episode steps: 617, steps per second:   4, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.012946, mean_q: 2.242216, mean_eps: 0.832838\n",
            " 169951/300000: episode: 246, duration: 181.109s, episode steps: 791, steps per second:   4, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.013352, mean_q: 2.254343, mean_eps: 0.832141\n",
            "Step 170000: saving model to checkpoints/dqn_weights_170000.h5f\n",
            " 170972/300000: episode: 247, duration: 234.946s, episode steps: 1021, steps per second:   4, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.014808, mean_q: 2.314064, mean_eps: 0.831244\n",
            " 171349/300000: episode: 248, duration: 86.803s, episode steps: 377, steps per second:   4, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.668 [0.000, 5.000],  loss: 0.014179, mean_q: 2.315376, mean_eps: 0.830552\n",
            " 171910/300000: episode: 249, duration: 129.251s, episode steps: 561, steps per second:   4, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.014221, mean_q: 2.325250, mean_eps: 0.830087\n",
            " 172723/300000: episode: 250, duration: 187.072s, episode steps: 813, steps per second:   4, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.014545, mean_q: 2.320636, mean_eps: 0.829407\n",
            " 173672/300000: episode: 251, duration: 221.877s, episode steps: 949, steps per second:   4, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.014315, mean_q: 2.329631, mean_eps: 0.828535\n",
            " 174156/300000: episode: 252, duration: 115.019s, episode steps: 484, steps per second:   4, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.014655, mean_q: 2.315771, mean_eps: 0.827826\n",
            " 174762/300000: episode: 253, duration: 139.363s, episode steps: 606, steps per second:   4, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.013927, mean_q: 2.318660, mean_eps: 0.827286\n",
            " 175731/300000: episode: 254, duration: 223.245s, episode steps: 969, steps per second:   4, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.014194, mean_q: 2.328333, mean_eps: 0.826506\n",
            " 176294/300000: episode: 255, duration: 129.585s, episode steps: 563, steps per second:   4, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.013465, mean_q: 2.326165, mean_eps: 0.825748\n",
            " 177174/300000: episode: 256, duration: 202.222s, episode steps: 880, steps per second:   4, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.643 [0.000, 5.000],  loss: 0.013048, mean_q: 2.314639, mean_eps: 0.825034\n",
            " 177733/300000: episode: 257, duration: 128.470s, episode steps: 559, steps per second:   4, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.012923, mean_q: 2.305654, mean_eps: 0.824322\n",
            " 178358/300000: episode: 258, duration: 143.260s, episode steps: 625, steps per second:   4, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.013099, mean_q: 2.330800, mean_eps: 0.823735\n",
            " 179195/300000: episode: 259, duration: 192.251s, episode steps: 837, steps per second:   4, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.634 [0.000, 5.000],  loss: 0.014126, mean_q: 2.325247, mean_eps: 0.823012\n",
            " 179738/300000: episode: 260, duration: 125.323s, episode steps: 543, steps per second:   4, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.014372, mean_q: 2.329937, mean_eps: 0.822329\n",
            "Step 180000: saving model to checkpoints/dqn_weights_180000.h5f\n",
            " 180133/300000: episode: 261, duration: 91.258s, episode steps: 395, steps per second:   4, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.013734, mean_q: 2.342324, mean_eps: 0.821864\n",
            " 180932/300000: episode: 262, duration: 184.146s, episode steps: 799, steps per second:   4, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.298 [0.000, 5.000],  loss: 0.015549, mean_q: 2.407301, mean_eps: 0.821273\n",
            " 181764/300000: episode: 263, duration: 191.799s, episode steps: 832, steps per second:   4, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.014917, mean_q: 2.417709, mean_eps: 0.820466\n",
            " 182720/300000: episode: 264, duration: 220.121s, episode steps: 956, steps per second:   4, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: 0.015228, mean_q: 2.400822, mean_eps: 0.819581\n",
            " 183592/300000: episode: 265, duration: 200.600s, episode steps: 872, steps per second:   4, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: 0.014866, mean_q: 2.413950, mean_eps: 0.818676\n",
            " 184109/300000: episode: 266, duration: 116.388s, episode steps: 517, steps per second:   4, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: 0.013773, mean_q: 2.409620, mean_eps: 0.817989\n",
            " 184645/300000: episode: 267, duration: 119.798s, episode steps: 536, steps per second:   4, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.014888, mean_q: 2.412467, mean_eps: 0.817467\n",
            " 185225/300000: episode: 268, duration: 133.307s, episode steps: 580, steps per second:   4, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.014182, mean_q: 2.405731, mean_eps: 0.816915\n",
            " 186580/300000: episode: 269, duration: 311.185s, episode steps: 1355, steps per second:   4, episode reward: 19.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.014295, mean_q: 2.410031, mean_eps: 0.815957\n",
            " 187262/300000: episode: 270, duration: 157.175s, episode steps: 682, steps per second:   4, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.013749, mean_q: 2.408210, mean_eps: 0.814949\n",
            " 188434/300000: episode: 271, duration: 268.406s, episode steps: 1172, steps per second:   4, episode reward: 11.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.014470, mean_q: 2.404480, mean_eps: 0.814031\n",
            " 189234/300000: episode: 272, duration: 183.709s, episode steps: 800, steps per second:   4, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.013967, mean_q: 2.399782, mean_eps: 0.813055\n",
            " 189798/300000: episode: 273, duration: 129.650s, episode steps: 564, steps per second:   4, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.013707, mean_q: 2.384874, mean_eps: 0.812380\n",
            "Step 190000: saving model to checkpoints/dqn_weights_190000.h5f\n",
            " 191142/300000: episode: 274, duration: 309.793s, episode steps: 1344, steps per second:   4, episode reward: 21.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.015054, mean_q: 2.494435, mean_eps: 0.811435\n",
            " 191889/300000: episode: 275, duration: 172.070s, episode steps: 747, steps per second:   4, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.016750, mean_q: 2.503088, mean_eps: 0.810400\n",
            " 192741/300000: episode: 276, duration: 196.145s, episode steps: 852, steps per second:   4, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.397 [0.000, 5.000],  loss: 0.015506, mean_q: 2.504401, mean_eps: 0.809609\n",
            " 193369/300000: episode: 277, duration: 144.656s, episode steps: 628, steps per second:   4, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.015451, mean_q: 2.497174, mean_eps: 0.808876\n",
            " 194007/300000: episode: 278, duration: 147.078s, episode steps: 638, steps per second:   4, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.014787, mean_q: 2.507380, mean_eps: 0.808249\n",
            " 194523/300000: episode: 279, duration: 119.197s, episode steps: 516, steps per second:   4, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: 0.014177, mean_q: 2.495403, mean_eps: 0.807678\n",
            " 195313/300000: episode: 280, duration: 182.006s, episode steps: 790, steps per second:   4, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.015516, mean_q: 2.509485, mean_eps: 0.807032\n",
            " 195850/300000: episode: 281, duration: 124.026s, episode steps: 537, steps per second:   4, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.014378, mean_q: 2.506323, mean_eps: 0.806375\n",
            " 196384/300000: episode: 282, duration: 123.738s, episode steps: 534, steps per second:   4, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.586 [0.000, 5.000],  loss: 0.015498, mean_q: 2.517754, mean_eps: 0.805845\n",
            " 196802/300000: episode: 283, duration: 97.040s, episode steps: 418, steps per second:   4, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.015252, mean_q: 2.501587, mean_eps: 0.805373\n",
            " 197755/300000: episode: 284, duration: 219.977s, episode steps: 953, steps per second:   4, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.014796, mean_q: 2.504608, mean_eps: 0.804695\n",
            " 198237/300000: episode: 285, duration: 111.567s, episode steps: 482, steps per second:   4, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.015070, mean_q: 2.501880, mean_eps: 0.803984\n",
            " 199012/300000: episode: 286, duration: 179.226s, episode steps: 775, steps per second:   4, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.014379, mean_q: 2.502402, mean_eps: 0.803362\n",
            " 199842/300000: episode: 287, duration: 191.447s, episode steps: 830, steps per second:   4, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.014534, mean_q: 2.493333, mean_eps: 0.802568\n",
            "Step 200000: saving model to checkpoints/dqn_weights_200000.h5f\n",
            " 200452/300000: episode: 288, duration: 141.283s, episode steps: 610, steps per second:   4, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.615 [0.000, 5.000],  loss: 0.016698, mean_q: 2.615094, mean_eps: 0.801855\n",
            " 201490/300000: episode: 289, duration: 239.554s, episode steps: 1038, steps per second:   4, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.016748, mean_q: 2.639022, mean_eps: 0.801039\n",
            " 202190/300000: episode: 290, duration: 165.898s, episode steps: 700, steps per second:   4, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.016517, mean_q: 2.634180, mean_eps: 0.800179\n",
            " 202852/300000: episode: 291, duration: 152.885s, episode steps: 662, steps per second:   4, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.016928, mean_q: 2.641545, mean_eps: 0.799505\n",
            " 203331/300000: episode: 292, duration: 110.938s, episode steps: 479, steps per second:   4, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.015902, mean_q: 2.635555, mean_eps: 0.798940\n",
            " 203727/300000: episode: 293, duration: 91.251s, episode steps: 396, steps per second:   4, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.326 [0.000, 5.000],  loss: 0.016652, mean_q: 2.652700, mean_eps: 0.798507\n",
            " 204169/300000: episode: 294, duration: 102.179s, episode steps: 442, steps per second:   4, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.305 [0.000, 5.000],  loss: 0.016818, mean_q: 2.636882, mean_eps: 0.798092\n",
            " 204952/300000: episode: 295, duration: 180.403s, episode steps: 783, steps per second:   4, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.016120, mean_q: 2.644939, mean_eps: 0.797486\n",
            " 205995/300000: episode: 296, duration: 240.694s, episode steps: 1043, steps per second:   4, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.015858, mean_q: 2.639799, mean_eps: 0.796582\n",
            " 206653/300000: episode: 297, duration: 152.178s, episode steps: 658, steps per second:   4, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.015744, mean_q: 2.637933, mean_eps: 0.795740\n",
            " 207590/300000: episode: 298, duration: 219.071s, episode steps: 937, steps per second:   4, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.016048, mean_q: 2.639834, mean_eps: 0.794950\n",
            " 207974/300000: episode: 299, duration: 89.122s, episode steps: 384, steps per second:   4, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.015281, mean_q: 2.621811, mean_eps: 0.794296\n",
            " 208555/300000: episode: 300, duration: 134.599s, episode steps: 581, steps per second:   4, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.015523, mean_q: 2.645735, mean_eps: 0.793819\n",
            " 209772/300000: episode: 301, duration: 280.823s, episode steps: 1217, steps per second:   4, episode reward: 15.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.016338, mean_q: 2.638584, mean_eps: 0.792929\n",
            "Step 210000: saving model to checkpoints/dqn_weights_210000.h5f\n",
            " 210447/300000: episode: 302, duration: 157.331s, episode steps: 675, steps per second:   4, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.016487, mean_q: 2.666797, mean_eps: 0.791992\n",
            " 210931/300000: episode: 303, duration: 112.265s, episode steps: 484, steps per second:   4, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.015671, mean_q: 2.685517, mean_eps: 0.791418\n",
            " 211659/300000: episode: 304, duration: 168.617s, episode steps: 728, steps per second:   4, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.017179, mean_q: 2.677884, mean_eps: 0.790818\n",
            " 212266/300000: episode: 305, duration: 140.673s, episode steps: 607, steps per second:   4, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.015507, mean_q: 2.674130, mean_eps: 0.790158\n",
            " 212656/300000: episode: 306, duration: 90.361s, episode steps: 390, steps per second:   4, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.321 [0.000, 5.000],  loss: 0.016635, mean_q: 2.682162, mean_eps: 0.789664\n",
            " 213399/300000: episode: 307, duration: 171.859s, episode steps: 743, steps per second:   4, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.016584, mean_q: 2.689848, mean_eps: 0.789103\n",
            " 214335/300000: episode: 308, duration: 216.699s, episode steps: 936, steps per second:   4, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.016922, mean_q: 2.686251, mean_eps: 0.788272\n",
            " 214914/300000: episode: 309, duration: 134.159s, episode steps: 579, steps per second:   4, episode reward: 12.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.017530, mean_q: 2.707034, mean_eps: 0.787522\n",
            " 215951/300000: episode: 310, duration: 275.092s, episode steps: 1037, steps per second:   4, episode reward: 18.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.016671, mean_q: 2.685764, mean_eps: 0.786722\n",
            " 217247/300000: episode: 311, duration: 311.998s, episode steps: 1296, steps per second:   4, episode reward: 17.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.015812, mean_q: 2.683653, mean_eps: 0.785567\n",
            " 217746/300000: episode: 312, duration: 119.567s, episode steps: 499, steps per second:   4, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.717 [0.000, 5.000],  loss: 0.016218, mean_q: 2.694397, mean_eps: 0.784679\n",
            " 218121/300000: episode: 313, duration: 89.461s, episode steps: 375, steps per second:   4, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.015786, mean_q: 2.688492, mean_eps: 0.784246\n",
            " 218783/300000: episode: 314, duration: 158.538s, episode steps: 662, steps per second:   4, episode reward: 16.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.015509, mean_q: 2.693887, mean_eps: 0.783733\n",
            " 219412/300000: episode: 315, duration: 147.711s, episode steps: 629, steps per second:   4, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: 0.015801, mean_q: 2.692594, mean_eps: 0.783094\n",
            " 219945/300000: episode: 316, duration: 124.941s, episode steps: 533, steps per second:   4, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.015629, mean_q: 2.677624, mean_eps: 0.782519\n",
            "Step 220000: saving model to checkpoints/dqn_weights_220000.h5f\n",
            " 220783/300000: episode: 317, duration: 197.270s, episode steps: 838, steps per second:   4, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.017108, mean_q: 2.730346, mean_eps: 0.781840\n",
            " 221505/300000: episode: 318, duration: 168.300s, episode steps: 722, steps per second:   4, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: 0.018022, mean_q: 2.751281, mean_eps: 0.781068\n",
            " 222690/300000: episode: 319, duration: 275.636s, episode steps: 1185, steps per second:   4, episode reward: 10.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.017810, mean_q: 2.723997, mean_eps: 0.780124\n",
            " 223172/300000: episode: 320, duration: 113.036s, episode steps: 482, steps per second:   4, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.016381, mean_q: 2.739643, mean_eps: 0.779299\n",
            " 224305/300000: episode: 321, duration: 275.562s, episode steps: 1133, steps per second:   4, episode reward: 15.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.017349, mean_q: 2.730327, mean_eps: 0.778499\n",
            " 224699/300000: episode: 322, duration: 108.143s, episode steps: 394, steps per second:   4, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.338 [0.000, 5.000],  loss: 0.017043, mean_q: 2.747969, mean_eps: 0.777744\n",
            " 225405/300000: episode: 323, duration: 177.027s, episode steps: 706, steps per second:   4, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.016671, mean_q: 2.724601, mean_eps: 0.777199\n",
            " 225814/300000: episode: 324, duration: 95.465s, episode steps: 409, steps per second:   4, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.619 [0.000, 5.000],  loss: 0.016780, mean_q: 2.736379, mean_eps: 0.776647\n",
            " 226350/300000: episode: 325, duration: 124.412s, episode steps: 536, steps per second:   4, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.016006, mean_q: 2.727713, mean_eps: 0.776179\n",
            " 226761/300000: episode: 326, duration: 96.182s, episode steps: 411, steps per second:   4, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.018162, mean_q: 2.748572, mean_eps: 0.775711\n",
            " 227414/300000: episode: 327, duration: 151.976s, episode steps: 653, steps per second:   4, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.016506, mean_q: 2.741734, mean_eps: 0.775184\n",
            " 228106/300000: episode: 328, duration: 161.235s, episode steps: 692, steps per second:   4, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.017311, mean_q: 2.717208, mean_eps: 0.774518\n",
            " 228453/300000: episode: 329, duration: 80.840s, episode steps: 347, steps per second:   4, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.015367, mean_q: 2.731618, mean_eps: 0.774004\n",
            " 229266/300000: episode: 330, duration: 189.257s, episode steps: 813, steps per second:   4, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.016407, mean_q: 2.736336, mean_eps: 0.773430\n",
            " 229848/300000: episode: 331, duration: 135.705s, episode steps: 582, steps per second:   4, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.653 [0.000, 5.000],  loss: 0.016662, mean_q: 2.737910, mean_eps: 0.772739\n",
            "Step 230000: saving model to checkpoints/dqn_weights_230000.h5f\n",
            " 230777/300000: episode: 332, duration: 217.386s, episode steps: 929, steps per second:   4, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: 0.018011, mean_q: 2.786814, mean_eps: 0.771991\n",
            " 231444/300000: episode: 333, duration: 155.262s, episode steps: 667, steps per second:   4, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.019657, mean_q: 2.803595, mean_eps: 0.771201\n",
            " 231875/300000: episode: 334, duration: 100.576s, episode steps: 431, steps per second:   4, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.640 [0.000, 5.000],  loss: 0.018365, mean_q: 2.810526, mean_eps: 0.770658\n",
            " 232343/300000: episode: 335, duration: 109.847s, episode steps: 468, steps per second:   4, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.018064, mean_q: 2.791365, mean_eps: 0.770213\n",
            " 233100/300000: episode: 336, duration: 176.289s, episode steps: 757, steps per second:   4, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.017535, mean_q: 2.792805, mean_eps: 0.769606\n",
            " 233790/300000: episode: 337, duration: 160.616s, episode steps: 690, steps per second:   4, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.017931, mean_q: 2.809360, mean_eps: 0.768890\n",
            " 234163/300000: episode: 338, duration: 87.197s, episode steps: 373, steps per second:   4, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.678 [0.000, 5.000],  loss: 0.017801, mean_q: 2.813373, mean_eps: 0.768364\n",
            " 234718/300000: episode: 339, duration: 129.689s, episode steps: 555, steps per second:   4, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.679 [0.000, 5.000],  loss: 0.017902, mean_q: 2.801095, mean_eps: 0.767904\n",
            " 235608/300000: episode: 340, duration: 207.807s, episode steps: 890, steps per second:   4, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.017744, mean_q: 2.798468, mean_eps: 0.767189\n",
            " 235990/300000: episode: 341, duration: 89.188s, episode steps: 382, steps per second:   4, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.665 [0.000, 5.000],  loss: 0.018136, mean_q: 2.791827, mean_eps: 0.766559\n",
            " 236591/300000: episode: 342, duration: 140.111s, episode steps: 601, steps per second:   4, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.018615, mean_q: 2.801101, mean_eps: 0.766073\n",
            " 237190/300000: episode: 343, duration: 139.648s, episode steps: 599, steps per second:   4, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.018244, mean_q: 2.807063, mean_eps: 0.765479\n",
            " 238006/300000: episode: 344, duration: 190.298s, episode steps: 816, steps per second:   4, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.018189, mean_q: 2.805633, mean_eps: 0.764778\n",
            " 238812/300000: episode: 345, duration: 188.084s, episode steps: 806, steps per second:   4, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.016874, mean_q: 2.809440, mean_eps: 0.763976\n",
            " 239511/300000: episode: 346, duration: 163.141s, episode steps: 699, steps per second:   4, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.017040, mean_q: 2.798010, mean_eps: 0.763231\n",
            "Step 240000: saving model to checkpoints/dqn_weights_240000.h5f\n",
            " 240021/300000: episode: 347, duration: 119.225s, episode steps: 510, steps per second:   4, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.017751, mean_q: 2.794603, mean_eps: 0.762632\n",
            " 240586/300000: episode: 348, duration: 131.679s, episode steps: 565, steps per second:   4, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.628 [0.000, 5.000],  loss: 0.017244, mean_q: 2.760568, mean_eps: 0.762100\n",
            " 241306/300000: episode: 349, duration: 167.689s, episode steps: 720, steps per second:   4, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.017538, mean_q: 2.745104, mean_eps: 0.761464\n",
            " 241997/300000: episode: 350, duration: 160.942s, episode steps: 691, steps per second:   4, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: 0.017493, mean_q: 2.740236, mean_eps: 0.760766\n",
            " 242406/300000: episode: 351, duration: 95.403s, episode steps: 409, steps per second:   4, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.333 [0.000, 5.000],  loss: 0.016721, mean_q: 2.753106, mean_eps: 0.760221\n",
            " 243522/300000: episode: 352, duration: 260.086s, episode steps: 1116, steps per second:   4, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.018298, mean_q: 2.751631, mean_eps: 0.759466\n",
            " 244194/300000: episode: 353, duration: 156.596s, episode steps: 672, steps per second:   4, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.311 [0.000, 5.000],  loss: 0.018170, mean_q: 2.767671, mean_eps: 0.758581\n",
            " 244842/300000: episode: 354, duration: 151.185s, episode steps: 648, steps per second:   4, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.017324, mean_q: 2.746591, mean_eps: 0.757928\n",
            " 245231/300000: episode: 355, duration: 90.868s, episode steps: 389, steps per second:   4, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.314 [0.000, 5.000],  loss: 0.016052, mean_q: 2.740513, mean_eps: 0.757414\n",
            " 245728/300000: episode: 356, duration: 115.929s, episode steps: 497, steps per second:   4, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.016696, mean_q: 2.758489, mean_eps: 0.756976\n",
            "done, took 56416.629 seconds\n",
            "⏱ Tiempo de fin: 10:01:26\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "print(f\"⏱ Tiempo de inicio: {datetime.now().strftime('%H:%M:%S')}\")\n",
        "\n",
        "dqn.fit(env, nb_steps=300000, visualize=False, verbose=2,callbacks=[checkpoint_callback])\n",
        "\n",
        "print(f\"⏱ Tiempo de fin: {datetime.now().strftime('%H:%M:%S')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ae8n7eplpE_u",
        "outputId": "1bd0bbb3-113b-4394-f0fc-f817f0136e4f"
      },
      "outputs": [
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "[WARNING] dqn_04_weights.h5f.index already exists - overwrite? [y/n] y\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIP] Next time specify overwrite=True!\n"
          ]
        }
      ],
      "source": [
        "dqn.save_weights('dqn_04_weights.h5f')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSVcMgOsR0Nv",
        "outputId": "5208ce9f-fe6e-41eb-af05-f797d4db9370"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing for 10 episodes ...\n",
            "Episode 1: reward: 13.000, steps: 697\n",
            "Episode 2: reward: 15.000, steps: 912\n",
            "Episode 3: reward: 11.000, steps: 669\n",
            "Episode 4: reward: 13.000, steps: 671\n",
            "Episode 5: reward: 4.000, steps: 429\n",
            "Episode 6: reward: 15.000, steps: 940\n",
            "Episode 7: reward: 22.000, steps: 920\n",
            "Episode 8: reward: 18.000, steps: 861\n",
            "Episode 9: reward: 12.000, steps: 907\n",
            "Episode 10: reward: 17.000, steps: 1029\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x27afbcfd850>"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights_filename = 'dqn_04_weights.h5f'.format(env_name)\n",
        "dqn.load_weights(weights_filename)\n",
        "dqn.test(env, nb_episodes=10, visualize=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento parte 2"
      ],
      "metadata": {
        "id": "aVZc0X-Igxos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dqn_weights_100000.h5f\n",
        "#Continuación al 325000 + 100000 + 100000+75000+100000 = 800000\n",
        "\n",
        "dqn.load_weights(\"dqn_weights_75000.h5f\")\n",
        "# 🔢 Paso de partida 3\n",
        "starting_step = 75000 #ultimo weight actualizado\n",
        "remaining_steps = 200000 - starting_step\n",
        "\n",
        "\n",
        "# 🧩 Callback personalizado para continuar numeración de checkpoints\n",
        "class OffsetModelCheckpoint(ModelIntervalCheckpoint):\n",
        "    def __init__(self, filepath, interval, offset):\n",
        "        super().__init__(filepath, interval)\n",
        "        self.offset = offset\n",
        "\n",
        "    def on_step_end(self, step, logs={}):\n",
        "        # Ajusta el número de paso en el nombre del archivo\n",
        "        self.step = step + self.offset\n",
        "        super().on_step_end(step, logs)\n",
        "\n",
        "# 🚀 Entrenamiento con pasos continuados desde 100000\n",
        "dqn.fit(env, nb_steps=remaining_steps, visualize=False, verbose=2,\n",
        "        callbacks=[\n",
        "            FileLogger(\"dqn_log_continuacion.json\", interval=10000),\n",
        "            OffsetModelCheckpoint(\"dqn_weights_{step}.h5f\", interval=25000, offset=starting_step)\n",
        "        ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htRNej0vy8_Q",
        "outputId": "2b88d6aa-12ef-4d1a-d3b9-03ffb424f0dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 125000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    634/125000: episode: 1, duration: 4.627s, episode steps: 634, steps per second: 137, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   1406/125000: episode: 2, duration: 5.157s, episode steps: 772, steps per second: 150, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   1807/125000: episode: 3, duration: 1.898s, episode steps: 401, steps per second: 211, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   2589/125000: episode: 4, duration: 3.808s, episode steps: 782, steps per second: 205, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.386 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   3305/125000: episode: 5, duration: 5.100s, episode steps: 716, steps per second: 140, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   3784/125000: episode: 6, duration: 2.415s, episode steps: 479, steps per second: 198, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   4298/125000: episode: 7, duration: 2.923s, episode steps: 514, steps per second: 176, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.619 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   4667/125000: episode: 8, duration: 2.109s, episode steps: 369, steps per second: 175, episode reward:  8.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   5574/125000: episode: 9, duration: 5.990s, episode steps: 907, steps per second: 151, episode reward: 20.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   6177/125000: episode: 10, duration: 3.165s, episode steps: 603, steps per second: 191, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   6684/125000: episode: 11, duration: 2.724s, episode steps: 507, steps per second: 186, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   7197/125000: episode: 12, duration: 2.659s, episode steps: 513, steps per second: 193, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   8081/125000: episode: 13, duration: 5.898s, episode steps: 884, steps per second: 150, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   8605/125000: episode: 14, duration: 2.764s, episode steps: 524, steps per second: 190, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.647 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   9363/125000: episode: 15, duration: 4.168s, episode steps: 758, steps per second: 182, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  10247/125000: episode: 16, duration: 6.038s, episode steps: 884, steps per second: 146, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  11119/125000: episode: 17, duration: 4.669s, episode steps: 872, steps per second: 187, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  11642/125000: episode: 18, duration: 2.564s, episode steps: 523, steps per second: 204, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  12037/125000: episode: 19, duration: 2.095s, episode steps: 395, steps per second: 189, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  12704/125000: episode: 20, duration: 4.974s, episode steps: 667, steps per second: 134, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  13694/125000: episode: 21, duration: 5.113s, episode steps: 990, steps per second: 194, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  14360/125000: episode: 22, duration: 3.719s, episode steps: 666, steps per second: 179, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  14805/125000: episode: 23, duration: 3.403s, episode steps: 445, steps per second: 131, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  15864/125000: episode: 24, duration: 7.916s, episode steps: 1059, steps per second: 134, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  16365/125000: episode: 25, duration: 2.612s, episode steps: 501, steps per second: 192, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  16888/125000: episode: 26, duration: 3.116s, episode steps: 523, steps per second: 168, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  17667/125000: episode: 27, duration: 5.018s, episode steps: 779, steps per second: 155, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  18695/125000: episode: 28, duration: 5.049s, episode steps: 1028, steps per second: 204, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  19242/125000: episode: 29, duration: 2.801s, episode steps: 547, steps per second: 195, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  19735/125000: episode: 30, duration: 3.994s, episode steps: 493, steps per second: 123, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  20135/125000: episode: 31, duration: 2.067s, episode steps: 400, steps per second: 194, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  20796/125000: episode: 32, duration: 3.323s, episode steps: 661, steps per second: 199, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  21343/125000: episode: 33, duration: 2.694s, episode steps: 547, steps per second: 203, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  22167/125000: episode: 34, duration: 5.674s, episode steps: 824, steps per second: 145, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  23243/125000: episode: 35, duration: 5.464s, episode steps: 1076, steps per second: 197, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  23644/125000: episode: 36, duration: 1.976s, episode steps: 401, steps per second: 203, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  24133/125000: episode: 37, duration: 2.597s, episode steps: 489, steps per second: 188, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  24641/125000: episode: 38, duration: 4.115s, episode steps: 508, steps per second: 123, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  25134/125000: episode: 39, duration: 3.046s, episode steps: 493, steps per second: 162, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.661 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  25622/125000: episode: 40, duration: 2.386s, episode steps: 488, steps per second: 205, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  26286/125000: episode: 41, duration: 3.416s, episode steps: 664, steps per second: 194, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  26999/125000: episode: 42, duration: 5.210s, episode steps: 713, steps per second: 137, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  27646/125000: episode: 43, duration: 3.364s, episode steps: 647, steps per second: 192, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  28299/125000: episode: 44, duration: 3.311s, episode steps: 653, steps per second: 197, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  28711/125000: episode: 45, duration: 1.969s, episode steps: 412, steps per second: 209, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  29208/125000: episode: 46, duration: 3.506s, episode steps: 497, steps per second: 142, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.602 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  30251/125000: episode: 47, duration: 5.798s, episode steps: 1043, steps per second: 180, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  30629/125000: episode: 48, duration: 1.758s, episode steps: 378, steps per second: 215, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.667 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  31068/125000: episode: 49, duration: 2.198s, episode steps: 439, steps per second: 200, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.636 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  31789/125000: episode: 50, duration: 4.698s, episode steps: 721, steps per second: 153, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.592 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  32222/125000: episode: 51, duration: 2.572s, episode steps: 433, steps per second: 168, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  32802/125000: episode: 52, duration: 2.846s, episode steps: 580, steps per second: 204, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.695 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  33315/125000: episode: 53, duration: 2.393s, episode steps: 513, steps per second: 214, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  34026/125000: episode: 54, duration: 4.018s, episode steps: 711, steps per second: 177, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  34747/125000: episode: 55, duration: 4.688s, episode steps: 721, steps per second: 154, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.632 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  35234/125000: episode: 56, duration: 2.512s, episode steps: 487, steps per second: 194, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.667 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  36016/125000: episode: 57, duration: 4.012s, episode steps: 782, steps per second: 195, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  36654/125000: episode: 58, duration: 4.246s, episode steps: 638, steps per second: 150, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  37171/125000: episode: 59, duration: 3.193s, episode steps: 517, steps per second: 162, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.714 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  37716/125000: episode: 60, duration: 2.633s, episode steps: 545, steps per second: 207, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  38454/125000: episode: 61, duration: 3.578s, episode steps: 738, steps per second: 206, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  39708/125000: episode: 62, duration: 7.918s, episode steps: 1254, steps per second: 158, episode reward: 26.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  40080/125000: episode: 63, duration: 1.894s, episode steps: 372, steps per second: 196, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  40474/125000: episode: 64, duration: 1.931s, episode steps: 394, steps per second: 204, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  40824/125000: episode: 65, duration: 1.790s, episode steps: 350, steps per second: 196, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.729 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  41347/125000: episode: 66, duration: 2.928s, episode steps: 523, steps per second: 179, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.623 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  41851/125000: episode: 67, duration: 3.871s, episode steps: 504, steps per second: 130, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  42985/125000: episode: 68, duration: 5.588s, episode steps: 1134, steps per second: 203, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  44189/125000: episode: 69, duration: 7.555s, episode steps: 1204, steps per second: 159, episode reward: 28.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  44966/125000: episode: 70, duration: 4.052s, episode steps: 777, steps per second: 192, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  45711/125000: episode: 71, duration: 4.348s, episode steps: 745, steps per second: 171, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  46397/125000: episode: 72, duration: 6.319s, episode steps: 686, steps per second: 109, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.733 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  47448/125000: episode: 73, duration: 5.592s, episode steps: 1051, steps per second: 188, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  48091/125000: episode: 74, duration: 3.368s, episode steps: 643, steps per second: 191, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  48450/125000: episode: 75, duration: 2.274s, episode steps: 359, steps per second: 158, episode reward:  6.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.713 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  48970/125000: episode: 76, duration: 3.856s, episode steps: 520, steps per second: 135, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  49364/125000: episode: 77, duration: 1.980s, episode steps: 394, steps per second: 199, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.815 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  49844/125000: episode: 78, duration: 2.594s, episode steps: 480, steps per second: 185, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.663 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  50326/125000: episode: 79, duration: 81.127s, episode steps: 482, steps per second:   6, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.685 [0.000, 5.000],  loss: 0.011988, mae: 0.480977, mean_q: 0.591011, mean_eps: 0.774266\n",
            "  50836/125000: episode: 80, duration: 122.197s, episode steps: 510, steps per second:   4, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.011484, mae: 0.479145, mean_q: 0.585658, mean_eps: 0.772388\n",
            "  51476/125000: episode: 81, duration: 156.931s, episode steps: 640, steps per second:   4, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.010772, mae: 0.475709, mean_q: 0.580060, mean_eps: 0.769800\n",
            "  51971/125000: episode: 82, duration: 119.482s, episode steps: 495, steps per second:   4, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.009741, mae: 0.476042, mean_q: 0.580918, mean_eps: 0.767246\n",
            "  52571/125000: episode: 83, duration: 143.439s, episode steps: 600, steps per second:   4, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.009943, mae: 0.471340, mean_q: 0.574531, mean_eps: 0.764783\n",
            "  53172/125000: episode: 84, duration: 142.251s, episode steps: 601, steps per second:   4, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.009456, mae: 0.472407, mean_q: 0.578133, mean_eps: 0.762081\n",
            "  53522/125000: episode: 85, duration: 84.129s, episode steps: 350, steps per second:   4, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.009044, mae: 0.472888, mean_q: 0.577837, mean_eps: 0.759941\n",
            "  54416/125000: episode: 86, duration: 210.955s, episode steps: 894, steps per second:   4, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.009258, mae: 0.472055, mean_q: 0.577535, mean_eps: 0.757142\n",
            "  55067/125000: episode: 87, duration: 153.907s, episode steps: 651, steps per second:   4, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.008847, mae: 0.470176, mean_q: 0.576097, mean_eps: 0.753665\n",
            "  56299/125000: episode: 88, duration: 298.046s, episode steps: 1232, steps per second:   4, episode reward: 16.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.007948, mae: 0.467888, mean_q: 0.573750, mean_eps: 0.749429\n",
            "  57138/125000: episode: 89, duration: 203.244s, episode steps: 839, steps per second:   4, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.248 [0.000, 5.000],  loss: 0.007476, mae: 0.471152, mean_q: 0.579060, mean_eps: 0.744769\n",
            "  57750/125000: episode: 90, duration: 148.132s, episode steps: 612, steps per second:   4, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.307 [0.000, 5.000],  loss: 0.007409, mae: 0.469741, mean_q: 0.578037, mean_eps: 0.741504\n",
            "  58268/125000: episode: 91, duration: 121.757s, episode steps: 518, steps per second:   4, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.006943, mae: 0.467585, mean_q: 0.574831, mean_eps: 0.738962\n",
            "  58731/125000: episode: 92, duration: 110.882s, episode steps: 463, steps per second:   4, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.203 [0.000, 5.000],  loss: 0.006642, mae: 0.465818, mean_q: 0.572870, mean_eps: 0.736754\n",
            "  59118/125000: episode: 93, duration: 92.218s, episode steps: 387, steps per second:   4, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.261 [0.000, 5.000],  loss: 0.006418, mae: 0.463832, mean_q: 0.571791, mean_eps: 0.734842\n",
            "  59959/125000: episode: 94, duration: 200.285s, episode steps: 841, steps per second:   4, episode reward: 20.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.006708, mae: 0.462724, mean_q: 0.570988, mean_eps: 0.732079\n",
            "  60483/125000: episode: 95, duration: 123.408s, episode steps: 524, steps per second:   4, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.634 [0.000, 5.000],  loss: 0.008201, mae: 0.490624, mean_q: 0.604158, mean_eps: 0.729008\n",
            "  61471/125000: episode: 96, duration: 235.448s, episode steps: 988, steps per second:   4, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.007944, mae: 0.493279, mean_q: 0.607539, mean_eps: 0.725606\n",
            "  61988/125000: episode: 97, duration: 123.289s, episode steps: 517, steps per second:   4, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.007317, mae: 0.496141, mean_q: 0.611961, mean_eps: 0.722219\n",
            "  62323/125000: episode: 98, duration: 79.244s, episode steps: 335, steps per second:   4, episode reward:  6.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.007284, mae: 0.495897, mean_q: 0.612368, mean_eps: 0.720302\n",
            "  62968/125000: episode: 99, duration: 153.939s, episode steps: 645, steps per second:   4, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: 0.006773, mae: 0.491007, mean_q: 0.606372, mean_eps: 0.718098\n",
            "  63567/125000: episode: 100, duration: 141.227s, episode steps: 599, steps per second:   4, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.006545, mae: 0.490937, mean_q: 0.606002, mean_eps: 0.715299\n",
            "  64224/125000: episode: 101, duration: 155.688s, episode steps: 657, steps per second:   4, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.659 [0.000, 5.000],  loss: 0.006263, mae: 0.491224, mean_q: 0.605351, mean_eps: 0.712472\n",
            "  64737/125000: episode: 102, duration: 124.993s, episode steps: 513, steps per second:   4, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.353 [0.000, 5.000],  loss: 0.006309, mae: 0.495133, mean_q: 0.611349, mean_eps: 0.709840\n",
            "  65304/125000: episode: 103, duration: 133.926s, episode steps: 567, steps per second:   4, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.006387, mae: 0.489166, mean_q: 0.603210, mean_eps: 0.707410\n",
            "  66120/125000: episode: 104, duration: 196.143s, episode steps: 816, steps per second:   4, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.343 [0.000, 5.000],  loss: 0.005739, mae: 0.489083, mean_q: 0.604608, mean_eps: 0.704298\n",
            "  66680/125000: episode: 105, duration: 134.394s, episode steps: 560, steps per second:   4, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.259 [0.000, 5.000],  loss: 0.006092, mae: 0.490236, mean_q: 0.605086, mean_eps: 0.701202\n",
            "  67203/125000: episode: 106, duration: 125.859s, episode steps: 523, steps per second:   4, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.006080, mae: 0.494678, mean_q: 0.611210, mean_eps: 0.698766\n",
            "  67864/125000: episode: 107, duration: 161.214s, episode steps: 661, steps per second:   4, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.006133, mae: 0.487727, mean_q: 0.602894, mean_eps: 0.696101\n",
            "  68607/125000: episode: 108, duration: 184.274s, episode steps: 743, steps per second:   4, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.005735, mae: 0.489630, mean_q: 0.605837, mean_eps: 0.692943\n",
            "  69514/125000: episode: 109, duration: 223.947s, episode steps: 907, steps per second:   4, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.622 [0.000, 5.000],  loss: 0.005835, mae: 0.487494, mean_q: 0.602982, mean_eps: 0.689230\n",
            "  70025/125000: episode: 110, duration: 125.750s, episode steps: 511, steps per second:   4, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.005731, mae: 0.488064, mean_q: 0.604163, mean_eps: 0.686039\n",
            "  71091/125000: episode: 111, duration: 264.181s, episode steps: 1066, steps per second:   4, episode reward: 14.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.617 [0.000, 5.000],  loss: 0.007558, mae: 0.521328, mean_q: 0.643369, mean_eps: 0.682491\n",
            "  71837/125000: episode: 112, duration: 182.904s, episode steps: 746, steps per second:   4, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.332 [0.000, 5.000],  loss: 0.006518, mae: 0.519342, mean_q: 0.640099, mean_eps: 0.678414\n",
            "  72270/125000: episode: 113, duration: 103.632s, episode steps: 433, steps per second:   4, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.806 [0.000, 5.000],  loss: 0.007048, mae: 0.524887, mean_q: 0.646578, mean_eps: 0.675762\n",
            "  72933/125000: episode: 114, duration: 160.426s, episode steps: 663, steps per second:   4, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.006731, mae: 0.519790, mean_q: 0.642088, mean_eps: 0.673296\n",
            "  73323/125000: episode: 115, duration: 93.591s, episode steps: 390, steps per second:   4, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.006362, mae: 0.519267, mean_q: 0.640569, mean_eps: 0.670926\n",
            "  74267/125000: episode: 116, duration: 228.242s, episode steps: 944, steps per second:   4, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.405 [0.000, 5.000],  loss: 0.006425, mae: 0.518701, mean_q: 0.639885, mean_eps: 0.667925\n",
            "  74819/125000: episode: 117, duration: 136.507s, episode steps: 552, steps per second:   4, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.006325, mae: 0.519381, mean_q: 0.641006, mean_eps: 0.664559\n",
            "  75209/125000: episode: 118, duration: 95.982s, episode steps: 390, steps per second:   4, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.005928, mae: 0.514596, mean_q: 0.636071, mean_eps: 0.662439\n",
            "  76073/125000: episode: 119, duration: 212.981s, episode steps: 864, steps per second:   4, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.006001, mae: 0.522086, mean_q: 0.644906, mean_eps: 0.659618\n",
            "  76424/125000: episode: 120, duration: 84.661s, episode steps: 351, steps per second:   4, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.370 [0.000, 5.000],  loss: 0.006246, mae: 0.521851, mean_q: 0.644763, mean_eps: 0.656884\n",
            "  77160/125000: episode: 121, duration: 182.030s, episode steps: 736, steps per second:   4, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.318 [0.000, 5.000],  loss: 0.005710, mae: 0.519249, mean_q: 0.641293, mean_eps: 0.654438\n",
            "  77796/125000: episode: 122, duration: 156.454s, episode steps: 636, steps per second:   4, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.005322, mae: 0.521345, mean_q: 0.645274, mean_eps: 0.651351\n",
            "  78172/125000: episode: 123, duration: 89.706s, episode steps: 376, steps per second:   4, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: 0.005320, mae: 0.522984, mean_q: 0.646439, mean_eps: 0.649074\n",
            "  79336/125000: episode: 124, duration: 282.285s, episode steps: 1164, steps per second:   4, episode reward: 19.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.005783, mae: 0.525156, mean_q: 0.648266, mean_eps: 0.645609\n",
            "  80317/125000: episode: 125, duration: 238.947s, episode steps: 981, steps per second:   4, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.006021, mae: 0.527036, mean_q: 0.650446, mean_eps: 0.640783\n",
            "  81148/125000: episode: 126, duration: 203.600s, episode steps: 831, steps per second:   4, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.298 [0.000, 5.000],  loss: 0.007346, mae: 0.551695, mean_q: 0.680611, mean_eps: 0.636706\n",
            "  82026/125000: episode: 127, duration: 212.264s, episode steps: 878, steps per second:   4, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.006772, mae: 0.546298, mean_q: 0.673571, mean_eps: 0.632861\n",
            "  83040/125000: episode: 128, duration: 241.188s, episode steps: 1014, steps per second:   4, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.006473, mae: 0.548580, mean_q: 0.675958, mean_eps: 0.628604\n",
            "  83465/125000: episode: 129, duration: 96.814s, episode steps: 425, steps per second:   4, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.006174, mae: 0.549155, mean_q: 0.676607, mean_eps: 0.625366\n",
            "  84209/125000: episode: 130, duration: 168.770s, episode steps: 744, steps per second:   4, episode reward: 19.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.006215, mae: 0.545550, mean_q: 0.672346, mean_eps: 0.622736\n",
            "  84667/125000: episode: 131, duration: 106.266s, episode steps: 458, steps per second:   4, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.347 [0.000, 5.000],  loss: 0.006375, mae: 0.550588, mean_q: 0.678593, mean_eps: 0.620031\n",
            "  85249/125000: episode: 132, duration: 134.883s, episode steps: 582, steps per second:   4, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.383 [0.000, 5.000],  loss: 0.006289, mae: 0.546209, mean_q: 0.673647, mean_eps: 0.617691\n",
            "  85792/125000: episode: 133, duration: 124.167s, episode steps: 543, steps per second:   4, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.006537, mae: 0.548321, mean_q: 0.675473, mean_eps: 0.615160\n",
            "  86306/125000: episode: 134, duration: 118.418s, episode steps: 514, steps per second:   4, episode reward: 11.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.006075, mae: 0.546155, mean_q: 0.675178, mean_eps: 0.612782\n",
            "  87428/125000: episode: 135, duration: 254.715s, episode steps: 1122, steps per second:   4, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.006290, mae: 0.550166, mean_q: 0.679400, mean_eps: 0.609101\n",
            "  88261/125000: episode: 136, duration: 188.514s, episode steps: 833, steps per second:   4, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.005719, mae: 0.546940, mean_q: 0.674266, mean_eps: 0.604702\n",
            "  89138/125000: episode: 137, duration: 200.432s, episode steps: 877, steps per second:   4, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.005840, mae: 0.542837, mean_q: 0.669812, mean_eps: 0.600854\n",
            "  89632/125000: episode: 138, duration: 112.760s, episode steps: 494, steps per second:   4, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: 0.005842, mae: 0.550935, mean_q: 0.678914, mean_eps: 0.597770\n",
            "  90214/125000: episode: 139, duration: 133.362s, episode steps: 582, steps per second:   4, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.784 [0.000, 5.000],  loss: 0.006667, mae: 0.555621, mean_q: 0.685314, mean_eps: 0.595349\n",
            "  90711/125000: episode: 140, duration: 113.897s, episode steps: 497, steps per second:   4, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.736 [0.000, 5.000],  loss: 0.008217, mae: 0.576812, mean_q: 0.711340, mean_eps: 0.592921\n",
            "  91185/125000: episode: 141, duration: 106.637s, episode steps: 474, steps per second:   4, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.639 [0.000, 5.000],  loss: 0.007941, mae: 0.573514, mean_q: 0.707156, mean_eps: 0.590736\n",
            "  91965/125000: episode: 142, duration: 178.063s, episode steps: 780, steps per second:   4, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.007871, mae: 0.574353, mean_q: 0.708143, mean_eps: 0.587915\n",
            "  92618/125000: episode: 143, duration: 148.427s, episode steps: 653, steps per second:   4, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.007007, mae: 0.564857, mean_q: 0.696021, mean_eps: 0.584691\n",
            "  93123/125000: episode: 144, duration: 114.228s, episode steps: 505, steps per second:   4, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.007135, mae: 0.576522, mean_q: 0.710722, mean_eps: 0.582085\n",
            "  93651/125000: episode: 145, duration: 120.606s, episode steps: 528, steps per second:   4, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: 0.007223, mae: 0.577290, mean_q: 0.711869, mean_eps: 0.579761\n",
            "  94159/125000: episode: 146, duration: 115.026s, episode steps: 508, steps per second:   4, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.325 [0.000, 5.000],  loss: 0.007019, mae: 0.578353, mean_q: 0.713439, mean_eps: 0.577430\n",
            "  94885/125000: episode: 147, duration: 164.014s, episode steps: 726, steps per second:   4, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.006614, mae: 0.570351, mean_q: 0.702536, mean_eps: 0.574653\n",
            "  95507/125000: episode: 148, duration: 142.551s, episode steps: 622, steps per second:   4, episode reward: 14.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.814 [0.000, 5.000],  loss: 0.006228, mae: 0.566955, mean_q: 0.698606, mean_eps: 0.571620\n",
            "  96576/125000: episode: 149, duration: 243.821s, episode steps: 1069, steps per second:   4, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.630 [0.000, 5.000],  loss: 0.006156, mae: 0.568608, mean_q: 0.701282, mean_eps: 0.567816\n",
            "  96941/125000: episode: 150, duration: 84.555s, episode steps: 365, steps per second:   4, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.633 [0.000, 5.000],  loss: 0.006312, mae: 0.568959, mean_q: 0.701591, mean_eps: 0.564589\n",
            "  97580/125000: episode: 151, duration: 145.220s, episode steps: 639, steps per second:   4, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: 0.006507, mae: 0.570505, mean_q: 0.702743, mean_eps: 0.562330\n",
            "  98050/125000: episode: 152, duration: 107.816s, episode steps: 470, steps per second:   4, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.657 [0.000, 5.000],  loss: 0.006360, mae: 0.571420, mean_q: 0.704288, mean_eps: 0.559835\n",
            "  98749/125000: episode: 153, duration: 158.461s, episode steps: 699, steps per second:   4, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.005988, mae: 0.566286, mean_q: 0.698506, mean_eps: 0.557204\n",
            "  99304/125000: episode: 154, duration: 126.042s, episode steps: 555, steps per second:   4, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.006123, mae: 0.569917, mean_q: 0.702977, mean_eps: 0.554383\n",
            "  99921/125000: episode: 155, duration: 139.916s, episode steps: 617, steps per second:   4, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.622 [0.000, 5.000],  loss: 0.005923, mae: 0.566077, mean_q: 0.698083, mean_eps: 0.551746\n",
            " 100478/125000: episode: 156, duration: 129.140s, episode steps: 557, steps per second:   4, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.661 [0.000, 5.000],  loss: 0.007984, mae: 0.582972, mean_q: 0.717914, mean_eps: 0.549104\n",
            " 101053/125000: episode: 157, duration: 131.487s, episode steps: 575, steps per second:   4, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.275 [0.000, 5.000],  loss: 0.008028, mae: 0.588658, mean_q: 0.725016, mean_eps: 0.546557\n",
            " 102127/125000: episode: 158, duration: 246.751s, episode steps: 1074, steps per second:   4, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.788 [0.000, 5.000],  loss: 0.008063, mae: 0.585983, mean_q: 0.721780, mean_eps: 0.542847\n",
            " 102769/125000: episode: 159, duration: 150.171s, episode steps: 642, steps per second:   4, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.007298, mae: 0.584425, mean_q: 0.719058, mean_eps: 0.538986\n",
            " 103115/125000: episode: 160, duration: 78.789s, episode steps: 346, steps per second:   4, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.711 [0.000, 5.000],  loss: 0.006655, mae: 0.590728, mean_q: 0.725533, mean_eps: 0.536763\n",
            " 103700/125000: episode: 161, duration: 134.600s, episode steps: 585, steps per second:   4, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.641 [0.000, 5.000],  loss: 0.007228, mae: 0.586391, mean_q: 0.719702, mean_eps: 0.534668\n",
            " 104092/125000: episode: 162, duration: 92.029s, episode steps: 392, steps per second:   4, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.709 [0.000, 5.000],  loss: 0.006664, mae: 0.581991, mean_q: 0.716289, mean_eps: 0.532470\n",
            " 104924/125000: episode: 163, duration: 191.780s, episode steps: 832, steps per second:   4, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.691 [0.000, 5.000],  loss: 0.006431, mae: 0.583789, mean_q: 0.718357, mean_eps: 0.529716\n",
            " 105549/125000: episode: 164, duration: 145.511s, episode steps: 625, steps per second:   4, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.629 [0.000, 5.000],  loss: 0.006437, mae: 0.582361, mean_q: 0.715844, mean_eps: 0.526438\n",
            " 106127/125000: episode: 165, duration: 132.234s, episode steps: 578, steps per second:   4, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.006433, mae: 0.580848, mean_q: 0.714414, mean_eps: 0.523731\n",
            " 106815/125000: episode: 166, duration: 156.981s, episode steps: 688, steps per second:   4, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.622 [0.000, 5.000],  loss: 0.006430, mae: 0.587616, mean_q: 0.723060, mean_eps: 0.520883\n",
            " 107363/125000: episode: 167, duration: 126.233s, episode steps: 548, steps per second:   4, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.006592, mae: 0.583908, mean_q: 0.718302, mean_eps: 0.518102\n",
            " 108051/125000: episode: 168, duration: 154.999s, episode steps: 688, steps per second:   4, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.006620, mae: 0.587186, mean_q: 0.722711, mean_eps: 0.515321\n",
            " 108560/125000: episode: 169, duration: 115.243s, episode steps: 509, steps per second:   4, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.006379, mae: 0.584494, mean_q: 0.719770, mean_eps: 0.512628\n",
            " 109057/125000: episode: 170, duration: 113.001s, episode steps: 497, steps per second:   4, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.634 [0.000, 5.000],  loss: 0.006422, mae: 0.584553, mean_q: 0.719652, mean_eps: 0.510364\n",
            " 109687/125000: episode: 171, duration: 143.009s, episode steps: 630, steps per second:   4, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.006351, mae: 0.587421, mean_q: 0.723644, mean_eps: 0.507828\n",
            " 110317/125000: episode: 172, duration: 142.594s, episode steps: 630, steps per second:   4, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: 0.007091, mae: 0.600028, mean_q: 0.738072, mean_eps: 0.504993\n",
            " 110894/125000: episode: 173, duration: 131.333s, episode steps: 577, steps per second:   4, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.008223, mae: 0.607929, mean_q: 0.747032, mean_eps: 0.502278\n",
            " 111261/125000: episode: 174, duration: 83.408s, episode steps: 367, steps per second:   4, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.657 [0.000, 5.000],  loss: 0.008376, mae: 0.605272, mean_q: 0.742902, mean_eps: 0.500154\n",
            " 111947/125000: episode: 175, duration: 155.969s, episode steps: 686, steps per second:   4, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.305 [0.000, 5.000],  loss: 0.007758, mae: 0.604332, mean_q: 0.742622, mean_eps: 0.497784\n",
            " 112437/125000: episode: 176, duration: 108.914s, episode steps: 490, steps per second:   4, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: 0.007623, mae: 0.609725, mean_q: 0.749552, mean_eps: 0.495138\n",
            " 113605/125000: episode: 177, duration: 265.072s, episode steps: 1168, steps per second:   4, episode reward: 23.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.334 [0.000, 5.000],  loss: 0.007527, mae: 0.610238, mean_q: 0.750962, mean_eps: 0.491408\n",
            " 114004/125000: episode: 178, duration: 90.044s, episode steps: 399, steps per second:   4, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.677 [0.000, 5.000],  loss: 0.007595, mae: 0.616648, mean_q: 0.757804, mean_eps: 0.487882\n",
            " 114534/125000: episode: 179, duration: 118.615s, episode steps: 530, steps per second:   4, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.270 [0.000, 5.000],  loss: 0.007122, mae: 0.612388, mean_q: 0.753439, mean_eps: 0.485792\n",
            " 115169/125000: episode: 180, duration: 143.102s, episode steps: 635, steps per second:   4, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.006972, mae: 0.611215, mean_q: 0.750895, mean_eps: 0.483170\n",
            " 115847/125000: episode: 181, duration: 153.624s, episode steps: 678, steps per second:   4, episode reward: 16.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.653 [0.000, 5.000],  loss: 0.006727, mae: 0.608314, mean_q: 0.748370, mean_eps: 0.480216\n",
            " 116331/125000: episode: 182, duration: 110.585s, episode steps: 484, steps per second:   4, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.007091, mae: 0.604318, mean_q: 0.743606, mean_eps: 0.477602\n",
            " 117167/125000: episode: 183, duration: 189.501s, episode steps: 836, steps per second:   4, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: 0.007006, mae: 0.608525, mean_q: 0.748469, mean_eps: 0.474632\n",
            " 117670/125000: episode: 184, duration: 113.381s, episode steps: 503, steps per second:   4, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.632 [0.000, 5.000],  loss: 0.006875, mae: 0.607395, mean_q: 0.746698, mean_eps: 0.471619\n",
            " 118352/125000: episode: 185, duration: 153.573s, episode steps: 682, steps per second:   4, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.006831, mae: 0.608621, mean_q: 0.749161, mean_eps: 0.468953\n",
            " 119301/125000: episode: 186, duration: 214.396s, episode steps: 949, steps per second:   4, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.729 [0.000, 5.000],  loss: 0.006338, mae: 0.610669, mean_q: 0.751742, mean_eps: 0.465283\n",
            " 119812/125000: episode: 187, duration: 116.115s, episode steps: 511, steps per second:   4, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.881 [0.000, 5.000],  loss: 0.007054, mae: 0.607993, mean_q: 0.747585, mean_eps: 0.461998\n",
            " 120657/125000: episode: 188, duration: 190.993s, episode steps: 845, steps per second:   4, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.922 [0.000, 5.000],  loss: 0.008684, mae: 0.632111, mean_q: 0.777301, mean_eps: 0.458947\n",
            " 121198/125000: episode: 189, duration: 121.723s, episode steps: 541, steps per second:   4, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.008513, mae: 0.645262, mean_q: 0.792039, mean_eps: 0.455828\n",
            " 121728/125000: episode: 190, duration: 119.497s, episode steps: 530, steps per second:   4, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.708 [0.000, 5.000],  loss: 0.008614, mae: 0.641960, mean_q: 0.788651, mean_eps: 0.453419\n",
            " 122500/125000: episode: 191, duration: 172.655s, episode steps: 772, steps per second:   4, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.008344, mae: 0.633270, mean_q: 0.777704, mean_eps: 0.450489\n",
            " 123242/125000: episode: 192, duration: 168.691s, episode steps: 742, steps per second:   4, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.770 [0.000, 5.000],  loss: 0.007810, mae: 0.635274, mean_q: 0.780082, mean_eps: 0.447083\n",
            " 123965/125000: episode: 193, duration: 163.738s, episode steps: 723, steps per second:   4, episode reward: 16.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.336 [0.000, 5.000],  loss: 0.007422, mae: 0.634824, mean_q: 0.781268, mean_eps: 0.443787\n",
            " 124380/125000: episode: 194, duration: 94.127s, episode steps: 415, steps per second:   4, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: 0.007180, mae: 0.635163, mean_q: 0.781220, mean_eps: 0.441226\n",
            "done, took 17828.386 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7a92eb93da90>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "weights_filename = 'dqn_weights_125000.h5f'.format(env)\n",
        "dqn.load_weights(weights_filename)\n",
        "dqn.test(env, nb_episodes=10, visualize=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-P1haTn_Goo",
        "outputId": "0b71a628-8cc2-4cab-defe-bff7ab8d5f4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 10 episodes ...\n",
            "Episode 1: reward: 9.000, steps: 520\n",
            "Episode 2: reward: 22.000, steps: 980\n",
            "Episode 3: reward: 10.000, steps: 601\n",
            "Episode 4: reward: 22.000, steps: 953\n",
            "Episode 5: reward: 21.000, steps: 1026\n",
            "Episode 6: reward: 10.000, steps: 638\n",
            "Episode 7: reward: 6.000, steps: 477\n",
            "Episode 8: reward: 9.000, steps: 522\n",
            "Episode 9: reward: 8.000, steps: 688\n",
            "Episode 10: reward: 7.000, steps: 598\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7a92e8fe7990>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento parte 3"
      ],
      "metadata": {
        "id": "1WNhfeASg9VN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "aqui colocar todo el entrenamiento de: https://colab.research.google.com/drive/1jITASRB4yK1a7xb61uvMEL4Be4oxlTuN"
      ],
      "metadata": {
        "id": "9OnM2peRlx0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AGENTE DQN\n",
        "dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory,\n",
        "               nb_steps_warmup=50000, enable_double_dqn=True,\n",
        "               enable_dueling_network=True, dueling_type='avg',\n",
        "               target_model_update=10000, policy=policy,\n",
        "               processor=AtariProcessor())\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "dqn.compile(Adam(lr=0.00025), metrics=['mae'])\n",
        "\n",
        "# CHECKPOINTS Y LOGGING\n",
        "checkpoint_path = drive_root + '/dqn_weights_{step}.h5f'\n",
        "weights_filename = drive_root + '/dqn_final_weights.h5f'\n",
        "\n",
        "callbacks = [\n",
        "    ModelIntervalCheckpoint(checkpoint_path, interval=25000),\n",
        "    FileLogger(drive_root + '/dqn_log.json', interval=10000)\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsZNx4gAH8Da",
        "outputId": "324b5c3e-ded5-4ec3-9f1d-c18a3b65bc18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ENTRENAMIENTO\n",
        "dqn.fit(env, nb_steps=1000000, visualize=False, verbose=2, callbacks=callbacks)\n",
        "dqn.save_weights(weights_filename, overwrite=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcf7QfIxH71S",
        "outputId": "f31a76fa-99a7-4c28-bedb-1dc72a83cf1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 1000000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    612/1000000: episode: 1, duration: 2.414s, episode steps: 612, steps per second: 254, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   1256/1000000: episode: 2, duration: 2.400s, episode steps: 644, steps per second: 268, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   1687/1000000: episode: 3, duration: 1.392s, episode steps: 431, steps per second: 310, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   2465/1000000: episode: 4, duration: 2.388s, episode steps: 778, steps per second: 326, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.634 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   3211/1000000: episode: 5, duration: 2.198s, episode steps: 746, steps per second: 339, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   3785/1000000: episode: 6, duration: 1.744s, episode steps: 574, steps per second: 329, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   4300/1000000: episode: 7, duration: 2.109s, episode steps: 515, steps per second: 244, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   4817/1000000: episode: 8, duration: 2.048s, episode steps: 517, steps per second: 252, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   5178/1000000: episode: 9, duration: 1.190s, episode steps: 361, steps per second: 303, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   5932/1000000: episode: 10, duration: 2.329s, episode steps: 754, steps per second: 324, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   6726/1000000: episode: 11, duration: 2.470s, episode steps: 794, steps per second: 321, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   7444/1000000: episode: 12, duration: 2.241s, episode steps: 718, steps per second: 320, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   7856/1000000: episode: 13, duration: 1.475s, episode steps: 412, steps per second: 279, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.367 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   8516/1000000: episode: 14, duration: 2.440s, episode steps: 660, steps per second: 270, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   9303/1000000: episode: 15, duration: 2.787s, episode steps: 787, steps per second: 282, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   9862/1000000: episode: 16, duration: 1.852s, episode steps: 559, steps per second: 302, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  10862/1000000: episode: 17, duration: 3.257s, episode steps: 1000, steps per second: 307, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  11541/1000000: episode: 18, duration: 2.446s, episode steps: 679, steps per second: 278, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  12209/1000000: episode: 19, duration: 2.121s, episode steps: 668, steps per second: 315, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  13521/1000000: episode: 20, duration: 4.330s, episode steps: 1312, steps per second: 303, episode reward: 24.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  14205/1000000: episode: 21, duration: 2.206s, episode steps: 684, steps per second: 310, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  15150/1000000: episode: 22, duration: 3.222s, episode steps: 945, steps per second: 293, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  15695/1000000: episode: 23, duration: 1.914s, episode steps: 545, steps per second: 285, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  17135/1000000: episode: 24, duration: 4.182s, episode steps: 1440, steps per second: 344, episode reward: 18.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  17764/1000000: episode: 25, duration: 1.985s, episode steps: 629, steps per second: 317, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  18363/1000000: episode: 26, duration: 1.914s, episode steps: 599, steps per second: 313, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  19686/1000000: episode: 27, duration: 4.628s, episode steps: 1323, steps per second: 286, episode reward: 20.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  20164/1000000: episode: 28, duration: 1.483s, episode steps: 478, steps per second: 322, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  20780/1000000: episode: 29, duration: 1.897s, episode steps: 616, steps per second: 325, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.619 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  21762/1000000: episode: 30, duration: 3.149s, episode steps: 982, steps per second: 312, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.660 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  22585/1000000: episode: 31, duration: 3.287s, episode steps: 823, steps per second: 250, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  23268/1000000: episode: 32, duration: 2.105s, episode steps: 683, steps per second: 324, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.633 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  23661/1000000: episode: 33, duration: 1.225s, episode steps: 393, steps per second: 321, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  24625/1000000: episode: 34, duration: 3.144s, episode steps: 964, steps per second: 307, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  25473/1000000: episode: 35, duration: 2.889s, episode steps: 848, steps per second: 294, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  26188/1000000: episode: 36, duration: 2.915s, episode steps: 715, steps per second: 245, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  26980/1000000: episode: 37, duration: 2.544s, episode steps: 792, steps per second: 311, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.676 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  27368/1000000: episode: 38, duration: 1.167s, episode steps: 388, steps per second: 333, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  28237/1000000: episode: 39, duration: 2.662s, episode steps: 869, steps per second: 326, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  29273/1000000: episode: 40, duration: 3.353s, episode steps: 1036, steps per second: 309, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  30606/1000000: episode: 41, duration: 4.801s, episode steps: 1333, steps per second: 278, episode reward: 19.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  30971/1000000: episode: 42, duration: 1.074s, episode steps: 365, steps per second: 340, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.668 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  31655/1000000: episode: 43, duration: 1.993s, episode steps: 684, steps per second: 343, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  32091/1000000: episode: 44, duration: 1.429s, episode steps: 436, steps per second: 305, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  33065/1000000: episode: 45, duration: 3.271s, episode steps: 974, steps per second: 298, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  33777/1000000: episode: 46, duration: 2.750s, episode steps: 712, steps per second: 259, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  34267/1000000: episode: 47, duration: 1.456s, episode steps: 490, steps per second: 337, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  34652/1000000: episode: 48, duration: 1.190s, episode steps: 385, steps per second: 323, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.618 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  35014/1000000: episode: 49, duration: 1.078s, episode steps: 362, steps per second: 336, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.660 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  35650/1000000: episode: 50, duration: 1.906s, episode steps: 636, steps per second: 334, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  36207/1000000: episode: 51, duration: 1.732s, episode steps: 557, steps per second: 322, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.670 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  36876/1000000: episode: 52, duration: 2.387s, episode steps: 669, steps per second: 280, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  38137/1000000: episode: 53, duration: 4.036s, episode steps: 1261, steps per second: 312, episode reward: 23.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  38642/1000000: episode: 54, duration: 1.463s, episode steps: 505, steps per second: 345, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  38975/1000000: episode: 55, duration: 1.053s, episode steps: 333, steps per second: 316, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  39699/1000000: episode: 56, duration: 2.258s, episode steps: 724, steps per second: 321, episode reward:  3.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  40110/1000000: episode: 57, duration: 1.292s, episode steps: 411, steps per second: 318, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  40728/1000000: episode: 58, duration: 2.351s, episode steps: 618, steps per second: 263, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  41118/1000000: episode: 59, duration: 1.458s, episode steps: 390, steps per second: 267, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.672 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  41734/1000000: episode: 60, duration: 1.969s, episode steps: 616, steps per second: 313, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  42660/1000000: episode: 61, duration: 2.699s, episode steps: 926, steps per second: 343, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  43232/1000000: episode: 62, duration: 1.918s, episode steps: 572, steps per second: 298, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  43966/1000000: episode: 63, duration: 2.286s, episode steps: 734, steps per second: 321, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  44634/1000000: episode: 64, duration: 2.752s, episode steps: 668, steps per second: 243, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  45188/1000000: episode: 65, duration: 1.510s, episode steps: 554, steps per second: 367, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  45926/1000000: episode: 66, duration: 2.411s, episode steps: 738, steps per second: 306, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  46893/1000000: episode: 67, duration: 3.040s, episode steps: 967, steps per second: 318, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  48199/1000000: episode: 68, duration: 4.525s, episode steps: 1306, steps per second: 289, episode reward: 14.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  49343/1000000: episode: 69, duration: 3.459s, episode steps: 1144, steps per second: 331, episode reward: 22.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  50144/1000000: episode: 70, duration: 23.850s, episode steps: 801, steps per second:  34, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.006639, mae: 0.019060, mean_q: 0.026977, mean_eps: 0.954935\n",
            "  50564/1000000: episode: 71, duration: 60.915s, episode steps: 420, steps per second:   7, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.617 [0.000, 5.000],  loss: 0.007052, mae: 0.020001, mean_q: 0.024775, mean_eps: 0.954682\n",
            "  51062/1000000: episode: 72, duration: 71.727s, episode steps: 498, steps per second:   7, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.008048, mae: 0.022247, mean_q: 0.026515, mean_eps: 0.954269\n",
            "  51856/1000000: episode: 73, duration: 115.243s, episode steps: 794, steps per second:   7, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.007479, mae: 0.020157, mean_q: 0.025653, mean_eps: 0.953687\n",
            "  52479/1000000: episode: 74, duration: 91.459s, episode steps: 623, steps per second:   7, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.006594, mae: 0.018736, mean_q: 0.023555, mean_eps: 0.953050\n",
            "  53118/1000000: episode: 75, duration: 92.965s, episode steps: 639, steps per second:   7, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.006485, mae: 0.020336, mean_q: 0.026323, mean_eps: 0.952482\n",
            "  53753/1000000: episode: 76, duration: 92.442s, episode steps: 635, steps per second:   7, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.006478, mae: 0.021046, mean_q: 0.027840, mean_eps: 0.951909\n",
            "  54243/1000000: episode: 77, duration: 71.125s, episode steps: 490, steps per second:   7, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.006990, mae: 0.020156, mean_q: 0.027538, mean_eps: 0.951402\n",
            "  54739/1000000: episode: 78, duration: 72.060s, episode steps: 496, steps per second:   7, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.006883, mae: 0.021547, mean_q: 0.028077, mean_eps: 0.950959\n",
            "  55250/1000000: episode: 79, duration: 75.657s, episode steps: 511, steps per second:   7, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.006689, mae: 0.020065, mean_q: 0.026031, mean_eps: 0.950505\n",
            "  56005/1000000: episode: 80, duration: 112.345s, episode steps: 755, steps per second:   7, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.006780, mae: 0.020606, mean_q: 0.028489, mean_eps: 0.949936\n",
            "  56848/1000000: episode: 81, duration: 124.519s, episode steps: 843, steps per second:   7, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.007079, mae: 0.022047, mean_q: 0.030907, mean_eps: 0.949217\n",
            "  57211/1000000: episode: 82, duration: 53.465s, episode steps: 363, steps per second:   7, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.006506, mae: 0.019642, mean_q: 0.026822, mean_eps: 0.948674\n",
            "  57834/1000000: episode: 83, duration: 90.588s, episode steps: 623, steps per second:   7, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.555 [0.000, 5.000],  loss: 0.006322, mae: 0.020297, mean_q: 0.029194, mean_eps: 0.948230\n",
            "  58391/1000000: episode: 84, duration: 81.361s, episode steps: 557, steps per second:   7, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.006641, mae: 0.020366, mean_q: 0.030510, mean_eps: 0.947699\n",
            "  58793/1000000: episode: 85, duration: 58.915s, episode steps: 402, steps per second:   7, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.348 [0.000, 5.000],  loss: 0.006773, mae: 0.020862, mean_q: 0.029947, mean_eps: 0.947268\n",
            "  59409/1000000: episode: 86, duration: 90.501s, episode steps: 616, steps per second:   7, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.006653, mae: 0.021708, mean_q: 0.033140, mean_eps: 0.946810\n",
            "  60309/1000000: episode: 87, duration: 131.109s, episode steps: 900, steps per second:   7, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.006222, mae: 0.027576, mean_q: 0.042896, mean_eps: 0.946127\n",
            "  60767/1000000: episode: 88, duration: 66.892s, episode steps: 458, steps per second:   7, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.006284, mae: 0.038877, mean_q: 0.060540, mean_eps: 0.945516\n",
            "  61264/1000000: episode: 89, duration: 74.546s, episode steps: 497, steps per second:   7, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.006937, mae: 0.042009, mean_q: 0.065439, mean_eps: 0.945086\n",
            "  61852/1000000: episode: 90, duration: 86.369s, episode steps: 588, steps per second:   7, episode reward:  2.000, mean reward:  0.003 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.006351, mae: 0.041518, mean_q: 0.065594, mean_eps: 0.944598\n",
            "  62502/1000000: episode: 91, duration: 95.504s, episode steps: 650, steps per second:   7, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.006551, mae: 0.040797, mean_q: 0.063553, mean_eps: 0.944041\n",
            "  63492/1000000: episode: 92, duration: 145.806s, episode steps: 990, steps per second:   7, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.006138, mae: 0.040053, mean_q: 0.063741, mean_eps: 0.943303\n",
            "  64007/1000000: episode: 93, duration: 75.330s, episode steps: 515, steps per second:   7, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.650 [0.000, 5.000],  loss: 0.006104, mae: 0.041112, mean_q: 0.067374, mean_eps: 0.942626\n",
            "  64947/1000000: episode: 94, duration: 138.677s, episode steps: 940, steps per second:   7, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.565 [0.000, 5.000],  loss: 0.006139, mae: 0.039995, mean_q: 0.064846, mean_eps: 0.941971\n",
            "  65638/1000000: episode: 95, duration: 100.592s, episode steps: 691, steps per second:   7, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.641 [0.000, 5.000],  loss: 0.005673, mae: 0.039373, mean_q: 0.065506, mean_eps: 0.941237\n",
            "  66327/1000000: episode: 96, duration: 100.996s, episode steps: 689, steps per second:   7, episode reward:  5.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.006035, mae: 0.040406, mean_q: 0.069085, mean_eps: 0.940616\n",
            "  67171/1000000: episode: 97, duration: 123.351s, episode steps: 844, steps per second:   7, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.005550, mae: 0.039878, mean_q: 0.067603, mean_eps: 0.939926\n",
            "  67769/1000000: episode: 98, duration: 88.053s, episode steps: 598, steps per second:   7, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.005319, mae: 0.037680, mean_q: 0.065568, mean_eps: 0.939277\n",
            "  68179/1000000: episode: 99, duration: 60.730s, episode steps: 410, steps per second:   7, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.005195, mae: 0.039365, mean_q: 0.068110, mean_eps: 0.938824\n",
            "  68682/1000000: episode: 100, duration: 73.985s, episode steps: 503, steps per second:   7, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.004504, mae: 0.035659, mean_q: 0.062575, mean_eps: 0.938413\n",
            "  69380/1000000: episode: 101, duration: 100.981s, episode steps: 698, steps per second:   7, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.005244, mae: 0.038012, mean_q: 0.066491, mean_eps: 0.937873\n",
            "  69799/1000000: episode: 102, duration: 61.010s, episode steps: 419, steps per second:   7, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.005509, mae: 0.039192, mean_q: 0.070827, mean_eps: 0.937370\n",
            "  70678/1000000: episode: 103, duration: 131.345s, episode steps: 879, steps per second:   7, episode reward: 23.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.006065, mae: 0.058191, mean_q: 0.094623, mean_eps: 0.936786\n",
            "  71193/1000000: episode: 104, duration: 76.375s, episode steps: 515, steps per second:   7, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.005810, mae: 0.062003, mean_q: 0.096820, mean_eps: 0.936159\n",
            "  71984/1000000: episode: 105, duration: 115.287s, episode steps: 791, steps per second:   7, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.005557, mae: 0.060770, mean_q: 0.094277, mean_eps: 0.935571\n",
            "  72404/1000000: episode: 106, duration: 62.417s, episode steps: 420, steps per second:   7, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.005427, mae: 0.061323, mean_q: 0.096277, mean_eps: 0.935026\n",
            "  73223/1000000: episode: 107, duration: 120.766s, episode steps: 819, steps per second:   7, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: 0.005623, mae: 0.060358, mean_q: 0.094659, mean_eps: 0.934468\n",
            "  73729/1000000: episode: 108, duration: 74.373s, episode steps: 506, steps per second:   7, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.005679, mae: 0.059697, mean_q: 0.094392, mean_eps: 0.933872\n",
            "  74588/1000000: episode: 109, duration: 125.539s, episode steps: 859, steps per second:   7, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.005357, mae: 0.059946, mean_q: 0.095586, mean_eps: 0.933258\n",
            "  75549/1000000: episode: 110, duration: 137.876s, episode steps: 961, steps per second:   7, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.005038, mae: 0.059313, mean_q: 0.093749, mean_eps: 0.932439\n",
            "  75974/1000000: episode: 111, duration: 61.355s, episode steps: 425, steps per second:   7, episode reward:  7.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.004338, mae: 0.055165, mean_q: 0.086929, mean_eps: 0.931815\n",
            "  76428/1000000: episode: 112, duration: 65.975s, episode steps: 454, steps per second:   7, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.004474, mae: 0.057413, mean_q: 0.090818, mean_eps: 0.931420\n",
            "  77070/1000000: episode: 113, duration: 93.858s, episode steps: 642, steps per second:   7, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.005388, mae: 0.059014, mean_q: 0.092456, mean_eps: 0.930926\n",
            "  77606/1000000: episode: 114, duration: 77.774s, episode steps: 536, steps per second:   7, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.575 [0.000, 5.000],  loss: 0.004418, mae: 0.055273, mean_q: 0.087371, mean_eps: 0.930396\n",
            "  78294/1000000: episode: 115, duration: 101.139s, episode steps: 688, steps per second:   7, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.004809, mae: 0.058185, mean_q: 0.094960, mean_eps: 0.929845\n",
            "  78909/1000000: episode: 116, duration: 89.773s, episode steps: 615, steps per second:   7, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: 0.004176, mae: 0.056344, mean_q: 0.090357, mean_eps: 0.929259\n",
            "  79423/1000000: episode: 117, duration: 75.861s, episode steps: 514, steps per second:   7, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.004689, mae: 0.057445, mean_q: 0.094201, mean_eps: 0.928751\n",
            "  80048/1000000: episode: 118, duration: 90.291s, episode steps: 625, steps per second:   7, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.004556, mae: 0.057171, mean_q: 0.092520, mean_eps: 0.928238\n",
            "  81353/1000000: episode: 119, duration: 190.772s, episode steps: 1305, steps per second:   7, episode reward: 21.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.005695, mae: 0.079166, mean_q: 0.121938, mean_eps: 0.927370\n",
            "  81846/1000000: episode: 120, duration: 71.952s, episode steps: 493, steps per second:   7, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.004995, mae: 0.077430, mean_q: 0.118960, mean_eps: 0.926561\n",
            "  82562/1000000: episode: 121, duration: 104.665s, episode steps: 716, steps per second:   7, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.325 [0.000, 5.000],  loss: 0.004635, mae: 0.075468, mean_q: 0.114960, mean_eps: 0.926017\n",
            "  83341/1000000: episode: 122, duration: 114.134s, episode steps: 779, steps per second:   7, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.004774, mae: 0.076864, mean_q: 0.117109, mean_eps: 0.925344\n",
            "  83987/1000000: episode: 123, duration: 94.850s, episode steps: 646, steps per second:   7, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.004544, mae: 0.076469, mean_q: 0.116957, mean_eps: 0.924703\n",
            "  84972/1000000: episode: 124, duration: 145.188s, episode steps: 985, steps per second:   7, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.004655, mae: 0.076211, mean_q: 0.116510, mean_eps: 0.923969\n",
            "  85351/1000000: episode: 125, duration: 56.320s, episode steps: 379, steps per second:   7, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.507 [0.000, 5.000],  loss: 0.004310, mae: 0.075407, mean_q: 0.116177, mean_eps: 0.923355\n",
            "  86023/1000000: episode: 126, duration: 99.282s, episode steps: 672, steps per second:   7, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.004394, mae: 0.075185, mean_q: 0.115420, mean_eps: 0.922882\n",
            "  86540/1000000: episode: 127, duration: 76.498s, episode steps: 517, steps per second:   7, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.004701, mae: 0.075829, mean_q: 0.116722, mean_eps: 0.922347\n",
            "  87493/1000000: episode: 128, duration: 141.361s, episode steps: 953, steps per second:   7, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.004179, mae: 0.074765, mean_q: 0.116480, mean_eps: 0.921686\n",
            "  88196/1000000: episode: 129, duration: 104.845s, episode steps: 703, steps per second:   7, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.004347, mae: 0.073752, mean_q: 0.114014, mean_eps: 0.920940\n",
            "  88924/1000000: episode: 130, duration: 108.277s, episode steps: 728, steps per second:   7, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.004378, mae: 0.074551, mean_q: 0.115818, mean_eps: 0.920296\n",
            "  89625/1000000: episode: 131, duration: 104.034s, episode steps: 701, steps per second:   7, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.003808, mae: 0.072579, mean_q: 0.112630, mean_eps: 0.919653\n",
            "  90029/1000000: episode: 132, duration: 60.135s, episode steps: 404, steps per second:   7, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.004195, mae: 0.075699, mean_q: 0.116972, mean_eps: 0.919156\n",
            "  90570/1000000: episode: 133, duration: 80.501s, episode steps: 541, steps per second:   7, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.691 [0.000, 5.000],  loss: 0.007563, mae: 0.114007, mean_q: 0.170180, mean_eps: 0.918731\n",
            "  91526/1000000: episode: 134, duration: 138.561s, episode steps: 956, steps per second:   7, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.006644, mae: 0.113837, mean_q: 0.166495, mean_eps: 0.918057\n",
            "  92346/1000000: episode: 135, duration: 121.435s, episode steps: 820, steps per second:   7, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.006293, mae: 0.113910, mean_q: 0.167583, mean_eps: 0.917258\n",
            "  93398/1000000: episode: 136, duration: 154.383s, episode steps: 1052, steps per second:   7, episode reward: 13.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.005782, mae: 0.112515, mean_q: 0.164385, mean_eps: 0.916416\n",
            "  94482/1000000: episode: 137, duration: 159.861s, episode steps: 1084, steps per second:   7, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.005236, mae: 0.112334, mean_q: 0.164035, mean_eps: 0.915454\n",
            "  95157/1000000: episode: 138, duration: 102.383s, episode steps: 675, steps per second:   7, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.005165, mae: 0.111252, mean_q: 0.162678, mean_eps: 0.914663\n",
            "  95804/1000000: episode: 139, duration: 96.979s, episode steps: 647, steps per second:   7, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.005259, mae: 0.110646, mean_q: 0.161782, mean_eps: 0.914068\n",
            "  96529/1000000: episode: 140, duration: 108.041s, episode steps: 725, steps per second:   7, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.005215, mae: 0.111812, mean_q: 0.163759, mean_eps: 0.913451\n",
            "  97096/1000000: episode: 141, duration: 84.597s, episode steps: 567, steps per second:   7, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.004864, mae: 0.112123, mean_q: 0.163002, mean_eps: 0.912869\n",
            "  97864/1000000: episode: 142, duration: 114.380s, episode steps: 768, steps per second:   7, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.004783, mae: 0.110621, mean_q: 0.163539, mean_eps: 0.912268\n",
            "  98253/1000000: episode: 143, duration: 58.184s, episode steps: 389, steps per second:   7, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.391 [0.000, 5.000],  loss: 0.004297, mae: 0.110313, mean_q: 0.163217, mean_eps: 0.911748\n",
            "  99627/1000000: episode: 144, duration: 204.478s, episode steps: 1374, steps per second:   7, episode reward: 13.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.004404, mae: 0.108940, mean_q: 0.160479, mean_eps: 0.910954\n",
            " 100295/1000000: episode: 145, duration: 100.159s, episode steps: 668, steps per second:   7, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.005922, mae: 0.122420, mean_q: 0.176728, mean_eps: 0.910036\n",
            " 100942/1000000: episode: 146, duration: 96.317s, episode steps: 647, steps per second:   7, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.007156, mae: 0.143526, mean_q: 0.203722, mean_eps: 0.909444\n",
            " 101624/1000000: episode: 147, duration: 101.070s, episode steps: 682, steps per second:   7, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.006319, mae: 0.137898, mean_q: 0.195697, mean_eps: 0.908846\n",
            " 102116/1000000: episode: 148, duration: 73.886s, episode steps: 492, steps per second:   7, episode reward: 12.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.006859, mae: 0.142359, mean_q: 0.200567, mean_eps: 0.908317\n",
            " 103423/1000000: episode: 149, duration: 193.163s, episode steps: 1307, steps per second:   7, episode reward: 21.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.005784, mae: 0.138563, mean_q: 0.196287, mean_eps: 0.907508\n",
            " 104292/1000000: episode: 150, duration: 128.783s, episode steps: 869, steps per second:   7, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.005814, mae: 0.140470, mean_q: 0.198322, mean_eps: 0.906529\n",
            " 104959/1000000: episode: 151, duration: 97.971s, episode steps: 667, steps per second:   7, episode reward: 14.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.005492, mae: 0.139124, mean_q: 0.197229, mean_eps: 0.905837\n",
            " 105546/1000000: episode: 152, duration: 85.051s, episode steps: 587, steps per second:   7, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.005480, mae: 0.137171, mean_q: 0.193724, mean_eps: 0.905273\n",
            " 106350/1000000: episode: 153, duration: 119.911s, episode steps: 804, steps per second:   7, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.561 [0.000, 5.000],  loss: 0.005176, mae: 0.140360, mean_q: 0.198409, mean_eps: 0.904647\n",
            " 107159/1000000: episode: 154, duration: 118.217s, episode steps: 809, steps per second:   7, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.005571, mae: 0.137631, mean_q: 0.194986, mean_eps: 0.903921\n",
            " 108220/1000000: episode: 155, duration: 154.381s, episode steps: 1061, steps per second:   7, episode reward: 11.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.005419, mae: 0.138754, mean_q: 0.198006, mean_eps: 0.903080\n",
            " 108782/1000000: episode: 156, duration: 81.604s, episode steps: 562, steps per second:   7, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.584 [0.000, 5.000],  loss: 0.004910, mae: 0.136320, mean_q: 0.194879, mean_eps: 0.902350\n",
            " 109732/1000000: episode: 157, duration: 137.952s, episode steps: 950, steps per second:   7, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.004933, mae: 0.136264, mean_q: 0.195175, mean_eps: 0.901669\n",
            " 110244/1000000: episode: 158, duration: 74.165s, episode steps: 512, steps per second:   7, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.006629, mae: 0.153609, mean_q: 0.217513, mean_eps: 0.901011\n",
            " 111076/1000000: episode: 159, duration: 120.887s, episode steps: 832, steps per second:   7, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.007760, mae: 0.171923, mean_q: 0.240432, mean_eps: 0.900406\n",
            " 111740/1000000: episode: 160, duration: 96.219s, episode steps: 664, steps per second:   7, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: 0.006890, mae: 0.167692, mean_q: 0.234768, mean_eps: 0.899733\n",
            " 112497/1000000: episode: 161, duration: 109.980s, episode steps: 757, steps per second:   7, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.006529, mae: 0.165715, mean_q: 0.230817, mean_eps: 0.899094\n",
            " 112908/1000000: episode: 162, duration: 59.471s, episode steps: 411, steps per second:   7, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.314 [0.000, 5.000],  loss: 0.006983, mae: 0.169105, mean_q: 0.235513, mean_eps: 0.898568\n",
            " 113415/1000000: episode: 163, duration: 73.646s, episode steps: 507, steps per second:   7, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.682 [0.000, 5.000],  loss: 0.005904, mae: 0.165732, mean_q: 0.230224, mean_eps: 0.898155\n",
            " 113980/1000000: episode: 164, duration: 81.225s, episode steps: 565, steps per second:   7, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.006416, mae: 0.166375, mean_q: 0.231779, mean_eps: 0.897673\n",
            " 115466/1000000: episode: 165, duration: 218.222s, episode steps: 1486, steps per second:   7, episode reward: 25.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.005794, mae: 0.166355, mean_q: 0.232751, mean_eps: 0.896750\n",
            " 116066/1000000: episode: 166, duration: 87.398s, episode steps: 600, steps per second:   7, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.005493, mae: 0.159157, mean_q: 0.221981, mean_eps: 0.895811\n",
            " 116475/1000000: episode: 167, duration: 59.590s, episode steps: 409, steps per second:   7, episode reward:  9.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.005336, mae: 0.159678, mean_q: 0.223347, mean_eps: 0.895357\n",
            " 116832/1000000: episode: 168, duration: 52.321s, episode steps: 357, steps per second:   7, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.005018, mae: 0.162687, mean_q: 0.226509, mean_eps: 0.895012\n",
            " 117810/1000000: episode: 169, duration: 142.489s, episode steps: 978, steps per second:   7, episode reward: 22.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.005514, mae: 0.161669, mean_q: 0.226100, mean_eps: 0.894412\n",
            " 118512/1000000: episode: 170, duration: 102.063s, episode steps: 702, steps per second:   7, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.005567, mae: 0.163872, mean_q: 0.230257, mean_eps: 0.893656\n",
            " 119031/1000000: episode: 171, duration: 76.582s, episode steps: 519, steps per second:   7, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: 0.004948, mae: 0.161730, mean_q: 0.227209, mean_eps: 0.893106\n",
            " 119669/1000000: episode: 172, duration: 92.983s, episode steps: 638, steps per second:   7, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.004427, mae: 0.156417, mean_q: 0.219714, mean_eps: 0.892585\n",
            " 120174/1000000: episode: 173, duration: 74.457s, episode steps: 505, steps per second:   7, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.341 [0.000, 5.000],  loss: 0.006222, mae: 0.172942, mean_q: 0.241799, mean_eps: 0.892071\n",
            " 120991/1000000: episode: 174, duration: 119.331s, episode steps: 817, steps per second:   7, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.008522, mae: 0.201517, mean_q: 0.277714, mean_eps: 0.891476\n",
            " 122327/1000000: episode: 175, duration: 195.298s, episode steps: 1336, steps per second:   7, episode reward: 12.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.007089, mae: 0.199797, mean_q: 0.274992, mean_eps: 0.890507\n",
            " 123340/1000000: episode: 176, duration: 148.459s, episode steps: 1013, steps per second:   7, episode reward: 22.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.006121, mae: 0.197308, mean_q: 0.271290, mean_eps: 0.889450\n",
            " 124015/1000000: episode: 177, duration: 98.236s, episode steps: 675, steps per second:   7, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.006607, mae: 0.195395, mean_q: 0.268326, mean_eps: 0.888691\n",
            " 124841/1000000: episode: 178, duration: 119.859s, episode steps: 826, steps per second:   7, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: 0.006441, mae: 0.198222, mean_q: 0.273243, mean_eps: 0.888015\n",
            " 125984/1000000: episode: 179, duration: 170.162s, episode steps: 1143, steps per second:   7, episode reward: 14.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.006063, mae: 0.195490, mean_q: 0.270013, mean_eps: 0.887129\n",
            " 126715/1000000: episode: 180, duration: 107.672s, episode steps: 731, steps per second:   7, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.006101, mae: 0.200611, mean_q: 0.276104, mean_eps: 0.886286\n",
            " 127358/1000000: episode: 181, duration: 94.469s, episode steps: 643, steps per second:   7, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: 0.005815, mae: 0.196167, mean_q: 0.269695, mean_eps: 0.885668\n",
            " 128154/1000000: episode: 182, duration: 116.563s, episode steps: 796, steps per second:   7, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.005674, mae: 0.198769, mean_q: 0.273692, mean_eps: 0.885020\n",
            " 128678/1000000: episode: 183, duration: 76.270s, episode steps: 524, steps per second:   7, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.005848, mae: 0.195026, mean_q: 0.268682, mean_eps: 0.884426\n",
            " 129466/1000000: episode: 184, duration: 115.544s, episode steps: 788, steps per second:   7, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.005425, mae: 0.195039, mean_q: 0.268666, mean_eps: 0.883836\n",
            " 130121/1000000: episode: 185, duration: 95.439s, episode steps: 655, steps per second:   7, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: 0.006128, mae: 0.202460, mean_q: 0.278057, mean_eps: 0.883186\n",
            " 130919/1000000: episode: 186, duration: 116.975s, episode steps: 798, steps per second:   7, episode reward:  7.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.008416, mae: 0.235932, mean_q: 0.319414, mean_eps: 0.882532\n",
            " 131449/1000000: episode: 187, duration: 78.104s, episode steps: 530, steps per second:   7, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.300 [0.000, 5.000],  loss: 0.007674, mae: 0.229938, mean_q: 0.310442, mean_eps: 0.881935\n",
            " 131967/1000000: episode: 188, duration: 75.789s, episode steps: 518, steps per second:   7, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.376 [0.000, 5.000],  loss: 0.007625, mae: 0.237238, mean_q: 0.320502, mean_eps: 0.881463\n",
            " 132367/1000000: episode: 189, duration: 59.060s, episode steps: 400, steps per second:   7, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.007058, mae: 0.228569, mean_q: 0.308934, mean_eps: 0.881050\n",
            " 133004/1000000: episode: 190, duration: 93.239s, episode steps: 637, steps per second:   7, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.006721, mae: 0.230345, mean_q: 0.312849, mean_eps: 0.880583\n",
            " 133667/1000000: episode: 191, duration: 96.697s, episode steps: 663, steps per second:   7, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.006507, mae: 0.229230, mean_q: 0.309330, mean_eps: 0.879999\n",
            " 134352/1000000: episode: 192, duration: 99.736s, episode steps: 685, steps per second:   7, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.006562, mae: 0.232090, mean_q: 0.314406, mean_eps: 0.879392\n",
            " 134936/1000000: episode: 193, duration: 85.295s, episode steps: 584, steps per second:   7, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.005987, mae: 0.228295, mean_q: 0.311186, mean_eps: 0.878821\n",
            " 135725/1000000: episode: 194, duration: 115.114s, episode steps: 789, steps per second:   7, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.006050, mae: 0.226422, mean_q: 0.307365, mean_eps: 0.878203\n",
            " 136475/1000000: episode: 195, duration: 109.326s, episode steps: 750, steps per second:   7, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: 0.006577, mae: 0.229431, mean_q: 0.311375, mean_eps: 0.877510\n",
            " 137019/1000000: episode: 196, duration: 79.687s, episode steps: 544, steps per second:   7, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.005642, mae: 0.226759, mean_q: 0.308651, mean_eps: 0.876928\n",
            " 137945/1000000: episode: 197, duration: 135.278s, episode steps: 926, steps per second:   7, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.005740, mae: 0.224624, mean_q: 0.305470, mean_eps: 0.876267\n",
            " 138785/1000000: episode: 198, duration: 122.285s, episode steps: 840, steps per second:   7, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.005762, mae: 0.222957, mean_q: 0.302390, mean_eps: 0.875472\n",
            " 139396/1000000: episode: 199, duration: 88.896s, episode steps: 611, steps per second:   7, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.005603, mae: 0.227539, mean_q: 0.310268, mean_eps: 0.874819\n",
            " 140328/1000000: episode: 200, duration: 136.739s, episode steps: 932, steps per second:   7, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.618 [0.000, 5.000],  loss: 0.006263, mae: 0.239840, mean_q: 0.325296, mean_eps: 0.874125\n",
            " 140959/1000000: episode: 201, duration: 94.710s, episode steps: 631, steps per second:   7, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.008288, mae: 0.260661, mean_q: 0.350568, mean_eps: 0.873421\n",
            " 141644/1000000: episode: 202, duration: 102.549s, episode steps: 685, steps per second:   7, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: 0.007563, mae: 0.260236, mean_q: 0.347791, mean_eps: 0.872829\n",
            " 142818/1000000: episode: 203, duration: 174.023s, episode steps: 1174, steps per second:   7, episode reward: 13.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.007055, mae: 0.260110, mean_q: 0.349474, mean_eps: 0.871993\n",
            " 143434/1000000: episode: 204, duration: 91.286s, episode steps: 616, steps per second:   7, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.006814, mae: 0.259169, mean_q: 0.347419, mean_eps: 0.871187\n",
            " 144249/1000000: episode: 205, duration: 119.647s, episode steps: 815, steps per second:   7, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.006295, mae: 0.257478, mean_q: 0.345457, mean_eps: 0.870543\n",
            " 144950/1000000: episode: 206, duration: 102.947s, episode steps: 701, steps per second:   7, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.368 [0.000, 5.000],  loss: 0.006690, mae: 0.258005, mean_q: 0.346608, mean_eps: 0.869861\n",
            " 145630/1000000: episode: 207, duration: 100.176s, episode steps: 680, steps per second:   7, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.006209, mae: 0.256397, mean_q: 0.344183, mean_eps: 0.869239\n",
            " 146787/1000000: episode: 208, duration: 169.951s, episode steps: 1157, steps per second:   7, episode reward: 23.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.006170, mae: 0.258027, mean_q: 0.346497, mean_eps: 0.868413\n",
            " 147423/1000000: episode: 209, duration: 94.149s, episode steps: 636, steps per second:   7, episode reward:  4.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.006119, mae: 0.256743, mean_q: 0.345578, mean_eps: 0.867606\n",
            " 148012/1000000: episode: 210, duration: 86.944s, episode steps: 589, steps per second:   7, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: 0.005691, mae: 0.253388, mean_q: 0.341363, mean_eps: 0.867055\n",
            " 148387/1000000: episode: 211, duration: 55.600s, episode steps: 375, steps per second:   7, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.005688, mae: 0.251503, mean_q: 0.339989, mean_eps: 0.866621\n",
            " 149237/1000000: episode: 212, duration: 124.408s, episode steps: 850, steps per second:   7, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: 0.005562, mae: 0.250867, mean_q: 0.337155, mean_eps: 0.866070\n",
            " 149874/1000000: episode: 213, duration: 93.173s, episode steps: 637, steps per second:   7, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.005191, mae: 0.251565, mean_q: 0.338015, mean_eps: 0.865401\n",
            " 151014/1000000: episode: 214, duration: 167.073s, episode steps: 1140, steps per second:   7, episode reward: 16.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.008748, mae: 0.292804, mean_q: 0.389965, mean_eps: 0.864601\n",
            " 151729/1000000: episode: 215, duration: 107.330s, episode steps: 715, steps per second:   7, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.007638, mae: 0.291527, mean_q: 0.387412, mean_eps: 0.863766\n",
            " 152435/1000000: episode: 216, duration: 104.902s, episode steps: 706, steps per second:   7, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: 0.007271, mae: 0.293516, mean_q: 0.390904, mean_eps: 0.863127\n",
            " 153322/1000000: episode: 217, duration: 131.095s, episode steps: 887, steps per second:   7, episode reward: 23.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.551 [0.000, 5.000],  loss: 0.007260, mae: 0.291167, mean_q: 0.387029, mean_eps: 0.862410\n",
            " 154000/1000000: episode: 218, duration: 99.328s, episode steps: 678, steps per second:   7, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.007171, mae: 0.291780, mean_q: 0.388539, mean_eps: 0.861706\n",
            " 154633/1000000: episode: 219, duration: 93.269s, episode steps: 633, steps per second:   7, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.006372, mae: 0.292197, mean_q: 0.388148, mean_eps: 0.861116\n",
            " 155168/1000000: episode: 220, duration: 80.299s, episode steps: 535, steps per second:   7, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: 0.006694, mae: 0.292563, mean_q: 0.389817, mean_eps: 0.860590\n",
            " 155697/1000000: episode: 221, duration: 78.594s, episode steps: 529, steps per second:   7, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.006502, mae: 0.288386, mean_q: 0.383194, mean_eps: 0.860111\n",
            " 156281/1000000: episode: 222, duration: 87.689s, episode steps: 584, steps per second:   7, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: 0.006113, mae: 0.291589, mean_q: 0.388448, mean_eps: 0.859610\n",
            " 156801/1000000: episode: 223, duration: 77.270s, episode steps: 520, steps per second:   7, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.006323, mae: 0.288430, mean_q: 0.383957, mean_eps: 0.859114\n",
            " 157350/1000000: episode: 224, duration: 82.326s, episode steps: 549, steps per second:   7, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.293 [0.000, 5.000],  loss: 0.006646, mae: 0.292980, mean_q: 0.389711, mean_eps: 0.858632\n",
            " 157722/1000000: episode: 225, duration: 55.797s, episode steps: 372, steps per second:   7, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.006135, mae: 0.291809, mean_q: 0.389156, mean_eps: 0.858218\n",
            " 158783/1000000: episode: 226, duration: 156.408s, episode steps: 1061, steps per second:   7, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.006067, mae: 0.288694, mean_q: 0.385081, mean_eps: 0.857573\n",
            " 159334/1000000: episode: 227, duration: 81.954s, episode steps: 551, steps per second:   7, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.006357, mae: 0.291547, mean_q: 0.390055, mean_eps: 0.856848\n",
            " 160116/1000000: episode: 228, duration: 120.234s, episode steps: 782, steps per second:   7, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.646 [0.000, 5.000],  loss: 0.006039, mae: 0.289173, mean_q: 0.385422, mean_eps: 0.856248\n",
            " 161023/1000000: episode: 229, duration: 135.532s, episode steps: 907, steps per second:   7, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.007939, mae: 0.327924, mean_q: 0.433963, mean_eps: 0.855488\n",
            " 161563/1000000: episode: 230, duration: 81.365s, episode steps: 540, steps per second:   7, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.007600, mae: 0.327617, mean_q: 0.433794, mean_eps: 0.854837\n",
            " 162280/1000000: episode: 231, duration: 107.047s, episode steps: 717, steps per second:   7, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.007118, mae: 0.323055, mean_q: 0.426793, mean_eps: 0.854271\n",
            " 162779/1000000: episode: 232, duration: 74.676s, episode steps: 499, steps per second:   7, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.007280, mae: 0.321427, mean_q: 0.423555, mean_eps: 0.853724\n",
            " 163241/1000000: episode: 233, duration: 69.104s, episode steps: 462, steps per second:   7, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.007362, mae: 0.321527, mean_q: 0.424662, mean_eps: 0.853291\n",
            " 163655/1000000: episode: 234, duration: 61.655s, episode steps: 414, steps per second:   7, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.006452, mae: 0.318569, mean_q: 0.421622, mean_eps: 0.852897\n",
            " 164058/1000000: episode: 235, duration: 60.010s, episode steps: 403, steps per second:   7, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: 0.007261, mae: 0.321257, mean_q: 0.422889, mean_eps: 0.852530\n",
            " 164701/1000000: episode: 236, duration: 95.145s, episode steps: 643, steps per second:   7, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.006578, mae: 0.319054, mean_q: 0.420999, mean_eps: 0.852059\n",
            " 165213/1000000: episode: 237, duration: 76.528s, episode steps: 512, steps per second:   7, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.006189, mae: 0.315939, mean_q: 0.418127, mean_eps: 0.851539\n",
            " 165789/1000000: episode: 238, duration: 86.313s, episode steps: 576, steps per second:   7, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: 0.006359, mae: 0.317977, mean_q: 0.419632, mean_eps: 0.851050\n",
            " 166807/1000000: episode: 239, duration: 151.667s, episode steps: 1018, steps per second:   7, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.006206, mae: 0.315564, mean_q: 0.416136, mean_eps: 0.850332\n",
            " 167701/1000000: episode: 240, duration: 131.836s, episode steps: 894, steps per second:   7, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.006786, mae: 0.318476, mean_q: 0.420898, mean_eps: 0.849472\n",
            " 168646/1000000: episode: 241, duration: 139.280s, episode steps: 945, steps per second:   7, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.006172, mae: 0.319658, mean_q: 0.423000, mean_eps: 0.848644\n",
            " 169037/1000000: episode: 242, duration: 57.023s, episode steps: 391, steps per second:   7, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.006541, mae: 0.318709, mean_q: 0.422358, mean_eps: 0.848043\n",
            " 169778/1000000: episode: 243, duration: 112.748s, episode steps: 741, steps per second:   7, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.718 [0.000, 5.000],  loss: 0.005787, mae: 0.317883, mean_q: 0.420793, mean_eps: 0.847534\n",
            " 170411/1000000: episode: 244, duration: 95.276s, episode steps: 633, steps per second:   7, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.281 [0.000, 5.000],  loss: 0.007224, mae: 0.334515, mean_q: 0.441219, mean_eps: 0.846915\n",
            " 171032/1000000: episode: 245, duration: 92.020s, episode steps: 621, steps per second:   7, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.008185, mae: 0.341862, mean_q: 0.449297, mean_eps: 0.846351\n",
            " 171624/1000000: episode: 246, duration: 87.033s, episode steps: 592, steps per second:   7, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: 0.006955, mae: 0.343344, mean_q: 0.451392, mean_eps: 0.845805\n",
            " 172282/1000000: episode: 247, duration: 96.665s, episode steps: 658, steps per second:   7, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.007506, mae: 0.338593, mean_q: 0.444728, mean_eps: 0.845243\n",
            " 173190/1000000: episode: 248, duration: 133.245s, episode steps: 908, steps per second:   7, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.006854, mae: 0.340075, mean_q: 0.446488, mean_eps: 0.844538\n",
            " 174264/1000000: episode: 249, duration: 159.876s, episode steps: 1074, steps per second:   7, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.422 [0.000, 5.000],  loss: 0.006536, mae: 0.338872, mean_q: 0.445991, mean_eps: 0.843646\n",
            " 174879/1000000: episode: 250, duration: 91.001s, episode steps: 615, steps per second:   7, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.005656, mae: 0.335023, mean_q: 0.442077, mean_eps: 0.842886\n",
            " 175547/1000000: episode: 251, duration: 99.141s, episode steps: 668, steps per second:   7, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.005995, mae: 0.335074, mean_q: 0.440055, mean_eps: 0.842309\n",
            " 176234/1000000: episode: 252, duration: 100.876s, episode steps: 687, steps per second:   7, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.005712, mae: 0.334276, mean_q: 0.440270, mean_eps: 0.841699\n",
            " 177010/1000000: episode: 253, duration: 114.658s, episode steps: 776, steps per second:   7, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.005361, mae: 0.332762, mean_q: 0.437932, mean_eps: 0.841041\n",
            " 177541/1000000: episode: 254, duration: 77.768s, episode steps: 531, steps per second:   7, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.369 [0.000, 5.000],  loss: 0.006418, mae: 0.333149, mean_q: 0.437811, mean_eps: 0.840453\n",
            " 178562/1000000: episode: 255, duration: 151.397s, episode steps: 1021, steps per second:   7, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.006076, mae: 0.334930, mean_q: 0.439368, mean_eps: 0.839754\n",
            " 179214/1000000: episode: 256, duration: 96.212s, episode steps: 652, steps per second:   7, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.005738, mae: 0.337646, mean_q: 0.444568, mean_eps: 0.839001\n",
            " 179714/1000000: episode: 257, duration: 74.429s, episode steps: 500, steps per second:   7, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: 0.005181, mae: 0.332313, mean_q: 0.437371, mean_eps: 0.838483\n",
            " 180405/1000000: episode: 258, duration: 103.613s, episode steps: 691, steps per second:   7, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.007622, mae: 0.361357, mean_q: 0.474109, mean_eps: 0.837947\n",
            " 181165/1000000: episode: 259, duration: 114.107s, episode steps: 760, steps per second:   7, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.008588, mae: 0.373642, mean_q: 0.488362, mean_eps: 0.837294\n",
            " 182051/1000000: episode: 260, duration: 132.608s, episode steps: 886, steps per second:   7, episode reward:  8.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.007545, mae: 0.364678, mean_q: 0.476880, mean_eps: 0.836553\n",
            " 182861/1000000: episode: 261, duration: 121.457s, episode steps: 810, steps per second:   7, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.007881, mae: 0.370311, mean_q: 0.483847, mean_eps: 0.835790\n",
            " 183502/1000000: episode: 262, duration: 95.880s, episode steps: 641, steps per second:   7, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.007298, mae: 0.369660, mean_q: 0.483653, mean_eps: 0.835137\n",
            " 184075/1000000: episode: 263, duration: 85.476s, episode steps: 573, steps per second:   7, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.007534, mae: 0.369276, mean_q: 0.483710, mean_eps: 0.834591\n",
            " 184767/1000000: episode: 264, duration: 103.947s, episode steps: 692, steps per second:   7, episode reward:  5.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.006938, mae: 0.367915, mean_q: 0.482150, mean_eps: 0.834022\n",
            " 185411/1000000: episode: 265, duration: 96.553s, episode steps: 644, steps per second:   7, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.006918, mae: 0.365542, mean_q: 0.477794, mean_eps: 0.833420\n",
            " 185941/1000000: episode: 266, duration: 79.637s, episode steps: 530, steps per second:   7, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: 0.006302, mae: 0.363662, mean_q: 0.475286, mean_eps: 0.832892\n",
            " 186775/1000000: episode: 267, duration: 125.084s, episode steps: 834, steps per second:   7, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.006604, mae: 0.368988, mean_q: 0.481671, mean_eps: 0.832278\n",
            " 187776/1000000: episode: 268, duration: 149.839s, episode steps: 1001, steps per second:   7, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.006415, mae: 0.366088, mean_q: 0.478796, mean_eps: 0.831452\n",
            " 188304/1000000: episode: 269, duration: 79.021s, episode steps: 528, steps per second:   7, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.006055, mae: 0.360346, mean_q: 0.471977, mean_eps: 0.830764\n",
            " 189035/1000000: episode: 270, duration: 109.142s, episode steps: 731, steps per second:   7, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.006043, mae: 0.363754, mean_q: 0.476057, mean_eps: 0.830198\n",
            " 189559/1000000: episode: 271, duration: 76.631s, episode steps: 524, steps per second:   7, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.006023, mae: 0.364796, mean_q: 0.477306, mean_eps: 0.829633\n",
            " 190218/1000000: episode: 272, duration: 96.216s, episode steps: 659, steps per second:   7, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.639 [0.000, 5.000],  loss: 0.006706, mae: 0.377405, mean_q: 0.492182, mean_eps: 0.829101\n",
            " 190869/1000000: episode: 273, duration: 95.510s, episode steps: 651, steps per second:   7, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.008636, mae: 0.399379, mean_q: 0.518073, mean_eps: 0.828511\n",
            " 191343/1000000: episode: 274, duration: 69.518s, episode steps: 474, steps per second:   7, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.008152, mae: 0.401714, mean_q: 0.521411, mean_eps: 0.828005\n",
            " 192001/1000000: episode: 275, duration: 96.314s, episode steps: 658, steps per second:   7, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.406 [0.000, 5.000],  loss: 0.008172, mae: 0.399086, mean_q: 0.517871, mean_eps: 0.827496\n",
            " 192853/1000000: episode: 276, duration: 124.447s, episode steps: 852, steps per second:   7, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: 0.007459, mae: 0.401206, mean_q: 0.521169, mean_eps: 0.826816\n",
            " 193403/1000000: episode: 277, duration: 81.076s, episode steps: 550, steps per second:   7, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.007452, mae: 0.397880, mean_q: 0.516936, mean_eps: 0.826185\n",
            " 193944/1000000: episode: 278, duration: 97.408s, episode steps: 541, steps per second:   6, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.627 [0.000, 5.000],  loss: 0.006952, mae: 0.394189, mean_q: 0.511708, mean_eps: 0.825694\n",
            " 194333/1000000: episode: 279, duration: 57.537s, episode steps: 389, steps per second:   7, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.007043, mae: 0.397335, mean_q: 0.515415, mean_eps: 0.825276\n",
            " 195307/1000000: episode: 280, duration: 143.197s, episode steps: 974, steps per second:   7, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.006896, mae: 0.393963, mean_q: 0.510784, mean_eps: 0.824662\n",
            " 196044/1000000: episode: 281, duration: 107.508s, episode steps: 737, steps per second:   7, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.006977, mae: 0.394788, mean_q: 0.513764, mean_eps: 0.823893\n",
            " 196730/1000000: episode: 282, duration: 100.585s, episode steps: 686, steps per second:   7, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: 0.006367, mae: 0.395692, mean_q: 0.514607, mean_eps: 0.823252\n",
            " 197227/1000000: episode: 283, duration: 72.584s, episode steps: 497, steps per second:   7, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.006744, mae: 0.390151, mean_q: 0.506570, mean_eps: 0.822720\n",
            " 197910/1000000: episode: 284, duration: 99.557s, episode steps: 683, steps per second:   7, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.006913, mae: 0.395502, mean_q: 0.513508, mean_eps: 0.822189\n",
            " 198263/1000000: episode: 285, duration: 51.465s, episode steps: 353, steps per second:   7, episode reward:  2.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.006639, mae: 0.388793, mean_q: 0.505626, mean_eps: 0.821723\n",
            " 198853/1000000: episode: 286, duration: 86.685s, episode steps: 590, steps per second:   7, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.700 [0.000, 5.000],  loss: 0.006222, mae: 0.393605, mean_q: 0.513274, mean_eps: 0.821298\n",
            " 199468/1000000: episode: 287, duration: 89.680s, episode steps: 615, steps per second:   7, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.006341, mae: 0.394796, mean_q: 0.514400, mean_eps: 0.820756\n",
            " 200038/1000000: episode: 288, duration: 83.092s, episode steps: 570, steps per second:   7, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.005771, mae: 0.397648, mean_q: 0.517994, mean_eps: 0.820223\n",
            " 200656/1000000: episode: 289, duration: 90.520s, episode steps: 618, steps per second:   7, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.009206, mae: 0.449015, mean_q: 0.582489, mean_eps: 0.819688\n",
            " 201426/1000000: episode: 290, duration: 112.643s, episode steps: 770, steps per second:   7, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.009077, mae: 0.448378, mean_q: 0.578593, mean_eps: 0.819064\n",
            " 202106/1000000: episode: 291, duration: 100.830s, episode steps: 680, steps per second:   7, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.008663, mae: 0.445468, mean_q: 0.575025, mean_eps: 0.818411\n",
            " 203130/1000000: episode: 292, duration: 149.973s, episode steps: 1024, steps per second:   7, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: 0.007902, mae: 0.443355, mean_q: 0.572478, mean_eps: 0.817644\n",
            " 203993/1000000: episode: 293, duration: 127.098s, episode steps: 863, steps per second:   7, episode reward: 19.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: 0.007266, mae: 0.437321, mean_q: 0.564796, mean_eps: 0.816795\n",
            " 205001/1000000: episode: 294, duration: 147.460s, episode steps: 1008, steps per second:   7, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.504 [0.000, 5.000],  loss: 0.007326, mae: 0.440399, mean_q: 0.567883, mean_eps: 0.815953\n",
            " 205498/1000000: episode: 295, duration: 73.860s, episode steps: 497, steps per second:   7, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.006843, mae: 0.434682, mean_q: 0.559950, mean_eps: 0.815276\n",
            " 206523/1000000: episode: 296, duration: 149.611s, episode steps: 1025, steps per second:   7, episode reward: 23.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.006888, mae: 0.436372, mean_q: 0.564757, mean_eps: 0.814591\n",
            " 207330/1000000: episode: 297, duration: 118.861s, episode steps: 807, steps per second:   7, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.006807, mae: 0.432892, mean_q: 0.559740, mean_eps: 0.813767\n",
            " 208353/1000000: episode: 298, duration: 150.379s, episode steps: 1023, steps per second:   7, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.006375, mae: 0.430159, mean_q: 0.556364, mean_eps: 0.812943\n",
            " 208749/1000000: episode: 299, duration: 58.311s, episode steps: 396, steps per second:   7, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.006411, mae: 0.433470, mean_q: 0.560996, mean_eps: 0.812305\n",
            " 209446/1000000: episode: 300, duration: 101.962s, episode steps: 697, steps per second:   7, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.006015, mae: 0.431050, mean_q: 0.556640, mean_eps: 0.811813\n",
            " 209982/1000000: episode: 301, duration: 79.739s, episode steps: 536, steps per second:   7, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.006491, mae: 0.430632, mean_q: 0.555080, mean_eps: 0.811258\n",
            " 210521/1000000: episode: 302, duration: 79.998s, episode steps: 539, steps per second:   7, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.009841, mae: 0.467064, mean_q: 0.601637, mean_eps: 0.810774\n",
            " 211208/1000000: episode: 303, duration: 100.661s, episode steps: 687, steps per second:   7, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.009461, mae: 0.475743, mean_q: 0.612455, mean_eps: 0.810222\n",
            " 211862/1000000: episode: 304, duration: 96.257s, episode steps: 654, steps per second:   7, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.008718, mae: 0.474382, mean_q: 0.610667, mean_eps: 0.809619\n",
            " 212531/1000000: episode: 305, duration: 99.087s, episode steps: 669, steps per second:   7, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.008728, mae: 0.469102, mean_q: 0.603237, mean_eps: 0.809024\n",
            " 213213/1000000: episode: 306, duration: 99.749s, episode steps: 682, steps per second:   7, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.008456, mae: 0.473634, mean_q: 0.608275, mean_eps: 0.808416\n",
            " 213910/1000000: episode: 307, duration: 102.435s, episode steps: 697, steps per second:   7, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.007672, mae: 0.470729, mean_q: 0.604837, mean_eps: 0.807795\n",
            " 214721/1000000: episode: 308, duration: 118.818s, episode steps: 811, steps per second:   7, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.007595, mae: 0.472582, mean_q: 0.607397, mean_eps: 0.807117\n",
            " 215695/1000000: episode: 309, duration: 144.087s, episode steps: 974, steps per second:   7, episode reward: 13.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.007457, mae: 0.471355, mean_q: 0.605690, mean_eps: 0.806313\n",
            " 216196/1000000: episode: 310, duration: 74.175s, episode steps: 501, steps per second:   7, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.443 [0.000, 5.000],  loss: 0.007132, mae: 0.463533, mean_q: 0.595978, mean_eps: 0.805649\n",
            " 216746/1000000: episode: 311, duration: 81.220s, episode steps: 550, steps per second:   7, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.007080, mae: 0.467517, mean_q: 0.601675, mean_eps: 0.805177\n",
            " 217335/1000000: episode: 312, duration: 86.588s, episode steps: 589, steps per second:   7, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.319 [0.000, 5.000],  loss: 0.007221, mae: 0.469878, mean_q: 0.603627, mean_eps: 0.804664\n",
            " 218025/1000000: episode: 313, duration: 102.010s, episode steps: 690, steps per second:   7, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.007406, mae: 0.470724, mean_q: 0.605553, mean_eps: 0.804088\n",
            " 218512/1000000: episode: 314, duration: 71.713s, episode steps: 487, steps per second:   7, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.006591, mae: 0.466382, mean_q: 0.600067, mean_eps: 0.803559\n",
            " 219071/1000000: episode: 315, duration: 81.883s, episode steps: 559, steps per second:   7, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: 0.006864, mae: 0.472544, mean_q: 0.606975, mean_eps: 0.803088\n",
            " 219577/1000000: episode: 316, duration: 74.804s, episode steps: 506, steps per second:   7, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.006793, mae: 0.473166, mean_q: 0.609971, mean_eps: 0.802609\n",
            " 219957/1000000: episode: 317, duration: 55.401s, episode steps: 380, steps per second:   7, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.689 [0.000, 5.000],  loss: 0.006814, mae: 0.470383, mean_q: 0.604960, mean_eps: 0.802210\n",
            " 220342/1000000: episode: 318, duration: 57.431s, episode steps: 385, steps per second:   7, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.009843, mae: 0.514437, mean_q: 0.658776, mean_eps: 0.801866\n",
            " 220947/1000000: episode: 319, duration: 89.646s, episode steps: 605, steps per second:   7, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.009728, mae: 0.516963, mean_q: 0.660411, mean_eps: 0.801420\n",
            " 221769/1000000: episode: 320, duration: 120.928s, episode steps: 822, steps per second:   7, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.009559, mae: 0.513863, mean_q: 0.657529, mean_eps: 0.800778\n",
            " 223184/1000000: episode: 321, duration: 207.247s, episode steps: 1415, steps per second:   7, episode reward: 19.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.008610, mae: 0.513722, mean_q: 0.656667, mean_eps: 0.799772\n",
            " 224671/1000000: episode: 322, duration: 217.990s, episode steps: 1487, steps per second:   7, episode reward: 10.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: 0.007976, mae: 0.508133, mean_q: 0.649047, mean_eps: 0.798466\n",
            " 225868/1000000: episode: 323, duration: 173.635s, episode steps: 1197, steps per second:   7, episode reward: 23.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.007272, mae: 0.508114, mean_q: 0.649054, mean_eps: 0.797258\n",
            " 227029/1000000: episode: 324, duration: 169.520s, episode steps: 1161, steps per second:   7, episode reward: 23.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.007003, mae: 0.504976, mean_q: 0.645028, mean_eps: 0.796197\n",
            " 227736/1000000: episode: 325, duration: 103.717s, episode steps: 707, steps per second:   7, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.007286, mae: 0.506330, mean_q: 0.646673, mean_eps: 0.795356\n",
            " 228525/1000000: episode: 326, duration: 115.879s, episode steps: 789, steps per second:   7, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.007317, mae: 0.503309, mean_q: 0.643136, mean_eps: 0.794683\n",
            " 229030/1000000: episode: 327, duration: 73.738s, episode steps: 505, steps per second:   7, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.007231, mae: 0.503493, mean_q: 0.642476, mean_eps: 0.794101\n",
            " 229981/1000000: episode: 328, duration: 138.891s, episode steps: 951, steps per second:   7, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: 0.007133, mae: 0.505992, mean_q: 0.645939, mean_eps: 0.793446\n",
            " 230774/1000000: episode: 329, duration: 115.996s, episode steps: 793, steps per second:   7, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.009757, mae: 0.541064, mean_q: 0.688544, mean_eps: 0.792661\n",
            " 231721/1000000: episode: 330, duration: 138.162s, episode steps: 947, steps per second:   7, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.009156, mae: 0.540056, mean_q: 0.686614, mean_eps: 0.791878\n",
            " 232227/1000000: episode: 331, duration: 74.385s, episode steps: 506, steps per second:   7, episode reward: 11.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.008870, mae: 0.538133, mean_q: 0.684014, mean_eps: 0.791224\n",
            " 232906/1000000: episode: 332, duration: 99.354s, episode steps: 679, steps per second:   7, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: 0.008334, mae: 0.534916, mean_q: 0.678722, mean_eps: 0.790691\n",
            " 233432/1000000: episode: 333, duration: 76.315s, episode steps: 526, steps per second:   7, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.008230, mae: 0.540925, mean_q: 0.687113, mean_eps: 0.790148\n",
            " 233942/1000000: episode: 334, duration: 74.122s, episode steps: 510, steps per second:   7, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.007909, mae: 0.543919, mean_q: 0.691565, mean_eps: 0.789682\n",
            " 234636/1000000: episode: 335, duration: 100.968s, episode steps: 694, steps per second:   7, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.007708, mae: 0.537795, mean_q: 0.682634, mean_eps: 0.789140\n",
            " 235027/1000000: episode: 336, duration: 57.056s, episode steps: 391, steps per second:   7, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: 0.007598, mae: 0.535651, mean_q: 0.679879, mean_eps: 0.788652\n",
            " 235572/1000000: episode: 337, duration: 78.577s, episode steps: 545, steps per second:   7, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.007559, mae: 0.535095, mean_q: 0.680549, mean_eps: 0.788231\n",
            " 236099/1000000: episode: 338, duration: 76.932s, episode steps: 527, steps per second:   7, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.351 [0.000, 5.000],  loss: 0.007706, mae: 0.535488, mean_q: 0.680487, mean_eps: 0.787748\n",
            " 236797/1000000: episode: 339, duration: 100.877s, episode steps: 698, steps per second:   7, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.007368, mae: 0.535085, mean_q: 0.681292, mean_eps: 0.787197\n",
            " 237488/1000000: episode: 340, duration: 100.538s, episode steps: 691, steps per second:   7, episode reward: 16.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: 0.007612, mae: 0.531528, mean_q: 0.676147, mean_eps: 0.786572\n",
            " 238154/1000000: episode: 341, duration: 97.575s, episode steps: 666, steps per second:   7, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.007360, mae: 0.533724, mean_q: 0.679019, mean_eps: 0.785962\n",
            " 239073/1000000: episode: 342, duration: 133.641s, episode steps: 919, steps per second:   7, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: 0.007205, mae: 0.532291, mean_q: 0.677520, mean_eps: 0.785248\n",
            " 239677/1000000: episode: 343, duration: 88.216s, episode steps: 604, steps per second:   7, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: 0.006806, mae: 0.530088, mean_q: 0.674981, mean_eps: 0.784563\n",
            " 240608/1000000: episode: 344, duration: 135.205s, episode steps: 931, steps per second:   7, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.008856, mae: 0.557140, mean_q: 0.706918, mean_eps: 0.783872\n",
            " 241126/1000000: episode: 345, duration: 75.445s, episode steps: 518, steps per second:   7, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.591 [0.000, 5.000],  loss: 0.009048, mae: 0.565931, mean_q: 0.717333, mean_eps: 0.783220\n",
            " 242051/1000000: episode: 346, duration: 135.022s, episode steps: 925, steps per second:   7, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.391 [0.000, 5.000],  loss: 0.008650, mae: 0.571896, mean_q: 0.724825, mean_eps: 0.782571\n",
            " 242861/1000000: episode: 347, duration: 117.524s, episode steps: 810, steps per second:   7, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.008249, mae: 0.569493, mean_q: 0.721345, mean_eps: 0.781790\n",
            " 243469/1000000: episode: 348, duration: 88.168s, episode steps: 608, steps per second:   7, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.630 [0.000, 5.000],  loss: 0.008270, mae: 0.572365, mean_q: 0.725462, mean_eps: 0.781152\n",
            " 244198/1000000: episode: 349, duration: 105.838s, episode steps: 729, steps per second:   7, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.008108, mae: 0.570313, mean_q: 0.722237, mean_eps: 0.780550\n",
            " 244990/1000000: episode: 350, duration: 115.129s, episode steps: 792, steps per second:   7, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.007414, mae: 0.564734, mean_q: 0.714736, mean_eps: 0.779866\n",
            " 245735/1000000: episode: 351, duration: 107.962s, episode steps: 745, steps per second:   7, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.007762, mae: 0.564541, mean_q: 0.714324, mean_eps: 0.779174\n",
            " 246784/1000000: episode: 352, duration: 152.198s, episode steps: 1049, steps per second:   7, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.467 [0.000, 5.000],  loss: 0.007342, mae: 0.563254, mean_q: 0.712554, mean_eps: 0.778367\n",
            " 247328/1000000: episode: 353, duration: 78.632s, episode steps: 544, steps per second:   7, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.007100, mae: 0.556207, mean_q: 0.703921, mean_eps: 0.777650\n",
            " 247946/1000000: episode: 354, duration: 90.199s, episode steps: 618, steps per second:   7, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.006944, mae: 0.561291, mean_q: 0.710879, mean_eps: 0.777127\n",
            " 248474/1000000: episode: 355, duration: 77.287s, episode steps: 528, steps per second:   7, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.007052, mae: 0.562993, mean_q: 0.712348, mean_eps: 0.776611\n",
            " 249607/1000000: episode: 356, duration: 165.591s, episode steps: 1133, steps per second:   7, episode reward: 23.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.006867, mae: 0.554085, mean_q: 0.701208, mean_eps: 0.775864\n",
            " 250523/1000000: episode: 357, duration: 133.332s, episode steps: 916, steps per second:   7, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.009214, mae: 0.587555, mean_q: 0.743309, mean_eps: 0.774942\n",
            " 251036/1000000: episode: 358, duration: 75.551s, episode steps: 513, steps per second:   7, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.010291, mae: 0.599924, mean_q: 0.757401, mean_eps: 0.774299\n",
            " 251733/1000000: episode: 359, duration: 100.877s, episode steps: 697, steps per second:   7, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.009323, mae: 0.600288, mean_q: 0.757699, mean_eps: 0.773754\n",
            " 252646/1000000: episode: 360, duration: 132.939s, episode steps: 913, steps per second:   7, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.008872, mae: 0.604178, mean_q: 0.763333, mean_eps: 0.773030\n",
            " 253376/1000000: episode: 361, duration: 106.087s, episode steps: 730, steps per second:   7, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.008006, mae: 0.593298, mean_q: 0.748194, mean_eps: 0.772291\n",
            " 253803/1000000: episode: 362, duration: 62.666s, episode steps: 427, steps per second:   7, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.008358, mae: 0.596203, mean_q: 0.751182, mean_eps: 0.771770\n",
            " 254558/1000000: episode: 363, duration: 110.514s, episode steps: 755, steps per second:   7, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.008323, mae: 0.593834, mean_q: 0.748873, mean_eps: 0.771238\n",
            " 255181/1000000: episode: 364, duration: 91.573s, episode steps: 623, steps per second:   7, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.303 [0.000, 5.000],  loss: 0.008147, mae: 0.596910, mean_q: 0.754243, mean_eps: 0.770618\n",
            " 256178/1000000: episode: 365, duration: 146.123s, episode steps: 997, steps per second:   7, episode reward: 21.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.007719, mae: 0.594685, mean_q: 0.751915, mean_eps: 0.769889\n",
            " 256875/1000000: episode: 366, duration: 102.771s, episode steps: 697, steps per second:   7, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.007881, mae: 0.595260, mean_q: 0.752228, mean_eps: 0.769127\n",
            " 258060/1000000: episode: 367, duration: 173.151s, episode steps: 1185, steps per second:   7, episode reward: 12.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.007382, mae: 0.591994, mean_q: 0.749107, mean_eps: 0.768280\n",
            " 259362/1000000: episode: 368, duration: 190.406s, episode steps: 1302, steps per second:   7, episode reward: 23.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.006948, mae: 0.592215, mean_q: 0.749219, mean_eps: 0.767161\n",
            " 259757/1000000: episode: 369, duration: 58.208s, episode steps: 395, steps per second:   7, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: 0.007634, mae: 0.591885, mean_q: 0.748147, mean_eps: 0.766397\n",
            " 260514/1000000: episode: 370, duration: 110.342s, episode steps: 757, steps per second:   7, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.009762, mae: 0.617196, mean_q: 0.777615, mean_eps: 0.765879\n",
            " 261239/1000000: episode: 371, duration: 106.106s, episode steps: 725, steps per second:   7, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.009632, mae: 0.627966, mean_q: 0.791248, mean_eps: 0.765212\n",
            " 262188/1000000: episode: 372, duration: 139.133s, episode steps: 949, steps per second:   7, episode reward:  9.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.009356, mae: 0.626573, mean_q: 0.788254, mean_eps: 0.764458\n",
            " 262878/1000000: episode: 373, duration: 100.659s, episode steps: 690, steps per second:   7, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.009020, mae: 0.629644, mean_q: 0.792693, mean_eps: 0.763721\n",
            " 263810/1000000: episode: 374, duration: 136.381s, episode steps: 932, steps per second:   7, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.008627, mae: 0.621529, mean_q: 0.782431, mean_eps: 0.762991\n",
            " 264487/1000000: episode: 375, duration: 98.175s, episode steps: 677, steps per second:   7, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: 0.008309, mae: 0.622721, mean_q: 0.783720, mean_eps: 0.762267\n",
            " 265120/1000000: episode: 376, duration: 92.520s, episode steps: 633, steps per second:   7, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.007867, mae: 0.628148, mean_q: 0.791615, mean_eps: 0.761677\n",
            " 265674/1000000: episode: 377, duration: 81.132s, episode steps: 554, steps per second:   7, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.007894, mae: 0.625655, mean_q: 0.789034, mean_eps: 0.761143\n",
            " 266352/1000000: episode: 378, duration: 99.292s, episode steps: 678, steps per second:   7, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: 0.008116, mae: 0.620280, mean_q: 0.781458, mean_eps: 0.760589\n",
            " 266949/1000000: episode: 379, duration: 87.580s, episode steps: 597, steps per second:   7, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.007247, mae: 0.619213, mean_q: 0.779427, mean_eps: 0.760015\n",
            " 267559/1000000: episode: 380, duration: 90.186s, episode steps: 610, steps per second:   7, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.007477, mae: 0.622257, mean_q: 0.784089, mean_eps: 0.759472\n",
            " 268217/1000000: episode: 381, duration: 96.448s, episode steps: 658, steps per second:   7, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: 0.007321, mae: 0.625227, mean_q: 0.788536, mean_eps: 0.758901\n",
            " 268711/1000000: episode: 382, duration: 72.347s, episode steps: 494, steps per second:   7, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.393 [0.000, 5.000],  loss: 0.007680, mae: 0.618630, mean_q: 0.779180, mean_eps: 0.758383\n",
            " 269830/1000000: episode: 383, duration: 163.888s, episode steps: 1119, steps per second:   7, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.007010, mae: 0.615413, mean_q: 0.775275, mean_eps: 0.757657\n",
            " 270233/1000000: episode: 384, duration: 59.030s, episode steps: 403, steps per second:   7, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.008943, mae: 0.646607, mean_q: 0.813382, mean_eps: 0.756972\n",
            " 270575/1000000: episode: 385, duration: 50.134s, episode steps: 342, steps per second:   7, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.687 [0.000, 5.000],  loss: 0.010946, mae: 0.667751, mean_q: 0.838404, mean_eps: 0.756637\n",
            " 271088/1000000: episode: 386, duration: 75.289s, episode steps: 513, steps per second:   7, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.009976, mae: 0.669679, mean_q: 0.840233, mean_eps: 0.756252\n",
            " 271772/1000000: episode: 387, duration: 101.067s, episode steps: 684, steps per second:   7, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.010096, mae: 0.678274, mean_q: 0.850114, mean_eps: 0.755713\n",
            " 272318/1000000: episode: 388, duration: 80.044s, episode steps: 546, steps per second:   7, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.009235, mae: 0.669859, mean_q: 0.841386, mean_eps: 0.755160\n",
            " 273042/1000000: episode: 389, duration: 105.394s, episode steps: 724, steps per second:   7, episode reward: 18.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: 0.009034, mae: 0.669648, mean_q: 0.839390, mean_eps: 0.754588\n",
            " 273728/1000000: episode: 390, duration: 100.877s, episode steps: 686, steps per second:   7, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.008641, mae: 0.668405, mean_q: 0.838821, mean_eps: 0.753954\n",
            " 274109/1000000: episode: 391, duration: 56.028s, episode steps: 381, steps per second:   7, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.008592, mae: 0.671747, mean_q: 0.842340, mean_eps: 0.753474\n",
            " 275062/1000000: episode: 392, duration: 138.346s, episode steps: 953, steps per second:   7, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.008090, mae: 0.670949, mean_q: 0.841839, mean_eps: 0.752874\n",
            " 275454/1000000: episode: 393, duration: 57.313s, episode steps: 392, steps per second:   7, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.008185, mae: 0.670329, mean_q: 0.840350, mean_eps: 0.752268\n",
            " 275994/1000000: episode: 394, duration: 80.364s, episode steps: 540, steps per second:   7, episode reward: 14.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.380 [0.000, 5.000],  loss: 0.008274, mae: 0.676497, mean_q: 0.847931, mean_eps: 0.751849\n",
            " 276673/1000000: episode: 395, duration: 99.366s, episode steps: 679, steps per second:   7, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.007853, mae: 0.670883, mean_q: 0.840677, mean_eps: 0.751300\n",
            " 277275/1000000: episode: 396, duration: 88.503s, episode steps: 602, steps per second:   7, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.007870, mae: 0.669441, mean_q: 0.839668, mean_eps: 0.750724\n",
            " 278063/1000000: episode: 397, duration: 114.728s, episode steps: 788, steps per second:   7, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.007435, mae: 0.667420, mean_q: 0.838072, mean_eps: 0.750098\n",
            " 278609/1000000: episode: 398, duration: 79.840s, episode steps: 546, steps per second:   7, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.214 [0.000, 5.000],  loss: 0.007786, mae: 0.668472, mean_q: 0.839503, mean_eps: 0.749498\n",
            " 279135/1000000: episode: 399, duration: 76.469s, episode steps: 526, steps per second:   7, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.007393, mae: 0.659990, mean_q: 0.827941, mean_eps: 0.749016\n",
            " 279772/1000000: episode: 400, duration: 93.107s, episode steps: 637, steps per second:   7, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.606 [0.000, 5.000],  loss: 0.007824, mae: 0.663490, mean_q: 0.832193, mean_eps: 0.748492\n",
            " 280225/1000000: episode: 401, duration: 66.402s, episode steps: 453, steps per second:   7, episode reward:  5.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.009076, mae: 0.683070, mean_q: 0.855919, mean_eps: 0.748002\n",
            " 280699/1000000: episode: 402, duration: 69.175s, episode steps: 474, steps per second:   7, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.010745, mae: 0.695140, mean_q: 0.870117, mean_eps: 0.747585\n",
            " 281083/1000000: episode: 403, duration: 55.551s, episode steps: 384, steps per second:   7, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: 0.010728, mae: 0.689215, mean_q: 0.862090, mean_eps: 0.747199\n",
            " 281802/1000000: episode: 404, duration: 104.783s, episode steps: 719, steps per second:   7, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.009389, mae: 0.690211, mean_q: 0.864449, mean_eps: 0.746702\n",
            " 282198/1000000: episode: 405, duration: 57.998s, episode steps: 396, steps per second:   7, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.009615, mae: 0.694053, mean_q: 0.867922, mean_eps: 0.746200\n",
            " 282711/1000000: episode: 406, duration: 74.687s, episode steps: 513, steps per second:   7, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.630 [0.000, 5.000],  loss: 0.009186, mae: 0.684116, mean_q: 0.856440, mean_eps: 0.745791\n",
            " 283234/1000000: episode: 407, duration: 76.652s, episode steps: 523, steps per second:   7, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: 0.008852, mae: 0.689688, mean_q: 0.862813, mean_eps: 0.745325\n",
            " 283766/1000000: episode: 408, duration: 77.201s, episode steps: 532, steps per second:   7, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: 0.008701, mae: 0.690029, mean_q: 0.863059, mean_eps: 0.744850\n",
            " 284435/1000000: episode: 409, duration: 97.187s, episode steps: 669, steps per second:   7, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.008323, mae: 0.689801, mean_q: 0.864528, mean_eps: 0.744310\n",
            " 284833/1000000: episode: 410, duration: 58.055s, episode steps: 398, steps per second:   7, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.377 [0.000, 5.000],  loss: 0.008069, mae: 0.677783, mean_q: 0.848084, mean_eps: 0.743830\n",
            " 285505/1000000: episode: 411, duration: 97.630s, episode steps: 672, steps per second:   7, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.008502, mae: 0.688517, mean_q: 0.862842, mean_eps: 0.743348\n",
            " 286310/1000000: episode: 412, duration: 116.526s, episode steps: 805, steps per second:   7, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.008008, mae: 0.690466, mean_q: 0.863073, mean_eps: 0.742684\n",
            " 286948/1000000: episode: 413, duration: 92.851s, episode steps: 638, steps per second:   7, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.007856, mae: 0.685094, mean_q: 0.858002, mean_eps: 0.742034\n",
            " 287396/1000000: episode: 414, duration: 66.103s, episode steps: 448, steps per second:   7, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.625 [0.000, 5.000],  loss: 0.007613, mae: 0.682500, mean_q: 0.854091, mean_eps: 0.741546\n",
            " 288331/1000000: episode: 415, duration: 136.352s, episode steps: 935, steps per second:   7, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: 0.007943, mae: 0.690650, mean_q: 0.864323, mean_eps: 0.740923\n",
            " 288712/1000000: episode: 416, duration: 56.290s, episode steps: 381, steps per second:   7, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.730 [0.000, 5.000],  loss: 0.007517, mae: 0.690782, mean_q: 0.864848, mean_eps: 0.740331\n",
            " 289498/1000000: episode: 417, duration: 114.280s, episode steps: 786, steps per second:   7, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.007885, mae: 0.692190, mean_q: 0.865922, mean_eps: 0.739806\n",
            " 290184/1000000: episode: 418, duration: 100.093s, episode steps: 686, steps per second:   7, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.008688, mae: 0.702493, mean_q: 0.877975, mean_eps: 0.739144\n",
            " 290888/1000000: episode: 419, duration: 102.145s, episode steps: 704, steps per second:   7, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.011595, mae: 0.723230, mean_q: 0.903988, mean_eps: 0.738518\n",
            " 292055/1000000: episode: 420, duration: 169.637s, episode steps: 1167, steps per second:   7, episode reward: 27.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: 0.010291, mae: 0.719783, mean_q: 0.898816, mean_eps: 0.737676\n",
            " 292527/1000000: episode: 421, duration: 69.025s, episode steps: 472, steps per second:   7, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: 0.009687, mae: 0.717460, mean_q: 0.895160, mean_eps: 0.736939\n",
            " 293668/1000000: episode: 422, duration: 165.895s, episode steps: 1141, steps per second:   7, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.009303, mae: 0.714635, mean_q: 0.891946, mean_eps: 0.736213\n",
            " 294286/1000000: episode: 423, duration: 89.537s, episode steps: 618, steps per second:   7, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.008539, mae: 0.717861, mean_q: 0.895491, mean_eps: 0.735421\n",
            " 294825/1000000: episode: 424, duration: 78.511s, episode steps: 539, steps per second:   7, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.008837, mae: 0.715280, mean_q: 0.894430, mean_eps: 0.734901\n",
            " 295542/1000000: episode: 425, duration: 103.356s, episode steps: 717, steps per second:   7, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.682 [0.000, 5.000],  loss: 0.007904, mae: 0.706004, mean_q: 0.882126, mean_eps: 0.734335\n",
            " 296210/1000000: episode: 426, duration: 97.331s, episode steps: 668, steps per second:   7, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.008596, mae: 0.709504, mean_q: 0.886072, mean_eps: 0.733712\n",
            " 296613/1000000: episode: 427, duration: 58.151s, episode steps: 403, steps per second:   7, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: 0.007767, mae: 0.705712, mean_q: 0.881043, mean_eps: 0.733230\n",
            " 297208/1000000: episode: 428, duration: 86.568s, episode steps: 595, steps per second:   7, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.007723, mae: 0.713005, mean_q: 0.889174, mean_eps: 0.732781\n",
            " 298168/1000000: episode: 429, duration: 138.805s, episode steps: 960, steps per second:   7, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.423 [0.000, 5.000],  loss: 0.008165, mae: 0.711538, mean_q: 0.887825, mean_eps: 0.732081\n",
            " 298557/1000000: episode: 430, duration: 56.294s, episode steps: 389, steps per second:   7, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.007512, mae: 0.700905, mean_q: 0.875564, mean_eps: 0.731474\n",
            " 299134/1000000: episode: 431, duration: 83.605s, episode steps: 577, steps per second:   7, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: 0.008444, mae: 0.712551, mean_q: 0.890626, mean_eps: 0.731040\n",
            " 299612/1000000: episode: 432, duration: 69.364s, episode steps: 478, steps per second:   7, episode reward:  8.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.592 [0.000, 5.000],  loss: 0.008082, mae: 0.711368, mean_q: 0.887810, mean_eps: 0.730565\n",
            " 300315/1000000: episode: 433, duration: 102.327s, episode steps: 703, steps per second:   7, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.009036, mae: 0.732595, mean_q: 0.914356, mean_eps: 0.730033\n",
            " 301674/1000000: episode: 434, duration: 196.617s, episode steps: 1359, steps per second:   7, episode reward: 15.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.010875, mae: 0.748005, mean_q: 0.930654, mean_eps: 0.729105\n",
            " 302327/1000000: episode: 435, duration: 94.794s, episode steps: 653, steps per second:   7, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.225 [0.000, 5.000],  loss: 0.009892, mae: 0.749000, mean_q: 0.934292, mean_eps: 0.728200\n",
            " 303070/1000000: episode: 436, duration: 107.513s, episode steps: 743, steps per second:   7, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.009372, mae: 0.743206, mean_q: 0.925715, mean_eps: 0.727572\n",
            " 303862/1000000: episode: 437, duration: 115.000s, episode steps: 792, steps per second:   7, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.691 [0.000, 5.000],  loss: 0.009311, mae: 0.745644, mean_q: 0.928110, mean_eps: 0.726881\n",
            " 304941/1000000: episode: 438, duration: 156.311s, episode steps: 1079, steps per second:   7, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.651 [0.000, 5.000],  loss: 0.009069, mae: 0.744144, mean_q: 0.927374, mean_eps: 0.726039\n",
            " 305867/1000000: episode: 439, duration: 133.871s, episode steps: 926, steps per second:   7, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.325 [0.000, 5.000],  loss: 0.008637, mae: 0.746176, mean_q: 0.930312, mean_eps: 0.725137\n",
            " 306728/1000000: episode: 440, duration: 125.001s, episode steps: 861, steps per second:   7, episode reward: 18.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.674 [0.000, 5.000],  loss: 0.008315, mae: 0.742761, mean_q: 0.925364, mean_eps: 0.724333\n",
            " 307147/1000000: episode: 441, duration: 60.723s, episode steps: 419, steps per second:   7, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: 0.008191, mae: 0.744810, mean_q: 0.928944, mean_eps: 0.723757\n",
            " 307869/1000000: episode: 442, duration: 104.743s, episode steps: 722, steps per second:   7, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.693 [0.000, 5.000],  loss: 0.008077, mae: 0.744896, mean_q: 0.928754, mean_eps: 0.723243\n",
            " 308478/1000000: episode: 443, duration: 87.927s, episode steps: 609, steps per second:   7, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: 0.008305, mae: 0.741810, mean_q: 0.924119, mean_eps: 0.722644\n",
            " 309469/1000000: episode: 444, duration: 143.423s, episode steps: 991, steps per second:   7, episode reward: 24.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: 0.007750, mae: 0.739662, mean_q: 0.921884, mean_eps: 0.721924\n",
            " 310211/1000000: episode: 445, duration: 107.295s, episode steps: 742, steps per second:   7, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.666 [0.000, 5.000],  loss: 0.008756, mae: 0.750635, mean_q: 0.935238, mean_eps: 0.721144\n",
            " 311022/1000000: episode: 446, duration: 117.518s, episode steps: 811, steps per second:   7, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.011456, mae: 0.774871, mean_q: 0.962717, mean_eps: 0.720446\n",
            " 311547/1000000: episode: 447, duration: 76.446s, episode steps: 525, steps per second:   7, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.663 [0.000, 5.000],  loss: 0.009602, mae: 0.768649, mean_q: 0.955615, mean_eps: 0.719844\n",
            " 312180/1000000: episode: 448, duration: 91.200s, episode steps: 633, steps per second:   7, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.010585, mae: 0.783140, mean_q: 0.973807, mean_eps: 0.719323\n",
            " 312939/1000000: episode: 449, duration: 110.118s, episode steps: 759, steps per second:   7, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.311 [0.000, 5.000],  loss: 0.009660, mae: 0.768242, mean_q: 0.955004, mean_eps: 0.718697\n",
            " 313438/1000000: episode: 450, duration: 72.457s, episode steps: 499, steps per second:   7, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.009279, mae: 0.770354, mean_q: 0.958968, mean_eps: 0.718131\n",
            " 314807/1000000: episode: 451, duration: 198.628s, episode steps: 1369, steps per second:   7, episode reward: 25.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: 0.008870, mae: 0.766734, mean_q: 0.953461, mean_eps: 0.717290\n",
            " 316041/1000000: episode: 452, duration: 178.334s, episode steps: 1234, steps per second:   7, episode reward: 21.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.008868, mae: 0.767495, mean_q: 0.952745, mean_eps: 0.716119\n",
            " 316603/1000000: episode: 453, duration: 81.478s, episode steps: 562, steps per second:   7, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.008729, mae: 0.759998, mean_q: 0.944087, mean_eps: 0.715311\n",
            " 317601/1000000: episode: 454, duration: 143.811s, episode steps: 998, steps per second:   7, episode reward: 26.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: 0.008737, mae: 0.768397, mean_q: 0.954612, mean_eps: 0.714609\n",
            " 318183/1000000: episode: 455, duration: 84.328s, episode steps: 582, steps per second:   7, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.619 [0.000, 5.000],  loss: 0.008703, mae: 0.761694, mean_q: 0.946132, mean_eps: 0.713898\n",
            " 318770/1000000: episode: 456, duration: 85.223s, episode steps: 587, steps per second:   7, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.008261, mae: 0.762862, mean_q: 0.949523, mean_eps: 0.713372\n",
            " 319702/1000000: episode: 457, duration: 134.701s, episode steps: 932, steps per second:   7, episode reward: 18.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.007716, mae: 0.761760, mean_q: 0.946953, mean_eps: 0.712688\n",
            " 320617/1000000: episode: 458, duration: 132.237s, episode steps: 915, steps per second:   7, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.649 [0.000, 5.000],  loss: 0.010451, mae: 0.780953, mean_q: 0.970245, mean_eps: 0.711857\n",
            " 321140/1000000: episode: 459, duration: 75.786s, episode steps: 523, steps per second:   7, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.662 [0.000, 5.000],  loss: 0.011058, mae: 0.780485, mean_q: 0.969395, mean_eps: 0.711210\n",
            " 321465/1000000: episode: 460, duration: 46.876s, episode steps: 325, steps per second:   7, episode reward:  6.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: 0.010608, mae: 0.777261, mean_q: 0.963409, mean_eps: 0.710828\n",
            " 322448/1000000: episode: 461, duration: 142.084s, episode steps: 983, steps per second:   7, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: 0.010327, mae: 0.788008, mean_q: 0.978179, mean_eps: 0.710240\n",
            " 323079/1000000: episode: 462, duration: 92.326s, episode steps: 631, steps per second:   7, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.009548, mae: 0.774085, mean_q: 0.960594, mean_eps: 0.709513\n",
            " 323582/1000000: episode: 463, duration: 73.158s, episode steps: 503, steps per second:   7, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.009724, mae: 0.787148, mean_q: 0.976606, mean_eps: 0.709003\n",
            " 323978/1000000: episode: 464, duration: 57.471s, episode steps: 396, steps per second:   7, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.009175, mae: 0.779944, mean_q: 0.969202, mean_eps: 0.708598\n",
            " 324546/1000000: episode: 465, duration: 82.304s, episode steps: 568, steps per second:   7, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: 0.009752, mae: 0.792709, mean_q: 0.982690, mean_eps: 0.708165\n",
            " 325212/1000000: episode: 466, duration: 96.954s, episode steps: 666, steps per second:   7, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.688 [0.000, 5.000],  loss: 0.008856, mae: 0.786321, mean_q: 0.976067, mean_eps: 0.707609\n",
            " 325916/1000000: episode: 467, duration: 103.311s, episode steps: 704, steps per second:   7, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.009462, mae: 0.792188, mean_q: 0.981742, mean_eps: 0.706993\n",
            " 326771/1000000: episode: 468, duration: 124.072s, episode steps: 855, steps per second:   7, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.559 [0.000, 5.000],  loss: 0.008598, mae: 0.784301, mean_q: 0.974210, mean_eps: 0.706291\n",
            " 327917/1000000: episode: 469, duration: 166.182s, episode steps: 1146, steps per second:   7, episode reward: 17.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.008451, mae: 0.778282, mean_q: 0.965952, mean_eps: 0.705391\n",
            " 328619/1000000: episode: 470, duration: 102.219s, episode steps: 702, steps per second:   7, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.008516, mae: 0.778606, mean_q: 0.966175, mean_eps: 0.704559\n",
            " 329051/1000000: episode: 471, duration: 62.935s, episode steps: 432, steps per second:   7, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.007775, mae: 0.773935, mean_q: 0.960417, mean_eps: 0.704049\n",
            " 329430/1000000: episode: 472, duration: 55.892s, episode steps: 379, steps per second:   7, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: 0.008525, mae: 0.783279, mean_q: 0.971270, mean_eps: 0.703684\n",
            " 330214/1000000: episode: 473, duration: 114.874s, episode steps: 784, steps per second:   7, episode reward: 16.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.009681, mae: 0.795851, mean_q: 0.986584, mean_eps: 0.703161\n",
            " 330980/1000000: episode: 474, duration: 111.076s, episode steps: 766, steps per second:   7, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.011534, mae: 0.820687, mean_q: 1.016042, mean_eps: 0.702463\n",
            " 331647/1000000: episode: 475, duration: 97.946s, episode steps: 667, steps per second:   7, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.355 [0.000, 5.000],  loss: 0.011021, mae: 0.820456, mean_q: 1.015522, mean_eps: 0.701818\n",
            " 332300/1000000: episode: 476, duration: 95.343s, episode steps: 653, steps per second:   7, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: 0.010113, mae: 0.813827, mean_q: 1.008510, mean_eps: 0.701224\n",
            " 332681/1000000: episode: 477, duration: 55.582s, episode steps: 381, steps per second:   7, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.010430, mae: 0.814043, mean_q: 1.008790, mean_eps: 0.700759\n",
            " 333004/1000000: episode: 478, duration: 46.982s, episode steps: 323, steps per second:   7, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.635 [0.000, 5.000],  loss: 0.010460, mae: 0.806807, mean_q: 0.999233, mean_eps: 0.700442\n",
            " 334142/1000000: episode: 479, duration: 165.531s, episode steps: 1138, steps per second:   7, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.009658, mae: 0.817554, mean_q: 1.012841, mean_eps: 0.699785\n",
            " 334728/1000000: episode: 480, duration: 85.049s, episode steps: 586, steps per second:   7, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.009296, mae: 0.816990, mean_q: 1.012806, mean_eps: 0.699009\n",
            " 335121/1000000: episode: 481, duration: 57.230s, episode steps: 393, steps per second:   7, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: 0.009291, mae: 0.817501, mean_q: 1.011195, mean_eps: 0.698568\n",
            " 336371/1000000: episode: 482, duration: 181.509s, episode steps: 1250, steps per second:   7, episode reward: 22.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.009431, mae: 0.816824, mean_q: 1.011370, mean_eps: 0.697829\n",
            " 337203/1000000: episode: 483, duration: 120.822s, episode steps: 832, steps per second:   7, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: 0.009392, mae: 0.813316, mean_q: 1.007918, mean_eps: 0.696892\n",
            " 337731/1000000: episode: 484, duration: 77.352s, episode steps: 528, steps per second:   7, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.009106, mae: 0.812161, mean_q: 1.005027, mean_eps: 0.696280\n",
            " 338324/1000000: episode: 485, duration: 86.312s, episode steps: 593, steps per second:   7, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.597 [0.000, 5.000],  loss: 0.008688, mae: 0.814094, mean_q: 1.009130, mean_eps: 0.695776\n",
            " 338923/1000000: episode: 486, duration: 87.069s, episode steps: 599, steps per second:   7, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.008177, mae: 0.814158, mean_q: 1.008576, mean_eps: 0.695239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Continuando con la ejecución en el peso 325,000\n",
        "\n",
        "# Cargar pesos desde el paso 325,000\n",
        "dqn.load_weights(\"dqn_weights_325000.h5f\")\n",
        "\n"
      ],
      "metadata": {
        "id": "6hdiK0kNIYgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso de partida\n",
        "starting_step = 325000\n",
        "remaining_steps = 1000000 - starting_step\n",
        "\n",
        "\n",
        "# Callback personalizado para continuar numeración de checkpoints\n",
        "class OffsetModelCheckpoint(ModelIntervalCheckpoint):\n",
        "    def __init__(self, filepath, interval, offset):\n",
        "        super().__init__(filepath, interval)\n",
        "        self.offset = offset\n",
        "\n",
        "    def on_step_end(self, step, logs={}):\n",
        "        # Ajusta el número de paso en el nombre del archivo\n",
        "        self.step = step + self.offset\n",
        "        super().on_step_end(step, logs)\n",
        "\n",
        "#  Entrenamiento con pasos continuados desde 325000\n",
        "dqn.fit(env, nb_steps=remaining_steps, visualize=False, verbose=2,\n",
        "        callbacks=[\n",
        "            FileLogger(\"dqn_log_continuacion.json\", interval=10000),\n",
        "            OffsetModelCheckpoint(\"dqn_weights_{step}.h5f\", interval=25000, offset=starting_step)\n",
        "        ])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8R8ZWJlSX4V",
        "outputId": "b6e454d3-ded3-4967-888e-a70e522e228e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 675000 steps ...\n",
            "    964/675000: episode: 1, duration: 3.492s, episode steps: 964, steps per second: 276, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   1513/675000: episode: 2, duration: 1.993s, episode steps: 549, steps per second: 275, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   2209/675000: episode: 3, duration: 2.896s, episode steps: 696, steps per second: 240, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   2593/675000: episode: 4, duration: 2.313s, episode steps: 384, steps per second: 166, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.625 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   3243/675000: episode: 5, duration: 2.493s, episode steps: 650, steps per second: 261, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.386 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   4078/675000: episode: 6, duration: 3.031s, episode steps: 835, steps per second: 275, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   4503/675000: episode: 7, duration: 1.542s, episode steps: 425, steps per second: 276, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.372 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   4934/675000: episode: 8, duration: 1.540s, episode steps: 431, steps per second: 280, episode reward:  8.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   5916/675000: episode: 9, duration: 4.617s, episode steps: 982, steps per second: 213, episode reward: 23.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   6513/675000: episode: 10, duration: 2.343s, episode steps: 597, steps per second: 255, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   7361/675000: episode: 11, duration: 2.997s, episode steps: 848, steps per second: 283, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   8190/675000: episode: 12, duration: 2.962s, episode steps: 829, steps per second: 280, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   8954/675000: episode: 13, duration: 2.976s, episode steps: 764, steps per second: 257, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   9637/675000: episode: 14, duration: 3.485s, episode steps: 683, steps per second: 196, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  10326/675000: episode: 15, duration: 2.474s, episode steps: 689, steps per second: 279, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  10909/675000: episode: 16, duration: 2.082s, episode steps: 583, steps per second: 280, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  11481/675000: episode: 17, duration: 2.029s, episode steps: 572, steps per second: 282, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  12905/675000: episode: 18, duration: 6.283s, episode steps: 1424, steps per second: 227, episode reward: 13.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  13630/675000: episode: 19, duration: 2.518s, episode steps: 725, steps per second: 288, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  14082/675000: episode: 20, duration: 1.649s, episode steps: 452, steps per second: 274, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  15034/675000: episode: 21, duration: 3.951s, episode steps: 952, steps per second: 241, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  15939/675000: episode: 22, duration: 4.306s, episode steps: 905, steps per second: 210, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  16595/675000: episode: 23, duration: 2.701s, episode steps: 656, steps per second: 243, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  17430/675000: episode: 24, duration: 3.011s, episode steps: 835, steps per second: 277, episode reward: 22.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.414 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  18143/675000: episode: 25, duration: 2.586s, episode steps: 713, steps per second: 276, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  18944/675000: episode: 26, duration: 3.084s, episode steps: 801, steps per second: 260, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  19730/675000: episode: 27, duration: 3.991s, episode steps: 786, steps per second: 197, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  20325/675000: episode: 28, duration: 2.127s, episode steps: 595, steps per second: 280, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  20924/675000: episode: 29, duration: 2.148s, episode steps: 599, steps per second: 279, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  21801/675000: episode: 30, duration: 3.130s, episode steps: 877, steps per second: 280, episode reward: 17.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  22570/675000: episode: 31, duration: 3.474s, episode steps: 769, steps per second: 221, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  23090/675000: episode: 32, duration: 2.516s, episode steps: 520, steps per second: 207, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  23703/675000: episode: 33, duration: 2.182s, episode steps: 613, steps per second: 281, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  24428/675000: episode: 34, duration: 2.628s, episode steps: 725, steps per second: 276, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  24836/675000: episode: 35, duration: 1.471s, episode steps: 408, steps per second: 277, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.358 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  25492/675000: episode: 36, duration: 2.445s, episode steps: 656, steps per second: 268, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.366 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  26087/675000: episode: 37, duration: 3.166s, episode steps: 595, steps per second: 188, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  26724/675000: episode: 38, duration: 2.604s, episode steps: 637, steps per second: 245, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  27250/675000: episode: 39, duration: 1.895s, episode steps: 526, steps per second: 278, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  27951/675000: episode: 40, duration: 2.497s, episode steps: 701, steps per second: 281, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  28543/675000: episode: 41, duration: 2.170s, episode steps: 592, steps per second: 273, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.465 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  29222/675000: episode: 42, duration: 2.960s, episode steps: 679, steps per second: 229, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  29839/675000: episode: 43, duration: 3.046s, episode steps: 617, steps per second: 203, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  30659/675000: episode: 44, duration: 2.963s, episode steps: 820, steps per second: 277, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  31381/675000: episode: 45, duration: 2.610s, episode steps: 722, steps per second: 277, episode reward: 14.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  31812/675000: episode: 46, duration: 1.574s, episode steps: 431, steps per second: 274, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  32454/675000: episode: 47, duration: 2.527s, episode steps: 642, steps per second: 254, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  33478/675000: episode: 48, duration: 4.762s, episode steps: 1024, steps per second: 215, episode reward: 20.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  34222/675000: episode: 49, duration: 2.700s, episode steps: 744, steps per second: 276, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.363 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  34618/675000: episode: 50, duration: 1.434s, episode steps: 396, steps per second: 276, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  35266/675000: episode: 51, duration: 2.296s, episode steps: 648, steps per second: 282, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  35883/675000: episode: 52, duration: 2.473s, episode steps: 617, steps per second: 249, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  36510/675000: episode: 53, duration: 3.296s, episode steps: 627, steps per second: 190, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.464 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  37181/675000: episode: 54, duration: 2.407s, episode steps: 671, steps per second: 279, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  37945/675000: episode: 55, duration: 2.743s, episode steps: 764, steps per second: 279, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  38882/675000: episode: 56, duration: 3.349s, episode steps: 937, steps per second: 280, episode reward: 16.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  39635/675000: episode: 57, duration: 3.758s, episode steps: 753, steps per second: 200, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  40313/675000: episode: 58, duration: 2.691s, episode steps: 678, steps per second: 252, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  40939/675000: episode: 59, duration: 2.248s, episode steps: 626, steps per second: 278, episode reward:  4.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  41324/675000: episode: 60, duration: 1.365s, episode steps: 385, steps per second: 282, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  41806/675000: episode: 61, duration: 1.759s, episode steps: 482, steps per second: 274, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  42640/675000: episode: 62, duration: 3.282s, episode steps: 834, steps per second: 254, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  43422/675000: episode: 63, duration: 3.806s, episode steps: 782, steps per second: 205, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  44317/675000: episode: 64, duration: 3.190s, episode steps: 895, steps per second: 281, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.577 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  44801/675000: episode: 65, duration: 1.730s, episode steps: 484, steps per second: 280, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.382 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  45579/675000: episode: 66, duration: 2.766s, episode steps: 778, steps per second: 281, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  46345/675000: episode: 67, duration: 3.708s, episode steps: 766, steps per second: 207, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  46892/675000: episode: 68, duration: 2.327s, episode steps: 547, steps per second: 235, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  47642/675000: episode: 69, duration: 2.649s, episode steps: 750, steps per second: 283, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  48937/675000: episode: 70, duration: 4.616s, episode steps: 1295, steps per second: 281, episode reward: 21.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  49311/675000: episode: 71, duration: 1.389s, episode steps: 374, steps per second: 269, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  50196/675000: episode: 72, duration: 40.975s, episode steps: 885, steps per second:  22, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.433 [0.000, 5.000],  loss: 0.014748, mae: 0.892788, mean_q: 1.090333, mean_eps: 0.954912\n",
            "  50745/675000: episode: 73, duration: 105.810s, episode steps: 549, steps per second:   5, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.014155, mae: 0.893926, mean_q: 1.086903, mean_eps: 0.954577\n",
            "  51274/675000: episode: 74, duration: 102.888s, episode steps: 529, steps per second:   5, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.014563, mae: 0.890990, mean_q: 1.080688, mean_eps: 0.954092\n",
            "  52568/675000: episode: 75, duration: 248.886s, episode steps: 1294, steps per second:   5, episode reward: 23.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.013776, mae: 0.886152, mean_q: 1.074804, mean_eps: 0.953272\n",
            "  53211/675000: episode: 76, duration: 124.904s, episode steps: 643, steps per second:   5, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.012555, mae: 0.877071, mean_q: 1.064029, mean_eps: 0.952400\n",
            "  54580/675000: episode: 77, duration: 264.547s, episode steps: 1369, steps per second:   5, episode reward: 25.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.011766, mae: 0.878007, mean_q: 1.065372, mean_eps: 0.951495\n",
            "  55392/675000: episode: 78, duration: 159.454s, episode steps: 812, steps per second:   5, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.012226, mae: 0.872668, mean_q: 1.058530, mean_eps: 0.950513\n",
            "  56055/675000: episode: 79, duration: 129.147s, episode steps: 663, steps per second:   5, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.011318, mae: 0.872129, mean_q: 1.057477, mean_eps: 0.949849\n",
            "  57085/675000: episode: 80, duration: 206.933s, episode steps: 1030, steps per second:   5, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: 0.011079, mae: 0.877104, mean_q: 1.064645, mean_eps: 0.949087\n",
            "  58090/675000: episode: 81, duration: 195.969s, episode steps: 1005, steps per second:   5, episode reward: 12.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.011269, mae: 0.867325, mean_q: 1.052681, mean_eps: 0.948172\n",
            "  58887/675000: episode: 82, duration: 152.775s, episode steps: 797, steps per second:   5, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: 0.010377, mae: 0.871926, mean_q: 1.059425, mean_eps: 0.947361\n",
            "  59707/675000: episode: 83, duration: 158.377s, episode steps: 820, steps per second:   5, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.010617, mae: 0.871655, mean_q: 1.057919, mean_eps: 0.946633\n",
            "  60551/675000: episode: 84, duration: 164.599s, episode steps: 844, steps per second:   5, episode reward: 16.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.600 [0.000, 5.000],  loss: 0.010463, mae: 0.887944, mean_q: 1.078765, mean_eps: 0.945884\n",
            "  61203/675000: episode: 85, duration: 126.235s, episode steps: 652, steps per second:   5, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.010037, mae: 0.893005, mean_q: 1.085499, mean_eps: 0.945211\n",
            "  61816/675000: episode: 86, duration: 118.364s, episode steps: 613, steps per second:   5, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.010075, mae: 0.895805, mean_q: 1.089231, mean_eps: 0.944642\n",
            "  62498/675000: episode: 87, duration: 132.860s, episode steps: 682, steps per second:   5, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.620 [0.000, 5.000],  loss: 0.009462, mae: 0.891990, mean_q: 1.084770, mean_eps: 0.944059\n",
            "  63225/675000: episode: 88, duration: 141.824s, episode steps: 727, steps per second:   5, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.009143, mae: 0.885015, mean_q: 1.077576, mean_eps: 0.943425\n",
            "  64059/675000: episode: 89, duration: 162.215s, episode steps: 834, steps per second:   5, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.009014, mae: 0.885562, mean_q: 1.077405, mean_eps: 0.942723\n",
            "  64571/675000: episode: 90, duration: 99.859s, episode steps: 512, steps per second:   5, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: 0.008856, mae: 0.887359, mean_q: 1.078841, mean_eps: 0.942117\n",
            "  65204/675000: episode: 91, duration: 122.686s, episode steps: 633, steps per second:   5, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.008741, mae: 0.881143, mean_q: 1.072826, mean_eps: 0.941602\n",
            "  65692/675000: episode: 92, duration: 95.582s, episode steps: 488, steps per second:   5, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.588 [0.000, 5.000],  loss: 0.008548, mae: 0.889619, mean_q: 1.082857, mean_eps: 0.941097\n",
            "  66285/675000: episode: 93, duration: 116.956s, episode steps: 593, steps per second:   5, episode reward: 11.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.690 [0.000, 5.000],  loss: 0.008977, mae: 0.881348, mean_q: 1.072703, mean_eps: 0.940611\n",
            "  66926/675000: episode: 94, duration: 123.641s, episode steps: 641, steps per second:   5, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.008057, mae: 0.876543, mean_q: 1.066726, mean_eps: 0.940056\n",
            "  67434/675000: episode: 95, duration: 97.253s, episode steps: 508, steps per second:   5, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.007809, mae: 0.878085, mean_q: 1.069605, mean_eps: 0.939538\n",
            "  68546/675000: episode: 96, duration: 215.887s, episode steps: 1112, steps per second:   5, episode reward: 14.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.008413, mae: 0.878851, mean_q: 1.069782, mean_eps: 0.938809\n",
            "  69327/675000: episode: 97, duration: 150.027s, episode steps: 781, steps per second:   5, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: 0.007698, mae: 0.873677, mean_q: 1.064701, mean_eps: 0.937958\n",
            "  69717/675000: episode: 98, duration: 75.912s, episode steps: 390, steps per second:   5, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.008490, mae: 0.875835, mean_q: 1.066588, mean_eps: 0.937431\n",
            "  70124/675000: episode: 99, duration: 77.615s, episode steps: 407, steps per second:   5, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.631 [0.000, 5.000],  loss: 0.008459, mae: 0.885780, mean_q: 1.079391, mean_eps: 0.937072\n",
            "  70515/675000: episode: 100, duration: 75.850s, episode steps: 391, steps per second:   5, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.639 [0.000, 5.000],  loss: 0.010250, mae: 0.915829, mean_q: 1.116680, mean_eps: 0.936713\n",
            "  71140/675000: episode: 101, duration: 120.348s, episode steps: 625, steps per second:   5, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.009618, mae: 0.919662, mean_q: 1.120803, mean_eps: 0.936256\n",
            "  71726/675000: episode: 102, duration: 112.173s, episode steps: 586, steps per second:   5, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.377 [0.000, 5.000],  loss: 0.008764, mae: 0.919499, mean_q: 1.120389, mean_eps: 0.935711\n",
            "  72148/675000: episode: 103, duration: 81.090s, episode steps: 422, steps per second:   5, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: 0.009134, mae: 0.914626, mean_q: 1.113071, mean_eps: 0.935257\n",
            "  72721/675000: episode: 104, duration: 109.692s, episode steps: 573, steps per second:   5, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: 0.008848, mae: 0.909738, mean_q: 1.107917, mean_eps: 0.934809\n",
            "  73681/675000: episode: 105, duration: 185.888s, episode steps: 960, steps per second:   5, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.008653, mae: 0.917067, mean_q: 1.117169, mean_eps: 0.934120\n",
            "  74629/675000: episode: 106, duration: 184.323s, episode steps: 948, steps per second:   5, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.008285, mae: 0.912767, mean_q: 1.112760, mean_eps: 0.933261\n",
            "  75447/675000: episode: 107, duration: 157.969s, episode steps: 818, steps per second:   5, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.008477, mae: 0.918335, mean_q: 1.119053, mean_eps: 0.932466\n",
            "  75953/675000: episode: 108, duration: 98.368s, episode steps: 506, steps per second:   5, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.007764, mae: 0.913399, mean_q: 1.112799, mean_eps: 0.931870\n",
            "  76779/675000: episode: 109, duration: 157.715s, episode steps: 826, steps per second:   5, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.007857, mae: 0.914858, mean_q: 1.115286, mean_eps: 0.931271\n",
            "  77626/675000: episode: 110, duration: 162.936s, episode steps: 847, steps per second:   5, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.008044, mae: 0.912846, mean_q: 1.112030, mean_eps: 0.930518\n",
            "  78202/675000: episode: 111, duration: 112.559s, episode steps: 576, steps per second:   5, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.490 [0.000, 5.000],  loss: 0.007909, mae: 0.919828, mean_q: 1.122345, mean_eps: 0.929878\n",
            "  79054/675000: episode: 112, duration: 166.069s, episode steps: 852, steps per second:   5, episode reward: 14.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: 0.007411, mae: 0.909990, mean_q: 1.108822, mean_eps: 0.929235\n",
            "  80157/675000: episode: 113, duration: 212.717s, episode steps: 1103, steps per second:   5, episode reward: 20.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.007648, mae: 0.912710, mean_q: 1.113072, mean_eps: 0.928356\n",
            "  80715/675000: episode: 114, duration: 107.528s, episode steps: 558, steps per second:   5, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.008910, mae: 0.928335, mean_q: 1.132830, mean_eps: 0.927608\n",
            "  81092/675000: episode: 115, duration: 72.384s, episode steps: 377, steps per second:   5, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.008784, mae: 0.918142, mean_q: 1.118648, mean_eps: 0.927187\n",
            "  81854/675000: episode: 116, duration: 146.886s, episode steps: 762, steps per second:   5, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.008723, mae: 0.937020, mean_q: 1.143660, mean_eps: 0.926675\n",
            "  82626/675000: episode: 117, duration: 148.369s, episode steps: 772, steps per second:   5, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.491 [0.000, 5.000],  loss: 0.008437, mae: 0.927808, mean_q: 1.132417, mean_eps: 0.925984\n",
            "  83423/675000: episode: 118, duration: 153.066s, episode steps: 797, steps per second:   5, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.008137, mae: 0.931003, mean_q: 1.135728, mean_eps: 0.925278\n",
            "  83779/675000: episode: 119, duration: 68.359s, episode steps: 356, steps per second:   5, episode reward:  6.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.008745, mae: 0.923514, mean_q: 1.127464, mean_eps: 0.924760\n",
            "  84564/675000: episode: 120, duration: 150.833s, episode steps: 785, steps per second:   5, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: 0.007823, mae: 0.928503, mean_q: 1.134098, mean_eps: 0.924246\n",
            "  85246/675000: episode: 121, duration: 131.735s, episode steps: 682, steps per second:   5, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.007536, mae: 0.927744, mean_q: 1.133329, mean_eps: 0.923586\n",
            "  86150/675000: episode: 122, duration: 174.442s, episode steps: 904, steps per second:   5, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.007263, mae: 0.925079, mean_q: 1.129282, mean_eps: 0.922872\n",
            "  86661/675000: episode: 123, duration: 98.591s, episode steps: 511, steps per second:   5, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.007608, mae: 0.925095, mean_q: 1.131007, mean_eps: 0.922235\n",
            "  87446/675000: episode: 124, duration: 151.247s, episode steps: 785, steps per second:   5, episode reward: 19.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.007917, mae: 0.926876, mean_q: 1.131890, mean_eps: 0.921652\n",
            "  88029/675000: episode: 125, duration: 112.572s, episode steps: 583, steps per second:   5, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.667 [0.000, 5.000],  loss: 0.007633, mae: 0.921411, mean_q: 1.125516, mean_eps: 0.921037\n",
            "  88682/675000: episode: 126, duration: 124.743s, episode steps: 653, steps per second:   5, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.007847, mae: 0.924878, mean_q: 1.129435, mean_eps: 0.920481\n",
            "  89421/675000: episode: 127, duration: 145.206s, episode steps: 739, steps per second:   5, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.007424, mae: 0.925597, mean_q: 1.130885, mean_eps: 0.919854\n",
            "  90220/675000: episode: 128, duration: 155.467s, episode steps: 799, steps per second:   5, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.007838, mae: 0.936980, mean_q: 1.144757, mean_eps: 0.919162\n",
            "  90756/675000: episode: 129, duration: 104.988s, episode steps: 536, steps per second:   5, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: 0.009101, mae: 0.944010, mean_q: 1.152874, mean_eps: 0.918561\n",
            "  91781/675000: episode: 130, duration: 199.730s, episode steps: 1025, steps per second:   5, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.407 [0.000, 5.000],  loss: 0.008850, mae: 0.946800, mean_q: 1.153632, mean_eps: 0.917859\n",
            "  92467/675000: episode: 131, duration: 131.041s, episode steps: 686, steps per second:   5, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.008338, mae: 0.955329, mean_q: 1.164473, mean_eps: 0.917089\n",
            "  92976/675000: episode: 132, duration: 98.949s, episode steps: 509, steps per second:   5, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.424 [0.000, 5.000],  loss: 0.008368, mae: 0.943859, mean_q: 1.150569, mean_eps: 0.916551\n",
            "  93677/675000: episode: 133, duration: 134.506s, episode steps: 701, steps per second:   5, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.007603, mae: 0.947534, mean_q: 1.155983, mean_eps: 0.916007\n",
            "  94205/675000: episode: 134, duration: 101.519s, episode steps: 528, steps per second:   5, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.007617, mae: 0.934718, mean_q: 1.139980, mean_eps: 0.915454\n",
            "  94959/675000: episode: 135, duration: 145.210s, episode steps: 754, steps per second:   5, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.007473, mae: 0.954494, mean_q: 1.165510, mean_eps: 0.914877\n",
            "  95513/675000: episode: 136, duration: 106.937s, episode steps: 554, steps per second:   5, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.007702, mae: 0.940872, mean_q: 1.147212, mean_eps: 0.914288\n",
            "  96001/675000: episode: 137, duration: 93.807s, episode steps: 488, steps per second:   5, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.410 [0.000, 5.000],  loss: 0.007025, mae: 0.947329, mean_q: 1.156473, mean_eps: 0.913819\n",
            "  96604/675000: episode: 138, duration: 114.720s, episode steps: 603, steps per second:   5, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.007563, mae: 0.948766, mean_q: 1.157848, mean_eps: 0.913328\n",
            "  97180/675000: episode: 139, duration: 110.571s, episode steps: 576, steps per second:   5, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.007069, mae: 0.938020, mean_q: 1.143634, mean_eps: 0.912798\n",
            "  98004/675000: episode: 140, duration: 158.828s, episode steps: 824, steps per second:   5, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.619 [0.000, 5.000],  loss: 0.007312, mae: 0.945403, mean_q: 1.153696, mean_eps: 0.912168\n",
            "  99395/675000: episode: 141, duration: 267.410s, episode steps: 1391, steps per second:   5, episode reward: 16.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.006994, mae: 0.938736, mean_q: 1.145228, mean_eps: 0.911171\n",
            " 100319/675000: episode: 142, duration: 180.470s, episode steps: 924, steps per second:   5, episode reward:  8.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: 0.007454, mae: 0.952272, mean_q: 1.162482, mean_eps: 0.910129\n",
            " 101021/675000: episode: 143, duration: 138.054s, episode steps: 702, steps per second:   5, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.008541, mae: 0.968454, mean_q: 1.181731, mean_eps: 0.909397\n",
            " 101404/675000: episode: 144, duration: 75.927s, episode steps: 383, steps per second:   5, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: 0.008726, mae: 0.966208, mean_q: 1.179187, mean_eps: 0.908909\n",
            " 101996/675000: episode: 145, duration: 114.467s, episode steps: 592, steps per second:   5, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.008791, mae: 0.974303, mean_q: 1.187516, mean_eps: 0.908470\n",
            " 102367/675000: episode: 146, duration: 73.178s, episode steps: 371, steps per second:   5, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.008045, mae: 0.967699, mean_q: 1.179705, mean_eps: 0.908037\n",
            " 102884/675000: episode: 147, duration: 100.128s, episode steps: 517, steps per second:   5, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.553 [0.000, 5.000],  loss: 0.007913, mae: 0.979498, mean_q: 1.194575, mean_eps: 0.907637\n",
            " 103309/675000: episode: 148, duration: 82.859s, episode steps: 425, steps per second:   5, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: 0.008500, mae: 0.980610, mean_q: 1.197188, mean_eps: 0.907214\n",
            " 103804/675000: episode: 149, duration: 96.729s, episode steps: 495, steps per second:   5, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.007528, mae: 0.975279, mean_q: 1.189991, mean_eps: 0.906800\n",
            " 104289/675000: episode: 150, duration: 94.329s, episode steps: 485, steps per second:   5, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.647 [0.000, 5.000],  loss: 0.007948, mae: 0.973152, mean_q: 1.186676, mean_eps: 0.906359\n",
            " 105324/675000: episode: 151, duration: 200.733s, episode steps: 1035, steps per second:   5, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.628 [0.000, 5.000],  loss: 0.007396, mae: 0.978397, mean_q: 1.194351, mean_eps: 0.905675\n",
            " 105694/675000: episode: 152, duration: 74.217s, episode steps: 370, steps per second:   5, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.008581, mae: 0.980031, mean_q: 1.196141, mean_eps: 0.905042\n",
            " 106348/675000: episode: 153, duration: 125.913s, episode steps: 654, steps per second:   5, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: 0.007470, mae: 0.978271, mean_q: 1.192913, mean_eps: 0.904582\n",
            " 106847/675000: episode: 154, duration: 96.164s, episode steps: 499, steps per second:   5, episode reward:  3.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: 0.007123, mae: 0.973459, mean_q: 1.188096, mean_eps: 0.904063\n",
            " 107252/675000: episode: 155, duration: 78.860s, episode steps: 405, steps per second:   5, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.649 [0.000, 5.000],  loss: 0.007384, mae: 0.968615, mean_q: 1.183111, mean_eps: 0.903656\n",
            " 107960/675000: episode: 156, duration: 136.764s, episode steps: 708, steps per second:   5, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.007321, mae: 0.971543, mean_q: 1.186408, mean_eps: 0.903155\n",
            " 108339/675000: episode: 157, duration: 72.349s, episode steps: 379, steps per second:   5, episode reward:  8.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: 0.007595, mae: 0.972487, mean_q: 1.188323, mean_eps: 0.902666\n",
            " 109008/675000: episode: 158, duration: 129.598s, episode steps: 669, steps per second:   5, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.007148, mae: 0.973972, mean_q: 1.189813, mean_eps: 0.902194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dqn_weights_100000.h5f\n",
        "#Continuación al 325000 + 100000 = 425000\n",
        "\n",
        "# Paso de partida 2\n",
        "starting_step = 100000 #ultimo weight actualizado\n",
        "remaining_steps = 200000 - starting_step\n",
        "\n",
        "\n",
        "# Callback personalizado para continuar numeración de checkpoints\n",
        "class OffsetModelCheckpoint(ModelIntervalCheckpoint):\n",
        "    def __init__(self, filepath, interval, offset):\n",
        "        super().__init__(filepath, interval)\n",
        "        self.offset = offset\n",
        "\n",
        "    def on_step_end(self, step, logs={}):\n",
        "        # Ajusta el número de paso en el nombre del archivo\n",
        "        self.step = step + self.offset\n",
        "        super().on_step_end(step, logs)\n",
        "\n",
        "# Entrenamiento con pasos continuados desde 100000\n",
        "dqn.fit(env, nb_steps=remaining_steps, visualize=False, verbose=2,\n",
        "        callbacks=[\n",
        "            FileLogger(\"dqn_log_continuacion.json\", interval=10000),\n",
        "            OffsetModelCheckpoint(\"dqn_weights_{step}.h5f\", interval=25000, offset=starting_step)\n",
        "        ])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nV3IQgKqDrTx",
        "outputId": "f334c13f-8d1c-4e97-97c2-847eccbc35cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 100000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   641/100000: episode: 1, duration: 6.721s, episode steps: 641, steps per second:  95, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  1268/100000: episode: 2, duration: 2.881s, episode steps: 627, steps per second: 218, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  1897/100000: episode: 3, duration: 2.492s, episode steps: 629, steps per second: 252, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  2286/100000: episode: 4, duration: 1.526s, episode steps: 389, steps per second: 255, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  2820/100000: episode: 5, duration: 2.423s, episode steps: 534, steps per second: 220, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  3438/100000: episode: 6, duration: 3.702s, episode steps: 618, steps per second: 167, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  4192/100000: episode: 7, duration: 2.978s, episode steps: 754, steps per second: 253, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  4829/100000: episode: 8, duration: 2.535s, episode steps: 637, steps per second: 251, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  5787/100000: episode: 9, duration: 3.904s, episode steps: 958, steps per second: 245, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  6280/100000: episode: 10, duration: 3.425s, episode steps: 493, steps per second: 144, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.355 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  6667/100000: episode: 11, duration: 1.801s, episode steps: 387, steps per second: 215, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  7708/100000: episode: 12, duration: 5.492s, episode steps: 1041, steps per second: 190, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  8452/100000: episode: 13, duration: 4.156s, episode steps: 744, steps per second: 179, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  9234/100000: episode: 14, duration: 4.835s, episode steps: 782, steps per second: 162, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  9971/100000: episode: 15, duration: 3.038s, episode steps: 737, steps per second: 243, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 10352/100000: episode: 16, duration: 1.594s, episode steps: 381, steps per second: 239, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.304 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 10959/100000: episode: 17, duration: 2.540s, episode steps: 607, steps per second: 239, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 12036/100000: episode: 18, duration: 5.987s, episode steps: 1077, steps per second: 180, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.331 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 12635/100000: episode: 19, duration: 2.844s, episode steps: 599, steps per second: 211, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 13540/100000: episode: 20, duration: 4.032s, episode steps: 905, steps per second: 224, episode reward: 10.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 14483/100000: episode: 21, duration: 5.410s, episode steps: 943, steps per second: 174, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 15062/100000: episode: 22, duration: 2.322s, episode steps: 579, steps per second: 249, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 15606/100000: episode: 23, duration: 2.208s, episode steps: 544, steps per second: 246, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.346 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 15955/100000: episode: 24, duration: 1.450s, episode steps: 349, steps per second: 241, episode reward:  7.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 16459/100000: episode: 25, duration: 2.061s, episode steps: 504, steps per second: 245, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 16851/100000: episode: 26, duration: 1.601s, episode steps: 392, steps per second: 245, episode reward:  9.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.337 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 17374/100000: episode: 27, duration: 3.419s, episode steps: 523, steps per second: 153, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 18124/100000: episode: 28, duration: 3.300s, episode steps: 750, steps per second: 227, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 18648/100000: episode: 29, duration: 2.146s, episode steps: 524, steps per second: 244, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.204 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 19143/100000: episode: 30, duration: 2.029s, episode steps: 495, steps per second: 244, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 19669/100000: episode: 31, duration: 2.153s, episode steps: 526, steps per second: 244, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 20568/100000: episode: 32, duration: 5.200s, episode steps: 899, steps per second: 173, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 21323/100000: episode: 33, duration: 3.078s, episode steps: 755, steps per second: 245, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.244 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 22439/100000: episode: 34, duration: 4.510s, episode steps: 1116, steps per second: 247, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 23375/100000: episode: 35, duration: 5.065s, episode steps: 936, steps per second: 185, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.332 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 23988/100000: episode: 36, duration: 2.659s, episode steps: 613, steps per second: 231, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.388 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 25147/100000: episode: 37, duration: 5.217s, episode steps: 1159, steps per second: 222, episode reward: 18.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 25854/100000: episode: 38, duration: 3.102s, episode steps: 707, steps per second: 228, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 26380/100000: episode: 39, duration: 3.501s, episode steps: 526, steps per second: 150, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.327 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 27451/100000: episode: 40, duration: 4.285s, episode steps: 1071, steps per second: 250, episode reward: 13.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.331 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 28401/100000: episode: 41, duration: 3.695s, episode steps: 950, steps per second: 257, episode reward: 21.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 29128/100000: episode: 42, duration: 3.580s, episode steps: 727, steps per second: 203, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.347 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 29630/100000: episode: 43, duration: 2.885s, episode steps: 502, steps per second: 174, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 30856/100000: episode: 44, duration: 4.893s, episode steps: 1226, steps per second: 251, episode reward: 17.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.351 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 31340/100000: episode: 45, duration: 1.919s, episode steps: 484, steps per second: 252, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.281 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 32049/100000: episode: 46, duration: 3.109s, episode steps: 709, steps per second: 228, episode reward: 15.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.305 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 32558/100000: episode: 47, duration: 3.277s, episode steps: 509, steps per second: 155, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 32962/100000: episode: 48, duration: 1.632s, episode steps: 404, steps per second: 248, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.131 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 33439/100000: episode: 49, duration: 1.937s, episode steps: 477, steps per second: 246, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.191 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 33848/100000: episode: 50, duration: 1.673s, episode steps: 409, steps per second: 244, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.166 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 34897/100000: episode: 51, duration: 4.119s, episode steps: 1049, steps per second: 255, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.256 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 35533/100000: episode: 52, duration: 4.093s, episode steps: 636, steps per second: 155, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.360 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 36457/100000: episode: 53, duration: 3.767s, episode steps: 924, steps per second: 245, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.247 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 37085/100000: episode: 54, duration: 2.541s, episode steps: 628, steps per second: 247, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.287 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 37936/100000: episode: 55, duration: 3.504s, episode steps: 851, steps per second: 243, episode reward: 24.000, mean reward:  0.028 [ 0.000,  1.000], mean action: 2.175 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 38447/100000: episode: 56, duration: 3.432s, episode steps: 511, steps per second: 149, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 39640/100000: episode: 57, duration: 5.273s, episode steps: 1193, steps per second: 226, episode reward: 18.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.167 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 40390/100000: episode: 58, duration: 3.202s, episode steps: 750, steps per second: 234, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.260 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 40936/100000: episode: 59, duration: 2.424s, episode steps: 546, steps per second: 225, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.104 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 41428/100000: episode: 60, duration: 3.447s, episode steps: 492, steps per second: 143, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.252 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 41938/100000: episode: 61, duration: 2.083s, episode steps: 510, steps per second: 245, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.302 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 42510/100000: episode: 62, duration: 2.292s, episode steps: 572, steps per second: 250, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.208 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 43022/100000: episode: 63, duration: 2.053s, episode steps: 512, steps per second: 249, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 43438/100000: episode: 64, duration: 1.729s, episode steps: 416, steps per second: 241, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 44003/100000: episode: 65, duration: 2.563s, episode steps: 565, steps per second: 220, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.349 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 44943/100000: episode: 66, duration: 5.031s, episode steps: 940, steps per second: 187, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.215 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 45402/100000: episode: 67, duration: 1.853s, episode steps: 459, steps per second: 248, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.214 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 46532/100000: episode: 68, duration: 4.609s, episode steps: 1130, steps per second: 245, episode reward: 24.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.279 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 47485/100000: episode: 69, duration: 5.362s, episode steps: 953, steps per second: 178, episode reward: 23.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.352 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 47839/100000: episode: 70, duration: 1.462s, episode steps: 354, steps per second: 242, episode reward:  2.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.302 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 48166/100000: episode: 71, duration: 1.332s, episode steps: 327, steps per second: 246, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.162 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 48798/100000: episode: 72, duration: 2.651s, episode steps: 632, steps per second: 238, episode reward: 13.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.225 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 49638/100000: episode: 73, duration: 3.530s, episode steps: 840, steps per second: 238, episode reward: 17.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.211 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 50030/100000: episode: 74, duration: 9.635s, episode steps: 392, steps per second:  41, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.212 [0.000, 5.000],  loss: 0.006832, mae: 0.029681, mean_q: 0.036759, mean_eps: 0.774932\n",
            " 50803/100000: episode: 75, duration: 164.991s, episode steps: 773, steps per second:   5, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.007734, mae: 0.033104, mean_q: 0.042827, mean_eps: 0.773128\n",
            " 51754/100000: episode: 76, duration: 206.767s, episode steps: 951, steps per second:   5, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: 0.007015, mae: 0.029925, mean_q: 0.036879, mean_eps: 0.769249\n",
            " 52759/100000: episode: 77, duration: 213.899s, episode steps: 1005, steps per second:   5, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.007787, mae: 0.033912, mean_q: 0.042073, mean_eps: 0.764848\n",
            " 53514/100000: episode: 78, duration: 163.200s, episode steps: 755, steps per second:   5, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.007943, mae: 0.033837, mean_q: 0.042598, mean_eps: 0.760888\n",
            " 54356/100000: episode: 79, duration: 183.793s, episode steps: 842, steps per second:   5, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: 0.007823, mae: 0.034534, mean_q: 0.045047, mean_eps: 0.757295\n",
            " 55060/100000: episode: 80, duration: 150.351s, episode steps: 704, steps per second:   5, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: 0.007839, mae: 0.033094, mean_q: 0.043641, mean_eps: 0.753816\n",
            " 55678/100000: episode: 81, duration: 130.173s, episode steps: 618, steps per second:   5, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.631 [0.000, 5.000],  loss: 0.007664, mae: 0.033011, mean_q: 0.044292, mean_eps: 0.750842\n",
            " 56196/100000: episode: 82, duration: 109.323s, episode steps: 518, steps per second:   5, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: 0.006609, mae: 0.032812, mean_q: 0.044605, mean_eps: 0.748286\n",
            " 56847/100000: episode: 83, duration: 140.048s, episode steps: 651, steps per second:   5, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.455 [0.000, 5.000],  loss: 0.007480, mae: 0.033851, mean_q: 0.048151, mean_eps: 0.745655\n",
            " 57465/100000: episode: 84, duration: 131.809s, episode steps: 618, steps per second:   5, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.007150, mae: 0.031869, mean_q: 0.047173, mean_eps: 0.742800\n",
            " 58212/100000: episode: 85, duration: 158.078s, episode steps: 747, steps per second:   5, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.656 [0.000, 5.000],  loss: 0.006995, mae: 0.031621, mean_q: 0.046789, mean_eps: 0.739729\n",
            " 58801/100000: episode: 86, duration: 125.563s, episode steps: 589, steps per second:   5, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.007590, mae: 0.032185, mean_q: 0.048866, mean_eps: 0.736723\n",
            " 59454/100000: episode: 87, duration: 137.776s, episode steps: 653, steps per second:   5, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: 0.006474, mae: 0.030745, mean_q: 0.047785, mean_eps: 0.733928\n",
            " 60027/100000: episode: 88, duration: 120.892s, episode steps: 573, steps per second:   5, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.007322, mae: 0.034327, mean_q: 0.053638, mean_eps: 0.731170\n",
            " 60615/100000: episode: 89, duration: 124.733s, episode steps: 588, steps per second:   5, episode reward:  3.000, mean reward:  0.005 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: 0.007370, mae: 0.061908, mean_q: 0.091439, mean_eps: 0.728558\n",
            " 61238/100000: episode: 90, duration: 133.189s, episode steps: 623, steps per second:   5, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: 0.007394, mae: 0.060505, mean_q: 0.090061, mean_eps: 0.725833\n",
            " 61856/100000: episode: 91, duration: 130.133s, episode steps: 618, steps per second:   5, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.006734, mae: 0.058692, mean_q: 0.089085, mean_eps: 0.723041\n",
            " 62471/100000: episode: 92, duration: 131.425s, episode steps: 615, steps per second:   5, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.333 [0.000, 5.000],  loss: 0.006821, mae: 0.059799, mean_q: 0.090066, mean_eps: 0.720267\n",
            " 62902/100000: episode: 93, duration: 92.628s, episode steps: 431, steps per second:   5, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.007377, mae: 0.060771, mean_q: 0.093850, mean_eps: 0.717913\n",
            " 63490/100000: episode: 94, duration: 124.670s, episode steps: 588, steps per second:   5, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: 0.006858, mae: 0.059200, mean_q: 0.091841, mean_eps: 0.715620\n",
            " 64304/100000: episode: 95, duration: 171.394s, episode steps: 814, steps per second:   5, episode reward: 18.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.566 [0.000, 5.000],  loss: 0.006676, mae: 0.059360, mean_q: 0.094315, mean_eps: 0.712466\n",
            " 64712/100000: episode: 96, duration: 86.382s, episode steps: 408, steps per second:   5, episode reward:  8.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: 0.006389, mae: 0.057901, mean_q: 0.091562, mean_eps: 0.709716\n",
            " 65379/100000: episode: 97, duration: 142.730s, episode steps: 667, steps per second:   5, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: 0.006795, mae: 0.058775, mean_q: 0.093159, mean_eps: 0.707298\n",
            " 65793/100000: episode: 98, duration: 87.430s, episode steps: 414, steps per second:   5, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.114 [0.000, 5.000],  loss: 0.007031, mae: 0.059694, mean_q: 0.095246, mean_eps: 0.704865\n",
            " 66319/100000: episode: 99, duration: 111.377s, episode steps: 526, steps per second:   5, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.441 [0.000, 5.000],  loss: 0.006498, mae: 0.057485, mean_q: 0.092406, mean_eps: 0.702750\n",
            " 66734/100000: episode: 100, duration: 88.598s, episode steps: 415, steps per second:   5, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.581 [0.000, 5.000],  loss: 0.006364, mae: 0.057818, mean_q: 0.094484, mean_eps: 0.700633\n",
            " 67268/100000: episode: 101, duration: 112.798s, episode steps: 534, steps per second:   5, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.427 [0.000, 5.000],  loss: 0.005694, mae: 0.056102, mean_q: 0.090959, mean_eps: 0.698498\n",
            " 68435/100000: episode: 102, duration: 246.923s, episode steps: 1167, steps per second:   5, episode reward: 12.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.005792, mae: 0.056295, mean_q: 0.092429, mean_eps: 0.694671\n",
            " 69022/100000: episode: 103, duration: 123.709s, episode steps: 587, steps per second:   5, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: 0.006037, mae: 0.056751, mean_q: 0.095542, mean_eps: 0.690724\n",
            " 69755/100000: episode: 104, duration: 155.180s, episode steps: 733, steps per second:   5, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: 0.005823, mae: 0.056537, mean_q: 0.095478, mean_eps: 0.687754\n",
            " 70377/100000: episode: 105, duration: 133.923s, episode steps: 622, steps per second:   5, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: 0.006798, mae: 0.069310, mean_q: 0.115537, mean_eps: 0.684705\n",
            " 71523/100000: episode: 106, duration: 243.235s, episode steps: 1146, steps per second:   5, episode reward: 16.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.006906, mae: 0.076370, mean_q: 0.122650, mean_eps: 0.680727\n",
            " 72141/100000: episode: 107, duration: 131.555s, episode steps: 618, steps per second:   5, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: 0.006473, mae: 0.074461, mean_q: 0.116947, mean_eps: 0.676758\n",
            " 72822/100000: episode: 108, duration: 143.392s, episode steps: 681, steps per second:   5, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.678 [0.000, 5.000],  loss: 0.005980, mae: 0.072442, mean_q: 0.115583, mean_eps: 0.673835\n",
            " 73979/100000: episode: 109, duration: 244.630s, episode steps: 1157, steps per second:   5, episode reward: 16.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.576 [0.000, 5.000],  loss: 0.006004, mae: 0.073967, mean_q: 0.117022, mean_eps: 0.669700\n",
            " 74684/100000: episode: 110, duration: 148.941s, episode steps: 705, steps per second:   5, episode reward: 18.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.549 [0.000, 5.000],  loss: 0.005645, mae: 0.071746, mean_q: 0.116521, mean_eps: 0.665510\n",
            " 75239/100000: episode: 111, duration: 117.972s, episode steps: 555, steps per second:   5, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.328 [0.000, 5.000],  loss: 0.005820, mae: 0.073286, mean_q: 0.119067, mean_eps: 0.662675\n",
            " 75791/100000: episode: 112, duration: 116.821s, episode steps: 552, steps per second:   5, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: 0.005405, mae: 0.071656, mean_q: 0.115722, mean_eps: 0.660185\n",
            " 76611/100000: episode: 113, duration: 174.936s, episode steps: 820, steps per second:   5, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.005341, mae: 0.071126, mean_q: 0.116503, mean_eps: 0.657098\n",
            " 77268/100000: episode: 114, duration: 139.254s, episode steps: 657, steps per second:   5, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.801 [0.000, 5.000],  loss: 0.005077, mae: 0.069755, mean_q: 0.113111, mean_eps: 0.653774\n",
            " 77967/100000: episode: 115, duration: 149.090s, episode steps: 699, steps per second:   5, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: 0.005202, mae: 0.069464, mean_q: 0.113048, mean_eps: 0.650724\n",
            " 78617/100000: episode: 116, duration: 138.911s, episode steps: 650, steps per second:   5, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: 0.005709, mae: 0.070880, mean_q: 0.117170, mean_eps: 0.647688\n",
            " 79272/100000: episode: 117, duration: 139.030s, episode steps: 655, steps per second:   5, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: 0.004840, mae: 0.069152, mean_q: 0.114125, mean_eps: 0.644752\n",
            " 79643/100000: episode: 118, duration: 80.367s, episode steps: 371, steps per second:   5, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: 0.005064, mae: 0.068821, mean_q: 0.114009, mean_eps: 0.642444\n",
            " 80024/100000: episode: 119, duration: 81.037s, episode steps: 381, steps per second:   5, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.682 [0.000, 5.000],  loss: 0.005746, mae: 0.070843, mean_q: 0.117790, mean_eps: 0.640752\n",
            " 80685/100000: episode: 120, duration: 140.765s, episode steps: 661, steps per second:   5, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.505 [0.000, 5.000],  loss: 0.007657, mae: 0.112152, mean_q: 0.173189, mean_eps: 0.638407\n",
            " 81339/100000: episode: 121, duration: 138.678s, episode steps: 654, steps per second:   5, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.609 [0.000, 5.000],  loss: 0.006843, mae: 0.108298, mean_q: 0.163918, mean_eps: 0.635448\n",
            " 82473/100000: episode: 122, duration: 240.510s, episode steps: 1134, steps per second:   5, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: 0.006362, mae: 0.106865, mean_q: 0.160843, mean_eps: 0.631425\n",
            " 83280/100000: episode: 123, duration: 172.587s, episode steps: 807, steps per second:   5, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.005964, mae: 0.107144, mean_q: 0.161302, mean_eps: 0.627058\n",
            " 83918/100000: episode: 124, duration: 136.750s, episode steps: 638, steps per second:   5, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.310 [0.000, 5.000],  loss: 0.005579, mae: 0.103890, mean_q: 0.155684, mean_eps: 0.623807\n",
            " 84540/100000: episode: 125, duration: 131.485s, episode steps: 622, steps per second:   5, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: 0.005516, mae: 0.105548, mean_q: 0.158385, mean_eps: 0.620972\n",
            " 84938/100000: episode: 126, duration: 86.709s, episode steps: 398, steps per second:   5, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.613 [0.000, 5.000],  loss: 0.005476, mae: 0.104155, mean_q: 0.157566, mean_eps: 0.618677\n",
            " 85613/100000: episode: 127, duration: 144.368s, episode steps: 675, steps per second:   5, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: 0.005659, mae: 0.104365, mean_q: 0.157253, mean_eps: 0.616263\n",
            " 86120/100000: episode: 128, duration: 108.040s, episode steps: 507, steps per second:   5, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.369 [0.000, 5.000],  loss: 0.005308, mae: 0.104297, mean_q: 0.158365, mean_eps: 0.613603\n",
            " 87051/100000: episode: 129, duration: 196.729s, episode steps: 931, steps per second:   5, episode reward: 17.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.005092, mae: 0.102914, mean_q: 0.155827, mean_eps: 0.610367\n",
            " 87807/100000: episode: 130, duration: 160.863s, episode steps: 756, steps per second:   5, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.004875, mae: 0.100295, mean_q: 0.151943, mean_eps: 0.606572\n",
            " 88631/100000: episode: 131, duration: 175.579s, episode steps: 824, steps per second:   5, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.607 [0.000, 5.000],  loss: 0.004893, mae: 0.103069, mean_q: 0.158380, mean_eps: 0.603017\n",
            " 89212/100000: episode: 132, duration: 124.419s, episode steps: 581, steps per second:   5, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.458 [0.000, 5.000],  loss: 0.004483, mae: 0.101086, mean_q: 0.154980, mean_eps: 0.599855\n",
            " 89727/100000: episode: 133, duration: 109.754s, episode steps: 515, steps per second:   5, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.005505, mae: 0.103727, mean_q: 0.159652, mean_eps: 0.597389\n",
            " 90747/100000: episode: 134, duration: 218.440s, episode steps: 1020, steps per second:   5, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.007120, mae: 0.127459, mean_q: 0.190019, mean_eps: 0.593936\n",
            " 91376/100000: episode: 135, duration: 132.724s, episode steps: 629, steps per second:   5, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.459 [0.000, 5.000],  loss: 0.007242, mae: 0.135529, mean_q: 0.197823, mean_eps: 0.590225\n",
            " 92241/100000: episode: 136, duration: 186.864s, episode steps: 865, steps per second:   5, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.546 [0.000, 5.000],  loss: 0.006326, mae: 0.135754, mean_q: 0.200029, mean_eps: 0.586864\n",
            " 93040/100000: episode: 137, duration: 170.195s, episode steps: 799, steps per second:   5, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: 0.006043, mae: 0.133749, mean_q: 0.196095, mean_eps: 0.583120\n",
            " 93679/100000: episode: 138, duration: 136.119s, episode steps: 639, steps per second:   5, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.659 [0.000, 5.000],  loss: 0.006244, mae: 0.136710, mean_q: 0.201587, mean_eps: 0.579885\n",
            " 94429/100000: episode: 139, duration: 161.209s, episode steps: 750, steps per second:   5, episode reward: 16.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.783 [0.000, 5.000],  loss: 0.006218, mae: 0.132253, mean_q: 0.194958, mean_eps: 0.576759\n",
            " 95054/100000: episode: 140, duration: 133.776s, episode steps: 625, steps per second:   5, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.670 [0.000, 5.000],  loss: 0.005758, mae: 0.132040, mean_q: 0.195056, mean_eps: 0.573665\n",
            " 96229/100000: episode: 141, duration: 251.083s, episode steps: 1175, steps per second:   5, episode reward: 15.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.005369, mae: 0.130214, mean_q: 0.193011, mean_eps: 0.569616\n",
            " 96978/100000: episode: 142, duration: 160.727s, episode steps: 749, steps per second:   5, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.570 [0.000, 5.000],  loss: 0.005578, mae: 0.129142, mean_q: 0.191024, mean_eps: 0.565287\n",
            " 97380/100000: episode: 143, duration: 85.925s, episode steps: 402, steps per second:   5, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.296 [0.000, 5.000],  loss: 0.005212, mae: 0.125426, mean_q: 0.186017, mean_eps: 0.562697\n",
            " 98038/100000: episode: 144, duration: 140.441s, episode steps: 658, steps per second:   5, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.005570, mae: 0.129543, mean_q: 0.191975, mean_eps: 0.560312\n",
            " 98697/100000: episode: 145, duration: 141.185s, episode steps: 659, steps per second:   5, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: 0.005437, mae: 0.128887, mean_q: 0.190554, mean_eps: 0.557348\n",
            " 99030/100000: episode: 146, duration: 72.470s, episode steps: 333, steps per second:   5, episode reward:  5.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.348 [0.000, 5.000],  loss: 0.004832, mae: 0.126607, mean_q: 0.189476, mean_eps: 0.555117\n",
            " 99616/100000: episode: 147, duration: 126.612s, episode steps: 586, steps per second:   5, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.275 [0.000, 5.000],  loss: 0.004754, mae: 0.125222, mean_q: 0.186114, mean_eps: 0.553049\n",
            "done, took 10895.285 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x781e784d5490>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dqn.load_weights(\"dqn_weights_100000.h5f\")\n",
        "\n",
        "# Test sin visualizar\n",
        "test_episodes = 10\n",
        "results = dqn.test(env, nb_episodes=test_episodes, visualize=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1oxC2S-w6Ws",
        "outputId": "972cc29a-f76f-4a49-e068-5ec87f0fabb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 10 episodes ...\n",
            "Episode 1: reward: 8.000, steps: 575\n",
            "Episode 2: reward: 11.000, steps: 775\n",
            "Episode 3: reward: 9.000, steps: 821\n",
            "Episode 4: reward: 7.000, steps: 662\n",
            "Episode 5: reward: 17.000, steps: 1113\n",
            "Episode 6: reward: 7.000, steps: 749\n",
            "Episode 7: reward: 6.000, steps: 593\n",
            "Episode 8: reward: 10.000, steps: 697\n",
            "Episode 9: reward: 13.000, steps: 842\n",
            "Episode 10: reward: 6.000, steps: 537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dqn_weights_100000.h5f\n",
        "#Continuación al 325000 + 100000 + 100000 = 525000\n",
        "\n",
        "# Paso de partida 3\n",
        "starting_step = 100000 #ultimo weight actualizado\n",
        "remaining_steps = 200000 - starting_step\n",
        "\n",
        "\n",
        "# Callback personalizado para continuar numeración de checkpoints\n",
        "class OffsetModelCheckpoint(ModelIntervalCheckpoint):\n",
        "    def __init__(self, filepath, interval, offset):\n",
        "        super().__init__(filepath, interval)\n",
        "        self.offset = offset\n",
        "\n",
        "    def on_step_end(self, step, logs={}):\n",
        "        # Ajusta el número de paso en el nombre del archivo\n",
        "        self.step = step + self.offset\n",
        "        super().on_step_end(step, logs)\n",
        "\n",
        "# Entrenamiento con pasos continuados desde 100000\n",
        "dqn.fit(env, nb_steps=remaining_steps, visualize=False, verbose=2,\n",
        "        callbacks=[\n",
        "            FileLogger(\"dqn_log_continuacion.json\", interval=10000),\n",
        "            OffsetModelCheckpoint(\"dqn_weights_{step}.h5f\", interval=25000, offset=starting_step)\n",
        "        ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaqcU9Ulx8-D",
        "outputId": "22e982b4-7c7f-4c6b-ced3-c8aeb4c8b7e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 100000 steps ...\n",
            "  1151/100000: episode: 1, duration: 6.220s, episode steps: 1151, steps per second: 185, episode reward: 10.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  1817/100000: episode: 2, duration: 2.648s, episode steps: 666, steps per second: 252, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  2485/100000: episode: 3, duration: 2.714s, episode steps: 668, steps per second: 246, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.528 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  3296/100000: episode: 4, duration: 3.234s, episode steps: 811, steps per second: 251, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  4126/100000: episode: 5, duration: 4.890s, episode steps: 830, steps per second: 170, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  5026/100000: episode: 6, duration: 3.613s, episode steps: 900, steps per second: 249, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.419 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  5943/100000: episode: 7, duration: 3.711s, episode steps: 917, steps per second: 247, episode reward: 10.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  6470/100000: episode: 8, duration: 2.427s, episode steps: 527, steps per second: 217, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  7184/100000: episode: 9, duration: 4.009s, episode steps: 714, steps per second: 178, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  7823/100000: episode: 10, duration: 2.622s, episode steps: 639, steps per second: 244, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.579 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  8670/100000: episode: 11, duration: 3.466s, episode steps: 847, steps per second: 244, episode reward: 11.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  9191/100000: episode: 12, duration: 2.094s, episode steps: 521, steps per second: 249, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  9780/100000: episode: 13, duration: 3.415s, episode steps: 589, steps per second: 172, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 10295/100000: episode: 14, duration: 2.532s, episode steps: 515, steps per second: 203, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 11073/100000: episode: 15, duration: 3.112s, episode steps: 778, steps per second: 250, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 11586/100000: episode: 16, duration: 2.075s, episode steps: 513, steps per second: 247, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 12279/100000: episode: 17, duration: 2.768s, episode steps: 693, steps per second: 250, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.532 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 12853/100000: episode: 18, duration: 3.431s, episode steps: 574, steps per second: 167, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.497 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 13641/100000: episode: 19, duration: 3.543s, episode steps: 788, steps per second: 222, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.409 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 14343/100000: episode: 20, duration: 2.873s, episode steps: 702, steps per second: 244, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 15226/100000: episode: 21, duration: 3.559s, episode steps: 883, steps per second: 248, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 15890/100000: episode: 22, duration: 3.689s, episode steps: 664, steps per second: 180, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 16471/100000: episode: 23, duration: 2.805s, episode steps: 581, steps per second: 207, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 16969/100000: episode: 24, duration: 1.983s, episode steps: 498, steps per second: 251, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.598 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 17817/100000: episode: 25, duration: 3.388s, episode steps: 848, steps per second: 250, episode reward: 10.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 18666/100000: episode: 26, duration: 3.647s, episode steps: 849, steps per second: 233, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 19398/100000: episode: 27, duration: 4.152s, episode steps: 732, steps per second: 176, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 20181/100000: episode: 28, duration: 3.102s, episode steps: 783, steps per second: 252, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 20907/100000: episode: 29, duration: 2.899s, episode steps: 726, steps per second: 250, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.421 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 21562/100000: episode: 30, duration: 2.669s, episode steps: 655, steps per second: 245, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 22595/100000: episode: 31, duration: 5.683s, episode steps: 1033, steps per second: 182, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.666 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 23271/100000: episode: 32, duration: 2.791s, episode steps: 676, steps per second: 242, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 24329/100000: episode: 33, duration: 4.315s, episode steps: 1058, steps per second: 245, episode reward: 20.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 24982/100000: episode: 34, duration: 3.675s, episode steps: 653, steps per second: 178, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.614 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 25512/100000: episode: 35, duration: 2.664s, episode steps: 530, steps per second: 199, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 26148/100000: episode: 36, duration: 2.540s, episode steps: 636, steps per second: 250, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 26633/100000: episode: 37, duration: 1.959s, episode steps: 485, steps per second: 248, episode reward: 11.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 27529/100000: episode: 38, duration: 3.635s, episode steps: 896, steps per second: 246, episode reward: 11.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 28210/100000: episode: 39, duration: 4.280s, episode steps: 681, steps per second: 159, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 28829/100000: episode: 40, duration: 2.513s, episode steps: 619, steps per second: 246, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.439 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 29383/100000: episode: 41, duration: 2.251s, episode steps: 554, steps per second: 246, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.448 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 29768/100000: episode: 42, duration: 1.558s, episode steps: 385, steps per second: 247, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.558 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 30434/100000: episode: 43, duration: 2.708s, episode steps: 666, steps per second: 246, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 31236/100000: episode: 44, duration: 4.739s, episode steps: 802, steps per second: 169, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 31867/100000: episode: 45, duration: 2.505s, episode steps: 631, steps per second: 252, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 32599/100000: episode: 46, duration: 2.924s, episode steps: 732, steps per second: 250, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 33096/100000: episode: 47, duration: 1.982s, episode steps: 497, steps per second: 251, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 33724/100000: episode: 48, duration: 2.471s, episode steps: 628, steps per second: 254, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 34455/100000: episode: 49, duration: 4.973s, episode steps: 731, steps per second: 147, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 34803/100000: episode: 50, duration: 1.385s, episode steps: 348, steps per second: 251, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.457 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 35481/100000: episode: 51, duration: 2.726s, episode steps: 678, steps per second: 249, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 35979/100000: episode: 52, duration: 1.992s, episode steps: 498, steps per second: 250, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.329 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 36684/100000: episode: 53, duration: 2.850s, episode steps: 705, steps per second: 247, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.530 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 37444/100000: episode: 54, duration: 4.543s, episode steps: 760, steps per second: 167, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.429 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 38229/100000: episode: 55, duration: 3.209s, episode steps: 785, steps per second: 245, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 39121/100000: episode: 56, duration: 3.548s, episode steps: 892, steps per second: 251, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.537 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 39843/100000: episode: 57, duration: 3.223s, episode steps: 722, steps per second: 224, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 40484/100000: episode: 58, duration: 3.763s, episode steps: 641, steps per second: 170, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 41171/100000: episode: 59, duration: 2.800s, episode steps: 687, steps per second: 245, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.550 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 41619/100000: episode: 60, duration: 1.774s, episode steps: 448, steps per second: 253, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.404 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 42285/100000: episode: 61, duration: 2.672s, episode steps: 666, steps per second: 249, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.638 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 42864/100000: episode: 62, duration: 2.595s, episode steps: 579, steps per second: 223, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.392 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 43782/100000: episode: 63, duration: 4.888s, episode steps: 918, steps per second: 188, episode reward:  9.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 44460/100000: episode: 64, duration: 2.720s, episode steps: 678, steps per second: 249, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 44857/100000: episode: 65, duration: 1.617s, episode steps: 397, steps per second: 245, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 45249/100000: episode: 66, duration: 1.583s, episode steps: 392, steps per second: 248, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.413 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 46668/100000: episode: 67, duration: 7.294s, episode steps: 1419, steps per second: 195, episode reward: 15.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 47674/100000: episode: 68, duration: 4.213s, episode steps: 1006, steps per second: 239, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 48778/100000: episode: 69, duration: 4.564s, episode steps: 1104, steps per second: 242, episode reward: 19.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 49202/100000: episode: 70, duration: 2.888s, episode steps: 424, steps per second: 147, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.632 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 49806/100000: episode: 71, duration: 2.740s, episode steps: 604, steps per second: 220, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 50961/100000: episode: 72, duration: 206.040s, episode steps: 1155, steps per second:   6, episode reward: 14.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.009507, mae: 0.142794, mean_q: 0.191693, mean_eps: 0.772838\n",
            " 51394/100000: episode: 73, duration: 91.128s, episode steps: 433, steps per second:   5, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.522 [0.000, 5.000],  loss: 0.009900, mae: 0.142716, mean_q: 0.187388, mean_eps: 0.769703\n",
            " 52317/100000: episode: 74, duration: 197.634s, episode steps: 923, steps per second:   5, episode reward: 24.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: 0.008665, mae: 0.138493, mean_q: 0.182857, mean_eps: 0.766652\n",
            " 52924/100000: episode: 75, duration: 128.235s, episode steps: 607, steps per second:   5, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: 0.007913, mae: 0.136531, mean_q: 0.179270, mean_eps: 0.763210\n",
            " 53443/100000: episode: 76, duration: 110.271s, episode steps: 519, steps per second:   5, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.008348, mae: 0.136205, mean_q: 0.179042, mean_eps: 0.760676\n",
            " 54359/100000: episode: 77, duration: 196.538s, episode steps: 916, steps per second:   5, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.007539, mae: 0.133881, mean_q: 0.175251, mean_eps: 0.757448\n",
            " 55112/100000: episode: 78, duration: 160.836s, episode steps: 753, steps per second:   5, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.316 [0.000, 5.000],  loss: 0.007690, mae: 0.134746, mean_q: 0.177379, mean_eps: 0.753692\n",
            " 55922/100000: episode: 79, duration: 172.342s, episode steps: 810, steps per second:   5, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.590 [0.000, 5.000],  loss: 0.008267, mae: 0.136366, mean_q: 0.179187, mean_eps: 0.750176\n",
            " 56489/100000: episode: 80, duration: 120.743s, episode steps: 567, steps per second:   5, episode reward: 10.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.362 [0.000, 5.000],  loss: 0.007204, mae: 0.133424, mean_q: 0.175598, mean_eps: 0.747078\n",
            " 57147/100000: episode: 81, duration: 141.645s, episode steps: 658, steps per second:   5, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: 0.007730, mae: 0.133086, mean_q: 0.176268, mean_eps: 0.744321\n",
            " 57505/100000: episode: 82, duration: 76.384s, episode steps: 358, steps per second:   5, episode reward:  5.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.007002, mae: 0.131415, mean_q: 0.174969, mean_eps: 0.742035\n",
            " 58299/100000: episode: 83, duration: 170.337s, episode steps: 794, steps per second:   5, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.587 [0.000, 5.000],  loss: 0.007051, mae: 0.133393, mean_q: 0.178411, mean_eps: 0.739443\n",
            " 59001/100000: episode: 84, duration: 150.197s, episode steps: 702, steps per second:   5, episode reward: 18.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.006626, mae: 0.129014, mean_q: 0.172761, mean_eps: 0.736077\n",
            " 59537/100000: episode: 85, duration: 116.211s, episode steps: 536, steps per second:   5, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: 0.006974, mae: 0.131129, mean_q: 0.176448, mean_eps: 0.733292\n",
            " 60330/100000: episode: 86, duration: 169.009s, episode steps: 793, steps per second:   5, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.487 [0.000, 5.000],  loss: 0.007104, mae: 0.143868, mean_q: 0.192489, mean_eps: 0.730302\n",
            " 61288/100000: episode: 87, duration: 207.530s, episode steps: 958, steps per second:   5, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: 0.007925, mae: 0.168113, mean_q: 0.222502, mean_eps: 0.726362\n",
            " 62209/100000: episode: 88, duration: 196.762s, episode steps: 921, steps per second:   5, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.498 [0.000, 5.000],  loss: 0.007559, mae: 0.170193, mean_q: 0.226215, mean_eps: 0.722134\n",
            " 62871/100000: episode: 89, duration: 142.640s, episode steps: 662, steps per second:   5, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.449 [0.000, 5.000],  loss: 0.007120, mae: 0.165663, mean_q: 0.220371, mean_eps: 0.718572\n",
            " 63279/100000: episode: 90, duration: 86.701s, episode steps: 408, steps per second:   5, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.373 [0.000, 5.000],  loss: 0.006668, mae: 0.168749, mean_q: 0.225432, mean_eps: 0.716165\n",
            " 63974/100000: episode: 91, duration: 149.398s, episode steps: 695, steps per second:   5, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.380 [0.000, 5.000],  loss: 0.006525, mae: 0.164611, mean_q: 0.220188, mean_eps: 0.713683\n",
            " 64757/100000: episode: 92, duration: 167.225s, episode steps: 783, steps per second:   5, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.444 [0.000, 5.000],  loss: 0.006673, mae: 0.166710, mean_q: 0.223686, mean_eps: 0.710358\n",
            " 65313/100000: episode: 93, duration: 119.631s, episode steps: 556, steps per second:   5, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: 0.006996, mae: 0.167447, mean_q: 0.226110, mean_eps: 0.707345\n",
            " 65831/100000: episode: 94, duration: 110.594s, episode steps: 518, steps per second:   5, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.378 [0.000, 5.000],  loss: 0.005686, mae: 0.164366, mean_q: 0.223012, mean_eps: 0.704928\n",
            " 66237/100000: episode: 95, duration: 86.598s, episode steps: 406, steps per second:   5, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.712 [0.000, 5.000],  loss: 0.006398, mae: 0.165852, mean_q: 0.224372, mean_eps: 0.702849\n",
            " 67009/100000: episode: 96, duration: 164.764s, episode steps: 772, steps per second:   5, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.592 [0.000, 5.000],  loss: 0.006091, mae: 0.163230, mean_q: 0.220851, mean_eps: 0.700199\n",
            " 67709/100000: episode: 97, duration: 149.662s, episode steps: 700, steps per second:   5, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.005928, mae: 0.162627, mean_q: 0.220117, mean_eps: 0.696887\n",
            " 68246/100000: episode: 98, duration: 114.245s, episode steps: 537, steps per second:   5, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.518 [0.000, 5.000],  loss: 0.005837, mae: 0.164489, mean_q: 0.223385, mean_eps: 0.694103\n",
            " 69170/100000: episode: 99, duration: 198.521s, episode steps: 924, steps per second:   5, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.006107, mae: 0.166259, mean_q: 0.226316, mean_eps: 0.690816\n",
            " 70092/100000: episode: 100, duration: 196.435s, episode steps: 922, steps per second:   5, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: 0.005450, mae: 0.165156, mean_q: 0.225591, mean_eps: 0.686663\n",
            " 70634/100000: episode: 101, duration: 114.990s, episode steps: 542, steps per second:   5, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.006978, mae: 0.187698, mean_q: 0.253157, mean_eps: 0.683369\n",
            " 71011/100000: episode: 102, duration: 80.880s, episode steps: 377, steps per second:   5, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.006482, mae: 0.186147, mean_q: 0.250727, mean_eps: 0.681301\n",
            " 72200/100000: episode: 103, duration: 254.846s, episode steps: 1189, steps per second:   5, episode reward: 11.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.006597, mae: 0.188212, mean_q: 0.254413, mean_eps: 0.677778\n",
            " 72953/100000: episode: 104, duration: 160.280s, episode steps: 753, steps per second:   5, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.639 [0.000, 5.000],  loss: 0.005888, mae: 0.186177, mean_q: 0.252591, mean_eps: 0.673408\n",
            " 73588/100000: episode: 105, duration: 135.209s, episode steps: 635, steps per second:   5, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: 0.006076, mae: 0.187220, mean_q: 0.252966, mean_eps: 0.670285\n",
            " 74089/100000: episode: 106, duration: 107.722s, episode steps: 501, steps per second:   5, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.543 [0.000, 5.000],  loss: 0.005390, mae: 0.185422, mean_q: 0.250770, mean_eps: 0.667729\n",
            " 75337/100000: episode: 107, duration: 267.787s, episode steps: 1248, steps per second:   5, episode reward: 19.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: 0.005640, mae: 0.185342, mean_q: 0.251493, mean_eps: 0.663794\n",
            " 75968/100000: episode: 108, duration: 133.808s, episode steps: 631, steps per second:   5, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.539 [0.000, 5.000],  loss: 0.005525, mae: 0.184002, mean_q: 0.249863, mean_eps: 0.659566\n",
            " 76630/100000: episode: 109, duration: 142.684s, episode steps: 662, steps per second:   5, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: 0.005719, mae: 0.186104, mean_q: 0.253687, mean_eps: 0.656657\n",
            " 77049/100000: episode: 110, duration: 88.431s, episode steps: 419, steps per second:   5, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.004700, mae: 0.181404, mean_q: 0.246810, mean_eps: 0.654224\n",
            " 77439/100000: episode: 111, duration: 83.184s, episode steps: 390, steps per second:   5, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.615 [0.000, 5.000],  loss: 0.005239, mae: 0.185001, mean_q: 0.251764, mean_eps: 0.652404\n",
            " 78245/100000: episode: 112, duration: 172.267s, episode steps: 806, steps per second:   5, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.479 [0.000, 5.000],  loss: 0.004708, mae: 0.181699, mean_q: 0.248487, mean_eps: 0.649713\n",
            " 78969/100000: episode: 113, duration: 154.243s, episode steps: 724, steps per second:   5, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.345 [0.000, 5.000],  loss: 0.005120, mae: 0.181744, mean_q: 0.248657, mean_eps: 0.646271\n",
            " 79396/100000: episode: 114, duration: 92.780s, episode steps: 427, steps per second:   5, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.004959, mae: 0.182118, mean_q: 0.249774, mean_eps: 0.643681\n",
            " 80091/100000: episode: 115, duration: 147.206s, episode steps: 695, steps per second:   5, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.342 [0.000, 5.000],  loss: 0.004860, mae: 0.186235, mean_q: 0.254685, mean_eps: 0.641157\n",
            " 80591/100000: episode: 116, duration: 107.116s, episode steps: 500, steps per second:   5, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.338 [0.000, 5.000],  loss: 0.006874, mae: 0.222587, mean_q: 0.301225, mean_eps: 0.638468\n",
            " 80963/100000: episode: 117, duration: 79.699s, episode steps: 372, steps per second:   5, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.411 [0.000, 5.000],  loss: 0.006646, mae: 0.222013, mean_q: 0.300044, mean_eps: 0.636506\n",
            " 81914/100000: episode: 118, duration: 203.219s, episode steps: 951, steps per second:   5, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.401 [0.000, 5.000],  loss: 0.005730, mae: 0.216206, mean_q: 0.291231, mean_eps: 0.633529\n",
            " 82324/100000: episode: 119, duration: 88.930s, episode steps: 410, steps per second:   5, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.802 [0.000, 5.000],  loss: 0.005965, mae: 0.216691, mean_q: 0.292121, mean_eps: 0.630467\n",
            " 83397/100000: episode: 120, duration: 230.359s, episode steps: 1073, steps per second:   5, episode reward: 13.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.005801, mae: 0.217807, mean_q: 0.293692, mean_eps: 0.627130\n",
            " 84176/100000: episode: 121, duration: 165.926s, episode steps: 779, steps per second:   5, episode reward: 15.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.639 [0.000, 5.000],  loss: 0.005523, mae: 0.218104, mean_q: 0.293060, mean_eps: 0.622963\n",
            " 84819/100000: episode: 122, duration: 137.148s, episode steps: 643, steps per second:   5, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.277 [0.000, 5.000],  loss: 0.005305, mae: 0.218392, mean_q: 0.294749, mean_eps: 0.619763\n",
            " 85199/100000: episode: 123, duration: 81.179s, episode steps: 380, steps per second:   5, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.639 [0.000, 5.000],  loss: 0.005410, mae: 0.217906, mean_q: 0.293188, mean_eps: 0.617462\n",
            " 85711/100000: episode: 124, duration: 109.664s, episode steps: 512, steps per second:   5, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.005476, mae: 0.216335, mean_q: 0.291987, mean_eps: 0.615455\n",
            " 86301/100000: episode: 125, duration: 125.711s, episode steps: 590, steps per second:   5, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.656 [0.000, 5.000],  loss: 0.004979, mae: 0.216462, mean_q: 0.292042, mean_eps: 0.612975\n",
            " 87298/100000: episode: 126, duration: 214.145s, episode steps: 997, steps per second:   5, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.005264, mae: 0.216857, mean_q: 0.292906, mean_eps: 0.609405\n",
            " 88032/100000: episode: 127, duration: 156.423s, episode steps: 734, steps per second:   5, episode reward:  7.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.623 [0.000, 5.000],  loss: 0.005093, mae: 0.216660, mean_q: 0.292376, mean_eps: 0.605510\n",
            " 89130/100000: episode: 128, duration: 235.127s, episode steps: 1098, steps per second:   5, episode reward: 16.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.004779, mae: 0.216081, mean_q: 0.292436, mean_eps: 0.601388\n",
            " 89795/100000: episode: 129, duration: 141.356s, episode steps: 665, steps per second:   5, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.820 [0.000, 5.000],  loss: 0.004516, mae: 0.215396, mean_q: 0.291649, mean_eps: 0.597421\n",
            " 90465/100000: episode: 130, duration: 143.920s, episode steps: 670, steps per second:   5, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.693 [0.000, 5.000],  loss: 0.006831, mae: 0.240550, mean_q: 0.323992, mean_eps: 0.594417\n",
            " 91051/100000: episode: 131, duration: 126.623s, episode steps: 586, steps per second:   5, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.007319, mae: 0.254503, mean_q: 0.342590, mean_eps: 0.591591\n",
            " 91428/100000: episode: 132, duration: 81.095s, episode steps: 377, steps per second:   5, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.674 [0.000, 5.000],  loss: 0.006948, mae: 0.253420, mean_q: 0.340698, mean_eps: 0.589425\n",
            " 92075/100000: episode: 133, duration: 137.926s, episode steps: 647, steps per second:   5, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.389 [0.000, 5.000],  loss: 0.006482, mae: 0.251277, mean_q: 0.336819, mean_eps: 0.587121\n",
            " 92518/100000: episode: 134, duration: 94.799s, episode steps: 443, steps per second:   5, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: 0.006137, mae: 0.253020, mean_q: 0.338832, mean_eps: 0.584668\n",
            " 92944/100000: episode: 135, duration: 90.087s, episode steps: 426, steps per second:   5, episode reward:  4.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.275 [0.000, 5.000],  loss: 0.006179, mae: 0.252472, mean_q: 0.338482, mean_eps: 0.582713\n",
            " 93907/100000: episode: 136, duration: 205.181s, episode steps: 963, steps per second:   5, episode reward: 11.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.005704, mae: 0.249807, mean_q: 0.334407, mean_eps: 0.579588\n",
            " 94434/100000: episode: 137, duration: 113.199s, episode steps: 527, steps per second:   5, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.556 [0.000, 5.000],  loss: 0.005417, mae: 0.251953, mean_q: 0.336536, mean_eps: 0.576235\n",
            " 94971/100000: episode: 138, duration: 114.407s, episode steps: 537, steps per second:   5, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.005380, mae: 0.251983, mean_q: 0.336005, mean_eps: 0.573841\n",
            " 95463/100000: episode: 139, duration: 104.213s, episode steps: 492, steps per second:   5, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.254 [0.000, 5.000],  loss: 0.005761, mae: 0.249546, mean_q: 0.333096, mean_eps: 0.571526\n",
            " 96595/100000: episode: 140, duration: 240.883s, episode steps: 1132, steps per second:   5, episode reward: 25.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.361 [0.000, 5.000],  loss: 0.005120, mae: 0.248824, mean_q: 0.332357, mean_eps: 0.567872\n",
            " 97302/100000: episode: 141, duration: 150.626s, episode steps: 707, steps per second:   5, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.005777, mae: 0.247014, mean_q: 0.329896, mean_eps: 0.563734\n",
            " 97842/100000: episode: 142, duration: 114.355s, episode steps: 540, steps per second:   5, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.005362, mae: 0.248260, mean_q: 0.332156, mean_eps: 0.560928\n",
            " 98781/100000: episode: 143, duration: 200.539s, episode steps: 939, steps per second:   5, episode reward: 14.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.005268, mae: 0.250764, mean_q: 0.335627, mean_eps: 0.557601\n",
            " 99443/100000: episode: 144, duration: 140.451s, episode steps: 662, steps per second:   5, episode reward: 13.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.290 [0.000, 5.000],  loss: 0.004866, mae: 0.248900, mean_q: 0.332480, mean_eps: 0.553998\n",
            "done, took 10915.394 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x781e72853d50>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dqn.load_weights(\"dqn_weights_100000.h5f\")\n",
        "test_episodes = 10\n",
        "results = dqn.test(env, nb_episodes=test_episodes, visualize=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ng-v5wQnkec0",
        "outputId": "c2db62d9-fe02-4e03-ad40-36e141f51519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 10 episodes ...\n",
            "Episode 1: reward: 4.000, steps: 396\n",
            "Episode 2: reward: 4.000, steps: 411\n",
            "Episode 3: reward: 14.000, steps: 903\n",
            "Episode 4: reward: 23.000, steps: 1126\n",
            "Episode 5: reward: 10.000, steps: 697\n",
            "Episode 6: reward: 10.000, steps: 618\n",
            "Episode 7: reward: 12.000, steps: 682\n",
            "Episode 8: reward: 6.000, steps: 404\n",
            "Episode 9: reward: 6.000, steps: 570\n",
            "Episode 10: reward: 9.000, steps: 484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dqn_weights_100000.h5f\n",
        "#Continuación al 325000 + 100000 + 100000+100000 = 625000\n",
        "\n",
        "dqn.load_weights(\"dqn_weights_100000.h5f\")\n",
        "# Paso de partida 3\n",
        "starting_step = 100000 #ultimo weight actualizado\n",
        "remaining_steps = 200000 - starting_step\n",
        "\n",
        "\n",
        "# Callback personalizado para continuar numeración de checkpoints\n",
        "class OffsetModelCheckpoint(ModelIntervalCheckpoint):\n",
        "    def __init__(self, filepath, interval, offset):\n",
        "        super().__init__(filepath, interval)\n",
        "        self.offset = offset\n",
        "\n",
        "    def on_step_end(self, step, logs={}):\n",
        "        # Ajusta el número de paso en el nombre del archivo\n",
        "        self.step = step + self.offset\n",
        "        super().on_step_end(step, logs)\n",
        "\n",
        "# Entrenamiento con pasos continuados desde 100000\n",
        "dqn.fit(env, nb_steps=remaining_steps, visualize=False, verbose=2,\n",
        "        callbacks=[\n",
        "            FileLogger(\"dqn_log_continuacion.json\", interval=10000),\n",
        "            OffsetModelCheckpoint(\"dqn_weights_{step}.h5f\", interval=25000, offset=starting_step)\n",
        "        ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irGA8TqOlD3z",
        "outputId": "cd396f12-13f5-4772-a488-62cec68ac1c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 100000 steps ...\n",
            "   610/100000: episode: 1, duration: 2.797s, episode steps: 610, steps per second: 218, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   997/100000: episode: 2, duration: 2.538s, episode steps: 387, steps per second: 152, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.437 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  1729/100000: episode: 3, duration: 2.987s, episode steps: 732, steps per second: 245, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.430 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  2272/100000: episode: 4, duration: 2.140s, episode steps: 543, steps per second: 254, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.632 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  3108/100000: episode: 5, duration: 3.250s, episode steps: 836, steps per second: 257, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  3942/100000: episode: 6, duration: 4.200s, episode steps: 834, steps per second: 199, episode reward: 14.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.483 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  4665/100000: episode: 7, duration: 3.401s, episode steps: 723, steps per second: 213, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  5498/100000: episode: 8, duration: 3.296s, episode steps: 833, steps per second: 253, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  5906/100000: episode: 9, duration: 1.645s, episode steps: 408, steps per second: 248, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.610 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  6384/100000: episode: 10, duration: 1.925s, episode steps: 478, steps per second: 248, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  7349/100000: episode: 11, duration: 5.212s, episode steps: 965, steps per second: 185, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  8149/100000: episode: 12, duration: 3.129s, episode steps: 800, steps per second: 256, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  8956/100000: episode: 13, duration: 3.189s, episode steps: 807, steps per second: 253, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.569 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  9368/100000: episode: 14, duration: 1.645s, episode steps: 412, steps per second: 251, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.454 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  9908/100000: episode: 15, duration: 2.451s, episode steps: 540, steps per second: 220, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 10465/100000: episode: 16, duration: 3.302s, episode steps: 557, steps per second: 169, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 11014/100000: episode: 17, duration: 2.154s, episode steps: 549, steps per second: 255, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.417 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 12016/100000: episode: 18, duration: 3.944s, episode steps: 1002, steps per second: 254, episode reward: 10.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.385 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 12546/100000: episode: 19, duration: 2.076s, episode steps: 530, steps per second: 255, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 13305/100000: episode: 20, duration: 3.967s, episode steps: 759, steps per second: 191, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 13988/100000: episode: 21, duration: 3.171s, episode steps: 683, steps per second: 215, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 14532/100000: episode: 22, duration: 2.135s, episode steps: 544, steps per second: 255, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 15313/100000: episode: 23, duration: 3.054s, episode steps: 781, steps per second: 256, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 16405/100000: episode: 24, duration: 5.146s, episode steps: 1092, steps per second: 212, episode reward: 11.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 17189/100000: episode: 25, duration: 3.653s, episode steps: 784, steps per second: 215, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 18234/100000: episode: 26, duration: 4.098s, episode steps: 1045, steps per second: 255, episode reward: 22.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 18980/100000: episode: 27, duration: 2.966s, episode steps: 746, steps per second: 251, episode reward:  6.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 19463/100000: episode: 28, duration: 2.674s, episode steps: 483, steps per second: 181, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.472 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 20113/100000: episode: 29, duration: 3.311s, episode steps: 650, steps per second: 196, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 20628/100000: episode: 30, duration: 2.044s, episode steps: 515, steps per second: 252, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.402 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 21944/100000: episode: 31, duration: 5.133s, episode steps: 1316, steps per second: 256, episode reward: 16.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 22336/100000: episode: 32, duration: 1.696s, episode steps: 392, steps per second: 231, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.622 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 22747/100000: episode: 33, duration: 2.636s, episode steps: 411, steps per second: 156, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.482 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 23259/100000: episode: 34, duration: 2.319s, episode steps: 512, steps per second: 221, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 23810/100000: episode: 35, duration: 2.195s, episode steps: 551, steps per second: 251, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 24338/100000: episode: 36, duration: 2.128s, episode steps: 528, steps per second: 248, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 24983/100000: episode: 37, duration: 2.578s, episode steps: 645, steps per second: 250, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.431 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 25680/100000: episode: 38, duration: 3.780s, episode steps: 697, steps per second: 184, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 26354/100000: episode: 39, duration: 3.297s, episode steps: 674, steps per second: 204, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.604 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 27398/100000: episode: 40, duration: 4.260s, episode steps: 1044, steps per second: 245, episode reward: 17.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.608 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 28565/100000: episode: 41, duration: 5.218s, episode steps: 1167, steps per second: 224, episode reward: 19.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.548 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 29221/100000: episode: 42, duration: 3.522s, episode steps: 656, steps per second: 186, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 30542/100000: episode: 43, duration: 5.263s, episode steps: 1321, steps per second: 251, episode reward: 27.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 30957/100000: episode: 44, duration: 1.663s, episode steps: 415, steps per second: 249, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 31492/100000: episode: 45, duration: 2.281s, episode steps: 535, steps per second: 234, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 32040/100000: episode: 46, duration: 3.506s, episode steps: 548, steps per second: 156, episode reward: 12.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 32441/100000: episode: 47, duration: 1.586s, episode steps: 401, steps per second: 253, episode reward:  3.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.673 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 33218/100000: episode: 48, duration: 3.084s, episode steps: 777, steps per second: 252, episode reward:  8.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.484 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 33905/100000: episode: 49, duration: 2.755s, episode steps: 687, steps per second: 249, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.531 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 34676/100000: episode: 50, duration: 3.475s, episode steps: 771, steps per second: 222, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.447 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 35088/100000: episode: 51, duration: 2.686s, episode steps: 412, steps per second: 153, episode reward:  5.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.624 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 35714/100000: episode: 52, duration: 2.509s, episode steps: 626, steps per second: 249, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.366 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 36376/100000: episode: 53, duration: 2.622s, episode steps: 662, steps per second: 252, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.508 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 36996/100000: episode: 54, duration: 2.466s, episode steps: 620, steps per second: 251, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.595 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 37539/100000: episode: 55, duration: 2.206s, episode steps: 543, steps per second: 246, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.341 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 38068/100000: episode: 56, duration: 3.304s, episode steps: 529, steps per second: 160, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.605 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 38600/100000: episode: 57, duration: 2.354s, episode steps: 532, steps per second: 226, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.442 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 39248/100000: episode: 58, duration: 2.573s, episode steps: 648, steps per second: 252, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 39853/100000: episode: 59, duration: 2.394s, episode steps: 605, steps per second: 253, episode reward:  7.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.418 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 41035/100000: episode: 60, duration: 5.578s, episode steps: 1182, steps per second: 212, episode reward: 13.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 41545/100000: episode: 61, duration: 2.610s, episode steps: 510, steps per second: 195, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.525 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 42235/100000: episode: 62, duration: 2.786s, episode steps: 690, steps per second: 248, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.471 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 42748/100000: episode: 63, duration: 2.011s, episode steps: 513, steps per second: 255, episode reward:  5.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.390 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 43824/100000: episode: 64, duration: 4.302s, episode steps: 1076, steps per second: 250, episode reward: 22.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.585 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 44624/100000: episode: 65, duration: 4.501s, episode steps: 800, steps per second: 178, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 45138/100000: episode: 66, duration: 2.044s, episode steps: 514, steps per second: 251, episode reward:  9.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.488 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 45728/100000: episode: 67, duration: 2.342s, episode steps: 590, steps per second: 252, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 46507/100000: episode: 68, duration: 3.047s, episode steps: 779, steps per second: 256, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.594 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 47337/100000: episode: 69, duration: 4.383s, episode steps: 830, steps per second: 189, episode reward: 12.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 47999/100000: episode: 70, duration: 3.000s, episode steps: 662, steps per second: 221, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.415 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 48531/100000: episode: 71, duration: 2.121s, episode steps: 532, steps per second: 251, episode reward: 14.000, mean reward:  0.026 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 49128/100000: episode: 72, duration: 2.385s, episode steps: 597, steps per second: 250, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.461 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 50299/100000: episode: 73, duration: 68.856s, episode steps: 1171, steps per second:  17, episode reward: 18.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.369 [0.000, 5.000],  loss: 0.009908, mae: 0.275922, mean_q: 0.359381, mean_eps: 0.774327\n",
            " 51166/100000: episode: 74, duration: 187.965s, episode steps: 867, steps per second:   5, episode reward: 16.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.540 [0.000, 5.000],  loss: 0.009945, mae: 0.277955, mean_q: 0.357212, mean_eps: 0.771706\n",
            " 51880/100000: episode: 75, duration: 156.512s, episode steps: 714, steps per second:   5, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.574 [0.000, 5.000],  loss: 0.008318, mae: 0.271962, mean_q: 0.349091, mean_eps: 0.768149\n",
            " 52778/100000: episode: 76, duration: 193.088s, episode steps: 898, steps per second:   5, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.552 [0.000, 5.000],  loss: 0.008567, mae: 0.271810, mean_q: 0.347971, mean_eps: 0.764522\n",
            " 53438/100000: episode: 77, duration: 141.629s, episode steps: 660, steps per second:   5, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.503 [0.000, 5.000],  loss: 0.008339, mae: 0.269046, mean_q: 0.344864, mean_eps: 0.761016\n",
            " 53967/100000: episode: 78, duration: 114.901s, episode steps: 529, steps per second:   5, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.007420, mae: 0.267733, mean_q: 0.341773, mean_eps: 0.758341\n",
            " 54572/100000: episode: 79, duration: 129.313s, episode steps: 605, steps per second:   5, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.007177, mae: 0.268518, mean_q: 0.343593, mean_eps: 0.755790\n",
            " 55703/100000: episode: 80, duration: 243.029s, episode steps: 1131, steps per second:   5, episode reward: 16.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.523 [0.000, 5.000],  loss: 0.007450, mae: 0.267326, mean_q: 0.342150, mean_eps: 0.751884\n",
            " 57198/100000: episode: 81, duration: 320.036s, episode steps: 1495, steps per second:   5, episode reward: 14.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.007327, mae: 0.266661, mean_q: 0.341653, mean_eps: 0.745975\n",
            " 57689/100000: episode: 82, duration: 105.760s, episode steps: 491, steps per second:   5, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.006519, mae: 0.271472, mean_q: 0.349042, mean_eps: 0.741507\n",
            " 58600/100000: episode: 83, duration: 194.599s, episode steps: 911, steps per second:   5, episode reward: 19.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: 0.007065, mae: 0.267631, mean_q: 0.343186, mean_eps: 0.738352\n",
            " 59103/100000: episode: 84, duration: 108.082s, episode steps: 503, steps per second:   5, episode reward:  4.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: 0.006506, mae: 0.264403, mean_q: 0.339518, mean_eps: 0.735171\n",
            " 59718/100000: episode: 85, duration: 130.472s, episode steps: 615, steps per second:   5, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: 0.006236, mae: 0.263582, mean_q: 0.338720, mean_eps: 0.732655\n",
            " 60348/100000: episode: 86, duration: 135.217s, episode steps: 630, steps per second:   5, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.006959, mae: 0.274287, mean_q: 0.350313, mean_eps: 0.729854\n",
            " 60993/100000: episode: 87, duration: 137.726s, episode steps: 645, steps per second:   5, episode reward: 15.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.668 [0.000, 5.000],  loss: 0.007368, mae: 0.282574, mean_q: 0.360521, mean_eps: 0.726985\n",
            " 61392/100000: episode: 88, duration: 85.868s, episode steps: 399, steps per second:   5, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: 0.007070, mae: 0.283580, mean_q: 0.361542, mean_eps: 0.724636\n",
            " 61821/100000: episode: 89, duration: 91.610s, episode steps: 429, steps per second:   5, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.634 [0.000, 5.000],  loss: 0.006333, mae: 0.280111, mean_q: 0.358121, mean_eps: 0.722773\n",
            " 62197/100000: episode: 90, duration: 80.780s, episode steps: 376, steps per second:   5, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.370 [0.000, 5.000],  loss: 0.005933, mae: 0.278164, mean_q: 0.354410, mean_eps: 0.720962\n",
            " 62908/100000: episode: 91, duration: 151.896s, episode steps: 711, steps per second:   5, episode reward: 13.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.615 [0.000, 5.000],  loss: 0.006598, mae: 0.279452, mean_q: 0.357310, mean_eps: 0.718516\n",
            " 63934/100000: episode: 92, duration: 219.637s, episode steps: 1026, steps per second:   5, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.641 [0.000, 5.000],  loss: 0.006643, mae: 0.279172, mean_q: 0.357437, mean_eps: 0.714608\n",
            " 64562/100000: episode: 93, duration: 135.355s, episode steps: 628, steps per second:   5, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: 0.005923, mae: 0.276755, mean_q: 0.354466, mean_eps: 0.710886\n",
            " 65123/100000: episode: 94, duration: 120.733s, episode steps: 561, steps per second:   5, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.681 [0.000, 5.000],  loss: 0.006105, mae: 0.275101, mean_q: 0.351900, mean_eps: 0.708211\n",
            " 65959/100000: episode: 95, duration: 179.058s, episode steps: 836, steps per second:   5, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.475 [0.000, 5.000],  loss: 0.006067, mae: 0.278489, mean_q: 0.357209, mean_eps: 0.705068\n",
            " 66902/100000: episode: 96, duration: 200.625s, episode steps: 943, steps per second:   5, episode reward:  9.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.516 [0.000, 5.000],  loss: 0.005722, mae: 0.277119, mean_q: 0.355186, mean_eps: 0.701065\n",
            " 67622/100000: episode: 97, duration: 154.899s, episode steps: 720, steps per second:   5, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.005342, mae: 0.275584, mean_q: 0.353323, mean_eps: 0.697323\n",
            " 68212/100000: episode: 98, duration: 126.169s, episode steps: 590, steps per second:   5, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.578 [0.000, 5.000],  loss: 0.004873, mae: 0.271652, mean_q: 0.348974, mean_eps: 0.694376\n",
            " 68801/100000: episode: 99, duration: 125.584s, episode steps: 589, steps per second:   5, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.005968, mae: 0.276806, mean_q: 0.355866, mean_eps: 0.691723\n",
            " 69414/100000: episode: 100, duration: 130.348s, episode steps: 613, steps per second:   5, episode reward:  6.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.396 [0.000, 5.000],  loss: 0.005760, mae: 0.277674, mean_q: 0.358543, mean_eps: 0.689018\n",
            " 70329/100000: episode: 101, duration: 196.775s, episode steps: 915, steps per second:   5, episode reward: 12.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.005788, mae: 0.287977, mean_q: 0.369704, mean_eps: 0.685581\n",
            " 71398/100000: episode: 102, duration: 226.900s, episode steps: 1069, steps per second:   5, episode reward: 23.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.007197, mae: 0.312297, mean_q: 0.400102, mean_eps: 0.681117\n",
            " 72023/100000: episode: 103, duration: 133.757s, episode steps: 625, steps per second:   5, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.371 [0.000, 5.000],  loss: 0.006109, mae: 0.309324, mean_q: 0.397734, mean_eps: 0.677305\n",
            " 72662/100000: episode: 104, duration: 136.192s, episode steps: 639, steps per second:   5, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.463 [0.000, 5.000],  loss: 0.006846, mae: 0.312728, mean_q: 0.401760, mean_eps: 0.674461\n",
            " 73403/100000: episode: 105, duration: 156.993s, episode steps: 741, steps per second:   5, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.456 [0.000, 5.000],  loss: 0.005558, mae: 0.308410, mean_q: 0.395829, mean_eps: 0.671356\n",
            " 74067/100000: episode: 106, duration: 143.080s, episode steps: 664, steps per second:   5, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.380 [0.000, 5.000],  loss: 0.005809, mae: 0.307801, mean_q: 0.395758, mean_eps: 0.668195\n",
            " 74855/100000: episode: 107, duration: 167.522s, episode steps: 788, steps per second:   5, episode reward: 17.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.524 [0.000, 5.000],  loss: 0.005911, mae: 0.309702, mean_q: 0.398550, mean_eps: 0.664928\n",
            " 75530/100000: episode: 108, duration: 143.371s, episode steps: 675, steps per second:   5, episode reward: 15.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: 0.005487, mae: 0.307862, mean_q: 0.395754, mean_eps: 0.661636\n",
            " 76376/100000: episode: 109, duration: 180.051s, episode steps: 846, steps per second:   5, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.005477, mae: 0.310922, mean_q: 0.399857, mean_eps: 0.658214\n",
            " 76881/100000: episode: 110, duration: 108.639s, episode steps: 505, steps per second:   5, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.374 [0.000, 5.000],  loss: 0.005336, mae: 0.306441, mean_q: 0.394295, mean_eps: 0.655174\n",
            " 77515/100000: episode: 111, duration: 137.053s, episode steps: 634, steps per second:   5, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.353 [0.000, 5.000],  loss: 0.005657, mae: 0.309390, mean_q: 0.397867, mean_eps: 0.652611\n",
            " 78113/100000: episode: 112, duration: 129.334s, episode steps: 598, steps per second:   5, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.365 [0.000, 5.000],  loss: 0.004779, mae: 0.305953, mean_q: 0.393467, mean_eps: 0.649839\n",
            " 78921/100000: episode: 113, duration: 173.117s, episode steps: 808, steps per second:   5, episode reward: 11.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.251 [0.000, 5.000],  loss: 0.005099, mae: 0.308626, mean_q: 0.397586, mean_eps: 0.646676\n",
            " 79752/100000: episode: 114, duration: 178.075s, episode steps: 831, steps per second:   5, episode reward:  9.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.005017, mae: 0.306184, mean_q: 0.393741, mean_eps: 0.642988\n",
            " 80307/100000: episode: 115, duration: 120.000s, episode steps: 555, steps per second:   5, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: 0.006282, mae: 0.328394, mean_q: 0.421664, mean_eps: 0.639869\n",
            " 80955/100000: episode: 116, duration: 138.581s, episode steps: 648, steps per second:   5, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.366 [0.000, 5.000],  loss: 0.007173, mae: 0.343328, mean_q: 0.438072, mean_eps: 0.637163\n",
            " 81343/100000: episode: 117, duration: 82.973s, episode steps: 388, steps per second:   5, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.544 [0.000, 5.000],  loss: 0.006728, mae: 0.346929, mean_q: 0.443036, mean_eps: 0.634832\n",
            " 82024/100000: episode: 118, duration: 144.752s, episode steps: 681, steps per second:   5, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.261 [0.000, 5.000],  loss: 0.006601, mae: 0.346050, mean_q: 0.442807, mean_eps: 0.632427\n",
            " 82676/100000: episode: 119, duration: 140.775s, episode steps: 652, steps per second:   5, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.494 [0.000, 5.000],  loss: 0.006317, mae: 0.343251, mean_q: 0.437937, mean_eps: 0.629427\n",
            " 83326/100000: episode: 120, duration: 139.124s, episode steps: 650, steps per second:   5, episode reward: 14.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.535 [0.000, 5.000],  loss: 0.005981, mae: 0.344780, mean_q: 0.440659, mean_eps: 0.626498\n",
            " 83910/100000: episode: 121, duration: 125.516s, episode steps: 584, steps per second:   5, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.613 [0.000, 5.000],  loss: 0.005765, mae: 0.341783, mean_q: 0.436640, mean_eps: 0.623721\n",
            " 84282/100000: episode: 122, duration: 80.351s, episode steps: 372, steps per second:   5, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.376 [0.000, 5.000],  loss: 0.006139, mae: 0.349219, mean_q: 0.447515, mean_eps: 0.621570\n",
            " 84930/100000: episode: 123, duration: 138.778s, episode steps: 648, steps per second:   5, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.509 [0.000, 5.000],  loss: 0.005926, mae: 0.343666, mean_q: 0.438382, mean_eps: 0.619275\n",
            " 85880/100000: episode: 124, duration: 203.258s, episode steps: 950, steps per second:   5, episode reward: 22.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.468 [0.000, 5.000],  loss: 0.005788, mae: 0.341094, mean_q: 0.436894, mean_eps: 0.615680\n",
            " 86450/100000: episode: 125, duration: 121.434s, episode steps: 570, steps per second:   5, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.440 [0.000, 5.000],  loss: 0.005561, mae: 0.342856, mean_q: 0.438498, mean_eps: 0.612260\n",
            " 87450/100000: episode: 126, duration: 215.073s, episode steps: 1000, steps per second:   5, episode reward: 18.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.637 [0.000, 5.000],  loss: 0.005304, mae: 0.342313, mean_q: 0.438104, mean_eps: 0.608727\n",
            " 88092/100000: episode: 127, duration: 137.376s, episode steps: 642, steps per second:   5, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: 0.005920, mae: 0.344250, mean_q: 0.439961, mean_eps: 0.605033\n",
            " 88611/100000: episode: 128, duration: 111.540s, episode steps: 519, steps per second:   5, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.592 [0.000, 5.000],  loss: 0.005446, mae: 0.342708, mean_q: 0.438729, mean_eps: 0.602420\n",
            " 89185/100000: episode: 129, duration: 122.883s, episode steps: 574, steps per second:   5, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.822 [0.000, 5.000],  loss: 0.005520, mae: 0.342313, mean_q: 0.437406, mean_eps: 0.599961\n",
            " 90134/100000: episode: 130, duration: 203.374s, episode steps: 949, steps per second:   5, episode reward: 24.000, mean reward:  0.025 [ 0.000,  1.000], mean action: 2.452 [0.000, 5.000],  loss: 0.005966, mae: 0.343010, mean_q: 0.438535, mean_eps: 0.596534\n",
            " 91329/100000: episode: 131, duration: 255.264s, episode steps: 1195, steps per second:   5, episode reward: 25.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.007533, mae: 0.371585, mean_q: 0.474592, mean_eps: 0.591711\n",
            " 92060/100000: episode: 132, duration: 157.747s, episode steps: 731, steps per second:   5, episode reward: 17.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.007162, mae: 0.368004, mean_q: 0.468155, mean_eps: 0.587377\n",
            " 92517/100000: episode: 133, duration: 97.691s, episode steps: 457, steps per second:   5, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.705 [0.000, 5.000],  loss: 0.006773, mae: 0.370785, mean_q: 0.472556, mean_eps: 0.584704\n",
            " 92904/100000: episode: 134, duration: 82.939s, episode steps: 387, steps per second:   5, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.395 [0.000, 5.000],  loss: 0.006515, mae: 0.368532, mean_q: 0.470881, mean_eps: 0.582805\n",
            " 93346/100000: episode: 135, duration: 94.914s, episode steps: 442, steps per second:   5, episode reward:  6.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.821 [0.000, 5.000],  loss: 0.007180, mae: 0.376244, mean_q: 0.479945, mean_eps: 0.580940\n",
            " 93826/100000: episode: 136, duration: 103.891s, episode steps: 480, steps per second:   5, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.775 [0.000, 5.000],  loss: 0.006093, mae: 0.369110, mean_q: 0.470710, mean_eps: 0.578865\n",
            " 94365/100000: episode: 137, duration: 115.471s, episode steps: 539, steps per second:   5, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.319 [0.000, 5.000],  loss: 0.006154, mae: 0.368760, mean_q: 0.469785, mean_eps: 0.576573\n",
            " 94730/100000: episode: 138, duration: 78.788s, episode steps: 365, steps per second:   5, episode reward:  4.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.838 [0.000, 5.000],  loss: 0.006066, mae: 0.366949, mean_q: 0.466790, mean_eps: 0.574538\n",
            " 95254/100000: episode: 139, duration: 111.761s, episode steps: 524, steps per second:   5, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.296 [0.000, 5.000],  loss: 0.006288, mae: 0.371188, mean_q: 0.473384, mean_eps: 0.572538\n",
            " 95796/100000: episode: 140, duration: 115.079s, episode steps: 542, steps per second:   5, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.502 [0.000, 5.000],  loss: 0.005985, mae: 0.368878, mean_q: 0.471031, mean_eps: 0.570140\n",
            " 96864/100000: episode: 141, duration: 230.296s, episode steps: 1068, steps per second:   5, episode reward: 12.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.567 [0.000, 5.000],  loss: 0.006247, mae: 0.368294, mean_q: 0.471159, mean_eps: 0.566517\n",
            " 97257/100000: episode: 142, duration: 85.024s, episode steps: 393, steps per second:   5, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.244 [0.000, 5.000],  loss: 0.005782, mae: 0.368173, mean_q: 0.470118, mean_eps: 0.563230\n",
            " 97768/100000: episode: 143, duration: 109.620s, episode steps: 511, steps per second:   5, episode reward: 10.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.005643, mae: 0.374581, mean_q: 0.478770, mean_eps: 0.561196\n",
            " 98241/100000: episode: 144, duration: 101.768s, episode steps: 473, steps per second:   5, episode reward:  7.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.514 [0.000, 5.000],  loss: 0.005710, mae: 0.369630, mean_q: 0.471666, mean_eps: 0.558982\n",
            " 98676/100000: episode: 145, duration: 92.995s, episode steps: 435, steps per second:   5, episode reward:  8.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.209 [0.000, 5.000],  loss: 0.005925, mae: 0.366239, mean_q: 0.467507, mean_eps: 0.556939\n",
            " 99159/100000: episode: 146, duration: 104.513s, episode steps: 483, steps per second:   5, episode reward:  7.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: 0.005824, mae: 0.367796, mean_q: 0.470738, mean_eps: 0.554874\n",
            "done, took 10943.769 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x781e72815450>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_episodes = 100\n",
        "results = dqn.test(env, nb_episodes=test_episodes, visualize=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CaJs3WSdSjg",
        "outputId": "02269040-4a12-46d3-d359-21cd9c068652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 100 episodes ...\n",
            "Episode 1: reward: 20.000, steps: 979\n",
            "Episode 2: reward: 22.000, steps: 971\n",
            "Episode 3: reward: 26.000, steps: 1098\n",
            "Episode 4: reward: 4.000, steps: 531\n",
            "Episode 5: reward: 8.000, steps: 710\n",
            "Episode 6: reward: 14.000, steps: 854\n",
            "Episode 7: reward: 15.000, steps: 662\n",
            "Episode 8: reward: 10.000, steps: 916\n",
            "Episode 9: reward: 11.000, steps: 679\n",
            "Episode 10: reward: 36.000, steps: 1685\n",
            "Episode 11: reward: 19.000, steps: 963\n",
            "Episode 12: reward: 9.000, steps: 504\n",
            "Episode 13: reward: 20.000, steps: 991\n",
            "Episode 14: reward: 16.000, steps: 834\n",
            "Episode 15: reward: 20.000, steps: 990\n",
            "Episode 16: reward: 24.000, steps: 1014\n",
            "Episode 17: reward: 20.000, steps: 1088\n",
            "Episode 18: reward: 8.000, steps: 521\n",
            "Episode 19: reward: 13.000, steps: 654\n",
            "Episode 20: reward: 14.000, steps: 644\n",
            "Episode 21: reward: 20.000, steps: 1171\n",
            "Episode 22: reward: 5.000, steps: 589\n",
            "Episode 23: reward: 13.000, steps: 906\n",
            "Episode 24: reward: 12.000, steps: 807\n",
            "Episode 25: reward: 16.000, steps: 989\n",
            "Episode 26: reward: 8.000, steps: 681\n",
            "Episode 27: reward: 4.000, steps: 379\n",
            "Episode 28: reward: 6.000, steps: 506\n",
            "Episode 29: reward: 17.000, steps: 853\n",
            "Episode 30: reward: 11.000, steps: 744\n",
            "Episode 31: reward: 7.000, steps: 501\n",
            "Episode 32: reward: 9.000, steps: 500\n",
            "Episode 33: reward: 14.000, steps: 771\n",
            "Episode 34: reward: 16.000, steps: 1013\n",
            "Episode 35: reward: 17.000, steps: 975\n",
            "Episode 36: reward: 10.000, steps: 641\n",
            "Episode 37: reward: 19.000, steps: 905\n",
            "Episode 38: reward: 7.000, steps: 449\n",
            "Episode 39: reward: 13.000, steps: 739\n",
            "Episode 40: reward: 20.000, steps: 862\n",
            "Episode 41: reward: 4.000, steps: 322\n",
            "Episode 42: reward: 8.000, steps: 499\n",
            "Episode 43: reward: 9.000, steps: 769\n",
            "Episode 44: reward: 13.000, steps: 776\n",
            "Episode 45: reward: 6.000, steps: 488\n",
            "Episode 46: reward: 23.000, steps: 1233\n",
            "Episode 47: reward: 11.000, steps: 692\n",
            "Episode 48: reward: 16.000, steps: 758\n",
            "Episode 49: reward: 6.000, steps: 529\n",
            "Episode 50: reward: 15.000, steps: 934\n",
            "Episode 51: reward: 10.000, steps: 455\n",
            "Episode 52: reward: 8.000, steps: 651\n",
            "Episode 53: reward: 25.000, steps: 955\n",
            "Episode 54: reward: 10.000, steps: 657\n",
            "Episode 55: reward: 6.000, steps: 497\n",
            "Episode 56: reward: 13.000, steps: 702\n",
            "Episode 57: reward: 14.000, steps: 667\n",
            "Episode 58: reward: 16.000, steps: 886\n",
            "Episode 59: reward: 9.000, steps: 526\n",
            "Episode 60: reward: 7.000, steps: 520\n",
            "Episode 61: reward: 20.000, steps: 1085\n",
            "Episode 62: reward: 7.000, steps: 656\n",
            "Episode 63: reward: 17.000, steps: 733\n",
            "Episode 64: reward: 13.000, steps: 644\n",
            "Episode 65: reward: 17.000, steps: 1087\n",
            "Episode 66: reward: 17.000, steps: 1194\n",
            "Episode 67: reward: 13.000, steps: 815\n",
            "Episode 68: reward: 14.000, steps: 790\n",
            "Episode 69: reward: 8.000, steps: 449\n",
            "Episode 70: reward: 15.000, steps: 925\n",
            "Episode 71: reward: 12.000, steps: 660\n",
            "Episode 72: reward: 4.000, steps: 519\n",
            "Episode 73: reward: 16.000, steps: 907\n",
            "Episode 74: reward: 12.000, steps: 794\n",
            "Episode 75: reward: 12.000, steps: 774\n",
            "Episode 76: reward: 5.000, steps: 528\n",
            "Episode 77: reward: 13.000, steps: 672\n",
            "Episode 78: reward: 8.000, steps: 395\n",
            "Episode 79: reward: 11.000, steps: 576\n",
            "Episode 80: reward: 19.000, steps: 845\n",
            "Episode 81: reward: 5.000, steps: 500\n",
            "Episode 82: reward: 10.000, steps: 506\n",
            "Episode 83: reward: 10.000, steps: 687\n",
            "Episode 84: reward: 10.000, steps: 513\n",
            "Episode 85: reward: 10.000, steps: 617\n",
            "Episode 86: reward: 14.000, steps: 951\n",
            "Episode 87: reward: 10.000, steps: 498\n",
            "Episode 88: reward: 14.000, steps: 652\n",
            "Episode 89: reward: 17.000, steps: 614\n",
            "Episode 90: reward: 5.000, steps: 384\n",
            "Episode 91: reward: 21.000, steps: 1046\n",
            "Episode 92: reward: 15.000, steps: 667\n",
            "Episode 93: reward: 10.000, steps: 732\n",
            "Episode 94: reward: 11.000, steps: 646\n",
            "Episode 95: reward: 10.000, steps: 389\n",
            "Episode 96: reward: 26.000, steps: 1044\n",
            "Episode 97: reward: 20.000, steps: 719\n",
            "Episode 98: reward: 11.000, steps: 495\n",
            "Episode 99: reward: 13.000, steps: 711\n",
            "Episode 100: reward: 17.000, steps: 870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Promedio de la corrida anterior: 6.66"
      ],
      "metadata": {
        "id": "PRC09qPGQBRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dqn_weights_100000.h5f\n",
        "#Continuación al 325000 + 100000 + 100000+100000+100000 = 725000\n",
        "\n",
        "dqn.load_weights(\"dqn_weights_100000.h5f\")\n",
        "# Paso de partida 3\n",
        "starting_step = 100000 #ultimo weight actualizado\n",
        "remaining_steps = 200000 - starting_step\n",
        "\n",
        "\n",
        "# Callback personalizado para continuar numeración de checkpoints\n",
        "class OffsetModelCheckpoint(ModelIntervalCheckpoint):\n",
        "    def __init__(self, filepath, interval, offset):\n",
        "        super().__init__(filepath, interval)\n",
        "        self.offset = offset\n",
        "\n",
        "    def on_step_end(self, step, logs={}):\n",
        "        # Ajusta el número de paso en el nombre del archivo\n",
        "        self.step = step + self.offset\n",
        "        super().on_step_end(step, logs)\n",
        "\n",
        "# Entrenamiento con pasos continuados desde 100000\n",
        "dqn.fit(env, nb_steps=remaining_steps, visualize=False, verbose=2,\n",
        "        callbacks=[\n",
        "            FileLogger(\"dqn_log_continuacion.json\", interval=10000),\n",
        "            OffsetModelCheckpoint(\"dqn_weights_{step}.h5f\", interval=25000, offset=starting_step)\n",
        "        ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GA_LTA_isJL",
        "outputId": "7670d03b-46e2-4e00-e7ba-a2060d417ed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 100000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   653/100000: episode: 1, duration: 2.927s, episode steps: 653, steps per second: 223, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.403 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  1686/100000: episode: 2, duration: 3.620s, episode steps: 1033, steps per second: 285, episode reward: 19.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.353 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  2319/100000: episode: 3, duration: 2.411s, episode steps: 633, steps per second: 263, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.664 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  3246/100000: episode: 4, duration: 4.685s, episode steps: 927, steps per second: 198, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  3788/100000: episode: 5, duration: 1.935s, episode steps: 542, steps per second: 280, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  4181/100000: episode: 6, duration: 1.393s, episode steps: 393, steps per second: 282, episode reward:  3.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.583 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  4904/100000: episode: 7, duration: 2.550s, episode steps: 723, steps per second: 284, episode reward:  9.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.520 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  5843/100000: episode: 8, duration: 3.806s, episode steps: 939, steps per second: 247, episode reward: 15.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.568 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  6505/100000: episode: 9, duration: 3.191s, episode steps: 662, steps per second: 207, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  7115/100000: episode: 10, duration: 2.207s, episode steps: 610, steps per second: 276, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.474 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  7739/100000: episode: 11, duration: 2.193s, episode steps: 624, steps per second: 285, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.492 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  8127/100000: episode: 12, duration: 1.389s, episode steps: 388, steps per second: 279, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.541 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  9063/100000: episode: 13, duration: 3.443s, episode steps: 936, steps per second: 272, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "  9680/100000: episode: 14, duration: 3.418s, episode steps: 617, steps per second: 181, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 10016/100000: episode: 15, duration: 1.196s, episode steps: 336, steps per second: 281, episode reward:  3.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.432 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 10683/100000: episode: 16, duration: 2.390s, episode steps: 667, steps per second: 279, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.517 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 11389/100000: episode: 17, duration: 2.496s, episode steps: 706, steps per second: 283, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.438 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 11998/100000: episode: 18, duration: 2.124s, episode steps: 609, steps per second: 287, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.476 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 12787/100000: episode: 19, duration: 3.472s, episode steps: 789, steps per second: 227, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.496 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 13484/100000: episode: 20, duration: 3.204s, episode steps: 697, steps per second: 218, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.506 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 14275/100000: episode: 21, duration: 2.846s, episode steps: 791, steps per second: 278, episode reward: 14.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 14988/100000: episode: 22, duration: 2.554s, episode steps: 713, steps per second: 279, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.534 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 15818/100000: episode: 23, duration: 3.020s, episode steps: 830, steps per second: 275, episode reward: 15.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.536 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 16820/100000: episode: 24, duration: 4.973s, episode steps: 1002, steps per second: 201, episode reward: 14.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.477 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 17784/100000: episode: 25, duration: 3.438s, episode steps: 964, steps per second: 280, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.527 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 18372/100000: episode: 26, duration: 2.154s, episode steps: 588, steps per second: 273, episode reward:  4.000, mean reward:  0.007 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 18751/100000: episode: 27, duration: 1.360s, episode steps: 379, steps per second: 279, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.557 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 19105/100000: episode: 28, duration: 1.307s, episode steps: 354, steps per second: 271, episode reward:  6.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 19627/100000: episode: 29, duration: 2.824s, episode steps: 522, steps per second: 185, episode reward:  8.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 20002/100000: episode: 30, duration: 1.767s, episode steps: 375, steps per second: 212, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 20684/100000: episode: 31, duration: 2.475s, episode steps: 682, steps per second: 276, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 21283/100000: episode: 32, duration: 2.228s, episode steps: 599, steps per second: 269, episode reward: 10.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.593 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 21820/100000: episode: 33, duration: 1.923s, episode steps: 537, steps per second: 279, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.512 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 22436/100000: episode: 34, duration: 2.238s, episode steps: 616, steps per second: 275, episode reward:  9.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.515 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 23486/100000: episode: 35, duration: 5.084s, episode steps: 1050, steps per second: 207, episode reward: 11.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.462 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 24228/100000: episode: 36, duration: 2.727s, episode steps: 742, steps per second: 272, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 25111/100000: episode: 37, duration: 3.701s, episode steps: 883, steps per second: 239, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.564 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 25728/100000: episode: 38, duration: 2.214s, episode steps: 617, steps per second: 279, episode reward:  8.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.480 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 26141/100000: episode: 39, duration: 2.364s, episode steps: 413, steps per second: 175, episode reward:  9.000, mean reward:  0.022 [ 0.000,  1.000], mean action: 2.436 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 26548/100000: episode: 40, duration: 1.927s, episode steps: 407, steps per second: 211, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.658 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 26943/100000: episode: 41, duration: 1.397s, episode steps: 395, steps per second: 283, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 27551/100000: episode: 42, duration: 2.184s, episode steps: 608, steps per second: 278, episode reward: 11.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 28173/100000: episode: 43, duration: 2.247s, episode steps: 622, steps per second: 277, episode reward:  5.000, mean reward:  0.008 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 28741/100000: episode: 44, duration: 2.041s, episode steps: 568, steps per second: 278, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.562 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 29379/100000: episode: 45, duration: 2.893s, episode steps: 638, steps per second: 221, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.337 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 30082/100000: episode: 46, duration: 3.316s, episode steps: 703, steps per second: 212, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.612 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 30741/100000: episode: 47, duration: 2.338s, episode steps: 659, steps per second: 282, episode reward:  8.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.545 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 31433/100000: episode: 48, duration: 2.462s, episode steps: 692, steps per second: 281, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.538 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 32151/100000: episode: 49, duration: 2.590s, episode steps: 718, steps per second: 277, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.533 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 32692/100000: episode: 50, duration: 2.401s, episode steps: 541, steps per second: 225, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 33746/100000: episode: 51, duration: 4.710s, episode steps: 1054, steps per second: 224, episode reward: 21.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.542 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 34551/100000: episode: 52, duration: 2.909s, episode steps: 805, steps per second: 277, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.359 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 35466/100000: episode: 53, duration: 3.308s, episode steps: 915, steps per second: 277, episode reward: 13.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.489 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 36139/100000: episode: 54, duration: 2.911s, episode steps: 673, steps per second: 231, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.571 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 36802/100000: episode: 55, duration: 3.213s, episode steps: 663, steps per second: 206, episode reward: 12.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.434 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 37455/100000: episode: 56, duration: 2.325s, episode steps: 653, steps per second: 281, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.547 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 38333/100000: episode: 57, duration: 3.173s, episode steps: 878, steps per second: 277, episode reward: 15.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.473 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 39353/100000: episode: 58, duration: 3.751s, episode steps: 1020, steps per second: 272, episode reward: 16.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.466 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 39731/100000: episode: 59, duration: 2.173s, episode steps: 378, steps per second: 174, episode reward:  7.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.603 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 40097/100000: episode: 60, duration: 1.660s, episode steps: 366, steps per second: 221, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.582 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 40742/100000: episode: 61, duration: 2.338s, episode steps: 645, steps per second: 276, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 41288/100000: episode: 62, duration: 1.957s, episode steps: 546, steps per second: 279, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.416 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 41933/100000: episode: 63, duration: 2.266s, episode steps: 645, steps per second: 285, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.640 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 42312/100000: episode: 64, duration: 1.320s, episode steps: 379, steps per second: 287, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.596 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 42939/100000: episode: 65, duration: 2.678s, episode steps: 627, steps per second: 234, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.389 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 43448/100000: episode: 66, duration: 2.576s, episode steps: 509, steps per second: 198, episode reward:  2.000, mean reward:  0.004 [ 0.000,  1.000], mean action: 2.348 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 44155/100000: episode: 67, duration: 2.493s, episode steps: 707, steps per second: 284, episode reward:  8.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.364 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 44717/100000: episode: 68, duration: 1.985s, episode steps: 562, steps per second: 283, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.658 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 45761/100000: episode: 69, duration: 3.708s, episode steps: 1044, steps per second: 282, episode reward: 12.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.354 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 46394/100000: episode: 70, duration: 2.779s, episode steps: 633, steps per second: 228, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.389 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 47072/100000: episode: 71, duration: 3.163s, episode steps: 678, steps per second: 214, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 47719/100000: episode: 72, duration: 2.261s, episode steps: 647, steps per second: 286, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.519 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 48245/100000: episode: 73, duration: 1.869s, episode steps: 526, steps per second: 281, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.511 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 49139/100000: episode: 74, duration: 3.111s, episode steps: 894, steps per second: 287, episode reward: 18.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.510 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            " 49535/100000: episode: 75, duration: 1.409s, episode steps: 396, steps per second: 281, episode reward:  7.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.399 [0.000, 5.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 50159/100000: episode: 76, duration: 32.478s, episode steps: 624, steps per second:  19, episode reward:  7.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.554 [0.000, 5.000],  loss: 0.013205, mae: 0.400916, mean_q: 0.503530, mean_eps: 0.774642\n",
            " 50777/100000: episode: 77, duration: 111.125s, episode steps: 618, steps per second:   6, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.012779, mae: 0.399777, mean_q: 0.495600, mean_eps: 0.772896\n",
            " 51478/100000: episode: 78, duration: 127.555s, episode steps: 701, steps per second:   5, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.425 [0.000, 5.000],  loss: 0.011280, mae: 0.394649, mean_q: 0.485916, mean_eps: 0.769929\n",
            " 51858/100000: episode: 79, duration: 69.164s, episode steps: 380, steps per second:   5, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.271 [0.000, 5.000],  loss: 0.010363, mae: 0.398488, mean_q: 0.490119, mean_eps: 0.767496\n",
            " 52544/100000: episode: 80, duration: 124.081s, episode steps: 686, steps per second:   6, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.499 [0.000, 5.000],  loss: 0.009686, mae: 0.394424, mean_q: 0.484455, mean_eps: 0.765098\n",
            " 52908/100000: episode: 81, duration: 66.043s, episode steps: 364, steps per second:   6, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.335 [0.000, 5.000],  loss: 0.010165, mae: 0.395324, mean_q: 0.487929, mean_eps: 0.762735\n",
            " 53553/100000: episode: 82, duration: 114.464s, episode steps: 645, steps per second:   6, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.197 [0.000, 5.000],  loss: 0.009041, mae: 0.391882, mean_q: 0.483797, mean_eps: 0.760465\n",
            " 54171/100000: episode: 83, duration: 110.669s, episode steps: 618, steps per second:   6, episode reward: 10.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.615 [0.000, 5.000],  loss: 0.009210, mae: 0.389501, mean_q: 0.481114, mean_eps: 0.757623\n",
            " 54875/100000: episode: 84, duration: 124.954s, episode steps: 704, steps per second:   6, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.460 [0.000, 5.000],  loss: 0.008694, mae: 0.392919, mean_q: 0.487336, mean_eps: 0.754649\n",
            " 55420/100000: episode: 85, duration: 96.015s, episode steps: 545, steps per second:   6, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.716 [0.000, 5.000],  loss: 0.008249, mae: 0.388711, mean_q: 0.483440, mean_eps: 0.751839\n",
            " 56430/100000: episode: 86, duration: 176.035s, episode steps: 1010, steps per second:   6, episode reward: 15.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.311 [0.000, 5.000],  loss: 0.008390, mae: 0.392016, mean_q: 0.487698, mean_eps: 0.748340\n",
            " 57399/100000: episode: 87, duration: 171.733s, episode steps: 969, steps per second:   6, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.495 [0.000, 5.000],  loss: 0.007569, mae: 0.389763, mean_q: 0.485321, mean_eps: 0.743887\n",
            " 57956/100000: episode: 88, duration: 97.487s, episode steps: 557, steps per second:   6, episode reward: 11.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.408 [0.000, 5.000],  loss: 0.006844, mae: 0.386489, mean_q: 0.481424, mean_eps: 0.740453\n",
            " 58942/100000: episode: 89, duration: 174.049s, episode steps: 986, steps per second:   6, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.560 [0.000, 5.000],  loss: 0.007081, mae: 0.390948, mean_q: 0.487614, mean_eps: 0.736982\n",
            " 59585/100000: episode: 90, duration: 113.687s, episode steps: 643, steps per second:   6, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.493 [0.000, 5.000],  loss: 0.007073, mae: 0.390794, mean_q: 0.488279, mean_eps: 0.733317\n",
            " 60091/100000: episode: 91, duration: 88.492s, episode steps: 506, steps per second:   6, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.221 [0.000, 5.000],  loss: 0.007616, mae: 0.394932, mean_q: 0.493954, mean_eps: 0.730731\n",
            " 60775/100000: episode: 92, duration: 121.753s, episode steps: 684, steps per second:   6, episode reward: 14.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.529 [0.000, 5.000],  loss: 0.009064, mae: 0.424781, mean_q: 0.529746, mean_eps: 0.728054\n",
            " 61758/100000: episode: 93, duration: 173.120s, episode steps: 983, steps per second:   6, episode reward: 19.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.007915, mae: 0.420625, mean_q: 0.523425, mean_eps: 0.724303\n",
            " 62294/100000: episode: 94, duration: 94.554s, episode steps: 536, steps per second:   6, episode reward:  9.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.317 [0.000, 5.000],  loss: 0.007419, mae: 0.422889, mean_q: 0.525965, mean_eps: 0.720885\n",
            " 62960/100000: episode: 95, duration: 119.398s, episode steps: 666, steps per second:   6, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.446 [0.000, 5.000],  loss: 0.007155, mae: 0.422337, mean_q: 0.526238, mean_eps: 0.718181\n",
            " 63646/100000: episode: 96, duration: 123.319s, episode steps: 686, steps per second:   6, episode reward: 11.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.485 [0.000, 5.000],  loss: 0.007038, mae: 0.420533, mean_q: 0.526098, mean_eps: 0.715139\n",
            " 64703/100000: episode: 97, duration: 187.103s, episode steps: 1057, steps per second:   6, episode reward: 15.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.501 [0.000, 5.000],  loss: 0.006524, mae: 0.419975, mean_q: 0.525005, mean_eps: 0.711217\n",
            " 65123/100000: episode: 98, duration: 74.453s, episode steps: 420, steps per second:   6, episode reward:  7.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.500 [0.000, 5.000],  loss: 0.006620, mae: 0.422223, mean_q: 0.527588, mean_eps: 0.707894\n",
            " 65709/100000: episode: 99, duration: 104.369s, episode steps: 586, steps per second:   6, episode reward: 12.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.654 [0.000, 5.000],  loss: 0.006609, mae: 0.418025, mean_q: 0.521094, mean_eps: 0.705630\n",
            " 66157/100000: episode: 100, duration: 79.871s, episode steps: 448, steps per second:   6, episode reward:  6.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.663 [0.000, 5.000],  loss: 0.005907, mae: 0.415243, mean_q: 0.518682, mean_eps: 0.703304\n",
            " 66662/100000: episode: 101, duration: 86.158s, episode steps: 505, steps per second:   6, episode reward:  6.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.398 [0.000, 5.000],  loss: 0.006094, mae: 0.416559, mean_q: 0.521966, mean_eps: 0.701159\n",
            " 67390/100000: episode: 102, duration: 125.900s, episode steps: 728, steps per second:   6, episode reward: 11.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.212 [0.000, 5.000],  loss: 0.006187, mae: 0.418194, mean_q: 0.522331, mean_eps: 0.698385\n",
            " 68014/100000: episode: 103, duration: 113.365s, episode steps: 624, steps per second:   6, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.287 [0.000, 5.000],  loss: 0.005903, mae: 0.417452, mean_q: 0.522726, mean_eps: 0.695343\n",
            " 68671/100000: episode: 104, duration: 119.787s, episode steps: 657, steps per second:   5, episode reward:  6.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.589 [0.000, 5.000],  loss: 0.006105, mae: 0.418310, mean_q: 0.523231, mean_eps: 0.692461\n",
            " 69060/100000: episode: 105, duration: 69.687s, episode steps: 389, steps per second:   6, episode reward:  4.000, mean reward:  0.010 [ 0.000,  1.000], mean action: 2.704 [0.000, 5.000],  loss: 0.005825, mae: 0.419333, mean_q: 0.525001, mean_eps: 0.690108\n",
            " 70032/100000: episode: 106, duration: 174.426s, episode steps: 972, steps per second:   6, episode reward: 20.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.005859, mae: 0.421798, mean_q: 0.529391, mean_eps: 0.687045\n",
            " 70806/100000: episode: 107, duration: 139.064s, episode steps: 774, steps per second:   6, episode reward: 18.000, mean reward:  0.023 [ 0.000,  1.000], mean action: 2.258 [0.000, 5.000],  loss: 0.008311, mae: 0.461069, mean_q: 0.574775, mean_eps: 0.683117\n",
            " 71278/100000: episode: 108, duration: 85.059s, episode steps: 472, steps per second:   6, episode reward:  9.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.383 [0.000, 5.000],  loss: 0.007810, mae: 0.453337, mean_q: 0.565869, mean_eps: 0.680313\n",
            " 72438/100000: episode: 109, duration: 212.392s, episode steps: 1160, steps per second:   5, episode reward: 21.000, mean reward:  0.018 [ 0.000,  1.000], mean action: 2.450 [0.000, 5.000],  loss: 0.007064, mae: 0.456583, mean_q: 0.568923, mean_eps: 0.676641\n",
            " 73729/100000: episode: 110, duration: 231.769s, episode steps: 1291, steps per second:   6, episode reward: 31.000, mean reward:  0.024 [ 0.000,  1.000], mean action: 2.486 [0.000, 5.000],  loss: 0.006760, mae: 0.456514, mean_q: 0.569257, mean_eps: 0.671126\n",
            " 74062/100000: episode: 111, duration: 61.116s, episode steps: 333, steps per second:   5, episode reward:  2.000, mean reward:  0.006 [ 0.000,  1.000], mean action: 2.435 [0.000, 5.000],  loss: 0.006775, mae: 0.454644, mean_q: 0.566744, mean_eps: 0.667472\n",
            " 74881/100000: episode: 112, duration: 148.391s, episode steps: 819, steps per second:   6, episode reward: 13.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.379 [0.000, 5.000],  loss: 0.006320, mae: 0.455020, mean_q: 0.568634, mean_eps: 0.664880\n",
            " 75421/100000: episode: 113, duration: 98.893s, episode steps: 540, steps per second:   5, episode reward:  7.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.267 [0.000, 5.000],  loss: 0.006393, mae: 0.455412, mean_q: 0.569732, mean_eps: 0.661823\n",
            " 76197/100000: episode: 114, duration: 140.822s, episode steps: 776, steps per second:   6, episode reward: 10.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.580 [0.000, 5.000],  loss: 0.005789, mae: 0.454297, mean_q: 0.568631, mean_eps: 0.658862\n",
            " 77126/100000: episode: 115, duration: 168.593s, episode steps: 929, steps per second:   6, episode reward: 19.000, mean reward:  0.020 [ 0.000,  1.000], mean action: 2.453 [0.000, 5.000],  loss: 0.006170, mae: 0.454115, mean_q: 0.567804, mean_eps: 0.655025\n",
            " 77918/100000: episode: 116, duration: 145.367s, episode steps: 792, steps per second:   5, episode reward: 17.000, mean reward:  0.021 [ 0.000,  1.000], mean action: 2.380 [0.000, 5.000],  loss: 0.006052, mae: 0.457420, mean_q: 0.572706, mean_eps: 0.651153\n",
            " 78706/100000: episode: 117, duration: 139.439s, episode steps: 788, steps per second:   6, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.445 [0.000, 5.000],  loss: 0.006201, mae: 0.455783, mean_q: 0.569943, mean_eps: 0.647598\n",
            " 79092/100000: episode: 118, duration: 68.556s, episode steps: 386, steps per second:   6, episode reward:  5.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.358 [0.000, 5.000],  loss: 0.005804, mae: 0.457024, mean_q: 0.570309, mean_eps: 0.644957\n",
            " 80175/100000: episode: 119, duration: 200.041s, episode steps: 1083, steps per second:   5, episode reward: 21.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.426 [0.000, 5.000],  loss: 0.006023, mae: 0.455872, mean_q: 0.570635, mean_eps: 0.641652\n",
            " 80833/100000: episode: 120, duration: 120.954s, episode steps: 658, steps per second:   5, episode reward:  9.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.526 [0.000, 5.000],  loss: 0.007865, mae: 0.478241, mean_q: 0.596601, mean_eps: 0.637734\n",
            " 81540/100000: episode: 121, duration: 133.805s, episode steps: 707, steps per second:   5, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.007539, mae: 0.474135, mean_q: 0.591108, mean_eps: 0.634663\n",
            " 81881/100000: episode: 122, duration: 64.336s, episode steps: 341, steps per second:   5, episode reward:  5.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.572 [0.000, 5.000],  loss: 0.007516, mae: 0.474787, mean_q: 0.592971, mean_eps: 0.632305\n",
            " 82527/100000: episode: 123, duration: 117.186s, episode steps: 646, steps per second:   6, episode reward: 11.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.420 [0.000, 5.000],  loss: 0.006842, mae: 0.478603, mean_q: 0.596744, mean_eps: 0.630084\n",
            " 83206/100000: episode: 124, duration: 122.966s, episode steps: 679, steps per second:   6, episode reward: 10.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.381 [0.000, 5.000],  loss: 0.007150, mae: 0.476092, mean_q: 0.593653, mean_eps: 0.627103\n",
            " 83993/100000: episode: 125, duration: 142.498s, episode steps: 787, steps per second:   6, episode reward: 13.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.290 [0.000, 5.000],  loss: 0.006819, mae: 0.479226, mean_q: 0.598774, mean_eps: 0.623804\n",
            " 85000/100000: episode: 126, duration: 180.553s, episode steps: 1007, steps per second:   6, episode reward: 17.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.626 [0.000, 5.000],  loss: 0.006769, mae: 0.478350, mean_q: 0.597663, mean_eps: 0.619768\n",
            " 85628/100000: episode: 127, duration: 115.672s, episode steps: 628, steps per second:   5, episode reward: 12.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.481 [0.000, 5.000],  loss: 0.006845, mae: 0.478559, mean_q: 0.597111, mean_eps: 0.616089\n",
            " 86312/100000: episode: 128, duration: 127.448s, episode steps: 684, steps per second:   5, episode reward:  9.000, mean reward:  0.013 [ 0.000,  1.000], mean action: 2.563 [0.000, 5.000],  loss: 0.006342, mae: 0.478451, mean_q: 0.597389, mean_eps: 0.613137\n",
            " 86711/100000: episode: 129, duration: 71.953s, episode steps: 399, steps per second:   6, episode reward:  6.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.326 [0.000, 5.000],  loss: 0.005966, mae: 0.472321, mean_q: 0.589751, mean_eps: 0.610700\n",
            " 87282/100000: episode: 130, duration: 104.197s, episode steps: 571, steps per second:   5, episode reward:  8.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.336 [0.000, 5.000],  loss: 0.006405, mae: 0.479493, mean_q: 0.599160, mean_eps: 0.608518\n",
            " 87658/100000: episode: 131, duration: 67.911s, episode steps: 376, steps per second:   6, episode reward:  6.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.223 [0.000, 5.000],  loss: 0.005737, mae: 0.478596, mean_q: 0.598055, mean_eps: 0.606387\n",
            " 88399/100000: episode: 132, duration: 136.154s, episode steps: 741, steps per second:   5, episode reward: 12.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.331 [0.000, 5.000],  loss: 0.006346, mae: 0.480421, mean_q: 0.599248, mean_eps: 0.603874\n",
            " 89094/100000: episode: 133, duration: 129.498s, episode steps: 695, steps per second:   5, episode reward: 12.000, mean reward:  0.017 [ 0.000,  1.000], mean action: 2.412 [0.000, 5.000],  loss: 0.006255, mae: 0.479435, mean_q: 0.598102, mean_eps: 0.600643\n",
            " 89584/100000: episode: 134, duration: 91.970s, episode steps: 490, steps per second:   5, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.635 [0.000, 5.000],  loss: 0.006287, mae: 0.480330, mean_q: 0.598663, mean_eps: 0.597977\n",
            " 89930/100000: episode: 135, duration: 64.608s, episode steps: 346, steps per second:   5, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.358 [0.000, 5.000],  loss: 0.005728, mae: 0.480192, mean_q: 0.599580, mean_eps: 0.596096\n",
            " 90730/100000: episode: 136, duration: 145.877s, episode steps: 800, steps per second:   5, episode reward: 12.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.470 [0.000, 5.000],  loss: 0.008042, mae: 0.498815, mean_q: 0.622134, mean_eps: 0.593517\n",
            " 91598/100000: episode: 137, duration: 155.178s, episode steps: 868, steps per second:   6, episode reward: 13.000, mean reward:  0.015 [ 0.000,  1.000], mean action: 2.513 [0.000, 5.000],  loss: 0.007779, mae: 0.498039, mean_q: 0.620486, mean_eps: 0.589764\n",
            " 92114/100000: episode: 138, duration: 94.525s, episode steps: 516, steps per second:   5, episode reward:  8.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.645 [0.000, 5.000],  loss: 0.007389, mae: 0.494739, mean_q: 0.616968, mean_eps: 0.586650\n",
            " 92636/100000: episode: 139, duration: 96.491s, episode steps: 522, steps per second:   5, episode reward:  6.000, mean reward:  0.011 [ 0.000,  1.000], mean action: 2.521 [0.000, 5.000],  loss: 0.007347, mae: 0.500530, mean_q: 0.623504, mean_eps: 0.584315\n",
            " 92959/100000: episode: 140, duration: 59.470s, episode steps: 323, steps per second:   5, episode reward:  4.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.573 [0.000, 5.000],  loss: 0.006926, mae: 0.490797, mean_q: 0.610959, mean_eps: 0.582413\n",
            " 94181/100000: episode: 141, duration: 224.206s, episode steps: 1222, steps per second:   5, episode reward: 15.000, mean reward:  0.012 [ 0.000,  1.000], mean action: 2.469 [0.000, 5.000],  loss: 0.006969, mae: 0.493683, mean_q: 0.614339, mean_eps: 0.578937\n",
            " 94859/100000: episode: 142, duration: 123.790s, episode steps: 678, steps per second:   5, episode reward: 13.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.478 [0.000, 5.000],  loss: 0.006451, mae: 0.494394, mean_q: 0.615784, mean_eps: 0.574662\n",
            " 95379/100000: episode: 143, duration: 95.572s, episode steps: 520, steps per second:   5, episode reward: 10.000, mean reward:  0.019 [ 0.000,  1.000], mean action: 2.400 [0.000, 5.000],  loss: 0.006663, mae: 0.496371, mean_q: 0.617996, mean_eps: 0.571967\n",
            " 95914/100000: episode: 144, duration: 102.339s, episode steps: 535, steps per second:   5, episode reward:  5.000, mean reward:  0.009 [ 0.000,  1.000], mean action: 2.428 [0.000, 5.000],  loss: 0.006438, mae: 0.495004, mean_q: 0.615993, mean_eps: 0.569593\n",
            " 96613/100000: episode: 145, duration: 130.209s, episode steps: 699, steps per second:   5, episode reward: 10.000, mean reward:  0.014 [ 0.000,  1.000], mean action: 2.451 [0.000, 5.000],  loss: 0.006296, mae: 0.495735, mean_q: 0.618172, mean_eps: 0.566816\n",
            " 97191/100000: episode: 146, duration: 108.694s, episode steps: 578, steps per second:   5, episode reward:  9.000, mean reward:  0.016 [ 0.000,  1.000], mean action: 2.394 [0.000, 5.000],  loss: 0.005976, mae: 0.494328, mean_q: 0.615868, mean_eps: 0.563943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dqn.load_weights(\"dqn_weights_100000.h5f\")\n",
        "test_episodes = 10\n",
        "results = dqn.test(env,nb_episodes=test_episodes, visualize=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DizYvdoZTlgs",
        "outputId": "095e8c17-5cd1-48e1-cfce-167c909ddb8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 10 episodes ...\n",
            "Episode 1: reward: 8.000, steps: 381\n",
            "Episode 2: reward: 5.000, steps: 439\n",
            "Episode 3: reward: 9.000, steps: 523\n",
            "Episode 4: reward: 18.000, steps: 894\n",
            "Episode 5: reward: 14.000, steps: 888\n",
            "Episode 6: reward: 12.000, steps: 555\n",
            "Episode 7: reward: 26.000, steps: 1096\n",
            "Episode 8: reward: 4.000, steps: 410\n",
            "Episode 9: reward: 16.000, steps: 778\n",
            "Episode 10: reward: 20.000, steps: 1140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cU6hDN2bV3mq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NAlu8b1Gb2b"
      },
      "source": [
        "## 3. Justificación de los parámetros seleccionados y de los resultados obtenidos"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eduardo"
      ],
      "metadata": {
        "id": "VZgTa3gCvjJp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Edward"
      ],
      "metadata": {
        "id": "u-kRWJD6voEI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Luis"
      ],
      "metadata": {
        "id": "TsfWcIlfvqMR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carlos"
      ],
      "metadata": {
        "id": "5MzLdSpevsRX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANFQiicXK3sO"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}