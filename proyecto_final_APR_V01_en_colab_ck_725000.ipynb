{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNjZFfUQbulDl6bo6ZYYSP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuisIrigoyen/trabajo_final_RL/blob/pruebas_CarlosKong/proyecto_final_APR_V01_en_colab_ck_725000.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0G89Iq2xnT1"
      },
      "outputs": [],
      "source": [
        "# MONTAJE EN GOOGLE DRIVE\n",
        "mount='/content/gdrive'\n",
        "drive_root = mount + \"/My Drive/08_MIAR/actividades/proyecto practico\"\n",
        "\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  IN_COLAB=True\n",
        "except:\n",
        "  IN_COLAB=False\n",
        "\n",
        "import os\n",
        "if IN_COLAB:\n",
        "  print(\"Montando Google Drive en\", mount)\n",
        "  drive.mount(mount)\n",
        "  os.makedirs(drive_root, exist_ok=True)\n",
        "  %cd $drive_root\n",
        "%pwd\n",
        "\n",
        "# INSTALACIÃ“N DE DEPENDENCIAS\n",
        "%pip install gym==0.17.3\n",
        "%pip install git+https://github.com/Kojoley/atari-py.git\n",
        "%pip install keras-rl2==1.0.5\n",
        "%pip install tensorflow==2.12\n",
        "%pip install opencv-python\n",
        "\n",
        "# IMPORTACIONES\n",
        "import numpy as np\n",
        "import gym\n",
        "import cv2\n",
        "#import tensorflow as tf\n",
        "from PIL import Image\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten, Convolution2D, Permute\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.core import Processor\n",
        "from rl.callbacks import FileLogger, ModelIntervalCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ENTORNO\n",
        "env = gym.make('SpaceInvaders-v0')  # Cambia si deseas: 'Breakout-v0'\n",
        "nb_actions = env.action_space.n\n",
        "\n",
        "# PREPROCESAMIENTO\n",
        "class AtariProcessor(Processor):\n",
        "    def process_observation(self, observation):\n",
        "        img = cv2.cvtColor(observation, cv2.COLOR_RGB2GRAY)\n",
        "        img = cv2.resize(img, (84, 84))\n",
        "        return img.astype('uint8')\n",
        "\n",
        "    def process_state_batch(self, batch):\n",
        "        return batch.astype('float32') / 255.0\n",
        "\n",
        "    def process_reward(self, reward):\n",
        "        return np.clip(reward, -1., 1.)"
      ],
      "metadata": {
        "id": "ZOdZHSM3xy2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODELO DQN\n",
        "model = Sequential()\n",
        "model.add(Permute((2, 3, 1), input_shape=(4, 84, 84)))\n",
        "model.add(Convolution2D(32, (8, 8), strides=(4, 4), activation='relu'))\n",
        "model.add(Convolution2D(64, (4, 4), strides=(2, 2), activation='relu'))\n",
        "model.add(Convolution2D(64, (3, 3), strides=(1, 1), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(nb_actions, activation='linear'))\n",
        "\n",
        "# MEMORIA Y POLICY\n",
        "memory = SequentialMemory(limit=100000, window_length=4)\n",
        "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps',\n",
        "                              value_max=1.0, value_min=0.1, value_test=0.05,\n",
        "                              nb_steps=200000)"
      ],
      "metadata": {
        "id": "yjO7g4ygy78G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AGENTE DQN\n",
        "dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory,\n",
        "               nb_steps_warmup=50000, enable_double_dqn=True,\n",
        "               enable_dueling_network=True, dueling_type='avg',\n",
        "               target_model_update=10000, policy=policy,\n",
        "               processor=AtariProcessor())\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "dqn.compile(Adam(lr=0.00025), metrics=['mae'])\n",
        "\n",
        "# CHECKPOINTS Y LOGGING\n",
        "checkpoint_path = drive_root + '/dqn_weights_{step}.h5f'\n",
        "weights_filename = drive_root + '/dqn_final_weights.h5f'\n",
        "\n",
        "callbacks = [\n",
        "    ModelIntervalCheckpoint(checkpoint_path, interval=25000),\n",
        "    FileLogger(drive_root + '/dqn_log.json', interval=10000)\n",
        "]"
      ],
      "metadata": {
        "id": "I2rntCzIy9D8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dqn_weights_100000.h5f\n",
        "#ContinuaciÃ³n al 325000 + 100000 + 100000+100000+100000 = 825000\n",
        "\n",
        "dqn.load_weights(\"dqn_weights_100000.h5f\")\n",
        "# ðŸ”¢ Paso de partida 3\n",
        "starting_step = 100000 #ultimo weight actualizado\n",
        "remaining_steps = 200000 - starting_step\n",
        "\n",
        "\n",
        "# ðŸ§© Callback personalizado para continuar numeraciÃ³n de checkpoints\n",
        "class OffsetModelCheckpoint(ModelIntervalCheckpoint):\n",
        "    def __init__(self, filepath, interval, offset):\n",
        "        super().__init__(filepath, interval)\n",
        "        self.offset = offset\n",
        "\n",
        "    def on_step_end(self, step, logs={}):\n",
        "        # Ajusta el nÃºmero de paso en el nombre del archivo\n",
        "        self.step = step + self.offset\n",
        "        super().on_step_end(step, logs)\n",
        "\n",
        "# ðŸš€ Entrenamiento con pasos continuados desde 100000\n",
        "dqn.fit(env, nb_steps=remaining_steps, visualize=False, verbose=2,\n",
        "        callbacks=[\n",
        "            FileLogger(\"dqn_log_continuacion.json\", interval=10000),\n",
        "            OffsetModelCheckpoint(\"dqn_weights_{step}.h5f\", interval=25000, offset=starting_step)\n",
        "        ])"
      ],
      "metadata": {
        "id": "htRNej0vy8_Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}